{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324448d4-4ab5-4320-ab28-029dc9c49bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb416d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# print(os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68507fdb-8c39-451b-b351-51a348735365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564780bc-7de8-4823-b3eb-99f2b9dd15f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<groq.Groq at 0x10a88ddd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341639de-c0ca-4a76-82d8-cdcfa555b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-3.5-turbo-16k\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": \"is it too late to join the course?\"}]\n",
    "# )\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f6826b-e52f-4ab8-9efe-f6aefc105ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-82f8be87-513e-4696-b86f-3f8c5abdfb73', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Fast language models, also known as efficient language models or accelerated language models, have gained significant importance in recent years due to their ability to process and generate human-like language while being computationally efficient. The importance of fast language models can be attributed to several reasons:\\n\\n1. **Scalability**: Large language models, like BERT and its variants, have achieved state-of-the-art results in various NLP tasks. However, their computational requirements make it challenging to deploy them in real-world applications, especially those requiring fast inference times. Fast language models aim to strike a balance between model performance and computational efficiency, enabling easier deployment in resource-constrained environments.\\n2. **Real-time processing**: Fast language models can process and respond to user input in near-real-time, which is essential in applications like chatbots, voice assistants, and real-time language translation. This allows for more seamless and interactive user experiences.\\n3. **Edge computing**: With the increasing adoption of edge computing, fast language models enable devices with limited compute resources to perform language processing tasks locally, reducing the need for data transmission and latency.\\n4. **IoT and robotics**: Fast language models can be used in IoT devices and robots to enable them to understand and respond to voice commands, enabling automation and control in various settings.\\n5. **Cost-effectiveness**: Fast language models can be trained and deployed on lower-cost hardware, reducing the need for expensive GPU acceleration and cloud computing resources.\\n6. **Versatility**: Fast language models can be applied to various NLP tasks, including text classification, question answering, sentiment analysis, and language translation, making them a versatile tool for many applications.\\n7. **Improved latency**: Fast language models can reduce the latency associated with language processing tasks, enabling faster response times and more responsive user experiences.\\n8. **Enhanced accessibility**: Fast language models can be used to enable language processing for devices or individuals with limited computational resources, improving accessibility and inclusivity.\\n9. **Security**: Fast language models can be used to detect and prevent language-based attacks, such as phishing and spamming, by quickly analyzing and processing language patterns.\\n10. **Future-proofing**: As AI and NLP continue to evolve, fast language models will be essential for handling larger volumes of data and more complex tasks, ensuring that applications and devices are future-proofed for emerging technologies.\\n\\nIn summary, fast language models are critical for various applications that require efficient and scalable language processing capabilities, enabling real-time processing, edge computing, and cost-effective deployment. Their importance will continue to grow as AI and NLP advance and become more ubiquitous in our daily lives.', role='assistant', function_call=None, tool_calls=None))], created=1720064668, model='llama3-8b-8192', object='chat.completion', system_fingerprint='fp_6a6771ae9c', usage=CompletionUsage(completion_tokens=526, prompt_tokens=18, total_tokens=544, completion_time=0.435410047, prompt_time=0.003463365, queue_time=None, total_time=0.438873412), x_groq={'id': 'req_01j1xxfwjkfs78sr6p13f07m72'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7df9a250-9edc-4fc0-ba41-4620bad340b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as efficient language models or accelerated language models, have gained significant importance in recent years due to their ability to process and generate human-like language while being computationally efficient. The importance of fast language models can be attributed to several reasons:\n",
      "\n",
      "1. **Scalability**: Large language models, like BERT and its variants, have achieved state-of-the-art results in various NLP tasks. However, their computational requirements make it challenging to deploy them in real-world applications, especially those requiring fast inference times. Fast language models aim to strike a balance between model performance and computational efficiency, enabling easier deployment in resource-constrained environments.\n",
      "2. **Real-time processing**: Fast language models can process and respond to user input in near-real-time, which is essential in applications like chatbots, voice assistants, and real-time language translation. This allows for more seamless and interactive user experiences.\n",
      "3. **Edge computing**: With the increasing adoption of edge computing, fast language models enable devices with limited compute resources to perform language processing tasks locally, reducing the need for data transmission and latency.\n",
      "4. **IoT and robotics**: Fast language models can be used in IoT devices and robots to enable them to understand and respond to voice commands, enabling automation and control in various settings.\n",
      "5. **Cost-effectiveness**: Fast language models can be trained and deployed on lower-cost hardware, reducing the need for expensive GPU acceleration and cloud computing resources.\n",
      "6. **Versatility**: Fast language models can be applied to various NLP tasks, including text classification, question answering, sentiment analysis, and language translation, making them a versatile tool for many applications.\n",
      "7. **Improved latency**: Fast language models can reduce the latency associated with language processing tasks, enabling faster response times and more responsive user experiences.\n",
      "8. **Enhanced accessibility**: Fast language models can be used to enable language processing for devices or individuals with limited computational resources, improving accessibility and inclusivity.\n",
      "9. **Security**: Fast language models can be used to detect and prevent language-based attacks, such as phishing and spamming, by quickly analyzing and processing language patterns.\n",
      "10. **Future-proofing**: As AI and NLP continue to evolve, fast language models will be essential for handling larger volumes of data and more complex tasks, ensuring that applications and devices are future-proofed for emerging technologies.\n",
      "\n",
      "In summary, fast language models are critical for various applications that require efficient and scalable language processing capabilities, enabling real-time processing, edge computing, and cost-effective deployment. Their importance will continue to grow as AI and NLP advance and become more ubiquitous in our daily lives.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2cfae6c-ada9-419b-81ae-7b23fe1d353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to help you with your question! However, I'm a large language model, I don't have any information about a specific course or its enrollment deadline. Could you please provide more context or clarify which course you're referring to?\n",
      "\n",
      "If you're wondering about a course that you're interested in, I can offer a few suggestions to help you find the answer:\n",
      "\n",
      "1. Check the course webpage or website: Look for the course webpage or website and see if it provides information about the enrollment deadline or late enrollment options.\n",
      "2. Contact the course organizer or instructor: Reach out to the course organizer or instructor directly via email or phone to ask about the enrollment deadline or late enrollment options.\n",
      "3. Check with the institution: If the course is offered by a college, university, or institution, contact their admissions or enrollment office to ask about the deadline or late enrollment options.\n",
      "\n",
      "Remember to always verify the information before taking any action.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Is it too late to join the course?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d7cad-fba2-4ff7-8581-2bee6f914e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
