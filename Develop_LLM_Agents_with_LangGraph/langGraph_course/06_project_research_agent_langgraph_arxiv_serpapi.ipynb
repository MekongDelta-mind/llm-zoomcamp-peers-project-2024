{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0b0939-54f3-4326-896d-33a20ff04f67",
   "metadata": {},
   "source": [
    "# Master Project: Build a Research Agent with LangGraph, GPT-4o, RAG, Pinecone, ArXiv and Google SerpAPI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ca210-c2aa-4b72-90ac-d92fd27b5fcb",
   "metadata": {},
   "source": [
    "## 01 - Extracting Data from ArXiv into a Pandas DataFrame and Saving it as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5590276a-e496-4f19-b8a0-9535e10e30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e085274b-cd17-4681-890b-f5f33f647591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0e6e2fa-7716-41ab-a794-4bcef1fc86f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OPENAI_API_KEY:  ········\n",
      "Enter your LANGCHAIN_API_KEY:  ········\n",
      "Enter your TAVILY_API_KEY:  ········\n",
      "Enter your PINECONE_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OPENAI_API_KEY: \")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LANGCHAIN_API_KEY: \")\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your TAVILY_API_KEY: \")\n",
    "os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your PINECONE_API_KEY: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b00b072b-1da6-4aad-bf44-9524d06e339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-research-agent-langgraph\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4770ed-84db-40b3-959d-34309cf2b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Namespace for ArXiv's Atom-based XML format.\n",
    "ARXIV_NAMESPACE = '{http://www.w3.org/2005/Atom}'\n",
    "\n",
    "def extract_from_arxiv(search_query='cat:cs.AI', max_results=100, json_file_path='files/arxiv_dataset.json'):\n",
    "    \"\"\"\n",
    "    Fetches papers from the ArXiv API based on a search query, saves them as JSON, \n",
    "    and returns a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        search_query (str): The search query for ArXiv (default is 'cat:cs.AI').\n",
    "        max_results (int): The maximum number of results to retrieve (default is 100).\n",
    "        json_file_path (str): File path where JSON data will be saved.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the extracted paper information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the URL for the API request.\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&max_results={max_results}'\n",
    "    \n",
    "    # Send a GET request to the ArXiv API.\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the XML response.\n",
    "    root = ET.fromstring(response.content)\n",
    "    \n",
    "    papers = []\n",
    "    \n",
    "    # Loop through each \"entry\" in the XML, representing a single paper.\n",
    "    for entry in root.findall(f'{ARXIV_NAMESPACE}entry'):\n",
    "        title = entry.find(f'{ARXIV_NAMESPACE}title').text.strip()\n",
    "        summary = entry.find(f'{ARXIV_NAMESPACE}summary').text.strip()\n",
    "\n",
    "        # Get the authors of the paper.\n",
    "        author_elements = entry.findall(f'{ARXIV_NAMESPACE}author')\n",
    "        authors = [author.find(f'{ARXIV_NAMESPACE}name').text for author in author_elements]\n",
    "\n",
    "        # Get the paper's URL.\n",
    "        paper_url = entry.find(f'{ARXIV_NAMESPACE}id').text\n",
    "        arxiv_id = paper_url.split('/')[-1]\n",
    "\n",
    "        # Check for the PDF link.\n",
    "        pdf_link = next((link.attrib['href'] for link in entry.findall(f'{ARXIV_NAMESPACE}link') \n",
    "                         if link.attrib.get('title') == 'pdf'), None)\n",
    "\n",
    "        papers.append({\n",
    "            'title': title,\n",
    "            'summary': summary,\n",
    "            'authors': authors,\n",
    "            'arxiv_id': arxiv_id,\n",
    "            'url': paper_url,\n",
    "            'pdf_link': pdf_link\n",
    "        })\n",
    "    \n",
    "    # Convert list into a pandas DataFrame.\n",
    "    df = pd.DataFrame(papers)\n",
    "    \n",
    "    # Save the DataFrame to a JSON file.\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "        print(f'Data saved to {json_file_path} ...')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57f66c7-2f39-45b0-874b-8cd1c4163123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to files/arxiv_dataset.json ...\n"
     ]
    }
   ],
   "source": [
    "df = extract_from_arxiv(max_results=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e36a434-c0e3-4131-a4c4-f8218907156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = 'files/arxiv_dataset.json'\n",
    "with  open(file_name, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a91f1250-abe6-4373-8e16-505464190e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Induction of First-Order Decision Lists: Resul...</td>\n",
       "      <td>This paper presents a method for inducing logi...</td>\n",
       "      <td>[R. J. Mooney, M. E. Califf]</td>\n",
       "      <td>9506102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9506102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9506102v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Decision-Theoretic Foundations for Causal Reas...</td>\n",
       "      <td>We present a definition of cause and effect in...</td>\n",
       "      <td>[D. Heckerman, R. Shachter]</td>\n",
       "      <td>9512104v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9512104v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9512104v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A Semantics and Complete Algorithm for Subsump...</td>\n",
       "      <td>This paper analyzes the correctness of the sub...</td>\n",
       "      <td>[A. Borgida, P. F. Patel-Schneider]</td>\n",
       "      <td>9406101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9406101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9406101v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Flexibly Instructable Agents</td>\n",
       "      <td>This paper presents an approach to learning fr...</td>\n",
       "      <td>[S. B. Huffman, J. E. Laird]</td>\n",
       "      <td>9511101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9511101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9511101v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>On Planning while Learning</td>\n",
       "      <td>This paper introduces a framework for Planning...</td>\n",
       "      <td>[S. Safra, M. Tennenholtz]</td>\n",
       "      <td>9409101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9409101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9409101v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "31  Induction of First-Order Decision Lists: Resul...   \n",
       "42  Decision-Theoretic Foundations for Causal Reas...   \n",
       "11  A Semantics and Complete Algorithm for Subsump...   \n",
       "38                       Flexibly Instructable Agents   \n",
       "16                         On Planning while Learning   \n",
       "\n",
       "                                              summary  \\\n",
       "31  This paper presents a method for inducing logi...   \n",
       "42  We present a definition of cause and effect in...   \n",
       "11  This paper analyzes the correctness of the sub...   \n",
       "38  This paper presents an approach to learning fr...   \n",
       "16  This paper introduces a framework for Planning...   \n",
       "\n",
       "                                authors   arxiv_id  \\\n",
       "31         [R. J. Mooney, M. E. Califf]  9506102v1   \n",
       "42          [D. Heckerman, R. Shachter]  9512104v1   \n",
       "11  [A. Borgida, P. F. Patel-Schneider]  9406101v1   \n",
       "38         [S. B. Huffman, J. E. Laird]  9511101v1   \n",
       "16           [S. Safra, M. Tennenholtz]  9409101v1   \n",
       "\n",
       "                                  url                           pdf_link  \n",
       "31  http://arxiv.org/abs/cs/9506102v1  http://arxiv.org/pdf/cs/9506102v1  \n",
       "42  http://arxiv.org/abs/cs/9512104v1  http://arxiv.org/pdf/cs/9512104v1  \n",
       "11  http://arxiv.org/abs/cs/9406101v1  http://arxiv.org/pdf/cs/9406101v1  \n",
       "38  http://arxiv.org/abs/cs/9511101v1  http://arxiv.org/pdf/cs/9511101v1  \n",
       "16  http://arxiv.org/abs/cs/9409101v1  http://arxiv.org/pdf/cs/9409101v1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80ea48c6-55cb-4351-9bf8-44a0afedd2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2094d-90a9-4bfc-a8d6-402d0ac3b2d6",
   "metadata": {},
   "source": [
    "## 02 - Downloading the Research Papers (PDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cbe8dbc-ad91-4c2f-9822-e0d611d778aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_pdfs(df, download_folder='files'):\n",
    "    \"\"\"\n",
    "    Downloads PDFs from URLs listed in the DataFrame and saves them to a specified folder. \n",
    "    The file names are stored in a new column 'pdf_file_name' in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a 'pdf_link' column with URLs to download.\n",
    "        download_folder (str): Path to the folder where PDFs will be saved (default is 'files').\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with an additional 'pdf_file_name' column containing \n",
    "                      the paths of the downloaded PDF files or None if the download failed.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    \n",
    "    pdf_file_names = []\n",
    "    \n",
    "    # Loop through each row to download PDFs\n",
    "    for index, row in df.iterrows():\n",
    "        pdf_link = row['pdf_link']\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(pdf_link)\n",
    "            response.raise_for_status()\n",
    "    \n",
    "            file_name = os.path.join(download_folder, pdf_link.split('/')[-1]) + '.pdf'\n",
    "            pdf_file_names.append(file_name)\n",
    "    \n",
    "            # Save the downloaded PDF\n",
    "            with open(file_name, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            print(f'PDF downloaded successfully and saved as {file_name}')\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f'Failed to download the PDF: {e}')\n",
    "            pdf_file_names.append(None)\n",
    "    \n",
    "    df['pdf_file_name'] = pdf_file_names\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f89bcd3-30e0-4f74-a611-debab28a3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded successfully and saved as files/9308101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9308102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9309101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9311101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9311102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9312101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9401101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9402101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9402102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9402103v1.pdf\n",
      "PDF downloaded successfully and saved as files/9403101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9406101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9406102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9408101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9408102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9408103v1.pdf\n",
      "PDF downloaded successfully and saved as files/9409101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9412101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9412102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9412103v1.pdf\n",
      "PDF downloaded successfully and saved as files/9501101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9501102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9501103v1.pdf\n",
      "PDF downloaded successfully and saved as files/9503102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9504101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9505101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9505102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9505103v1.pdf\n",
      "PDF downloaded successfully and saved as files/9505104v1.pdf\n",
      "PDF downloaded successfully and saved as files/9505105v1.pdf\n",
      "PDF downloaded successfully and saved as files/9506101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9506102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9507101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9508101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9508102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9510101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9510102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9510103v1.pdf\n",
      "PDF downloaded successfully and saved as files/9511101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9512101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9512102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9512103v1.pdf\n",
      "PDF downloaded successfully and saved as files/9512104v1.pdf\n",
      "PDF downloaded successfully and saved as files/9512105v1.pdf\n",
      "PDF downloaded successfully and saved as files/9512106v1.pdf\n",
      "PDF downloaded successfully and saved as files/9512107v1.pdf\n",
      "PDF downloaded successfully and saved as files/9601101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9602101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9602102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9603101v1.pdf\n"
     ]
    }
   ],
   "source": [
    "df = download_pdfs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df81e8ed-2338-47d3-8cd8-21b6f41412d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77e13e88-5c2b-469a-84d3-6df8c6f588cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>pdf_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9308101v1</td>\n",
       "      <td>files/9308101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Market-Oriented Programming Environment and ...</td>\n",
       "      <td>Market price systems constitute a well-underst...</td>\n",
       "      <td>[M. P. Wellman]</td>\n",
       "      <td>9308102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9308102v1</td>\n",
       "      <td>files/9308102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Empirical Analysis of Search in GSAT</td>\n",
       "      <td>We describe an extensive study of search in GS...</td>\n",
       "      <td>[I. P. Gent, T. Walsh]</td>\n",
       "      <td>9309101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9309101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9309101v1</td>\n",
       "      <td>files/9309101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Difficulties of Learning Logic Programs wi...</td>\n",
       "      <td>As real logic programmers normally use cut (!)...</td>\n",
       "      <td>[F. Bergadano, D. Gunetti, U. Trinchero]</td>\n",
       "      <td>9311101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9311101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9311101v1</td>\n",
       "      <td>files/9311101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Agents: Completing Patterns and Const...</td>\n",
       "      <td>To support the goal of allowing users to recor...</td>\n",
       "      <td>[J. C. Schlimmer, L. A. Hermens]</td>\n",
       "      <td>9311102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9311102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9311102v1</td>\n",
       "      <td>files/9311102v1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                               Dynamic Backtracking   \n",
       "1  A Market-Oriented Programming Environment and ...   \n",
       "2            An Empirical Analysis of Search in GSAT   \n",
       "3  The Difficulties of Learning Logic Programs wi...   \n",
       "4  Software Agents: Completing Patterns and Const...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Because of their occasional need to return to ...   \n",
       "1  Market price systems constitute a well-underst...   \n",
       "2  We describe an extensive study of search in GS...   \n",
       "3  As real logic programmers normally use cut (!)...   \n",
       "4  To support the goal of allowing users to recor...   \n",
       "\n",
       "                                    authors   arxiv_id  \\\n",
       "0                          [M. L. Ginsberg]  9308101v1   \n",
       "1                           [M. P. Wellman]  9308102v1   \n",
       "2                    [I. P. Gent, T. Walsh]  9309101v1   \n",
       "3  [F. Bergadano, D. Gunetti, U. Trinchero]  9311101v1   \n",
       "4          [J. C. Schlimmer, L. A. Hermens]  9311102v1   \n",
       "\n",
       "                                 url                           pdf_link  \\\n",
       "0  http://arxiv.org/abs/cs/9308101v1  http://arxiv.org/pdf/cs/9308101v1   \n",
       "1  http://arxiv.org/abs/cs/9308102v1  http://arxiv.org/pdf/cs/9308102v1   \n",
       "2  http://arxiv.org/abs/cs/9309101v1  http://arxiv.org/pdf/cs/9309101v1   \n",
       "3  http://arxiv.org/abs/cs/9311101v1  http://arxiv.org/pdf/cs/9311101v1   \n",
       "4  http://arxiv.org/abs/cs/9311102v1  http://arxiv.org/pdf/cs/9311102v1   \n",
       "\n",
       "         pdf_file_name  \n",
       "0  files/9308101v1.pdf  \n",
       "1  files/9308102v1.pdf  \n",
       "2  files/9309101v1.pdf  \n",
       "3  files/9311101v1.pdf  \n",
       "4  files/9311102v1.pdf  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883f623-9c2d-461d-add4-d892252b586d",
   "metadata": {},
   "source": [
    "## 03 - Loading and Splitting PDF Files into Chunks, Expanding the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9250b14-57af-4fc8-880c-d43d2ae6e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_and_chunk_pdf(pdf_file_name, chunk_size=512):\n",
    "    \"\"\"\n",
    "    Loads a PDF file and splits its content into chunks of a specified size.\n",
    "\n",
    "    Args:\n",
    "        file (str): Path to the PDF file to be loaded.\n",
    "        chunk_size (int): The maximum size of each chunk in characters (default is 512).\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of document chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Loading and splitting into chunks: {pdf_file_name}')\n",
    "\n",
    "    # Load the content of the PDF\n",
    "    loader = PyPDFLoader(pdf_file_name)\n",
    "    data = loader.load()\n",
    "\n",
    "    # Split the content into chunks with slight overlap to preserve context\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=64)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2baf6fa1-f919-4a08-8890-9bfb57d660d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_df(df):\n",
    "    \"\"\"\n",
    "    Expands each row in the DataFrame by splitting PDF documents into chunks.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'pdf_file_name', 'arxiv_id', 'title', 'summary', \n",
    "                           'authors', and 'url' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame where each row represents a chunk of the original document, \n",
    "                      with additional metadata such as chunk identifiers and relationships to \n",
    "                      adjacent chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    expanded_rows = []  # List to store expanded rows with chunk information\n",
    "\n",
    "    # Loop through each row in the DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            chunks = load_and_chunk_pdf(row['pdf_file_name'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {row['pdf_file_name']}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Loop over the chunks and construct a new DataFrame row for each\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            prechunk_id = i-1 if i > 0 else ''  # Preceding chunk ID\n",
    "            postchunk_id = i+1 if i < len(chunks) - 1 else ''  # Following chunk ID\n",
    "\n",
    "            expanded_rows.append({\n",
    "                'id': f\"{row['arxiv_id']}#{i}\",  # Unique chunk identifier\n",
    "                'title': row['title'],\n",
    "                'summary': row['summary'],\n",
    "                'authors': row['authors'],\n",
    "                'arxiv_id': row['arxiv_id'],\n",
    "                'url': row['url'],\n",
    "                'chunk': chunk.page_content,  # Text content of the chunk\n",
    "                'prechunk_id': '' if i == 0 else f\"{row['arxiv_id']}#{prechunk_id}\",  # Previous chunk ID\n",
    "                'postchunk_id': '' if i == len(chunks) - 1 else f\"{row['arxiv_id']}#{postchunk_id}\"  # Next chunk ID\n",
    "            })\n",
    "\n",
    "    # Return a new expanded DataFrame\n",
    "    return pd.DataFrame(expanded_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cf91465-6078-45c5-81b1-dc32b17c4782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and splitting into chunks: files/9308101v1.pdf\n",
      "Loading and splitting into chunks: files/9308102v1.pdf\n",
      "Loading and splitting into chunks: files/9309101v1.pdf\n",
      "Loading and splitting into chunks: files/9311101v1.pdf\n",
      "Loading and splitting into chunks: files/9311102v1.pdf\n",
      "Loading and splitting into chunks: files/9312101v1.pdf\n",
      "Loading and splitting into chunks: files/9401101v1.pdf\n",
      "Loading and splitting into chunks: files/9402101v1.pdf\n",
      "Loading and splitting into chunks: files/9402102v1.pdf\n",
      "Loading and splitting into chunks: files/9402103v1.pdf\n",
      "Loading and splitting into chunks: files/9403101v1.pdf\n",
      "Loading and splitting into chunks: files/9406101v1.pdf\n",
      "Loading and splitting into chunks: files/9406102v1.pdf\n",
      "Loading and splitting into chunks: files/9408101v1.pdf\n",
      "Loading and splitting into chunks: files/9408102v1.pdf\n",
      "Loading and splitting into chunks: files/9408103v1.pdf\n",
      "Loading and splitting into chunks: files/9409101v1.pdf\n",
      "Loading and splitting into chunks: files/9412101v1.pdf\n",
      "Loading and splitting into chunks: files/9412102v1.pdf\n",
      "Loading and splitting into chunks: files/9412103v1.pdf\n",
      "Loading and splitting into chunks: files/9501101v1.pdf\n",
      "Loading and splitting into chunks: files/9501102v1.pdf\n",
      "Loading and splitting into chunks: files/9501103v1.pdf\n",
      "Loading and splitting into chunks: files/9503102v1.pdf\n",
      "Loading and splitting into chunks: files/9504101v1.pdf\n",
      "Loading and splitting into chunks: files/9505101v1.pdf\n",
      "Loading and splitting into chunks: files/9505102v1.pdf\n",
      "Loading and splitting into chunks: files/9505103v1.pdf\n",
      "Loading and splitting into chunks: files/9505104v1.pdf\n",
      "Loading and splitting into chunks: files/9505105v1.pdf\n",
      "Loading and splitting into chunks: files/9506101v1.pdf\n",
      "Loading and splitting into chunks: files/9506102v1.pdf\n",
      "Loading and splitting into chunks: files/9507101v1.pdf\n",
      "Loading and splitting into chunks: files/9508101v1.pdf\n",
      "Loading and splitting into chunks: files/9508102v1.pdf\n",
      "Loading and splitting into chunks: files/9510101v1.pdf\n",
      "Loading and splitting into chunks: files/9510102v1.pdf\n",
      "Loading and splitting into chunks: files/9510103v1.pdf\n",
      "Loading and splitting into chunks: files/9511101v1.pdf\n",
      "Loading and splitting into chunks: files/9512101v1.pdf\n",
      "Loading and splitting into chunks: files/9512102v1.pdf\n",
      "Loading and splitting into chunks: files/9512103v1.pdf\n",
      "Loading and splitting into chunks: files/9512104v1.pdf\n",
      "Loading and splitting into chunks: files/9512105v1.pdf\n",
      "Loading and splitting into chunks: files/9512106v1.pdf\n",
      "Loading and splitting into chunks: files/9512107v1.pdf\n",
      "Loading and splitting into chunks: files/9601101v1.pdf\n",
      "Loading and splitting into chunks: files/9602101v1.pdf\n",
      "Loading and splitting into chunks: files/9602102v1.pdf\n",
      "Loading and splitting into chunks: files/9603101v1.pdf\n"
     ]
    }
   ],
   "source": [
    "expanded_df = expand_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9702977e-4fc4-4eb2-a97b-007e60932b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12370, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac953197-5c1c-412f-9d62-e5da74923536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>url</th>\n",
       "      <th>chunk</th>\n",
       "      <th>prechunk_id</th>\n",
       "      <th>postchunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9308101v1#0</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>Journal of Arti/\f",
       "cial In telligence Researc h ...</td>\n",
       "      <td></td>\n",
       "      <td>9308101v1#1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9308101v1#1</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>problem/. In this pap er/, w e presen t a meth...</td>\n",
       "      <td>9308101v1#0</td>\n",
       "      <td>9308101v1#2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9308101v1#2</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>b y earlier approac hes/.\\n/1/. In tro duction...</td>\n",
       "      <td>9308101v1#1</td>\n",
       "      <td>9308101v1#3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9308101v1#3</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>remaining problem in t w o/. W e no w b egin t...</td>\n",
       "      <td>9308101v1#2</td>\n",
       "      <td>9308101v1#4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9308101v1#4</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>there is no p oin t in w asting time completin...</td>\n",
       "      <td>9308101v1#3</td>\n",
       "      <td>9308101v1#5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                 title  \\\n",
       "0  9308101v1#0  Dynamic Backtracking   \n",
       "1  9308101v1#1  Dynamic Backtracking   \n",
       "2  9308101v1#2  Dynamic Backtracking   \n",
       "3  9308101v1#3  Dynamic Backtracking   \n",
       "4  9308101v1#4  Dynamic Backtracking   \n",
       "\n",
       "                                             summary           authors  \\\n",
       "0  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "1  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "2  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "3  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "4  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "\n",
       "    arxiv_id                                url  \\\n",
       "0  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "1  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "2  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "3  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "4  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "\n",
       "                                               chunk  prechunk_id postchunk_id  \n",
       "0  Journal of Arti/\n",
       "cial In telligence Researc h ...               9308101v1#1  \n",
       "1  problem/. In this pap er/, w e presen t a meth...  9308101v1#0  9308101v1#2  \n",
       "2  b y earlier approac hes/.\\n/1/. In tro duction...  9308101v1#1  9308101v1#3  \n",
       "3  remaining problem in t w o/. W e no w b egin t...  9308101v1#2  9308101v1#4  \n",
       "4  there is no p oin t in w asting time completin...  9308101v1#3  9308101v1#5  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00b8c9-c479-46b1-b986-cc98ac66f001",
   "metadata": {},
   "source": [
    "## 04 - Building a Knowledge Base for the RAG System Using Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78760219-7a1f-4e4d-b18c-a3e413ab0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_router.encoders import OpenAIEncoder\n",
    "\n",
    "# Check if 'OPENAI_API_KEY' is set; prompt if not\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY') or getpass('OpenAI API key: ')\n",
    "\n",
    "# Initialize the OpenAIEncoder with a specific model\n",
    "encoder = OpenAIEncoder(name='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bc92651-2c92-4f95-b98e-656b33e2ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder('hello hallo hola salut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fc85db8-28b8-4333-886a-7904aed5b65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = len(encoder('hello hallo hola salut')[0])\n",
    "dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753bd9bc-6e2a-44b6-82f3-563f2c51ce2a",
   "metadata": {},
   "source": [
    "## 05 - Creating a Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9e76cd8-801b-49d3-868c-0763eeb74761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Check if 'PINECONE_API_KEY' is set; prompt if not\n",
    "api_key = os.getenv('PINECONE_API_KEY') or getpass('Pinecone API key: ')\n",
    "\n",
    "# Initialize the Pinecone client\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "# Define the serverless specification for Pinecone (AWS region 'us-east-1')\n",
    "spec = ServerlessSpec(\n",
    "    cloud='aws', \n",
    "    region='us-east-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b0229ec-81fe-4baa-83b9-210c9c5281fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Define the name of the index\n",
    "index_name = 'langgraph-research-agent'\n",
    "\n",
    "# Check if the index exists; create it if it doesn't\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=dims,  # Embedding dimension (1536)\n",
    "        metric='cosine',\n",
    "        spec=spec  # Cloud provider and region specification\n",
    "    )\n",
    "\n",
    "    # Wait until the index is fully initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Add a short delay before checking the stats\n",
    "time.sleep(1)\n",
    "\n",
    "# View the index statistics\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed4fe8-1ada-492a-9819-7a1266d84c77",
   "metadata": {},
   "source": [
    "## 06 - Populating the Knowledge Base and Uploading it to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21ba1754-ce79-4cce-bc42-ee21fd1bdd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>url</th>\n",
       "      <th>chunk</th>\n",
       "      <th>prechunk_id</th>\n",
       "      <th>postchunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9308101v1#0</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>Journal of Arti/\f",
       "cial In telligence Researc h ...</td>\n",
       "      <td></td>\n",
       "      <td>9308101v1#1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9308101v1#1</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>problem/. In this pap er/, w e presen t a meth...</td>\n",
       "      <td>9308101v1#0</td>\n",
       "      <td>9308101v1#2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9308101v1#2</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>b y earlier approac hes/.\\n/1/. In tro duction...</td>\n",
       "      <td>9308101v1#1</td>\n",
       "      <td>9308101v1#3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9308101v1#3</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>remaining problem in t w o/. W e no w b egin t...</td>\n",
       "      <td>9308101v1#2</td>\n",
       "      <td>9308101v1#4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9308101v1#4</td>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>there is no p oin t in w asting time completin...</td>\n",
       "      <td>9308101v1#3</td>\n",
       "      <td>9308101v1#5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                 title  \\\n",
       "0  9308101v1#0  Dynamic Backtracking   \n",
       "1  9308101v1#1  Dynamic Backtracking   \n",
       "2  9308101v1#2  Dynamic Backtracking   \n",
       "3  9308101v1#3  Dynamic Backtracking   \n",
       "4  9308101v1#4  Dynamic Backtracking   \n",
       "\n",
       "                                             summary           authors  \\\n",
       "0  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "1  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "2  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "3  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "4  Because of their occasional need to return to ...  [M. L. Ginsberg]   \n",
       "\n",
       "    arxiv_id                                url  \\\n",
       "0  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "1  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "2  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "3  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "4  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "\n",
       "                                               chunk  prechunk_id postchunk_id  \n",
       "0  Journal of Arti/\n",
       "cial In telligence Researc h ...               9308101v1#1  \n",
       "1  problem/. In this pap er/, w e presen t a meth...  9308101v1#0  9308101v1#2  \n",
       "2  b y earlier approac hes/.\\n/1/. In tro duction...  9308101v1#1  9308101v1#3  \n",
       "3  remaining problem in t w o/. W e no w b egin t...  9308101v1#2  9308101v1#4  \n",
       "4  there is no p oin t in w asting time completin...  9308101v1#3  9308101v1#5  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abfe0435-e4a8-401f-938a-30e27f3e372a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952bafbd39b549fbbb35dc123e6b15fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "data = expanded_df\n",
    "batch_size = 64  # Set batch size\n",
    "\n",
    "# Loop through the data in batches, using tqdm for a progress bar\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i + batch_size)  # Define batch endpoint\n",
    "    batch = data[i:i_end].to_dict(orient='records')  # Slice data into a batch\n",
    "\n",
    "    # Extract metadata for each chunk in the batch\n",
    "    metadata = [{\n",
    "        'arxiv_id': r['arxiv_id'],\n",
    "        'title': r['title'],\n",
    "        'chunk': r['chunk'],\n",
    "    } for r in batch]\n",
    "    \n",
    "    # Generate unique IDs for each chunk\n",
    "    ids = [r['id'] for r in batch]\n",
    "    \n",
    "    # Extract the chunk content\n",
    "    chunks = [r['chunk'] for r in batch]\n",
    "    \n",
    "    # Convert chunks into embeddings\n",
    "    embeds = encoder(chunks)\n",
    "    \n",
    "    # Upload embeddings, IDs, and metadata to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbd0f83a-6565-4cd0-99c1-9081e7853995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 12370}},\n",
       " 'total_vector_count': 12370}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the index statistics.\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976e085-766b-4dd6-aa53-ca549a84b554",
   "metadata": {},
   "source": [
    "## 07 - Implementing the ArXiv Fetch Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc8c4301-85a4-411e-819e-6a08ca8ad853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\">\\n\\n<head>  <title>[1706.03762] Attention Is All You Need</title>\\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n  <link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/static/browse/0.3.4/images/icons/apple-touch-icon.png\">\\n  <link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"/static/browse/0.3.4/images/icons/favicon-32x32.png\">\\n  <link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"/static/browse/0.3.4/images/icons/favicon-16x16.png\">\\n  <link rel=\"manifest\" href=\"/static/browse/0.3.4/images/icons/site.webmanifest\">\\n  <link rel=\"mask-icon\" href=\"/static/browse/0.3.4/images/icons/safari-pinned-tab.svg\" color=\"#5bbad5\">\\n  <meta name=\"msapplication-TileColor\" content=\"#da532c\">\\n  <meta name=\"theme-color\" content=\"#ffffff\">\\n  <link rel=\"stylesheet\" type=\"text/css\" media=\"screen\" href=\"/static/browse/0.3.4/css/arXiv.css?v=20240822\" />\\n  <link rel=\"stylesheet\" type=\"text/css\" media=\"print\" href=\"/static/browse/0.3.4/css/arXiv-print.css?v=20200611\" />\\n  <link rel=\"stylesheet\" type=\"text/css\" media=\"screen\" href=\"/static/browse/0.3.4/css/browse_search.css\" />\\n  <script language=\"javascript\" src=\"/static/browse/0.3.4/js/accordion.js\" /></script>\\n  <link rel=\"canonical\" href=\"https://arxiv.org/abs/1706.03762\"/>\\n  <meta name=\"description\" content=\"Abstract page for arXiv paper 1706.03762: Attention Is All You Need\"><meta property=\"og:type\" content=\"website\" />\\n<meta property=\"og:site_name\" content=\"arXiv.org\" />\\n<meta property=\"og:title\" content=\"Attention Is All You Need\" />\\n<meta property=\"og:url\" content=\"https://arxiv.org/abs/1706.03762v7\" />\\n<meta property=\"og:image\" content=\"/static/browse/0.3.4/images/arxiv-logo-fb.png\" />\\n<meta property=\"og:image:secure_url\" content=\"/static/browse/0.3.4/images/arxiv-logo-fb.png\" />\\n<meta property=\"og:image:width\" content=\"1200\" />\\n<meta property=\"og:image:height\" content=\"700\" />\\n<meta property=\"og:image:alt\" content=\"arXiv logo\"/>\\n<meta property=\"og:description\" content=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\"/>\\n<meta name=\"twitter:site\" content=\"@arxiv\"/>\\n<meta name=\"twitter:card\" content=\"summary\"/>\\n<meta name=\"twitter:title\" content=\"Attention Is All You Need\"/>\\n<meta name=\"twitter:description\" content=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder...\"/>\\n<meta name=\"twitter:image\" content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\"/>\\n<meta name=\"twitter:image:alt\" content=\"arXiv logo\"/>\\n  <link rel=\"stylesheet\" media=\"screen\" type=\"text/css\" href=\"/static/browse/0.3.4/css/tooltip.css\"/><link rel=\"stylesheet\" media=\"screen\" type=\"text/css\" href=\"https://static.arxiv.org/js/bibex-dev/bibex.css?20200709\"/>  <script src=\"/static/browse/0.3.4/js/mathjaxToggle.min.js\" type=\"text/javascript\"></script>  <script src=\"//code.jquery.com/jquery-latest.min.js\" type=\"text/javascript\"></script>\\n  <script src=\"//cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js\" type=\"text/javascript\"></script>\\n  <script src=\"//cdn.jsdelivr.net/npm/dompurify@2.3.5/dist/purify.min.js\"></script>\\n  <script src=\"/static/browse/0.3.4/js/toggle-labs.js?20241022\" type=\"text/javascript\"></script>\\n  <script src=\"/static/browse/0.3.4/js/cite.js\" type=\"text/javascript\"></script><meta name=\"citation_title\" content=\"Attention Is All You Need\" /><meta name=\"citation_author\" content=\"Vaswani, Ashish\" /><meta name=\"citation_author\" content=\"Shazeer, Noam\" /><meta name=\"citation_author\" content=\"Parmar, Niki\" /><meta name=\"citation_author\" content=\"Uszkoreit, Jakob\" /><meta name=\"citation_author\" content=\"Jones, Llion\" /><meta name=\"citation_author\" content=\"Gomez, Aidan N.\" /><meta name=\"citation_author\" content=\"Kaiser, Lukasz\" /><meta name=\"citation_author\" content=\"Polosukhin, Illia\" /><meta name=\"citation_date\" content=\"2017/06/12\" /><meta name=\"citation_online_date\" content=\"2023/08/02\" /><meta name=\"citation_pdf_url\" content=\"http://arxiv.org/pdf/1706.03762\" /><meta name=\"citation_arxiv_id\" content=\"1706.03762\" /><meta name=\"citation_abstract\" content=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\" />\\n</head>\\n\\n<body  class=\"with-cu-identity\">\\n  \\n  <div class=\"flex-wrap-footer\">\\n    <header>\\n      <a href=\"#content\" class=\"is-sr-only\">Skip to main content</a>\\n      <!-- start desktop header -->\\n      <div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\\n        <div class=\"column\" id=\"cu-logo\">\\n          <a href=\"https://www.cornell.edu/\"><img src=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\" alt=\"Cornell University\" /></a>\\n        </div><div class=\"column\" id=\"support-ack\">\\n          <span id=\"support-ack-url\">We gratefully acknowledge support from the Simons Foundation, <a href=\"https://info.arxiv.org/about/ourmembers.html\">member institutions</a>, and all contributors.</span>\\n          <a href=\"https://info.arxiv.org/about/donate.html\" class=\"btn-header-donate\">Donate</a>\\n        </div>\\n      </div>\\n\\n      <div id=\"header\" class=\"is-hidden-mobile\">\\n<a aria-hidden=\"true\" tabindex=\"-1\" href=\"/IgnoreMe\"></a>\\n  <div class=\"header-breadcrumbs is-hidden-mobile\">\\n    <a href=\"/\"><img src=\"/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg\" alt=\"arxiv logo\" style=\"height:40px;\"/></a> <span>&gt;</span> <a href=\"/list/cs/recent\">cs</a> <span>&gt;</span> arXiv:1706.03762\\n  </div>\\n          <div class=\"search-block level-right\">\\n    <form class=\"level-item mini-search\" method=\"GET\" action=\"https://arxiv.org/search\">\\n      <div class=\"field has-addons\">\\n        <div class=\"control\">\\n          <input class=\"input is-small\" type=\"text\" name=\"query\" placeholder=\"Search...\" aria-label=\"Search term or terms\" />\\n          <p class=\"help\"><a href=\"https://info.arxiv.org/help\">Help</a> | <a href=\"https://arxiv.org/search/advanced\">Advanced Search</a></p>\\n        </div>\\n        <div class=\"control\">\\n          <div class=\"select is-small\">\\n            <select name=\"searchtype\" aria-label=\"Field to search\">\\n              <option value=\"all\" selected=\"selected\">All fields</option>\\n              <option value=\"title\">Title</option>\\n              <option value=\"author\">Author</option>\\n              <option value=\"abstract\">Abstract</option>\\n              <option value=\"comments\">Comments</option>\\n              <option value=\"journal_ref\">Journal reference</option>\\n              <option value=\"acm_class\">ACM classification</option>\\n              <option value=\"msc_class\">MSC classification</option>\\n              <option value=\"report_num\">Report number</option>\\n              <option value=\"paper_id\">arXiv identifier</option>\\n              <option value=\"doi\">DOI</option>\\n              <option value=\"orcid\">ORCID</option>\\n              <option value=\"author_id\">arXiv author ID</option>\\n              <option value=\"help\">Help pages</option>\\n              <option value=\"full_text\">Full text</option>\\n            </select>\\n          </div>\\n        </div>\\n        <input type=\"hidden\" name=\"source\" value=\"header\">\\n        <button class=\"button is-small is-cul-darker\">Search</button>\\n      </div>\\n    </form>\\n  </div>\\n     </div><!-- /end desktop header -->\\n\\n      <div class=\"mobile-header\">\\n        <div class=\"columns is-mobile\">\\n          <div class=\"column logo-arxiv\"><a href=\"https://arxiv.org/\"><img src=\"/static/browse/0.3.4/images/arxiv-logomark-small-white.svg\" alt=\"arXiv logo\" style=\"height:60px;\" /></a></div>\\n          <div class=\"column logo-cornell\"><a href=\"https://www.cornell.edu/\">\\n            <picture>\\n              <source media=\"(min-width: 501px)\"\\n                srcset=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg  400w\"\\n                sizes=\"400w\" />\\n              <source srcset=\"/static/browse/0.3.4/images/icons/cu/cornell_seal_simple_black.svg 2x\" />\\n              <img src=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\" alt=\"Cornell University Logo\" />\\n            </picture>\\n          </a></div>\\n          <div class=\"column nav\" id=\"toggle-container\" role=\"menubar\">\\n            <button class=\"toggle-control\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-white\"><title>open search</title><path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\"/></svg></button>\\n            <div class=\"mobile-toggle-block toggle-target\">\\n              <form class=\"mobile-search-form\" method=\"GET\" action=\"https://arxiv.org/search\">\\n                <div class=\"field has-addons\">\\n                  <input class=\"input\" type=\"text\" name=\"query\" placeholder=\"Search...\" aria-label=\"Search term or terms\" />\\n                  <input type=\"hidden\" name=\"source\" value=\"header\">\\n                  <input type=\"hidden\" name=\"searchtype\" value=\"all\">\\n                  <button class=\"button\">GO</button>\\n                </div>\\n              </form>\\n            </div>\\n\\n            <button class=\"toggle-control\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\" class=\"icon filter-white\" role=\"menu\"><title>open navigation menu</title><path d=\"M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z\"/ ></svg></button>\\n            <div class=\"mobile-toggle-block toggle-target\">\\n              <nav class=\"mobile-menu\" aria-labelledby=\"mobilemenulabel\">\\n                <h2 id=\"mobilemenulabel\">quick links</h2>\\n                <ul>\\n                    <li><a href=\"https://arxiv.org/login\">Login</a></li>\\n                    <li><a href=\"https://info.arxiv.org/help\">Help Pages</a></li>\\n                    <li><a href=\"https://info.arxiv.org/about\">About</a></li>\\n                </ul>\\n              </nav>\\n            </div>\\n          </div>\\n        </div>\\n      </div><!-- /end mobile-header -->\\n    </header>\\n\\n    <main>\\n      <div id=\"content\">\\n<!--\\nrdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n         xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\\n         xmlns:trackback=\"http://madskills.com/public/xml/rss/module/trackback/\">\\n    <rdf:Description\\n        rdf:about=\"/abs/1706.03762\"\\n        dc:identifier=\"/abs/1706.03762\"\\n        dc:title=\"Attention Is All You Need\"\\n        trackback:ping=\"/trackback/1706.03762\" />\\n    </rdf:RDF>\\n--><div id=\"abs-outer\">\\n\\n  <div class=\"leftcolumn\">\\n    <div class=\"subheader\">\\n      <h1>Computer Science > Computation and Language</h1>\\n    </div>\\n\\n    <div class=\"header-breadcrumbs-mobile\">\\n      <strong>arXiv:1706.03762</strong> (cs)\\n    </div>\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/static/base/1.0.1/css/abs.css\">\\n<div id=\"content-inner\">\\n  <div id=\"abs\">\\n    <div class=\"dateline\">\\n  [Submitted on 12 Jun 2017 (<a href=\"https://arxiv.org/abs/1706.03762v1\">v1</a>), last revised 2 Aug 2023 (this version, v7)]</div>\\n    <h1 class=\"title mathjax\"><span class=\"descriptor\">Title:</span>Attention Is All You Need</h1>\\n    <div class=\"authors\"><span class=\"descriptor\">Authors:</span><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vaswani,+A\" rel=\"nofollow\">Ashish Vaswani</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shazeer,+N\" rel=\"nofollow\">Noam Shazeer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Parmar,+N\" rel=\"nofollow\">Niki Parmar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Uszkoreit,+J\" rel=\"nofollow\">Jakob Uszkoreit</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jones,+L\" rel=\"nofollow\">Llion Jones</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gomez,+A+N\" rel=\"nofollow\">Aidan N. Gomez</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kaiser,+L\" rel=\"nofollow\">Lukasz Kaiser</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Polosukhin,+I\" rel=\"nofollow\">Illia Polosukhin</a></div>            <div id=\"download-button-info\" hidden>View a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors</div>\\n    <a class=\"mobile-submission-download\" href=\"/pdf/1706.03762\">View PDF</a>\\n    <a class=\"mobile-submission-download\" href=\"https://arxiv.org/html/1706.03762v7\">HTML (experimental)</a>\\n\\n\\n\\n    <blockquote class=\"abstract mathjax\">\\n            <span class=\"descriptor\">Abstract:</span>The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\\n    </blockquote>\\n\\n    <!--CONTEXT-->\\n    <div class=\"metatable\">\\n      <table summary=\"Additional metadata\">        <tr>\\n          <td class=\"tablecell label\">Comments:</td>\\n          <td class=\"tablecell comments mathjax\">15 pages, 5 figures</td>\\n        </tr>\\n<tr>\\n          <td class=\"tablecell label\">Subjects:</td>\\n          <td class=\"tablecell subjects\">\\n            <span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)</td>\\n        </tr><tr>\\n          <td class=\"tablecell label\">Cite as:</td>\\n          <td class=\"tablecell arxivid\"><span class=\"arxivid\"><a href=\"https://arxiv.org/abs/1706.03762\">arXiv:1706.03762</a> [cs.CL]</span></td>\\n        </tr>\\n        <tr>\\n          <td class=\"tablecell label\">&nbsp;</td>\\n          <td class=\"tablecell arxividv\">(or <span class=\"arxivid\">\\n              <a href=\"https://arxiv.org/abs/1706.03762v7\">arXiv:1706.03762v7</a> [cs.CL]</span> for this version)\\n          </td>\\n        </tr>\\n        <tr>\\n          <td class=\"tablecell label\">&nbsp;</td>\\n          <td class=\"tablecell arxivdoi\">              <a href=\"https://doi.org/10.48550/arXiv.1706.03762\"  id=\"arxiv-doi-link\">https://doi.org/10.48550/arXiv.1706.03762</a><div class=\"button-and-tooltip\">\\n              <button class=\"more-info\" aria-describedby=\"more-info-desc-1\">\\n                <svg height=\"15\" role=\"presentation\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><path fill=\"currentColor\" d=\"M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z\" class=\"\"></path></svg>\\n                <span class=\"visually-hidden\">Focus to learn more</span>\\n              </button>\\n              <!-- tooltip description -->\\n              <div role=\"tooltip\" id=\"more-info-desc-1\">\\n                <span class=\"left-corner\"></span>                  arXiv-issued DOI via DataCite</div>\\n            </div>\\n          </td>\\n        </tr></table>\\n    </div>\\n  </div>\\n</div>\\n    <div class=\"submission-history\">\\n      <h2>Submission history</h2> From: Llion Jones [<a href=\"/show-email/f53b7360/1706.03762\" rel=\"nofollow\">view email</a>]      <br/>            <strong><a href=\"/abs/1706.03762v1\" rel=\"nofollow\">[v1]</a></strong>\\n        Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v2\" rel=\"nofollow\">[v2]</a></strong>\\n        Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v3\" rel=\"nofollow\">[v3]</a></strong>\\n        Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v4\" rel=\"nofollow\">[v4]</a></strong>\\n        Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v5\" rel=\"nofollow\">[v5]</a></strong>\\n        Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v6\" rel=\"nofollow\">[v6]</a></strong>\\n        Mon, 24 Jul 2023 00:48:54 UTC (1,124 KB)<br/>\\n    <strong>[v7]</strong>\\n        Wed, 2 Aug 2023 00:41:18 UTC (1,124 KB)<br/>\\n</div>\\n  </div>\\n  <!--end leftcolumn-->\\n<div class=\"extra-services\">    <div class=\"full-text\">\\n      <a name=\"other\"></a>\\n      <span class=\"descriptor\">Full-text links:</span>\\n      <h2>Access Paper:</h2>\\n      <ul>\\n  <div id=\"download-button-info\" hidden>\\nView a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors</div><li><a href=\"/pdf/1706.03762\" aria-describedby=\"download-button-info\" accesskey=\"f\" class=\"abs-button download-pdf\">View PDF</a></li><li><a href=\"https://arxiv.org/html/1706.03762v7\" class=\"abs-button\" id=\"latexml-download-link\">HTML (experimental)</a></li><li><a href=\"/src/1706.03762\" class=\"abs-button download-eprint\">TeX Source</a></li><li><a href=\"/format/1706.03762\" class=\"abs-button download-format\">Other Formats</a></li></ul>\\n      <div class=\"abs-license\"><a href=\"http://arxiv.org/licenses/nonexclusive-distrib/1.0/\" title=\"Rights to this article\">view license</a></div>\\n    </div>\\n    <!--end full-text-->    <div class=\"browse\">\\n    Current browse context: <div class=\"current\">cs.CL</div>\\n\\n  <div class=\"prevnext\">\\n<span class=\"arrow\">\\n      <a class=\"abs-button prev-url\" href=\"/prevnext?id=1706.03762&amp;function=prev&amp;context=cs.CL\"\\n         accesskey=\"p\" title=\"previous in cs.CL (accesskey p)\" rel=\"nofollow\">&lt;&nbsp;prev</a>\\n    </span>\\n    <span class=\"is-hidden-mobile\">&nbsp; | &nbsp;</span>    <span class=\"arrow\">\\n      <a class=\"abs-button next-url\" href=\"/prevnext?id=1706.03762&amp;function=next&amp;context=cs.CL\" accesskey=\"n\"\\n         title=\"next in cs.CL (accesskey n)\"  rel=\"nofollow\">next&nbsp;&gt;</a>\\n    </span><br/>\\n  </div><div class=\"list\">\\n    <a class=\"abs-button abs-button-grey abs-button-small context-new\" href=\"/list/cs.CL/new\"  rel=\"nofollow\">new</a>\\n    <span class=\"is-hidden-mobile\"> | </span>\\n    <a class=\"abs-button abs-button-grey abs-button-small context-recent\" href=\"/list/cs.CL/recent\" rel=\"nofollow\">recent</a>\\n    <span class=\"is-hidden-mobile\"> | </span><a class=\"abs-button abs-button-grey abs-button-small context-id\" href=\"/list/cs.CL/2017-06\" rel=\"nofollow\">2017-06</a>\\n  </div><div class=\"abs-switch-cat\">\\n    Change to browse by:\\n    <div class=\"switch context-change\">\\n        <a href=\"/abs/1706.03762?context=cs\" rel=\"nofollow\">cs</a><br class=\"is-hidden-mobile\">\\n        <a class=\"subclass\" href=\"/abs/1706.03762?context=cs.LG\" rel=\"nofollow\">cs.LG</a><br class=\"is-hidden-mobile\">\\n    </div>\\n  </div>\\n\\n    </div>\\n      <div class=\"extra-ref-cite\">\\n        <h3>References &amp; Citations</h3>\\n        <ul>\\n          <li><a  class=\"abs-button abs-button-small cite-ads\" href=\"https://ui.adsabs.harvard.edu/abs/arXiv:1706.03762\">NASA ADS</a></li><li><a  class=\"abs-button abs-button-small cite-google-scholar\" href=\"https://scholar.google.com/scholar_lookup?arxiv_id=1706.03762\" target=\"_blank\" rel=\"noopener\">Google Scholar</a></li>\\n          <li><a  class=\"abs-button abs-button-small cite-semantic-scholar\" href=\"https://api.semanticscholar.org/arXiv:1706.03762\" target=\"_blank\" rel=\"noopener\">Semantic Scholar</a></li>\\n        </ul>\\n        <div style=\"clear:both;\"></div>\\n      </div>\\n\\n    <div class=\"extra-general\">\\n        <div class=\"what-is-this\">\\n            <h3><a  class=\"abs-button abs-button-grey abs-button-small trackback-link\" href=\"/tb/1706.03762\"> 123 blog links</a></h3> (<a href=\"https://info.arxiv.org/help/trackback.html\" class=\"trackback-help\">what is this?</a>)\\n        </div>\\n    </div>\\n<div class=\"dblp\">\\n    <h3><a href=\"https://dblp.uni-trier.de\">DBLP</a> - CS Bibliography</h3>\\n    <div class=\"list\">\\n      <a href=\"https://dblp.uni-trier.de/db/journals/corr/corr1706.html#VaswaniSPUJGKP17\" title=\"listing on DBLP\">listing</a> | <a href=\"https://dblp.uni-trier.de/rec/bibtex/journals/corr/VaswaniSPUJGKP17\" title=\"DBLP bibtex record\">bibtex</a>    </div>\\n    <div class=\"list\">\\n<a href=\"https://dblp.uni-trier.de/search/author?author=Ashish%20Vaswani\" title=\"DBLP author search\">Ashish Vaswani</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Noam%20Shazeer\" title=\"DBLP author search\">Noam Shazeer</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Niki%20Parmar\" title=\"DBLP author search\">Niki Parmar</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Jakob%20Uszkoreit\" title=\"DBLP author search\">Jakob Uszkoreit</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Llion%20Jones\" title=\"DBLP author search\">Llion Jones</a>      <div class=\"list\">&hellip;</div>\\n    </div>\\n  </div><div class=\\'extra-ref-cite\\'>\\n    <a id=\\'bib-cite-css\\' hidden=\\'true\\' href=\\'/static/browse/0.3.4/css/cite.css\\'>a</a>\\n\\n    <span id=\\'bib-cite-trigger\\' class=\"bib-cite-button abs-button\">export BibTeX citation</span>\\n    <span id=\\'bib-cite-loading\\' hidden=\\'true\\'>Loading...</span>\\n</div>\\n\\n<div id=\\'bib-cite-modal\\' class=\\'bib-modal\\' hidden=\\'true\\'>\\n    <div class=\\'bib-modal-content\\'>\\n        <div class=\\'bib-modal-title\\'>\\n            <h2>BibTeX formatted citation</h2>\\n            <span class=\\'bib-modal-close\\' >&times;</span>\\n        </div>\\n        <div>\\n            <textarea id=\\'bib-cite-target\\' class=\"bib-citation-content\" aria-label=\"loading the citation\">loading...</textarea>\\n        </div>\\n        <div>\\n            <span>Data provided by: </span>\\n            <a id=\\'bib-cite-source-api\\'></a>\\n        </div>\\n    </div>\\n</div><div class=\"bookmarks\">\\n  <div><h3>Bookmark</h3></div><a class=\"abs-button abs-button-grey abs-button-small\" href=\"http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/1706.03762&amp;description=Attention Is All You Need\"\\n     title=\"Bookmark on BibSonomy\">\\n    <img src=\"/static/browse/0.3.4/images/icons/social/bibsonomy.png\"\\n         alt=\"BibSonomy logo\"/>\\n  </a>\\n  <a class=\"abs-button abs-button-grey abs-button-small\" href=\"https://reddit.com/submit?url=https://arxiv.org/abs/1706.03762&amp;title=Attention Is All You Need\"\\n     title=\"Bookmark on Reddit\">\\n    <img src=\"/static/browse/0.3.4/images/icons/social/reddit.png\"\\n         alt=\"Reddit logo\"/>\\n  </a>\\n</div>  </div>\\n  <!--end extra-services-->\\n<!-- LABS AREA -->\\n<div id=\"labstabs\">\\n  <div class=\"labstabs\"><input type=\"radio\" name=\"tabs\" id=\"tabone\"checked=\"checked\">\\n    <label for=\"tabone\">Bibliographic Tools</label>\\n    <div class=\"tab labs-display-bib\">\\n      <h1>Bibliographic and Citation Tools</h1>\\n      <div class=\"toggle\">\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input id=\"bibex-toggle\" type=\"checkbox\" class=\"lab-toggle\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Bibliographic Explorer Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-bibex\">Bibliographic Explorer</span> <em>(<a href=\"https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer\">What is the Explorer?</a>)</em>\\n          </div>\\n        </div>\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"connectedpapers-toggle\"\\n                type=\"checkbox\"\\n                class=\"lab-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/connectedpapers.js\"\\n                aria-labelledby=\"label-for-connected-papers\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Connected Papers Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-connected-papers\">Connected Papers</span> <em>(<a href=\"https://www.connectedpapers.com/about\" target=\"_blank\">What is Connected Papers?</a>)</em>\\n          </div>\\n        </div><div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"litmaps-toggle\"\\n                type=\"checkbox\"\\n                class=\"lab-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/litmaps.js?20210617\"\\n                aria-labelledby=\"label-for-litmaps\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Litmaps Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-litmaps\">Litmaps</span> <em>(<a href=\"https://www.litmaps.co/\" target=\"_blank\">What is Litmaps?</a>)</em>\\n          </div>\\n        </div>\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"scite-toggle\"\\n                type=\"checkbox\"\\n                class=\"lab-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/scite.js?20210617\"\\n                aria-labelledby=\"label-for-scite\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">scite.ai Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-scite\">scite Smart Citations</span> <em>(<a href=\"https://www.scite.ai/\" target=\"_blank\">What are Smart Citations?</a>)</em>\\n          </div>\\n        </div>\\n      </div>\\n        <div class=\"labs-content-placeholder labs-display\" style=\"display: none;\"></div>\\n        <div style=\"min-height: 15px\" id=\"connectedpapers-output\"></div>\\n        <div style=\"min-height: 15px\" id=\"litmaps-open-in\"></div>\\n        <div style=\"min-height: 15px\" id=\"scite-open-in\"></div>\\n    </div>\\n\\n\\n    <input type=\"radio\" name=\"tabs\" id=\"tabtwo\">\\n    <label for=\"tabtwo\">Code, Data, Media</label>\\n    <div class=\"tab\">\\n      <h1>Code, Data and Media Associated with this Article</h1>\\n      <div class=\"toggle\">\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"alphaxiv-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/alphaxiv.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-alphaxiv\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">alphaXiv Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-alphaxiv\">alphaXiv</span> <em>(<a href=\"https://alphaxiv.org/\" target=\"_blank\">What is alphaXiv?</a>)</em>\\n          </div>\\n        </div>\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input        \\n                id=\"catalyzex-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/catalyzex.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-cx\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Links to Code Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-cx\">CatalyzeX Code Finder for Papers</span> <em>(<a href=\"https://www.catalyzex.com\" target=\"_blank\">What is CatalyzeX?</a>)</em>\\n          </div>\\n        </div>\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"dagshub-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/dagshub.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-dagshub\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">DagsHub Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-dagshub\">DagsHub</span> <em>(<a href=\"https://dagshub.com/\" target=\"_blank\">What is DagsHub?</a>)</em>\\n          </div>\\n        </div>\\n  \\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"gotitpub-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/gotitpub.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-gotitpub\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">GotitPub Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-gotitpub\">Gotit.pub</span> <em>(<a href=\"http://gotit.pub/faq\" target=\"_blank\">What is GotitPub?</a>)</em>\\n          </div>\\n        </div>\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"huggingface-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/huggingface.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-huggingface\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Huggingface Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-huggingface\">Hugging Face</span> <em>(<a href=\"https://huggingface.co/huggingface\" target=\"_blank\">What is Huggingface?</a>)</em>\\n          </div>\\n        </div>\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"paperwithcode-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/paperswithcode.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-pwc\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Links to Code Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-pwc\">Papers with Code</span> <em>(<a href=\"https://paperswithcode.com/\" target=\"_blank\">What is Papers with Code?</a>)</em>\\n          </div>\\n        </div>\\n\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"sciencecast-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/sciencecast.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-sciencecast\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">ScienceCast Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-sciencecast\">ScienceCast</span> <em>(<a href=\"https://sciencecast.org/welcome\" target=\"_blank\">What is ScienceCast?</a>)</em>\\n          </div>\\n        </div>\\n      </div>\\n\\n      <div id=\"alphaxiv-output\" style=\"display:none\"></div>\\n      <div id=\"catalyzex-output\" style=\"display:none\"></div>\\n      <div id=\"dagshub-output\" style=\"display:none\"></div>\\n      <div id=\"gotitpub-output\" style=\"display:none\"></div>\\n      <div id=\"pwc-output\" style=\"display:none\"></div>\\n      <div id=\"pwc-data-output\" style=\"display:none\"></div>\\n      <div id=\"sciencecast-output\" style=\"display:none\"></div>\\n      <div id=\"huggingface-output\" style=\"display:none\"></div>\\n    </div>\\n\\n\\n      <input type=\"radio\" name=\"tabs\" id=\"labstabs-demos-input\">\\n      <label for=\"labstabs-demos-input\" id=\"labstabs-demos-label\">Demos</label>\\n      <div class=\"tab\">\\n        <h1>Demos</h1>\\n        <div class=\"toggle\">\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input\\n                  id=\"replicate-toggle\"\\n                  data-script-url=\"/static/browse/0.3.4/js/replicate.js\"\\n                  type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-replicate\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Replicate Toggle</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-replicate\">Replicate</span> <em>(<a href=\"https://replicate.com/docs/arxiv/about\" target=\"_blank\">What is Replicate?</a>)</em>\\n            </div>\\n          </div>\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input\\n                  id=\"spaces-toggle\"\\n                  data-script-url=\"/static/browse/0.3.4/js/spaces.js\"\\n                  type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-spaces\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Spaces Toggle</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-spaces\">Hugging Face Spaces</span> <em>(<a href=\"https://huggingface.co/docs/hub/spaces\" target=\"_blank\">What is Spaces?</a>)</em>\\n            </div>\\n          </div>\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input\\n                  id=\"txyz-toggle\"\\n                  data-script-url=\"/static/browse/0.3.4/js/txyz.js\"\\n                  type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-txyz\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Spaces Toggle</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-txyz\">TXYZ.AI</span> <em>(<a href=\"https://txyz.ai\" target=\"_blank\">What is TXYZ.AI?</a>)</em>\\n            </div>\\n          </div>\\n        </div>\\n        <div id=\"replicate-output\"></div>\\n        <div id=\"spaces-output\"></div>\\n        <div id=\"txyz-output\"></div>\\n      </div>\\n      <input type=\"radio\" name=\"tabs\" id=\"tabfour\">\\n      <label for=\"tabfour\">Related Papers</label>\\n      <div class=\"tab\">\\n        <h1>Recommenders and Search Tools</h1>\\n        <div class=\"toggle\">\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input id=\"influenceflower-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/influenceflower.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-influenceflower\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Link to Influence Flower</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-influenceflower\">Influence Flower</span> <em>(<a href=\"https://influencemap.cmlab.dev/\" target=\"_blank\">What are Influence Flowers?</a>)</em>\\n            </div>\\n          </div>\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input id=\"core-recommender-toggle\" type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-core\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Core recommender toggle</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-core\">CORE Recommender</span> <em>(<a href=\"https://core.ac.uk/services/recommender\">What is CORE?</a>)</em>\\n            </div>\\n          </div></div>\\n        <div id=\"influenceflower-output\"></div>\\n        <div id=\"influenceflower-output-graph\" style=\"display:none\">\\n          <ul class=\"flower-tabs\">\\n            <li class=\"active\"><a class=\"btn tab-btn\" onclick=\"openTab(event, \\'tab-author\\')\">Author</a></li>\\n            <li><a class=\"btn tab-btn\" onclick=\"openTab(event, \\'tab-venue\\')\">Venue</a></li>\\n            <li><a class=\"btn tab-btn\" onclick=\"openTab(event, \\'tab-inst\\')\">Institution</a></li>\\n            <li><a class=\"btn tab-btn\" onclick=\"openTab(event, \\'tab-topic\\')\">Topic</a></li>\\n          </ul>\\n          <div class=\"flower-tab-content\">\\n            <div class=\"tab-flower active\" id=\"tab-author\"><svg id=\"flower-graph-author\"></svg></div>\\n            <div class=\"tab-flower\" id=\"tab-venue\"><svg id=\"flower-graph-venue\"></svg></div>\\n            <div class=\"tab-flower\" id=\"tab-inst\"><svg id=\"flower-graph-inst\"></svg></div>\\n            <div class=\"tab-flower\" id=\"tab-topic\"><svg id=\"flower-graph-topic\"></svg></div>\\n          </div>\\n        </div>\\n        <div id=\"coreRecommenderOutput\"></div>\\n        <div id=\"iarxivOutput\"></div>\\n      </div>\\n\\n      <input type=\"radio\" name=\"tabs\" id=\"tabfive\">\\n      <label for=\"tabfive\">\\n        About arXivLabs\\n      </label>\\n      <div class=\"tab\">\\n        <div class=\"columns\">\\n          <div class=\"column\">\\n            <h1>arXivLabs: experimental projects with community collaborators</h1>\\n            <p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>\\n            <p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>\\n            <p>Have an idea for a project that will add value for arXiv\\'s community? <a href=\"https://info.arxiv.org/labs/index.html\"><strong>Learn more about arXivLabs</strong></a>.</p>\\n          </div>\\n          <div class=\"column is-narrow is-full-mobile\">\\n            <p class=\"icon-labs\"><svg xmlns=\"http://www.w3.org/2000/svg\" role=\"presentation\" viewBox=\"0 0 635.572 811\"><path d=\"M175.6 676v27h-27v-27zm-54 27v27h27v-27zm-27 27v27h27v-27zm396-54v27h-27v-27zm0 27v27h27v-27zm27 27v27h27v-27zm-27-414h27v27h-27zm27 0h27v-27h-27zm27-27h27v-27h-27zm-396 45h-27v-27h27zm-27-54h-27v27h27zm-27-27h-27v27h27z\"/><path d=\"M94.6 730v27h-27v-27zm477 0v27h-27v-27zm-27-495h27v27h-27zm-450 18h-27v-27h27zm477 9h27v27h-27zm-54 495h27v27h-27zm-423 0h27v27h-27zm-54-504h27v27h-27z\" fill=\"#666\"/><path d=\"M67.6 730v27h-27v-27zm54 54v27h-27v-27zm0-108v27h27v-27zm-27 27v27h27v-27zm-81 0v27h27v-27zm585 27v27h-27v-27zm-108-54v27h27v-27zm27 27v27h27v-27zm81 0v27h27v-27zm-54-495h27v27h-27zm-54 108h27v-27h-27zm27-27h27v-27h-27zm0-81h27v-27h-27zm-423 18h-27v-27h27zm54 54h-27v27h27zm-27-27h-27v27h27zm0-81h-27v27h27zm423 612v27h-27v-27zm81-522v27h-27v-27zm-585-9v27h-27v-27z\" fill=\"#999\"/><path d=\"M94.6 784v27h-27v-27zm-27-27v27h27v-27zm-27-54v27h27v-27zm27 0v27h27v-27zm0-27v27h27v-27zm27 0v27h27v-27zm0-27v27h27v-27zm27 0v27h27v-27zm-108 81v27h27v-27zm558 54v27h-27v-27zm-27-27v27h27v-27zm27-54v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm108 81v27h27v-27zm0-495h27v27h-27zm-27 27h27v-27h-27zm-54-27h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm81-108h27v-27h-27zm-504 45h-27v-27h27zm27-27h-27v27h27zm54-27h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm-81-108h-27v27h27z\" fill=\"#ccc\"/><path d=\"M598.6 665.1H41.5C-76.5 667 176 280.2 176 280.2h53a46.5 46.5 0 0162.8-56.3 29.2 29.2 0 1128.5 35.9h-1a46.5 46.5 0 01-1.5 20.3l142.5-.1s255.3 387 138.3 385.1zM291 181a29.3 29.3 0 10-29.2-29.3A29.3 29.3 0 00291 181zm65.4-66.8a22.4 22.4 0 10-22.5-22.4 22.4 22.4 0 0022.5 22.4z\" fill=\"#fc0\"/><path d=\"M245.5 172V10h153v162s324 495 198 495h-558c-126 0 207-495 207-495zm126 54h56m-13 72h56m-9 72h56m-20 72h56m-22 72h56m-29 72h56m-457-45c20.8 41.7 87.3 81 160.7 81 72.1 0 142.1-38.2 163.4-81\" fill=\"none\" stroke=\"#000\" stroke-miterlimit=\"10\" stroke-width=\"20\"/><path d=\"M273.3 421.7c0 31-9.8 56.3-21.9 56.3s-21.8-25.2-21.8-56.3 9.8-56.3 21.8-56.3 21.9 25.2 21.9 56.3zm114.4-56.3c-12 0-21.8 25.2-21.8 56.3s9.7 56.3 21.8 56.3 21.9-25.2 21.9-56.3-9.8-56.3-21.9-56.3zM150.1 526.6c-18.2 6.7-27.5 22.9-23.2 30.2s14.8-5.5 33-12.2 37.4-4.9 33-12.2-24.5-12.6-42.8-5.8zm296 5.8c-4.2 7.3 14.9 5.5 33.1 12.2s28.7 19.5 33 12.2-5-23.5-23.2-30.2-38.5-1.5-42.8 5.8z\"/></svg></p>\\n          </div>\\n        </div>\\n      </div>\\n\\n    </div>\\n</div>\\n<!-- END LABS AREA -->\\n  <div class=\"endorsers\">\\n    <a href=\"/auth/show-endorsers/1706.03762\" class=\"endorser-who\" rel=\"nofollow\">Which authors of this paper are endorsers?</a> |\\n    <a id=\"mathjax_toggle\" href=\"javascript:setMathjaxCookie()\">Disable MathJax</a> (<a href=\"https://info.arxiv.org/help/mathjax.html\">What is MathJax?</a>)\\n    <span class=\"help\" style=\"font-style: normal; float: right; margin-top: 0; margin-right: 1em;\"></span>\\n  </div>\\n  <script type=\"text/javascript\" language=\"javascript\">mathjaxToggle();</script>\\n</div>\\n      </div>\\n    </main>\\n\\n    <footer style=\"clear: both;\">\\n      <div class=\"columns is-desktop\" role=\"navigation\" aria-label=\"Secondary\" style=\"margin: -0.75em -0.75em 0.75em -0.75em\">\\n        <!-- Macro-Column 1 -->\\n        <div class=\"column\" style=\"padding: 0;\">\\n          <div class=\"columns\">\\n            <div class=\"column\">\\n              <ul style=\"list-style: none; line-height: 2;\">\\n                <li><a href=\"https://info.arxiv.org/about\">About</a></li>\\n                <li><a href=\"https://info.arxiv.org/help\">Help</a></li>\\n              </ul>\\n            </div>\\n            <div class=\"column\">\\n              <ul style=\"list-style: none; line-height: 2;\">\\n                <li>\\n                  <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"/></svg>\\n                  <a href=\"https://info.arxiv.org/help/contact.html\"> Contact</a>\\n                </li>\\n                <li>\\n                  <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d=\"M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z\"/></svg>\\n                  <a href=\"https://info.arxiv.org/help/subscribe\"> Subscribe</a>\\n                </li>\\n              </ul>\\n            </div>\\n          </div>\\n        </div>\\n        <!-- End Macro-Column 1 -->\\n        <!-- Macro-Column 2 -->\\n        <div class=\"column\" style=\"padding: 0;\">\\n          <div class=\"columns\">\\n            <div class=\"column\">\\n              <ul style=\"list-style: none; line-height: 2;\">\\n                <li><a href=\"https://info.arxiv.org/help/license/index.html\">Copyright</a></li>\\n                <li><a href=\"https://info.arxiv.org/help/policies/privacy_policy.html\">Privacy Policy</a></li>\\n              </ul>\\n            </div>\\n            <div class=\"column sorry-app-links\">\\n              <ul style=\"list-style: none; line-height: 2;\">\\n                <li><a href=\"https://info.arxiv.org/help/web_accessibility.html\">Web Accessibility Assistance</a></li>\\n                <li>\\n                  <p class=\"help\">\\n                    <a class=\"a11y-main-link\" href=\"https://status.arxiv.org\" target=\"_blank\">arXiv Operational Status <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\" class=\"icon filter-dark_grey\" role=\"presentation\"><path d=\"M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z\"/></svg></a><br>\\n                    Get status notifications via\\n                    <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/email/new\" target=\"_blank\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"/></svg>email</a>\\n                    or <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/slack/new\" target=\"_blank\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\" class=\"icon filter-black\" role=\"presentation\"><path d=\"M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z\"/></svg>slack</a>\\n                  </p>\\n                </li>\\n              </ul>\\n            </div>\\n          </div>\\n        </div> <!-- end MetaColumn 2 -->\\n        <!-- End Macro-Column 2 -->\\n      </div>\\n    </footer>\\n  </div>\\n\\n  <script src=\"/static/base/1.0.1/js/member_acknowledgement.js\"></script>\\n\\n</body>\\n\\n</html>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# Specify the arXiv ID for the paper\n",
    "arxiv_id = '1706.03762'\n",
    "\n",
    "# Make a GET request to retrieve the page for the specified paper\n",
    "res = requests.get(f'https://arxiv.org/abs/{arxiv_id}')\n",
    "\n",
    "# Access the content of the response as a string (HTML)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b01e2b6-e83b-4eb5-8329-60d45cc4d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Compile a regular expression pattern to find the abstract in the HTML response\n",
    "abstract_pattern = re.compile(\n",
    "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "# Search for the abstract in the HTML response text\n",
    "re_match = abstract_pattern.search(res.text)\n",
    "\n",
    "# Check if the abstract was found and print it; otherwise, display an error message\n",
    "if re_match:\n",
    "    print(re_match.group(1))\n",
    "else:\n",
    "    print('Abstract not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a74788b7-b1b6-4d5f-bffa-64158b797a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Compile a regular expression pattern to find the abstract in the HTML response\n",
    "abstract_pattern = re.compile(\n",
    "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "@tool('fetch_arxiv')\n",
    "def fetch_arxiv(arxiv_id: str) -> str:\n",
    "    '''Fetches the abstract from an ArXiv paper given its ArXiv ID.\n",
    "\n",
    "    Args:\n",
    "        arxiv_id (str): The ArXiv paper ID.\n",
    "    \n",
    "    Returns:\n",
    "        str: The extracted abstract text from the ArXiv paper.\n",
    "    '''\n",
    "\n",
    "    res = requests.get(f'https://arxiv.org/abs/{arxiv_id}')\n",
    "    \n",
    "    re_match = abstract_pattern.search(res.text)\n",
    "\n",
    "    return re_match.group(1) if re_match else 'Abstract not found.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9e6b22d-b371-405f-aa2f-b31875d3f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n"
     ]
    }
   ],
   "source": [
    "# Defining the ArXiv paper ID and invoking the tool with that ID.\n",
    "arxiv_id = '1706.03762'\n",
    "output = fetch_arxiv.invoke(input={'arxiv_id': arxiv_id})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc0e37-0a75-42b5-87c8-205984bb43f8",
   "metadata": {},
   "source": [
    "## 08 - Implementing the Web Search Tools with Google SerpAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cdaa120-21ee-441d-9c52-7a4892862691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "SerpAPI key:  ········\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "from getpass import getpass\n",
    "\n",
    "# Set up the SerpAPI request parameters, including the API key.\n",
    "serpapi_params = {\n",
    "    'engine': 'google',  \n",
    "    'api_key': os.getenv('SERPAPI_KEY') or getpass('SerpAPI key: ')  # Get the API key securely.\n",
    "}\n",
    "\n",
    "# Perform a Google search for the keyword \"water\" and limit the results to 5.\n",
    "search = GoogleSearch({\n",
    "    **serpapi_params,\n",
    "    'q': 'water',\n",
    "    'num': 5\n",
    "})\n",
    "\n",
    "\n",
    "# Extract the main search results from the API response.\n",
    "results = search.get_dict().get('organic_results', [])\n",
    "\n",
    "# Format the search results for readability.\n",
    "formatted_results = '\\n---\\n'.join(\n",
    "    ['\\n'.join([x['title'], x['snippet'], x['link']]) for x in results]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4121837-21e3-49e0-87b2-1dbadcb76791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water\n",
      "Water is an inorganic compound with the chemical formula H 2O. It is a transparent, tasteless, odorless, and nearly colorless chemical substance.\n",
      "https://en.wikipedia.org/wiki/Water\n",
      "---\n",
      "Waters Corporation | Laboratory Instruments ...\n",
      "Waters is the leading provider of lab equipment, supplies and software for scientists across the world. Easily research and order everything your lab needs!\n",
      "https://www.waters.com/nextgen/us/en.html?srsltid=AfmBOopY715XtsW-xqsy1_FnfbwgWClvdSaEcWHZ7nH9PzX-01hnnT08\n",
      "---\n",
      "Water | Definition, Chemical Formula, Structure, Molecule ...\n",
      "Water, substance composed of the chemical elements hydrogen and oxygen and existing in gaseous, liquid, and solid states. It is one of the ...\n",
      "https://www.britannica.com/science/water\n",
      "---\n",
      "Water For People: Clean Water Around the World\n",
      "Water For People is helping millions of people across nine countries get access to clean water. You can make a difference!\n",
      "https://www.waterforpeople.org/\n"
     ]
    }
   ],
   "source": [
    "print(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58a5b4b9-ef5b-48a1-9b7f-33c8a5197874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "# Define the 'web_search' tool using the '@tool' decorator.\n",
    "@tool('web_search')\n",
    "def web_search(query: str) -> str:\n",
    "    '''Finds general knowledge information using a Google search.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of the top search results, including title, snippet, and link.\n",
    "    '''\n",
    "\n",
    "    search = GoogleSearch({\n",
    "        **serpapi_params,  \n",
    "        'q': query,        \n",
    "        'num': 5         \n",
    "    })\n",
    "   \n",
    "    results = search.get_dict().get('organic_results', [])\n",
    "    formatted_results = '\\n---\\n'.join(\n",
    "        ['\\n'.join([x['title'], x['snippet'], x['link']]) for x in results]\n",
    "    )\n",
    "    \n",
    "    # Return the formatted results or a 'No results found.' message if no results exist.\n",
    "    return formatted_results if results else 'No results found.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd9c17d2-62d5-494b-a2d5-bbdc2075f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water on Mars\n",
      "Mars contains water, though mostly as permafrost. As top surface layer water appears readily visible at some places, such as the polar Korolev Crater.\n",
      "https://en.wikipedia.org/wiki/Water_on_Mars\n",
      "---\n",
      "NASA Confirms Evidence That Liquid Water Flows ...\n",
      "New findings from NASA's Mars Reconnaissance Orbiter (MRO) provide the strongest evidence yet that liquid water flows intermittently on present-day Mars.\n",
      "https://www.nasa.gov/news-release/nasa-confirms-evidence-that-liquid-water-flows-on-todays-mars/\n",
      "---\n",
      "Scientists find oceans of water on Mars. It's just too deep to ...\n",
      "A new analysis of Mars' interior suggests that much of the liquid water still exists in the pores of rocks 10-20 kilometers below the surface.\n",
      "https://news.berkeley.edu/2024/08/12/scientists-find-oceans-of-water-on-mars-its-just-too-deep-to-tap/\n"
     ]
    }
   ],
   "source": [
    "# Invoke the 'web_search' tool with the query 'water on mars'\n",
    "output = web_search.invoke(input={'query': 'water on mars'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38ebdc4d-be15-4444-b1de-bc72ad96f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language model\n",
      "A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation.\n",
      "https://en.wikipedia.org/wiki/Large_language_model\n",
      "---\n",
      "What is LLM? - Large Language Models Explained\n",
      "Large language models, also known as LLMs, are very large deep learning models that are pre-trained on vast amounts of data. The underlying transformer is a ...\n",
      "https://aws.amazon.com/what-is/large-language-model/\n",
      "---\n",
      "What Are Large Language Models (LLMs)?\n",
      "Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\n",
      "https://www.ibm.com/topics/large-language-models\n"
     ]
    }
   ],
   "source": [
    "output = web_search.invoke(input={'query': 'llms'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f4419-c493-42cd-af42-2f53045ca2a8",
   "metadata": {},
   "source": [
    "## 09 - Creating RAG Tools for Retrieval-Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b378233-2b2a-4dfb-aaa1-85e55dfe93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rag_contexts(matches: list) -> str:\n",
    "    '''Formats the retrieved context matches into a readable string format.\n",
    "\n",
    "    Args:\n",
    "        matches (list): A list of matched documents with metadata.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of document titles, chunks, and ArXiv IDs.\n",
    "    '''\n",
    "    formatted_results = []\n",
    "    \n",
    "    # Loop through each match and extract its metadata.\n",
    "    for x in matches:\n",
    "        text = (\n",
    "            f\"Title: {x['metadata']['title']}\\n\"\n",
    "            f\"Chunk: {x['metadata']['chunk']}\\n\"\n",
    "            f\"ArXiv ID: {x['metadata']['arxiv_id']}\\n\"\n",
    "        )\n",
    "        # Append each formatted string to the results list.\n",
    "        formatted_results.append(text)\n",
    "    \n",
    "    # Join all the individual formatted strings into one large string.\n",
    "    return '\\n---\\n'.join(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90e54a6e-da66-4ce7-a1cf-4a31533c196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def rag_search_filter(query: str, arxiv_id: str) -> str:\n",
    "    '''Finds information from the ArXiv database using a natural language query and a specific ArXiv ID.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query in natural language.\n",
    "        arxiv_id (str): The ArXiv ID of the specific paper to filter by.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of relevant document contexts.\n",
    "    '''\n",
    "    \n",
    "    # Encode the query into a vector representation.\n",
    "    xq = encoder([query])\n",
    "    \n",
    "    # Perform a search on the Pinecone index, filtering by ArXiv ID.\n",
    "    xc = index.query(vector=xq, top_k=6, include_metadata=True, filter={'arxiv_id': arxiv_id})\n",
    "    \n",
    "    # Format and return the search results.\n",
    "    return format_rag_contexts(xc['matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75d97f3f-5a1e-46c5-8788-45a846a45704",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool('rag_search')\n",
    "def rag_search(query: str) -> str:\n",
    "    '''Finds specialist information on AI using a natural language query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query in natural language.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of relevant document contexts.\n",
    "    '''\n",
    "    \n",
    "    # Encode the query into a vector representation.\n",
    "    xq = encoder([query])\n",
    "    \n",
    "    # Perform a broader search without filtering by ArXiv ID.\n",
    "    xc = index.query(vector=xq, top_k=5, include_metadata=True)\n",
    "    \n",
    "    # Format and return the search results.\n",
    "    return format_rag_contexts(xc['matches'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400e267-d3a0-48e8-9d07-5d5359af6f27",
   "metadata": {},
   "source": [
    "## 10 - Implementing the Final Answer Generation Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67d90b36-ebe5-4de8-8dbd-f18f26e90572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# Define the 'final_answer' tool to compile the research report.\n",
    "@tool\n",
    "def final_answer(\n",
    "    introduction: str,\n",
    "    research_steps: str or list,\n",
    "    main_body: str,\n",
    "    conclusion: str,\n",
    "    sources: str or list\n",
    ") -> str:\n",
    "    '''Returns a natural language response in the form of a research report.\n",
    "\n",
    "    Args:\n",
    "        introduction (str): A short paragraph introducing the user's question and the topic.\n",
    "        research_steps (str or list): Bullet points or text explaining the steps taken for research.\n",
    "        main_body (str): The bulk of the answer, 3-4 paragraphs long, providing high-quality information.\n",
    "        conclusion (str): A short paragraph summarizing the findings.\n",
    "        sources (str or list): A list or text providing the sources referenced during the research.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted research report string.\n",
    "    '''\n",
    "\n",
    "    # Format research steps if given as a list.\n",
    "    if isinstance(research_steps, list):\n",
    "        research_steps = '\\n'.join([f'- {r}' for r in research_steps])\n",
    "    \n",
    "    # Format sources if given as a list.\n",
    "    if isinstance(sources, list):\n",
    "        sources = '\\n'.join([f'- {s}' for s in sources])\n",
    "    \n",
    "    # Construct and return the final research report.\n",
    "    return f'{introduction}\\n\\nResearch Steps:\\n{research_steps}\\n\\nMain Body:\\n{main_body}\\n\\n \\\n",
    "    Conclusion:\\n{conclusion}\\n\\nSources:\\n{sources}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbab5d-822a-4306-a857-364371ee21d2",
   "metadata": {},
   "source": [
    "## 11 - Initializing the \"Oracle\" LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcdd8fed-d48a-49e9-9af6-eee93c839f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Define the system prompt guiding the AI's decision-making process.\n",
    "system_prompt = (\n",
    "    '''You are the oracle, the great AI decision-maker.\n",
    "    Given the user's query, you must decide what to do with it based on the\n",
    "    list of tools provided to you.\n",
    "\n",
    "    If you see that a tool has been used (in the scratchpad) with a particular\n",
    "    query, do NOT use that same tool with the same query again. Also, do NOT use\n",
    "    any tool more than twice (i.e., if the tool appears in the scratchpad twice, do\n",
    "    not use it again).\n",
    "\n",
    "    You should aim to collect information from a diverse range of sources before\n",
    "    providing the answer to the user. Once you have collected plenty of information\n",
    "    to answer the user's question (stored in the scratchpad), use the final_answer tool.'''\n",
    ")\n",
    "\n",
    "\n",
    "# Create a prompt template for the conversation flow.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),  # Define the AI's role and rules.\n",
    "    \n",
    "    # Insert past chat messages to maintain context.\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    \n",
    "    # Insert user's input dynamically.\n",
    "    ('user', '{input}'),\n",
    "    \n",
    "    # Include the assistant's scratchpad to track tool usage and intermediate steps.\n",
    "    ('assistant', 'scratchpad: {scratchpad}'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccb144e4-66a6-4e22-a4e1-af5eaf375127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolCall, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# Initialize the OpenAI language model with specific settings.\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o',\n",
    "    openai_api_key=os.environ['OPENAI_API_KEY'],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Define the list of tools available to the oracle.\n",
    "tools = [\n",
    "    rag_search_filter,\n",
    "    rag_search,\n",
    "    fetch_arxiv,\n",
    "    web_search,\n",
    "    final_answer\n",
    "]\n",
    "\n",
    "# Function to create the scratchpad from the intermediate tool calls.\n",
    "def create_scratchpad(intermediate_steps: list[ToolCall]) -> str:\n",
    "    research_steps = []\n",
    "    \n",
    "    # Loop over each step and process tool calls with actual outputs.\n",
    "    for i, action in enumerate(intermediate_steps):\n",
    "        if action.log != 'TBD':\n",
    "            research_steps.append(\n",
    "                f'Tool: {action.tool}, input: {action.tool_input}\\n'\n",
    "                f'Output: {action.log}'\n",
    "            )\n",
    "    \n",
    "    # Join the research steps into a readable log.\n",
    "    return '\\n---\\n'.join(research_steps)\n",
    "\n",
    "# Define the oracle's decision-making pipeline.\n",
    "oracle = (\n",
    "    {\n",
    "        'input': lambda x: x['input'],\n",
    "        'chat_history': lambda x: x['chat_history'],\n",
    "        'scratchpad': lambda x: create_scratchpad(intermediate_steps=x['intermediate_steps']),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice='any')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c17de-f7c7-432e-b061-8fc3e8c2170c",
   "metadata": {},
   "source": [
    "## 12 -  Testing the Oracle and the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f2931b2-00fb-4fe1-814a-5262d8cc7587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_Ahyg8ycfUkl3YdG4a8F2zWEp', 'function': {'arguments': '{\"arxiv_id\":\"2407.21783\"}', 'name': 'fetch_arxiv'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 604, 'total_tokens': 625, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9d50cd990b', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-6e0663dc-53f5-4670-8550-47bcda989233-0' tool_calls=[{'name': 'fetch_arxiv', 'args': {'arxiv_id': '2407.21783'}, 'id': 'call_Ahyg8ycfUkl3YdG4a8F2zWEp', 'type': 'tool_call'}] usage_metadata={'input_tokens': 604, 'output_tokens': 21, 'total_tokens': 625, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# input = 'Tell me something interesting about dynamic backtracking AI and LLMs'\n",
    "# input = 'Who won the Super Bowl 2024?'\n",
    "input = 'What is the ArXiv paper with the ID 2407.21783 all about?'\n",
    "# Create the inputs dictionary, containing the user's query and initial empty chat history and intermediate steps.\n",
    "inputs = {\n",
    "    'input': input,\n",
    "    'chat_history': [],\n",
    "    'intermediate_steps': [],\n",
    "}\n",
    "\n",
    "# Invoke the oracle with the inputs, processing the query and returning a response.\n",
    "out = oracle.invoke(inputs)\n",
    "\n",
    "# Display the oracle's response.\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55eb86f3-60b2-4846-97e5-780e1dbdc679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'fetch_arxiv',\n",
       "  'args': {'arxiv_id': '2407.21783'},\n",
       "  'id': 'call_Ahyg8ycfUkl3YdG4a8F2zWEp',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c01f38b7-a98c-4c3a-a42b-628c7101ad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fetch_arxiv'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the name of the tool\n",
    "out.tool_calls[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93ccfd9e-d0b3-4958-adb7-b1ff95b332d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arxiv_id': '2407.21783'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the tool's arguments\n",
    "out.tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0043d-2108-4f6e-9e87-cf81464e269e",
   "metadata": {},
   "source": [
    "## 12 - Building a Decision-Making Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d3bb5db-a73a-48fb-93e6-af45b5f460f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_oracle(): main function that executes the oracle and processes its output to extract the relevant tool and its arguments.\n",
    "# We'll use this information to update the state for future steps.\n",
    "def run_oracle(state: dict) -> dict:\n",
    "    '''Runs the oracle and processes the output to extract tool information.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state containing the 'intermediate_steps'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new state with updated 'intermediate_steps' including the tool action.\n",
    "    '''\n",
    "    \n",
    "    print('run_oracle')\n",
    "    print(f'intermediate_steps: {state[\"intermediate_steps\"]}')\n",
    "    \n",
    "    # Invoke the oracle with the current state.\n",
    "    out = oracle.invoke(state)\n",
    "\n",
    "    # Extract the tool name and its arguments from the oracle's response.\n",
    "    tool_name = out.tool_calls[0]['name']\n",
    "    tool_args = out.tool_calls[0]['args']\n",
    "\n",
    "    # Create an AgentAction object, which records the tool used and the input provided.\n",
    "    action_out = AgentAction(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "        log='TBD'  # To be determined later after the tool runs.\n",
    "    )\n",
    "\n",
    "    # Return a new state with updated 'intermediate_steps'.\n",
    "    return {\n",
    "        'intermediate_steps': [action_out]\n",
    "    }\n",
    "\n",
    "\n",
    "# The router() function determines the next tool to use based on the current state.\n",
    "def router(state: dict) -> str:\n",
    "    '''Determines the next tool to use based on the current state.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state containing 'intermediate_steps'.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the tool to use next.\n",
    "    '''\n",
    "\n",
    "    if isinstance(state['intermediate_steps'], list):\n",
    "        return state['intermediate_steps'][-1].tool\n",
    "    else:\n",
    "        print('Router invalid format')\n",
    "        return 'final_answer'\n",
    "\n",
    "\n",
    "tool_str_to_func = {\n",
    "    'rag_search_filter': rag_search_filter,\n",
    "    'rag_search': rag_search,\n",
    "    'fetch_arxiv': fetch_arxiv,\n",
    "    'web_search': web_search,\n",
    "    'final_answer': final_answer\n",
    "}\n",
    "\n",
    "# The run_tool() function executes the appropriate tool based on the current state.\n",
    "def run_tool(state: dict) -> dict:\n",
    "    '''Executes the appropriate tool based on the current state.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state containing the 'intermediate_steps'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new state with updated 'intermediate_steps' including the tool's result.\n",
    "    '''\n",
    "\n",
    "    tool_name = state['intermediate_steps'][-1].tool\n",
    "    tool_args = state['intermediate_steps'][-1].tool_input\n",
    "\n",
    "    print(f'{tool_name}.invoke(input={tool_args})')\n",
    "\n",
    "    out = tool_str_to_func[tool_name].invoke(input=tool_args)\n",
    "\n",
    "    action_out = AgentAction(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "        log=str(out)\n",
    "    )\n",
    "\n",
    "    return {'intermediate_steps': [action_out]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd8409-8ea2-423d-aaaa-c1e22b37e846",
   "metadata": {},
   "source": [
    "## 13 - Defining the Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "518f0bc7-0e35-4303-bd0d-cc5ecea74629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.agents import AgentAction\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    '''Represents the state of an agent.'''\n",
    "    \n",
    "    input: str\n",
    "    chat_history: List[BaseMessage]\n",
    "    intermediate_steps: Annotated[List[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a7dd7-e22b-45e1-b815-11c41a7663c9",
   "metadata": {},
   "source": [
    "## 14 - Defining the Graph for Decision-Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1ccb605-0576-43f5-b3ed-b5acde9b7f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Initialize the state graph with AgentState to manage the workflow.\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node('oracle', run_oracle)\n",
    "graph.add_node('rag_search_filter', run_tool)\n",
    "graph.add_node('rag_search', run_tool)\n",
    "graph.add_node('fetch_arxiv', run_tool)\n",
    "graph.add_node('web_search', run_tool)\n",
    "graph.add_node('final_answer', run_tool)\n",
    "\n",
    "# Set the entry point to 'oracle'.\n",
    "graph.set_entry_point('oracle')\n",
    "\n",
    "# Add conditional edges to determine the next step using the router function.\n",
    "graph.add_conditional_edges(source='oracle', path=router)\n",
    "\n",
    "# Add edges from each tool back to 'oracle', except 'final_answer', which leads to 'END'.\n",
    "for tool_obj in tools:\n",
    "    if tool_obj.name != 'final_answer':\n",
    "        graph.add_edge(tool_obj.name, 'oracle')\n",
    "\n",
    "graph.add_edge('final_answer', END)\n",
    "\n",
    "# Compile the graph to make it executable.\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbd51be8-467f-4874-9043-1225a86798e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display the graph as a PNG using Mermaid rendering.\n",
    "display(Image(runnable.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "283d97c9-158b-4570-811a-26995b39ee27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_oracle\n",
      "intermediate_steps: []\n",
      "rag_search.invoke(input={'query': 'Dynamic Backtracking AI'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nthe automatic realization that the problem splits in to disjoin t subproblems/. Other authors\\nha v e also discussed the idea of applying divide/-and/-conquer tec hniques to csp s /(Seidel/, /1/9/8/1/;\\nZabih/, /1/9/9/0/)/, but their metho ds su/\\x0ber from the disadv an tage that they constrain the order in\\nwhic h unassigned v ariables are assigned v alues/, p erhaps at o dds with the common heuristic\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: of assigning v alues /\\x0crst to those v ariables that are most tigh tly constrained/. Dynamic\\nbac ktrac king can also b e exp ected to b e of use in situations where the problem in question\\ndo es not split in to t w o or more disjoin t subproblems/.\\n/1\\n/6/. Exp erimen tation\\nDynamic bac ktrac king has b een incorp orated in to the crossw ord/-puzzle generation program\\ndescrib ed in /(Ginsb erg/, F rank/, Halpin/, /& T orrance/, /1/9/9/0/)/, and leads to signi/\\x0ccan t p erfor/-\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: FLECS: Planning with a Flexible Commitment Strategy\\nChunk: searc hing recursiv ely forw ard through the state space/, they searc h bac kw ards from the goal/.\\nTheir searc h is driv en b y the set of actions that can directly ac hiev e the goal/.\\nThere are t w o main w a ys of p erforming bac kw ard/-c haining/. Sev eral planners do re/-\\ngression b y searc hing the space of p ossible plans/. Planners/, suc h as no ah /, tweak /, snlp /,\\n/1/. Least/-commitmen t planners really delay commitmen ts to plan step orderings and to v ariable bindings/.\\nArXiv ID: 9506101v1\\n')]\n",
      "rag_search.invoke(input={'query': 'LLMs (Large Language Models)'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nthe automatic realization that the problem splits in to disjoin t subproblems/. Other authors\\nha v e also discussed the idea of applying divide/-and/-conquer tec hniques to csp s /(Seidel/, /1/9/8/1/;\\nZabih/, /1/9/9/0/)/, but their metho ds su/\\x0ber from the disadv an tage that they constrain the order in\\nwhic h unassigned v ariables are assigned v alues/, p erhaps at o dds with the common heuristic\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: of assigning v alues /\\x0crst to those v ariables that are most tigh tly constrained/. Dynamic\\nbac ktrac king can also b e exp ected to b e of use in situations where the problem in question\\ndo es not split in to t w o or more disjoin t subproblems/.\\n/1\\n/6/. Exp erimen tation\\nDynamic bac ktrac king has b een incorp orated in to the crossw ord/-puzzle generation program\\ndescrib ed in /(Ginsb erg/, F rank/, Halpin/, /& T orrance/, /1/9/9/0/)/, and leads to signi/\\x0ccan t p erfor/-\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: FLECS: Planning with a Flexible Commitment Strategy\\nChunk: searc hing recursiv ely forw ard through the state space/, they searc h bac kw ards from the goal/.\\nTheir searc h is driv en b y the set of actions that can directly ac hiev e the goal/.\\nThere are t w o main w a ys of p erforming bac kw ard/-c haining/. Sev eral planners do re/-\\ngression b y searc hing the space of p ossible plans/. Planners/, suc h as no ah /, tweak /, snlp /,\\n/1/. Least/-commitmen t planners really delay commitmen ts to plan step orderings and to v ariable bindings/.\\nArXiv ID: 9506101v1\\n'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='Title: Learning the Past Tense of English Verbs: The Symbolic Pattern\\n  Associator vs. Connectionist Models\\nChunk: of language/.\\n/2/./2 MacWhinney and Lein bac h/\\'s Mo del\\nMacWhinney and Lein bac h /(/1/9/9/1/) rep ort a new connectionist mo del on the learning of the\\npast tenses of English v erbs/. They claim that the results from the new sim ulation are far\\nsup erior to Rumelhart and McClelland/\\'s results/, and that they can answ er most of the crit/-\\nicisms aimed at the earlier mo del/. The ma jor departure from Rumelhart and McClelland/\\'s\\nArXiv ID: 9402101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: learning mo del is the class of one/-clause constan t/-depth determinate programs with at most\\na constan t n um b er of /\\\\closed/\" recursiv e literals/. The largest learnable class w e iden tify\\nthat requires extra /\\\\hin ts/\" is the class of constan t/-depth determinate programs consisting\\nof a single nonrecursiv e base clause and a single recursiv e clause from the class describ ed\\nab o v e/. All of our results are pro v ed in the mo del of identi/\\x0cc ation fr om e quivalenc e queries\\nArXiv ID: 9505104v1\\n\\n---\\nTitle: An Integrated Framework for Learning and Reasoning\\nChunk: Ablex Publishing Corp/.\\nD /\\x14 zeroski/, S/./, Muggleton/, S/./, /& Russell/, S/. /(/1/9/9/3/)/. Learnabilit y of constrained logic programs/.\\nIn Pr o c e e dings of the Eur op e an Confer enc e on Machine L e arning /(ECML/\\'/9/3/)/, LNAI\\n/6/6/7 /, pp/. /3/4/2/{/3/4/7/.\\nElman/, J/. /(/1/9/9/1/)/. Incremen tal learning/, or the imp ortance of starting small/. T ec h/. rep/.\\nCRL /9/1/0/1/, Univ ersit y of California/, San Diego/, Cen ter for Researc h in Language/, La\\nJolla/, CA/.\\nArXiv ID: 9508102v1\\n\\n---\\nTitle: Operations for Learning with Graphical Models\\nChunk: Learning with Graphical Models\\nMcLac hlan/, G/. J/./, /& Basford/, K/. E/. /(/1/9/8/8/)/. Mixtur e Mo dels/: Infer enc e and Applic ations to\\nClustering /. New Y ork/: Marcel Dekk er/.\\nMeilijson/, I/. /(/1/9/8/9/)/. A fast impro v emen t to the EM algorithm on its o wn terms/. J/. R oy/.\\nStatist/. So c/. B /, /5/1 /(/1/)/, /1/2/7/{/1/3/8/.\\nMin ton/, S/./, Johnson/, M/./, Philips/, A/./, /& Laird/, P /. /(/1/9/9/0/)/. Solving large/-scale constrain t/-\\nArXiv ID: 9412102v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\n/2/./3 A Mo del of Learnabilit y\\nIn this section/, w e will presen t our mo del of learnabilit y /. W e will /\\x0crst review the necessary\\nde/\\x0cnitions for a standard learning mo del/, the mo del of learning from equiv alence queries\\n/(Angluin/, /1/9/8/8/, /1/9/8/9/)/, and discuss its relationship to other learning mo dels/. W e will then\\nin tro duce an extension to this mo del whic h is necessary for analyzing ILP problems/.\\nArXiv ID: 9505104v1\\n')]\n",
      "web_search.invoke(input={'query': 'Dynamic Backtracking AI'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nthe automatic realization that the problem splits in to disjoin t subproblems/. Other authors\\nha v e also discussed the idea of applying divide/-and/-conquer tec hniques to csp s /(Seidel/, /1/9/8/1/;\\nZabih/, /1/9/9/0/)/, but their metho ds su/\\x0ber from the disadv an tage that they constrain the order in\\nwhic h unassigned v ariables are assigned v alues/, p erhaps at o dds with the common heuristic\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: of assigning v alues /\\x0crst to those v ariables that are most tigh tly constrained/. Dynamic\\nbac ktrac king can also b e exp ected to b e of use in situations where the problem in question\\ndo es not split in to t w o or more disjoin t subproblems/.\\n/1\\n/6/. Exp erimen tation\\nDynamic bac ktrac king has b een incorp orated in to the crossw ord/-puzzle generation program\\ndescrib ed in /(Ginsb erg/, F rank/, Halpin/, /& T orrance/, /1/9/9/0/)/, and leads to signi/\\x0ccan t p erfor/-\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: FLECS: Planning with a Flexible Commitment Strategy\\nChunk: searc hing recursiv ely forw ard through the state space/, they searc h bac kw ards from the goal/.\\nTheir searc h is driv en b y the set of actions that can directly ac hiev e the goal/.\\nThere are t w o main w a ys of p erforming bac kw ard/-c haining/. Sev eral planners do re/-\\ngression b y searc hing the space of p ossible plans/. Planners/, suc h as no ah /, tweak /, snlp /,\\n/1/. Least/-commitmen t planners really delay commitmen ts to plan step orderings and to v ariable bindings/.\\nArXiv ID: 9506101v1\\n'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='Title: Learning the Past Tense of English Verbs: The Symbolic Pattern\\n  Associator vs. Connectionist Models\\nChunk: of language/.\\n/2/./2 MacWhinney and Lein bac h/\\'s Mo del\\nMacWhinney and Lein bac h /(/1/9/9/1/) rep ort a new connectionist mo del on the learning of the\\npast tenses of English v erbs/. They claim that the results from the new sim ulation are far\\nsup erior to Rumelhart and McClelland/\\'s results/, and that they can answ er most of the crit/-\\nicisms aimed at the earlier mo del/. The ma jor departure from Rumelhart and McClelland/\\'s\\nArXiv ID: 9402101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: learning mo del is the class of one/-clause constan t/-depth determinate programs with at most\\na constan t n um b er of /\\\\closed/\" recursiv e literals/. The largest learnable class w e iden tify\\nthat requires extra /\\\\hin ts/\" is the class of constan t/-depth determinate programs consisting\\nof a single nonrecursiv e base clause and a single recursiv e clause from the class describ ed\\nab o v e/. All of our results are pro v ed in the mo del of identi/\\x0cc ation fr om e quivalenc e queries\\nArXiv ID: 9505104v1\\n\\n---\\nTitle: An Integrated Framework for Learning and Reasoning\\nChunk: Ablex Publishing Corp/.\\nD /\\x14 zeroski/, S/./, Muggleton/, S/./, /& Russell/, S/. /(/1/9/9/3/)/. Learnabilit y of constrained logic programs/.\\nIn Pr o c e e dings of the Eur op e an Confer enc e on Machine L e arning /(ECML/\\'/9/3/)/, LNAI\\n/6/6/7 /, pp/. /3/4/2/{/3/4/7/.\\nElman/, J/. /(/1/9/9/1/)/. Incremen tal learning/, or the imp ortance of starting small/. T ec h/. rep/.\\nCRL /9/1/0/1/, Univ ersit y of California/, San Diego/, Cen ter for Researc h in Language/, La\\nJolla/, CA/.\\nArXiv ID: 9508102v1\\n\\n---\\nTitle: Operations for Learning with Graphical Models\\nChunk: Learning with Graphical Models\\nMcLac hlan/, G/. J/./, /& Basford/, K/. E/. /(/1/9/8/8/)/. Mixtur e Mo dels/: Infer enc e and Applic ations to\\nClustering /. New Y ork/: Marcel Dekk er/.\\nMeilijson/, I/. /(/1/9/8/9/)/. A fast impro v emen t to the EM algorithm on its o wn terms/. J/. R oy/.\\nStatist/. So c/. B /, /5/1 /(/1/)/, /1/2/7/{/1/3/8/.\\nMin ton/, S/./, Johnson/, M/./, Philips/, A/./, /& Laird/, P /. /(/1/9/9/0/)/. Solving large/-scale constrain t/-\\nArXiv ID: 9412102v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\n/2/./3 A Mo del of Learnabilit y\\nIn this section/, w e will presen t our mo del of learnabilit y /. W e will /\\x0crst review the necessary\\nde/\\x0cnitions for a standard learning mo del/, the mo del of learning from equiv alence queries\\n/(Angluin/, /1/9/8/8/, /1/9/8/9/)/, and discuss its relationship to other learning mo dels/. W e will then\\nin tro duce an extension to this mo del whic h is necessary for analyzing ILP problems/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Dynamic Backtracking\\nThe technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and ...\\nhttps://arxiv.org/pdf/cs.AI/9308101\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nDynamic backtracking | Journal of Artificial Intelligence ...\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://dl.acm.org/doi/10.5555/1618595.1618597\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf')]\n",
      "web_search.invoke(input={'query': 'LLMs (Large Language Models)'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nthe automatic realization that the problem splits in to disjoin t subproblems/. Other authors\\nha v e also discussed the idea of applying divide/-and/-conquer tec hniques to csp s /(Seidel/, /1/9/8/1/;\\nZabih/, /1/9/9/0/)/, but their metho ds su/\\x0ber from the disadv an tage that they constrain the order in\\nwhic h unassigned v ariables are assigned v alues/, p erhaps at o dds with the common heuristic\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: of assigning v alues /\\x0crst to those v ariables that are most tigh tly constrained/. Dynamic\\nbac ktrac king can also b e exp ected to b e of use in situations where the problem in question\\ndo es not split in to t w o or more disjoin t subproblems/.\\n/1\\n/6/. Exp erimen tation\\nDynamic bac ktrac king has b een incorp orated in to the crossw ord/-puzzle generation program\\ndescrib ed in /(Ginsb erg/, F rank/, Halpin/, /& T orrance/, /1/9/9/0/)/, and leads to signi/\\x0ccan t p erfor/-\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: FLECS: Planning with a Flexible Commitment Strategy\\nChunk: searc hing recursiv ely forw ard through the state space/, they searc h bac kw ards from the goal/.\\nTheir searc h is driv en b y the set of actions that can directly ac hiev e the goal/.\\nThere are t w o main w a ys of p erforming bac kw ard/-c haining/. Sev eral planners do re/-\\ngression b y searc hing the space of p ossible plans/. Planners/, suc h as no ah /, tweak /, snlp /,\\n/1/. Least/-commitmen t planners really delay commitmen ts to plan step orderings and to v ariable bindings/.\\nArXiv ID: 9506101v1\\n'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='Title: Learning the Past Tense of English Verbs: The Symbolic Pattern\\n  Associator vs. Connectionist Models\\nChunk: of language/.\\n/2/./2 MacWhinney and Lein bac h/\\'s Mo del\\nMacWhinney and Lein bac h /(/1/9/9/1/) rep ort a new connectionist mo del on the learning of the\\npast tenses of English v erbs/. They claim that the results from the new sim ulation are far\\nsup erior to Rumelhart and McClelland/\\'s results/, and that they can answ er most of the crit/-\\nicisms aimed at the earlier mo del/. The ma jor departure from Rumelhart and McClelland/\\'s\\nArXiv ID: 9402101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: learning mo del is the class of one/-clause constan t/-depth determinate programs with at most\\na constan t n um b er of /\\\\closed/\" recursiv e literals/. The largest learnable class w e iden tify\\nthat requires extra /\\\\hin ts/\" is the class of constan t/-depth determinate programs consisting\\nof a single nonrecursiv e base clause and a single recursiv e clause from the class describ ed\\nab o v e/. All of our results are pro v ed in the mo del of identi/\\x0cc ation fr om e quivalenc e queries\\nArXiv ID: 9505104v1\\n\\n---\\nTitle: An Integrated Framework for Learning and Reasoning\\nChunk: Ablex Publishing Corp/.\\nD /\\x14 zeroski/, S/./, Muggleton/, S/./, /& Russell/, S/. /(/1/9/9/3/)/. Learnabilit y of constrained logic programs/.\\nIn Pr o c e e dings of the Eur op e an Confer enc e on Machine L e arning /(ECML/\\'/9/3/)/, LNAI\\n/6/6/7 /, pp/. /3/4/2/{/3/4/7/.\\nElman/, J/. /(/1/9/9/1/)/. Incremen tal learning/, or the imp ortance of starting small/. T ec h/. rep/.\\nCRL /9/1/0/1/, Univ ersit y of California/, San Diego/, Cen ter for Researc h in Language/, La\\nJolla/, CA/.\\nArXiv ID: 9508102v1\\n\\n---\\nTitle: Operations for Learning with Graphical Models\\nChunk: Learning with Graphical Models\\nMcLac hlan/, G/. J/./, /& Basford/, K/. E/. /(/1/9/8/8/)/. Mixtur e Mo dels/: Infer enc e and Applic ations to\\nClustering /. New Y ork/: Marcel Dekk er/.\\nMeilijson/, I/. /(/1/9/8/9/)/. A fast impro v emen t to the EM algorithm on its o wn terms/. J/. R oy/.\\nStatist/. So c/. B /, /5/1 /(/1/)/, /1/2/7/{/1/3/8/.\\nMin ton/, S/./, Johnson/, M/./, Philips/, A/./, /& Laird/, P /. /(/1/9/9/0/)/. Solving large/-scale constrain t/-\\nArXiv ID: 9412102v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\n/2/./3 A Mo del of Learnabilit y\\nIn this section/, w e will presen t our mo del of learnabilit y /. W e will /\\x0crst review the necessary\\nde/\\x0cnitions for a standard learning mo del/, the mo del of learning from equiv alence queries\\n/(Angluin/, /1/9/8/8/, /1/9/8/9/)/, and discuss its relationship to other learning mo dels/. W e will then\\nin tro duce an extension to this mo del whic h is necessary for analyzing ILP problems/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Dynamic Backtracking\\nThe technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and ...\\nhttps://arxiv.org/pdf/cs.AI/9308101\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nDynamic backtracking | Journal of Artificial Intelligence ...\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://dl.acm.org/doi/10.5555/1618595.1618597\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf'), AgentAction(tool='web_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='Large language model\\nA large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation.\\nhttps://en.wikipedia.org/wiki/Large_language_model\\n---\\nWhat is LLM? - Large Language Models Explained\\nLarge language models, also known as LLMs, are very large deep learning models that are pre-trained on vast amounts of data. The underlying transformer is a ...\\nhttps://aws.amazon.com/what-is/large-language-model/\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/topics/large-language-models\\n---\\nWhat is a large language model (LLM)?\\nLarge language models (LLMs) are machine learning models that can comprehend and generate human language text. Learn how LLMs work and their security risks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/')]\n",
      "final_answer.invoke(input={'introduction': 'Dynamic Backtracking and Large Language Models (LLMs) are two fascinating areas in the field of artificial intelligence, each contributing uniquely to problem-solving and language processing. Dynamic Backtracking offers a novel approach to search algorithms, while LLMs represent a significant advancement in natural language understanding and generation.', 'research_steps': '1. Conducted a specialized search on Dynamic Backtracking AI using the RAG search tool.\\n2. Conducted a specialized search on LLMs using the RAG search tool.\\n3. Performed a web search for additional information on Dynamic Backtracking AI.\\n4. Performed a web search for additional information on LLMs.', 'main_body': 'Dynamic Backtracking is a sophisticated technique in AI that enhances traditional backtracking methods by allowing backtrack points to be moved deeper into the search space. This approach helps avoid the erasure of meaningful progress when solving complex search problems. It is particularly useful in constraint satisfaction problems (CSPs) where the problem does not naturally split into disjoint subproblems. Dynamic Backtracking has been applied successfully in areas such as crossword puzzle generation, demonstrating significant performance improvements.\\n\\nOn the other hand, Large Language Models (LLMs) are a type of deep learning model designed for natural language processing tasks. These models, such as GPT-3, are pre-trained on vast amounts of text data and are capable of understanding and generating human-like text. LLMs utilize transformer architectures to process and generate language, making them highly effective for tasks like translation, summarization, and conversation. The development of LLMs has revolutionized the field of AI by enabling machines to perform complex language tasks with remarkable accuracy.', 'conclusion': 'Dynamic Backtracking and LLMs represent significant advancements in AI, each addressing different challenges. While Dynamic Backtracking improves search efficiency in AI problem-solving, LLMs enhance the ability of machines to understand and generate human language. Together, these technologies continue to push the boundaries of what AI can achieve.', 'sources': '1. Journal of Artificial Intelligence Research - Dynamic Backtracking\\n2. Wikipedia - Large Language Models\\n3. AWS - What is LLM?\\n4. IBM - What Are Large Language Models (LLMs)?'})\n"
     ]
    }
   ],
   "source": [
    "# Run the graph with input.\n",
    "output = runnable.invoke({\n",
    "    'input': 'Tell me something interesting about Dynamic Backtracking AI and LLMs',\n",
    "    'chat_history': [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d4b86b3e-58de-4e93-a123-a3561f7adf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'chat_history', 'intermediate_steps'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48543117-fd35-4419-a197-0e639a927e04",
   "metadata": {},
   "source": [
    "## 15 - Generating Reports: Building a Formatted Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "966f336c-bcf5-4d17-bacd-a07b2d5b2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_report(output: dict) -> str:\n",
    "    '''Builds a formatted report based on the oracle's output.\n",
    "\n",
    "    Args:\n",
    "        output (dict): A dictionary containing the various sections of the report (graph's output).\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the full research report.\n",
    "    '''\n",
    "    research_steps = output['research_steps']\n",
    "    if isinstance(research_steps, list):\n",
    "        research_steps = '\\n'.join([f'- {r}' for r in research_steps])\n",
    "    \n",
    "    sources = output['sources']\n",
    "    if isinstance(sources, list):\n",
    "        sources = '\\n'.join([f'- {s}' for s in sources])\n",
    "    \n",
    "    return f\"\"\"\n",
    "        INTRODUCTION\n",
    "        ------------\n",
    "        {output['introduction']}\n",
    "        \n",
    "        RESEARCH STEPS\n",
    "        --------------\n",
    "        {research_steps}\n",
    "        \n",
    "        REPORT\n",
    "        ------\n",
    "        {output['main_body']}\n",
    "        \n",
    "        CONCLUSION\n",
    "        ----------\n",
    "        {output['conclusion']}\n",
    "        \n",
    "        SOURCES\n",
    "        -------\n",
    "        {sources}\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f020786c-b591-48e3-9992-a29e282d26cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_oracle\n",
      "intermediate_steps: []\n",
      "rag_search.invoke(input={'query': 'Dynamic Backtracking AI'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nthe automatic realization that the problem splits in to disjoin t subproblems/. Other authors\\nha v e also discussed the idea of applying divide/-and/-conquer tec hniques to csp s /(Seidel/, /1/9/8/1/;\\nZabih/, /1/9/9/0/)/, but their metho ds su/\\x0ber from the disadv an tage that they constrain the order in\\nwhic h unassigned v ariables are assigned v alues/, p erhaps at o dds with the common heuristic\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: of assigning v alues /\\x0crst to those v ariables that are most tigh tly constrained/. Dynamic\\nbac ktrac king can also b e exp ected to b e of use in situations where the problem in question\\ndo es not split in to t w o or more disjoin t subproblems/.\\n/1\\n/6/. Exp erimen tation\\nDynamic bac ktrac king has b een incorp orated in to the crossw ord/-puzzle generation program\\ndescrib ed in /(Ginsb erg/, F rank/, Halpin/, /& T orrance/, /1/9/9/0/)/, and leads to signi/\\x0ccan t p erfor/-\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: FLECS: Planning with a Flexible Commitment Strategy\\nChunk: searc hing recursiv ely forw ard through the state space/, they searc h bac kw ards from the goal/.\\nTheir searc h is driv en b y the set of actions that can directly ac hiev e the goal/.\\nThere are t w o main w a ys of p erforming bac kw ard/-c haining/. Sev eral planners do re/-\\ngression b y searc hing the space of p ossible plans/. Planners/, suc h as no ah /, tweak /, snlp /,\\n/1/. Least/-commitmen t planners really delay commitmen ts to plan step orderings and to v ariable bindings/.\\nArXiv ID: 9506101v1\\n')]\n",
      "rag_search.invoke(input={'query': 'LLMs (Large Language Models)'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nthe automatic realization that the problem splits in to disjoin t subproblems/. Other authors\\nha v e also discussed the idea of applying divide/-and/-conquer tec hniques to csp s /(Seidel/, /1/9/8/1/;\\nZabih/, /1/9/9/0/)/, but their metho ds su/\\x0ber from the disadv an tage that they constrain the order in\\nwhic h unassigned v ariables are assigned v alues/, p erhaps at o dds with the common heuristic\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: of assigning v alues /\\x0crst to those v ariables that are most tigh tly constrained/. Dynamic\\nbac ktrac king can also b e exp ected to b e of use in situations where the problem in question\\ndo es not split in to t w o or more disjoin t subproblems/.\\n/1\\n/6/. Exp erimen tation\\nDynamic bac ktrac king has b een incorp orated in to the crossw ord/-puzzle generation program\\ndescrib ed in /(Ginsb erg/, F rank/, Halpin/, /& T orrance/, /1/9/9/0/)/, and leads to signi/\\x0ccan t p erfor/-\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: FLECS: Planning with a Flexible Commitment Strategy\\nChunk: searc hing recursiv ely forw ard through the state space/, they searc h bac kw ards from the goal/.\\nTheir searc h is driv en b y the set of actions that can directly ac hiev e the goal/.\\nThere are t w o main w a ys of p erforming bac kw ard/-c haining/. Sev eral planners do re/-\\ngression b y searc hing the space of p ossible plans/. Planners/, suc h as no ah /, tweak /, snlp /,\\n/1/. Least/-commitmen t planners really delay commitmen ts to plan step orderings and to v ariable bindings/.\\nArXiv ID: 9506101v1\\n'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='Title: Learning the Past Tense of English Verbs: The Symbolic Pattern\\n  Associator vs. Connectionist Models\\nChunk: of language/.\\n/2/./2 MacWhinney and Lein bac h/\\'s Mo del\\nMacWhinney and Lein bac h /(/1/9/9/1/) rep ort a new connectionist mo del on the learning of the\\npast tenses of English v erbs/. They claim that the results from the new sim ulation are far\\nsup erior to Rumelhart and McClelland/\\'s results/, and that they can answ er most of the crit/-\\nicisms aimed at the earlier mo del/. The ma jor departure from Rumelhart and McClelland/\\'s\\nArXiv ID: 9402101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: learning mo del is the class of one/-clause constan t/-depth determinate programs with at most\\na constan t n um b er of /\\\\closed/\" recursiv e literals/. The largest learnable class w e iden tify\\nthat requires extra /\\\\hin ts/\" is the class of constan t/-depth determinate programs consisting\\nof a single nonrecursiv e base clause and a single recursiv e clause from the class describ ed\\nab o v e/. All of our results are pro v ed in the mo del of identi/\\x0cc ation fr om e quivalenc e queries\\nArXiv ID: 9505104v1\\n\\n---\\nTitle: An Integrated Framework for Learning and Reasoning\\nChunk: Ablex Publishing Corp/.\\nD /\\x14 zeroski/, S/./, Muggleton/, S/./, /& Russell/, S/. /(/1/9/9/3/)/. Learnabilit y of constrained logic programs/.\\nIn Pr o c e e dings of the Eur op e an Confer enc e on Machine L e arning /(ECML/\\'/9/3/)/, LNAI\\n/6/6/7 /, pp/. /3/4/2/{/3/4/7/.\\nElman/, J/. /(/1/9/9/1/)/. Incremen tal learning/, or the imp ortance of starting small/. T ec h/. rep/.\\nCRL /9/1/0/1/, Univ ersit y of California/, San Diego/, Cen ter for Researc h in Language/, La\\nJolla/, CA/.\\nArXiv ID: 9508102v1\\n\\n---\\nTitle: Operations for Learning with Graphical Models\\nChunk: Learning with Graphical Models\\nMcLac hlan/, G/. J/./, /& Basford/, K/. E/. /(/1/9/8/8/)/. Mixtur e Mo dels/: Infer enc e and Applic ations to\\nClustering /. New Y ork/: Marcel Dekk er/.\\nMeilijson/, I/. /(/1/9/8/9/)/. A fast impro v emen t to the EM algorithm on its o wn terms/. J/. R oy/.\\nStatist/. So c/. B /, /5/1 /(/1/)/, /1/2/7/{/1/3/8/.\\nMin ton/, S/./, Johnson/, M/./, Philips/, A/./, /& Laird/, P /. /(/1/9/9/0/)/. Solving large/-scale constrain t/-\\nArXiv ID: 9412102v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\n/2/./3 A Mo del of Learnabilit y\\nIn this section/, w e will presen t our mo del of learnabilit y /. W e will /\\x0crst review the necessary\\nde/\\x0cnitions for a standard learning mo del/, the mo del of learning from equiv alence queries\\n/(Angluin/, /1/9/8/8/, /1/9/8/9/)/, and discuss its relationship to other learning mo dels/. W e will then\\nin tro duce an extension to this mo del whic h is necessary for analyzing ILP problems/.\\nArXiv ID: 9505104v1\\n')]\n",
      "web_search.invoke(input={'query': 'Dynamic Backtracking AI'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nthe automatic realization that the problem splits in to disjoin t subproblems/. Other authors\\nha v e also discussed the idea of applying divide/-and/-conquer tec hniques to csp s /(Seidel/, /1/9/8/1/;\\nZabih/, /1/9/9/0/)/, but their metho ds su/\\x0ber from the disadv an tage that they constrain the order in\\nwhic h unassigned v ariables are assigned v alues/, p erhaps at o dds with the common heuristic\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: of assigning v alues /\\x0crst to those v ariables that are most tigh tly constrained/. Dynamic\\nbac ktrac king can also b e exp ected to b e of use in situations where the problem in question\\ndo es not split in to t w o or more disjoin t subproblems/.\\n/1\\n/6/. Exp erimen tation\\nDynamic bac ktrac king has b een incorp orated in to the crossw ord/-puzzle generation program\\ndescrib ed in /(Ginsb erg/, F rank/, Halpin/, /& T orrance/, /1/9/9/0/)/, and leads to signi/\\x0ccan t p erfor/-\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: FLECS: Planning with a Flexible Commitment Strategy\\nChunk: searc hing recursiv ely forw ard through the state space/, they searc h bac kw ards from the goal/.\\nTheir searc h is driv en b y the set of actions that can directly ac hiev e the goal/.\\nThere are t w o main w a ys of p erforming bac kw ard/-c haining/. Sev eral planners do re/-\\ngression b y searc hing the space of p ossible plans/. Planners/, suc h as no ah /, tweak /, snlp /,\\n/1/. Least/-commitmen t planners really delay commitmen ts to plan step orderings and to v ariable bindings/.\\nArXiv ID: 9506101v1\\n'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='Title: Learning the Past Tense of English Verbs: The Symbolic Pattern\\n  Associator vs. Connectionist Models\\nChunk: of language/.\\n/2/./2 MacWhinney and Lein bac h/\\'s Mo del\\nMacWhinney and Lein bac h /(/1/9/9/1/) rep ort a new connectionist mo del on the learning of the\\npast tenses of English v erbs/. They claim that the results from the new sim ulation are far\\nsup erior to Rumelhart and McClelland/\\'s results/, and that they can answ er most of the crit/-\\nicisms aimed at the earlier mo del/. The ma jor departure from Rumelhart and McClelland/\\'s\\nArXiv ID: 9402101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: learning mo del is the class of one/-clause constan t/-depth determinate programs with at most\\na constan t n um b er of /\\\\closed/\" recursiv e literals/. The largest learnable class w e iden tify\\nthat requires extra /\\\\hin ts/\" is the class of constan t/-depth determinate programs consisting\\nof a single nonrecursiv e base clause and a single recursiv e clause from the class describ ed\\nab o v e/. All of our results are pro v ed in the mo del of identi/\\x0cc ation fr om e quivalenc e queries\\nArXiv ID: 9505104v1\\n\\n---\\nTitle: An Integrated Framework for Learning and Reasoning\\nChunk: Ablex Publishing Corp/.\\nD /\\x14 zeroski/, S/./, Muggleton/, S/./, /& Russell/, S/. /(/1/9/9/3/)/. Learnabilit y of constrained logic programs/.\\nIn Pr o c e e dings of the Eur op e an Confer enc e on Machine L e arning /(ECML/\\'/9/3/)/, LNAI\\n/6/6/7 /, pp/. /3/4/2/{/3/4/7/.\\nElman/, J/. /(/1/9/9/1/)/. Incremen tal learning/, or the imp ortance of starting small/. T ec h/. rep/.\\nCRL /9/1/0/1/, Univ ersit y of California/, San Diego/, Cen ter for Researc h in Language/, La\\nJolla/, CA/.\\nArXiv ID: 9508102v1\\n\\n---\\nTitle: Operations for Learning with Graphical Models\\nChunk: Learning with Graphical Models\\nMcLac hlan/, G/. J/./, /& Basford/, K/. E/. /(/1/9/8/8/)/. Mixtur e Mo dels/: Infer enc e and Applic ations to\\nClustering /. New Y ork/: Marcel Dekk er/.\\nMeilijson/, I/. /(/1/9/8/9/)/. A fast impro v emen t to the EM algorithm on its o wn terms/. J/. R oy/.\\nStatist/. So c/. B /, /5/1 /(/1/)/, /1/2/7/{/1/3/8/.\\nMin ton/, S/./, Johnson/, M/./, Philips/, A/./, /& Laird/, P /. /(/1/9/9/0/)/. Solving large/-scale constrain t/-\\nArXiv ID: 9412102v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\n/2/./3 A Mo del of Learnabilit y\\nIn this section/, w e will presen t our mo del of learnabilit y /. W e will /\\x0crst review the necessary\\nde/\\x0cnitions for a standard learning mo del/, the mo del of learning from equiv alence queries\\n/(Angluin/, /1/9/8/8/, /1/9/8/9/)/, and discuss its relationship to other learning mo dels/. W e will then\\nin tro duce an extension to this mo del whic h is necessary for analyzing ILP problems/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Dynamic Backtracking\\nThe technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and ...\\nhttps://arxiv.org/pdf/cs.AI/9308101\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nDynamic backtracking | Journal of Artificial Intelligence ...\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://dl.acm.org/doi/10.5555/1618595.1618597\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf')]\n",
      "web_search.invoke(input={'query': 'LLMs (Large Language Models)'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nthe automatic realization that the problem splits in to disjoin t subproblems/. Other authors\\nha v e also discussed the idea of applying divide/-and/-conquer tec hniques to csp s /(Seidel/, /1/9/8/1/;\\nZabih/, /1/9/9/0/)/, but their metho ds su/\\x0ber from the disadv an tage that they constrain the order in\\nwhic h unassigned v ariables are assigned v alues/, p erhaps at o dds with the common heuristic\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: of assigning v alues /\\x0crst to those v ariables that are most tigh tly constrained/. Dynamic\\nbac ktrac king can also b e exp ected to b e of use in situations where the problem in question\\ndo es not split in to t w o or more disjoin t subproblems/.\\n/1\\n/6/. Exp erimen tation\\nDynamic bac ktrac king has b een incorp orated in to the crossw ord/-puzzle generation program\\ndescrib ed in /(Ginsb erg/, F rank/, Halpin/, /& T orrance/, /1/9/9/0/)/, and leads to signi/\\x0ccan t p erfor/-\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: FLECS: Planning with a Flexible Commitment Strategy\\nChunk: searc hing recursiv ely forw ard through the state space/, they searc h bac kw ards from the goal/.\\nTheir searc h is driv en b y the set of actions that can directly ac hiev e the goal/.\\nThere are t w o main w a ys of p erforming bac kw ard/-c haining/. Sev eral planners do re/-\\ngression b y searc hing the space of p ossible plans/. Planners/, suc h as no ah /, tweak /, snlp /,\\n/1/. Least/-commitmen t planners really delay commitmen ts to plan step orderings and to v ariable bindings/.\\nArXiv ID: 9506101v1\\n'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='Title: Learning the Past Tense of English Verbs: The Symbolic Pattern\\n  Associator vs. Connectionist Models\\nChunk: of language/.\\n/2/./2 MacWhinney and Lein bac h/\\'s Mo del\\nMacWhinney and Lein bac h /(/1/9/9/1/) rep ort a new connectionist mo del on the learning of the\\npast tenses of English v erbs/. They claim that the results from the new sim ulation are far\\nsup erior to Rumelhart and McClelland/\\'s results/, and that they can answ er most of the crit/-\\nicisms aimed at the earlier mo del/. The ma jor departure from Rumelhart and McClelland/\\'s\\nArXiv ID: 9402101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: learning mo del is the class of one/-clause constan t/-depth determinate programs with at most\\na constan t n um b er of /\\\\closed/\" recursiv e literals/. The largest learnable class w e iden tify\\nthat requires extra /\\\\hin ts/\" is the class of constan t/-depth determinate programs consisting\\nof a single nonrecursiv e base clause and a single recursiv e clause from the class describ ed\\nab o v e/. All of our results are pro v ed in the mo del of identi/\\x0cc ation fr om e quivalenc e queries\\nArXiv ID: 9505104v1\\n\\n---\\nTitle: An Integrated Framework for Learning and Reasoning\\nChunk: Ablex Publishing Corp/.\\nD /\\x14 zeroski/, S/./, Muggleton/, S/./, /& Russell/, S/. /(/1/9/9/3/)/. Learnabilit y of constrained logic programs/.\\nIn Pr o c e e dings of the Eur op e an Confer enc e on Machine L e arning /(ECML/\\'/9/3/)/, LNAI\\n/6/6/7 /, pp/. /3/4/2/{/3/4/7/.\\nElman/, J/. /(/1/9/9/1/)/. Incremen tal learning/, or the imp ortance of starting small/. T ec h/. rep/.\\nCRL /9/1/0/1/, Univ ersit y of California/, San Diego/, Cen ter for Researc h in Language/, La\\nJolla/, CA/.\\nArXiv ID: 9508102v1\\n\\n---\\nTitle: Operations for Learning with Graphical Models\\nChunk: Learning with Graphical Models\\nMcLac hlan/, G/. J/./, /& Basford/, K/. E/. /(/1/9/8/8/)/. Mixtur e Mo dels/: Infer enc e and Applic ations to\\nClustering /. New Y ork/: Marcel Dekk er/.\\nMeilijson/, I/. /(/1/9/8/9/)/. A fast impro v emen t to the EM algorithm on its o wn terms/. J/. R oy/.\\nStatist/. So c/. B /, /5/1 /(/1/)/, /1/2/7/{/1/3/8/.\\nMin ton/, S/./, Johnson/, M/./, Philips/, A/./, /& Laird/, P /. /(/1/9/9/0/)/. Solving large/-scale constrain t/-\\nArXiv ID: 9412102v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\n/2/./3 A Mo del of Learnabilit y\\nIn this section/, w e will presen t our mo del of learnabilit y /. W e will /\\x0crst review the necessary\\nde/\\x0cnitions for a standard learning mo del/, the mo del of learning from equiv alence queries\\n/(Angluin/, /1/9/8/8/, /1/9/8/9/)/, and discuss its relationship to other learning mo dels/. W e will then\\nin tro duce an extension to this mo del whic h is necessary for analyzing ILP problems/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI'}, log='Dynamic Backtracking\\nThe technique developed is a variant of dependency-directed backtracking that uses only polynomial space while still providing useful control information and ...\\nhttps://arxiv.org/pdf/cs.AI/9308101\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nDynamic backtracking | Journal of Artificial Intelligence ...\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://dl.acm.org/doi/10.5555/1618595.1618597\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf'), AgentAction(tool='web_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs (Large Language Models)'}, log='Large language model\\nA large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation.\\nhttps://en.wikipedia.org/wiki/Large_language_model\\n---\\nWhat is LLM? - Large Language Models Explained\\nLarge language models, also known as LLMs, are very large deep learning models that are pre-trained on vast amounts of data. The underlying transformer is a ...\\nhttps://aws.amazon.com/what-is/large-language-model/\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/topics/large-language-models\\n---\\nWhat is a large language model (LLM)?\\nLarge language models (LLMs) are machine learning models that can comprehend and generate human language text. Learn how LLMs work and their security risks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/')]\n",
      "final_answer.invoke(input={'introduction': 'Dynamic Backtracking and Large Language Models (LLMs) are two fascinating areas in the field of artificial intelligence. Dynamic Backtracking is a method used to enhance the efficiency of search algorithms, while LLMs are advanced AI models designed for natural language processing tasks.', 'research_steps': '1. Conducted a specialized search on Dynamic Backtracking AI using the RAG search tool.\\n2. Conducted a specialized search on LLMs using the RAG search tool.\\n3. Performed a web search for additional information on Dynamic Backtracking AI.\\n4. Performed a web search for additional information on LLMs.', 'main_body': 'Dynamic Backtracking is a variant of dependency-directed backtracking that optimizes the search process by moving backtrack points deeper into the search space. This technique is particularly useful in constraint satisfaction problems (CSPs) where it helps in reducing the number of nodes examined, thus saving computational resources. The method has been applied in various AI subfields, including planning and vision, and has been incorporated into applications like crossword-puzzle generation, demonstrating significant performance improvements.\\n\\nOn the other hand, Large Language Models (LLMs) are a type of deep learning model designed for natural language processing tasks. These models, such as GPT-3, are pre-trained on vast amounts of text data and are capable of understanding and generating human-like text. LLMs utilize transformer architectures, which allow them to process and generate language with remarkable fluency and coherence. They have a wide range of applications, from chatbots and virtual assistants to content creation and translation services. However, their large size and complexity also pose challenges, including high computational costs and potential biases in generated content.', 'conclusion': 'Dynamic Backtracking and LLMs represent significant advancements in AI, each addressing different challenges within the field. While Dynamic Backtracking enhances search efficiency in CSPs, LLMs push the boundaries of what is possible in natural language processing. Both technologies continue to evolve, offering exciting possibilities for future AI applications.', 'sources': '- Journal of Artificial Intelligence Research\\n- ArXiv papers on Dynamic Backtracking\\n- Wikipedia and IBM articles on Large Language Models\\n- AWS and Cloudflare resources on LLMs'})\n"
     ]
    }
   ],
   "source": [
    "# Run the graph with input.\n",
    "output = runnable.invoke({\n",
    "    'input': 'Tell me something interesting about Dynamic Backtracking AI and LLMs',\n",
    "    'chat_history': [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb34cf34-34b0-4ca3-8cc8-174d0a7d316d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'introduction': 'Dynamic Backtracking and Large Language Models (LLMs) are two fascinating areas in the field of artificial intelligence. Dynamic Backtracking is a method used to enhance the efficiency of search algorithms, while LLMs are advanced AI models designed for natural language processing tasks.',\n",
       " 'research_steps': '1. Conducted a specialized search on Dynamic Backtracking AI using the RAG search tool.\\n2. Conducted a specialized search on LLMs using the RAG search tool.\\n3. Performed a web search for additional information on Dynamic Backtracking AI.\\n4. Performed a web search for additional information on LLMs.',\n",
       " 'main_body': 'Dynamic Backtracking is a variant of dependency-directed backtracking that optimizes the search process by moving backtrack points deeper into the search space. This technique is particularly useful in constraint satisfaction problems (CSPs) where it helps in reducing the number of nodes examined, thus saving computational resources. The method has been applied in various AI subfields, including planning and vision, and has been incorporated into applications like crossword-puzzle generation, demonstrating significant performance improvements.\\n\\nOn the other hand, Large Language Models (LLMs) are a type of deep learning model designed for natural language processing tasks. These models, such as GPT-3, are pre-trained on vast amounts of text data and are capable of understanding and generating human-like text. LLMs utilize transformer architectures, which allow them to process and generate language with remarkable fluency and coherence. They have a wide range of applications, from chatbots and virtual assistants to content creation and translation services. However, their large size and complexity also pose challenges, including high computational costs and potential biases in generated content.',\n",
       " 'conclusion': 'Dynamic Backtracking and LLMs represent significant advancements in AI, each addressing different challenges within the field. While Dynamic Backtracking enhances search efficiency in CSPs, LLMs push the boundaries of what is possible in natural language processing. Both technologies continue to evolve, offering exciting possibilities for future AI applications.',\n",
       " 'sources': '- Journal of Artificial Intelligence Research\\n- ArXiv papers on Dynamic Backtracking\\n- Wikipedia and IBM articles on Large Language Models\\n- AWS and Cloudflare resources on LLMs'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['intermediate_steps'][-1].tool_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21e5d884-5780-44ee-8817-cc6690869a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['introduction', 'research_steps', 'main_body', 'conclusion', 'sources'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['intermediate_steps'][-1].tool_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b4afd25-443f-4699-986e-719f20ac2366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        INTRODUCTION\n",
      "        ------------\n",
      "        Dynamic Backtracking and Large Language Models (LLMs) are two fascinating areas in the field of artificial intelligence. Dynamic Backtracking is a method used to enhance the efficiency of search algorithms, while LLMs are advanced AI models designed for natural language processing tasks.\n",
      "        \n",
      "        RESEARCH STEPS\n",
      "        --------------\n",
      "        1. Conducted a specialized search on Dynamic Backtracking AI using the RAG search tool.\n",
      "2. Conducted a specialized search on LLMs using the RAG search tool.\n",
      "3. Performed a web search for additional information on Dynamic Backtracking AI.\n",
      "4. Performed a web search for additional information on LLMs.\n",
      "        \n",
      "        REPORT\n",
      "        ------\n",
      "        Dynamic Backtracking is a variant of dependency-directed backtracking that optimizes the search process by moving backtrack points deeper into the search space. This technique is particularly useful in constraint satisfaction problems (CSPs) where it helps in reducing the number of nodes examined, thus saving computational resources. The method has been applied in various AI subfields, including planning and vision, and has been incorporated into applications like crossword-puzzle generation, demonstrating significant performance improvements.\n",
      "\n",
      "On the other hand, Large Language Models (LLMs) are a type of deep learning model designed for natural language processing tasks. These models, such as GPT-3, are pre-trained on vast amounts of text data and are capable of understanding and generating human-like text. LLMs utilize transformer architectures, which allow them to process and generate language with remarkable fluency and coherence. They have a wide range of applications, from chatbots and virtual assistants to content creation and translation services. However, their large size and complexity also pose challenges, including high computational costs and potential biases in generated content.\n",
      "        \n",
      "        CONCLUSION\n",
      "        ----------\n",
      "        Dynamic Backtracking and LLMs represent significant advancements in AI, each addressing different challenges within the field. While Dynamic Backtracking enhances search efficiency in CSPs, LLMs push the boundaries of what is possible in natural language processing. Both technologies continue to evolve, offering exciting possibilities for future AI applications.\n",
      "        \n",
      "        SOURCES\n",
      "        -------\n",
      "        - Journal of Artificial Intelligence Research\n",
      "- ArXiv papers on Dynamic Backtracking\n",
      "- Wikipedia and IBM articles on Large Language Models\n",
      "- AWS and Cloudflare resources on LLMs\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "report = build_report(\n",
    "    output=output['intermediate_steps'][-1].tool_input\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8be09b44-2caf-4050-9c92-5e8f532074a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "        INTRODUCTION\n",
       "        ------------\n",
       "        Dynamic Backtracking and Large Language Models (LLMs) are two fascinating areas in the field of artificial intelligence. Dynamic Backtracking is a method used to enhance the efficiency of search algorithms, while LLMs are advanced AI models designed for natural language processing tasks.\n",
       "        \n",
       "        RESEARCH STEPS\n",
       "        --------------\n",
       "        1. Conducted a specialized search on Dynamic Backtracking AI using the RAG search tool.\n",
       "2. Conducted a specialized search on LLMs using the RAG search tool.\n",
       "3. Performed a web search for additional information on Dynamic Backtracking AI.\n",
       "4. Performed a web search for additional information on LLMs.\n",
       "        \n",
       "        REPORT\n",
       "        ------\n",
       "        Dynamic Backtracking is a variant of dependency-directed backtracking that optimizes the search process by moving backtrack points deeper into the search space. This technique is particularly useful in constraint satisfaction problems (CSPs) where it helps in reducing the number of nodes examined, thus saving computational resources. The method has been applied in various AI subfields, including planning and vision, and has been incorporated into applications like crossword-puzzle generation, demonstrating significant performance improvements.\n",
       "\n",
       "On the other hand, Large Language Models (LLMs) are a type of deep learning model designed for natural language processing tasks. These models, such as GPT-3, are pre-trained on vast amounts of text data and are capable of understanding and generating human-like text. LLMs utilize transformer architectures, which allow them to process and generate language with remarkable fluency and coherence. They have a wide range of applications, from chatbots and virtual assistants to content creation and translation services. However, their large size and complexity also pose challenges, including high computational costs and potential biases in generated content.\n",
       "        \n",
       "        CONCLUSION\n",
       "        ----------\n",
       "        Dynamic Backtracking and LLMs represent significant advancements in AI, each addressing different challenges within the field. While Dynamic Backtracking enhances search efficiency in CSPs, LLMs push the boundaries of what is possible in natural language processing. Both technologies continue to evolve, offering exciting possibilities for future AI applications.\n",
       "        \n",
       "        SOURCES\n",
       "        -------\n",
       "        - Journal of Artificial Intelligence Research\n",
       "- ArXiv papers on Dynamic Backtracking\n",
       "- Wikipedia and IBM articles on Large Language Models\n",
       "- AWS and Cloudflare resources on LLMs\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "797f230f-157e-4533-aea4-8df81d2ace77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_oracle\n",
      "intermediate_steps: []\n",
      "web_search.invoke(input={'query': 'FIFA World Cup 2026 overview'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'FIFA World Cup 2026 overview'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'FIFA World Cup 2026 overview'}, log='FIFA World Cup 26™\\nThe FIFA World Cup 26™ will be the 23rd edition of the tournament but the first to feature 48 teams and three host countries: Canada, Mexico and the United ...\\nhttps://www.fifa.com/en/tournaments/mens/worldcup/canadamexicousa2026\\n---\\n2026 FIFA World Cup\\nThe tournament will take place from June 11 to July 19, 2026. It will be jointly hosted by 16 cities in three North American countries: Canada, Mexico, and the ...\\nhttps://en.wikipedia.org/wiki/2026_FIFA_World_Cup')]\n",
      "rag_search.invoke(input={'query': 'FIFA World Cup 2026 details'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'FIFA World Cup 2026 overview'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'FIFA World Cup 2026 overview'}, log='FIFA World Cup 26™\\nThe FIFA World Cup 26™ will be the 23rd edition of the tournament but the first to feature 48 teams and three host countries: Canada, Mexico and the United ...\\nhttps://www.fifa.com/en/tournaments/mens/worldcup/canadamexicousa2026\\n---\\n2026 FIFA World Cup\\nThe tournament will take place from June 11 to July 19, 2026. It will be jointly hosted by 16 cities in three North American countries: Canada, Mexico, and the ...\\nhttps://en.wikipedia.org/wiki/2026_FIFA_World_Cup'), AgentAction(tool='rag_search', tool_input={'query': 'FIFA World Cup 2026 details'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'FIFA World Cup 2026 details'}, log=\"Title: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\ns\\ns\\ns s s/BnZr\\n/BnZr\\n/BnZr\\n/BnZr\\n/BnZr\\n/BnZr\\n/BnZr\\n/BnZr /@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@\\n/@ /BnZr\\n/BnZr\\n/BnZr\\n/BnZr\\n/BnZr\\n/BnZr\\n/BnZr\\n/BnZr\\nAlbania\\nDenmark\\nEngland\\nBulgaria\\nCzec hoslo v akia\\nFigure /1/: A small map/-coloring problem\\ncoun try color red y ello w blue\\nAlbania red\\nBulgaria y ello w\\nCzec hoslo v akia blue A\\nDenmark\\nEngland\\nF or eac h coun try /, w e indicate its curren t color and the eliminating explanations that mean\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: Czec hoslo v akia/'s color w on/'t help and w e m ust deal with Bulgaria instead/. The elimination\\nlists are no w/:\\ncoun try color red y ello w blue\\nAlbania red\\nBulgaria\\nCzec hoslo v akia blue A\\nDenmark A B A/,B\\nEngland A B\\nW e remo v e the eliminating explanations in v olving Bulgaria and also add to Bulgaria/'s elim/-\\nination list the pair\\n/(y ello w /; A /)\\nindicating correctly that Bulgaria cannot b e colored y ello w b ecause of the curren t c hoice of\\ncolor for Albania /(red/)/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: Ginsber g\\ncoun try color red y ello w blue\\nAlbania red\\nBulgaria y ello w\\nCzec hoslo v akia blue A\\nDenmark A B\\nEngland A B\\nNext/, w e add to Denmark/'s elimination list the pair\\n/(blue /; f A/; B g /)\\nThis indicates correctly that b ecause of the curren t colors for Albania and Bulgaria/, Den/-\\nmark cannot b e colored blue /(b ecause of the subsequen t dead end at England/)/. Since ev ery\\ncolor is no w eliminated/, w e m ust bac ktrac k to a coun try in the set f A/; B g /. Changing\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: p oin t/, the elimination lists are as follo ws/:\\ncoun try color red y ello w blue\\nAlbania red\\nBulgaria y ello w\\nCzec hoslo v akia blue A\\nDenmark blue A B\\nEngland A B D\\nW e bac ktrac k to Denmark b ecause it is the most recen t of the three p ossibilities/, and\\nb egin b y remo ving an y eliminating explanation in v olving Denmark from the ab o v e table to\\nget/:\\n/3/3\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Using Pivot Consistency to Decompose and Solve Functional CSPs\\nChunk: D a vid\\nCURRENCIES\\nPes\\n/$\\nF rF\\nLANGUA GES\\nF r ench\\nEnglish\\nSp anish\\nCOUNTRIES\\nF r anc e GB USA Sp ain\\nCITIES\\nParis\\nL ondon\\nWashington\\nNew/-Y ork\\nMadrid\\nGUIDES\\nA\\nB\\nC\\n/$\\nCURRENCIES LANGUA GES\\nCITIES GUIDES\\nCOUNTRIES\\nFigure /9/: After Pivot /( COUNTRIES/,LANGUA GES /)\\nW e no w detail these computations/:\\n/\\x0f Computation of Pivot /( COUNTRIES/,LANGUA GES /) /(Figure /9/)/:\\nW e p erform Compatible /( COUNTRIES/,LANGUA GES/,COUNTRIES /) whic h do es not\\nArXiv ID: 9505101v1\\n\")]\n",
      "final_answer.invoke(input={'introduction': 'The FIFA World Cup 2026 is set to be a landmark event in the history of international football, marking the first time the tournament will feature 48 teams and be hosted across three countries.', 'research_steps': '1. Conducted a web search to gather general information about the FIFA World Cup 2026.\\n2. Utilized a specialized AI search to find detailed insights about the event.', 'main_body': 'The FIFA World Cup 2026 will be the 23rd edition of the tournament and is scheduled to take place from June 11 to July 19, 2026. This edition is particularly significant as it will be the first to expand the number of participating teams from 32 to 48, allowing for a broader representation of countries from around the world. The tournament will be jointly hosted by three North American countries: Canada, Mexico, and the United States. This marks the first time the World Cup will be hosted by three nations, and the first time since 1994 that the United States will host the event. Mexico will be hosting the World Cup for the third time, having previously hosted in 1970 and 1986, while Canada will be hosting for the first time.\\n\\nThe decision to expand the tournament to 48 teams was made to increase global participation and interest in the sport. The format will include a total of 80 matches, with the final match scheduled to be held in the United States. The host cities will include major metropolitan areas across the three countries, providing a diverse cultural experience for fans and players alike.\\n\\nThe expansion and the tri-nation hosting are expected to bring significant economic benefits to the host countries, with increased tourism and global attention. The event is also seen as an opportunity to promote unity and collaboration among the host nations, showcasing their ability to work together on a global stage.', 'conclusion': 'The FIFA World Cup 2026 promises to be a groundbreaking event, with its expanded format and unique hosting arrangement. It is set to offer an exciting and inclusive experience for football fans worldwide, while also fostering international cooperation and cultural exchange.', 'sources': '1. FIFA official website: https://www.fifa.com/en/tournaments/mens/worldcup/canadamexicousa2026\\n2. Wikipedia: https://en.wikipedia.org/wiki/2026_FIFA_World_Cup'})\n"
     ]
    }
   ],
   "source": [
    "output = runnable.invoke({\n",
    "    'input': 'tell me about FIFA World Cup 26',\n",
    "    'chat_history': []  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9529d8ec-e901-4e19-a0df-c4dfa4ba0109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "        INTRODUCTION\n",
       "        ------------\n",
       "        The FIFA World Cup 2026 is set to be a landmark event in the history of international football, marking the first time the tournament will feature 48 teams and be hosted across three countries.\n",
       "        \n",
       "        RESEARCH STEPS\n",
       "        --------------\n",
       "        1. Conducted a web search to gather general information about the FIFA World Cup 2026.\n",
       "2. Utilized a specialized AI search to find detailed insights about the event.\n",
       "        \n",
       "        REPORT\n",
       "        ------\n",
       "        The FIFA World Cup 2026 will be the 23rd edition of the tournament and is scheduled to take place from June 11 to July 19, 2026. This edition is particularly significant as it will be the first to expand the number of participating teams from 32 to 48, allowing for a broader representation of countries from around the world. The tournament will be jointly hosted by three North American countries: Canada, Mexico, and the United States. This marks the first time the World Cup will be hosted by three nations, and the first time since 1994 that the United States will host the event. Mexico will be hosting the World Cup for the third time, having previously hosted in 1970 and 1986, while Canada will be hosting for the first time.\n",
       "\n",
       "The decision to expand the tournament to 48 teams was made to increase global participation and interest in the sport. The format will include a total of 80 matches, with the final match scheduled to be held in the United States. The host cities will include major metropolitan areas across the three countries, providing a diverse cultural experience for fans and players alike.\n",
       "\n",
       "The expansion and the tri-nation hosting are expected to bring significant economic benefits to the host countries, with increased tourism and global attention. The event is also seen as an opportunity to promote unity and collaboration among the host nations, showcasing their ability to work together on a global stage.\n",
       "        \n",
       "        CONCLUSION\n",
       "        ----------\n",
       "        The FIFA World Cup 2026 promises to be a groundbreaking event, with its expanded format and unique hosting arrangement. It is set to offer an exciting and inclusive experience for football fans worldwide, while also fostering international cooperation and cultural exchange.\n",
       "        \n",
       "        SOURCES\n",
       "        -------\n",
       "        1. FIFA official website: https://www.fifa.com/en/tournaments/mens/worldcup/canadamexicousa2026\n",
       "2. Wikipedia: https://en.wikipedia.org/wiki/2026_FIFA_World_Cup\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = build_report(\n",
    "    output=output['intermediate_steps'][-1].tool_input\n",
    ")\n",
    "\n",
    "# print(report)\n",
    "display(Markdown(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b9d1ded-e949-4f9a-8813-cb79d9ead5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_oracle\n",
      "intermediate_steps: []\n",
      "fetch_arxiv.invoke(input={'arxiv_id': '2409.17990'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='This paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune Temporal Adapters for Llama 3 8B on full timelines from a panel of British Twitter users, and extract longitudinal aggregates of emotions and attitudes with established questionnaires. We validate our estimates against representative British survey data and find strong positive, significant correlations for several collective emotions. The obtained estimates are robust across multiple training seeds and prompt formulations, and in line with collective emotions extracted using a traditional classification model trained on labeled data. To the best of our knowledge, this is the first work to extend the analysis of affect in LLMs to a longitudinal setting through Temporal Adapters. Our work enables new approaches towards the longitudinal analysis of social media data.')]\n",
      "rag_search_filter.invoke(input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='This paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune Temporal Adapters for Llama 3 8B on full timelines from a panel of British Twitter users, and extract longitudinal aggregates of emotions and attitudes with established questionnaires. We validate our estimates against representative British survey data and find strong positive, significant correlations for several collective emotions. The obtained estimates are robust across multiple training seeds and prompt formulations, and in line with collective emotions extracted using a traditional classification model trained on labeled data. To the best of our knowledge, this is the first work to extend the analysis of affect in LLMs to a longitudinal setting through Temporal Adapters. Our work enables new approaches towards the longitudinal analysis of social media data.'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log='')]\n",
      "rag_search_filter.invoke(input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='This paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune Temporal Adapters for Llama 3 8B on full timelines from a panel of British Twitter users, and extract longitudinal aggregates of emotions and attitudes with established questionnaires. We validate our estimates against representative British survey data and find strong positive, significant correlations for several collective emotions. The obtained estimates are robust across multiple training seeds and prompt formulations, and in line with collective emotions extracted using a traditional classification model trained on labeled data. To the best of our knowledge, this is the first work to extend the analysis of affect in LLMs to a longitudinal setting through Temporal Adapters. Our work enables new approaches towards the longitudinal analysis of social media data.'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log=''), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log='')]\n",
      "rag_search.invoke(input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='This paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune Temporal Adapters for Llama 3 8B on full timelines from a panel of British Twitter users, and extract longitudinal aggregates of emotions and attitudes with established questionnaires. We validate our estimates against representative British survey data and find strong positive, significant correlations for several collective emotions. The obtained estimates are robust across multiple training seeds and prompt formulations, and in line with collective emotions extracted using a traditional classification model trained on labeled data. To the best of our knowledge, this is the first work to extend the analysis of affect in LLMs to a longitudinal setting through Temporal Adapters. Our work enables new approaches towards the longitudinal analysis of social media data.'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log=''), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log=''), AgentAction(tool='rag_search', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media'}, log='Title: Operations for Learning with Graphical Models\\nChunk: Learning with Graphical Models\\nMcLac hlan/, G/. J/./, /& Basford/, K/. E/. /(/1/9/8/8/)/. Mixtur e Mo dels/: Infer enc e and Applic ations to\\nClustering /. New Y ork/: Marcel Dekk er/.\\nMeilijson/, I/. /(/1/9/8/9/)/. A fast impro v emen t to the EM algorithm on its o wn terms/. J/. R oy/.\\nStatist/. So c/. B /, /5/1 /(/1/)/, /1/2/7/{/1/3/8/.\\nMin ton/, S/./, Johnson/, M/./, Philips/, A/./, /& Laird/, P /. /(/1/9/9/0/)/. Solving large/-scale constrain t/-\\nArXiv ID: 9412102v1\\n\\n---\\nTitle: Diffusion of Context and Credit Information in Markovian Models\\nChunk: tially an application of established mathematical results on Mark o v c hains to the problem\\nof learning long term dep endencies in homogeneous and non/-homogeneous HMMs/. These\\nargumen ts w ere also supp orted b y exp erimen ts on arti/\\x0ccial data/, studying the phenomenon\\nof di/\\x0busion of credit and the corresp onding di/\\x0ecult y in training HMMs to learn long/-term\\ndep endencies/.\\nIOHMMs /(Bengio /& F rasconi/, /1/9/9/4/, /1/9/9/5b/) and POMDPs /(Sondik/, /1/9/7/3/, /1/9/7/8/; Chris/-\\nArXiv ID: 9510101v1\\n\\n---\\nTitle: Diffusion of Context and Credit Information in Markovian Models\\nChunk: AI idea of using a m ulti/-scale represen tation/. The state v ariable is decomp osed in to sev eral\\n/\\\\sub/-state/\" v ariables /(whose Cartesian pro duct is equal to the /\\\\full/\" state v ariable/)/, eac h\\nop erating at a di/\\x0beren t time scale/. The a/-priori assumption is that long/-term con text will\\nb e represen ted b y /\\\\slo w/\" state v ariables/, whic h m ust b e insensitiv e to the precise timing of\\nev en ts/. This allo ws the propagation of con text /(and credit/, for learning/) o v er long durations\\nArXiv ID: 9510101v1\\n\\n---\\nTitle: Diffusion of Context and Credit Information in Markovian Models\\nChunk: con tin uous optimization/, suc h as gradien t descen t and the Baum/-W elc h algorithm/.\\n/1/. In tro duction\\nProblems of learning on temp oral domains can b e signi/\\x0ccan tly hindered b y the presence\\nof long/-term dep endencies in the training data/. A sequence of random v ariables /(e/.g/./,\\na sequence of observ ations f y\\n/1\\n/; y\\n/2\\n/; /: /: /: y\\nt\\n/; /: /: /: y\\nT\\ng /, denoted y\\nT\\n/1\\n/) is said to exhibit long/-term\\ndep endencies if the v ariables y\\nt\\nArXiv ID: 9510101v1\\n\\n---\\nTitle: Learning the Past Tense of English Verbs: The Symbolic Pattern\\n  Associator vs. Connectionist Models\\nChunk: of language/.\\n/2/./2 MacWhinney and Lein bac h/\\'s Mo del\\nMacWhinney and Lein bac h /(/1/9/9/1/) rep ort a new connectionist mo del on the learning of the\\npast tenses of English v erbs/. They claim that the results from the new sim ulation are far\\nsup erior to Rumelhart and McClelland/\\'s results/, and that they can answ er most of the crit/-\\nicisms aimed at the earlier mo del/. The ma jor departure from Rumelhart and McClelland/\\'s\\nArXiv ID: 9402101v1\\n')]\n",
      "web_search.invoke(input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='fetch_arxiv', tool_input={'arxiv_id': '2409.17990'}, log='This paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune Temporal Adapters for Llama 3 8B on full timelines from a panel of British Twitter users, and extract longitudinal aggregates of emotions and attitudes with established questionnaires. We validate our estimates against representative British survey data and find strong positive, significant correlations for several collective emotions. The obtained estimates are robust across multiple training seeds and prompt formulations, and in line with collective emotions extracted using a traditional classification model trained on labeled data. To the best of our knowledge, this is the first work to extend the analysis of affect in LLMs to a longitudinal setting through Temporal Adapters. Our work enables new approaches towards the longitudinal analysis of social media data.'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log=''), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media', 'arxiv_id': '2409.17990'}, log=''), AgentAction(tool='rag_search', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media'}, log='Title: Operations for Learning with Graphical Models\\nChunk: Learning with Graphical Models\\nMcLac hlan/, G/. J/./, /& Basford/, K/. E/. /(/1/9/8/8/)/. Mixtur e Mo dels/: Infer enc e and Applic ations to\\nClustering /. New Y ork/: Marcel Dekk er/.\\nMeilijson/, I/. /(/1/9/8/9/)/. A fast impro v emen t to the EM algorithm on its o wn terms/. J/. R oy/.\\nStatist/. So c/. B /, /5/1 /(/1/)/, /1/2/7/{/1/3/8/.\\nMin ton/, S/./, Johnson/, M/./, Philips/, A/./, /& Laird/, P /. /(/1/9/9/0/)/. Solving large/-scale constrain t/-\\nArXiv ID: 9412102v1\\n\\n---\\nTitle: Diffusion of Context and Credit Information in Markovian Models\\nChunk: tially an application of established mathematical results on Mark o v c hains to the problem\\nof learning long term dep endencies in homogeneous and non/-homogeneous HMMs/. These\\nargumen ts w ere also supp orted b y exp erimen ts on arti/\\x0ccial data/, studying the phenomenon\\nof di/\\x0busion of credit and the corresp onding di/\\x0ecult y in training HMMs to learn long/-term\\ndep endencies/.\\nIOHMMs /(Bengio /& F rasconi/, /1/9/9/4/, /1/9/9/5b/) and POMDPs /(Sondik/, /1/9/7/3/, /1/9/7/8/; Chris/-\\nArXiv ID: 9510101v1\\n\\n---\\nTitle: Diffusion of Context and Credit Information in Markovian Models\\nChunk: AI idea of using a m ulti/-scale represen tation/. The state v ariable is decomp osed in to sev eral\\n/\\\\sub/-state/\" v ariables /(whose Cartesian pro duct is equal to the /\\\\full/\" state v ariable/)/, eac h\\nop erating at a di/\\x0beren t time scale/. The a/-priori assumption is that long/-term con text will\\nb e represen ted b y /\\\\slo w/\" state v ariables/, whic h m ust b e insensitiv e to the precise timing of\\nev en ts/. This allo ws the propagation of con text /(and credit/, for learning/) o v er long durations\\nArXiv ID: 9510101v1\\n\\n---\\nTitle: Diffusion of Context and Credit Information in Markovian Models\\nChunk: con tin uous optimization/, suc h as gradien t descen t and the Baum/-W elc h algorithm/.\\n/1/. In tro duction\\nProblems of learning on temp oral domains can b e signi/\\x0ccan tly hindered b y the presence\\nof long/-term dep endencies in the training data/. A sequence of random v ariables /(e/.g/./,\\na sequence of observ ations f y\\n/1\\n/; y\\n/2\\n/; /: /: /: y\\nt\\n/; /: /: /: y\\nT\\ng /, denoted y\\nT\\n/1\\n/) is said to exhibit long/-term\\ndep endencies if the v ariables y\\nt\\nArXiv ID: 9510101v1\\n\\n---\\nTitle: Learning the Past Tense of English Verbs: The Symbolic Pattern\\n  Associator vs. Connectionist Models\\nChunk: of language/.\\n/2/./2 MacWhinney and Lein bac h/\\'s Mo del\\nMacWhinney and Lein bac h /(/1/9/9/1/) rep ort a new connectionist mo del on the learning of the\\npast tenses of English v erbs/. They claim that the results from the new sim ulation are far\\nsup erior to Rumelhart and McClelland/\\'s results/, and that they can answ er most of the crit/-\\nicisms aimed at the earlier mo del/. The ma jor departure from Rumelhart and McClelland/\\'s\\nArXiv ID: 9402101v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'temporally aligned Large Language Models for longitudinal analysis of social media'}, log='Extracting Affect Aggregates from Longitudinal Social ...\\nThis paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data.\\nhttps://arxiv.org/abs/2409.17990\\n---\\narXiv:2409.17990v1 [cs.CY] 26 Sep 2024\\nAbstract. This paper proposes temporally aligned Large Language. Models (LLMs) as a tool for longitudinal analysis of social media data.\\nhttps://arxiv.org/pdf/2409.17990\\n---\\nA Temporal Psycholinguistics Approach to Identity ...\\nThis paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune ...\\nhttps://www.aimodels.fyi/papers/arxiv/temporal-psycholinguistics-approach-to-identity-resolution-social\\n---\\nA Systematic Analysis on the Temporal Generalization of ...\\nWe propose a unified evaluation scheme to assess the performance of language models (LMs) under temporal shift on standard social media tasks.\\nhttps://www.researchgate.net/publication/380820386_A_Systematic_Analysis_on_the_Temporal_Generalization_of_Language_Models_in_Social_Media\\n---\\nyizhongw/llm-temporal-alignment: Methods and evaluation ...\\nOur work investigates the temporal chaos of pretrained LMs and explores various methods to align their internal knowledge to a target time.\\nhttps://github.com/yizhongw/llm-temporal-alignment')]\n",
      "final_answer.invoke(input={'introduction': 'The paper with ArXiv ID 2409.17990 explores the innovative use of temporally aligned Large Language Models (LLMs) for the longitudinal analysis of social media data. This research aims to enhance the understanding of social media trends over time by leveraging advanced machine learning techniques.', 'research_steps': '1. Retrieved the abstract of the paper using the ArXiv ID.\\n2. Attempted to gather more detailed information using a specialized ArXiv search filter.\\n3. Conducted a general web search to find additional context and related studies.', 'main_body': \"The paper introduces a novel approach by fine-tuning Temporal Adapters for the Llama 3 8B model on comprehensive timelines from a panel of British Twitter users. This method allows for the extraction of longitudinal aggregates of emotions and attitudes using established questionnaires. The researchers validated their estimates against representative British survey data, finding strong positive correlations for several collective emotions. This validation suggests that the model's estimates are robust across different training seeds and prompt formulations. Furthermore, the results align with those obtained using traditional classification models trained on labeled data. This study is pioneering in extending the analysis of affect in LLMs to a longitudinal setting through the use of Temporal Adapters, offering new methodologies for analyzing social media data over time.\", 'conclusion': 'The research presented in this paper marks a significant advancement in the field of social media analysis by introducing temporally aligned LLMs. This approach not only provides robust and validated estimates of collective emotions but also opens new avenues for longitudinal studies in social media analytics.', 'sources': '- ArXiv abstract and paper: https://arxiv.org/abs/2409.17990\\n- Web search results on related topics and methodologies.'})\n"
     ]
    }
   ],
   "source": [
    "output = runnable.invoke({\n",
    "    'input': 'Create a summary about this AxXiv paper with the ID 2409.17990',\n",
    "    'chat_history': []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d3787b2-550d-43be-af54-06c3a3d1a37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "        INTRODUCTION\n",
       "        ------------\n",
       "        The paper with ArXiv ID 2409.17990 explores the innovative use of temporally aligned Large Language Models (LLMs) for the longitudinal analysis of social media data. This research aims to enhance the understanding of social media trends over time by leveraging advanced machine learning techniques.\n",
       "        \n",
       "        RESEARCH STEPS\n",
       "        --------------\n",
       "        1. Retrieved the abstract of the paper using the ArXiv ID.\n",
       "2. Attempted to gather more detailed information using a specialized ArXiv search filter.\n",
       "3. Conducted a general web search to find additional context and related studies.\n",
       "        \n",
       "        REPORT\n",
       "        ------\n",
       "        The paper introduces a novel approach by fine-tuning Temporal Adapters for the Llama 3 8B model on comprehensive timelines from a panel of British Twitter users. This method allows for the extraction of longitudinal aggregates of emotions and attitudes using established questionnaires. The researchers validated their estimates against representative British survey data, finding strong positive correlations for several collective emotions. This validation suggests that the model's estimates are robust across different training seeds and prompt formulations. Furthermore, the results align with those obtained using traditional classification models trained on labeled data. This study is pioneering in extending the analysis of affect in LLMs to a longitudinal setting through the use of Temporal Adapters, offering new methodologies for analyzing social media data over time.\n",
       "        \n",
       "        CONCLUSION\n",
       "        ----------\n",
       "        The research presented in this paper marks a significant advancement in the field of social media analysis by introducing temporally aligned LLMs. This approach not only provides robust and validated estimates of collective emotions but also opens new avenues for longitudinal studies in social media analytics.\n",
       "        \n",
       "        SOURCES\n",
       "        -------\n",
       "        - ArXiv abstract and paper: https://arxiv.org/abs/2409.17990\n",
       "- Web search results on related topics and methodologies.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = build_report(\n",
    "    output=output['intermediate_steps'][-1].tool_input\n",
    ")\n",
    "\n",
    "# print(report)\n",
    "display(Markdown(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb7bf988-20e5-4209-8203-cdb3cd5e2113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        INTRODUCTION\n",
      "        ------------\n",
      "        The paper with ArXiv ID 2409.17990 explores the innovative use of temporally aligned Large Language Models (LLMs) for the longitudinal analysis of social media data. This research aims to enhance the understanding of social media trends over time by leveraging advanced machine learning techniques.\n",
      "        \n",
      "        RESEARCH STEPS\n",
      "        --------------\n",
      "        1. Retrieved the abstract of the paper using the ArXiv ID.\n",
      "2. Attempted to gather more detailed information using a specialized ArXiv search filter.\n",
      "3. Conducted a general web search to find additional context and related studies.\n",
      "        \n",
      "        REPORT\n",
      "        ------\n",
      "        The paper introduces a novel approach by fine-tuning Temporal Adapters for the Llama 3 8B model on comprehensive timelines from a panel of British Twitter users. This method allows for the extraction of longitudinal aggregates of emotions and attitudes using established questionnaires. The researchers validated their estimates against representative British survey data, finding strong positive correlations for several collective emotions. This validation suggests that the model's estimates are robust across different training seeds and prompt formulations. Furthermore, the results align with those obtained using traditional classification models trained on labeled data. This study is pioneering in extending the analysis of affect in LLMs to a longitudinal setting through the use of Temporal Adapters, offering new methodologies for analyzing social media data over time.\n",
      "        \n",
      "        CONCLUSION\n",
      "        ----------\n",
      "        The research presented in this paper marks a significant advancement in the field of social media analysis by introducing temporally aligned LLMs. This approach not only provides robust and validated estimates of collective emotions but also opens new avenues for longitudinal studies in social media analytics.\n",
      "        \n",
      "        SOURCES\n",
      "        -------\n",
      "        - ArXiv abstract and paper: https://arxiv.org/abs/2409.17990\n",
      "- Web search results on related topics and methodologies.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8fe667db-7d63-495a-be72-09620eff07d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_oracle\n",
      "intermediate_steps: []\n",
      "rag_search.invoke(input={'query': 'future of LLM Agents'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log=\"Title: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nHo w ev er/, to use suc h abstract kno wledge/, studen ts m ust learn ho w it applies to sp eci/\\x0cc\\nsituations /(Singley /& Anderson/, /1/9/8/9/)/.\\n/9/./2 Limitations of the Agen t\\nAn agen t/'s inheren t limitations constrain what it can b e taugh t/. W e ha v e dev elop ed our\\ntheory of learning from tutorial instruction within a particular computational mo del of\\nagen ts /(the PSCM/)/, and within this computational mo del/, w e implemen ted an agen t with\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nreceiv ed little atten tion in AI/, it has the p oten tial to b e a p o w erful kno wledge source for\\narti/\\x0ccial agen ts as w ell/.\\nMuc h of tutorial instruction/'s p o w er comes from its c ommunic ative /\\rexibility /: The in/-\\nstructor can comm unicate whatev er t yp e of kno wledge a studen t ma y need in whatev er\\nsituation it is needed/. The c hallenge in designing a tutorable agen t is to supp ort the\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: e ach agent has only one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achieving\\nthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c an\\nb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.\\nPro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear that\\nit migh t learn only facts ab out the p ossible initial states and b eha viors/.\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: Provably Bounded-Optimal Agents\\nChunk: /3/./2 Sp ecifying agen t implemen tations\\nW e will consider a ph ysical agen t as consisting of an arc hitecture and a program/. The\\narc hitecture is resp onsible for in terfacing b et w een the program and the en vironmen t/, and\\nfor running the program itself/. With eac h arc hitecture M /, w e asso ciate a /\\x0cnite programming\\nlanguage L\\nM\\n/, whic h is just the set of all programs runnable b y the arc hitecture/. An agent\\npr o gr am is a program l /2 L\\nM\\nArXiv ID: 9505103v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: Safra and Tennenhol tz\\n/6/./2 Multi/-Agen t Systems\\nAnother in teresting extension is concerned with the case where there is more than one agen t\\nin the system/. F or ease of exp osition/, w e will assume that there are t w o agen ts that generate\\nactions/.\\n/4\\nAn in teresting feature of the m ulti/-agen t case is that an agen t migh t not b e familiar\\nwith the goal and the initial state of the other agen t/. Hence/, Planning while Learning refers\\nArXiv ID: 9409101v1\\n\")]\n",
      "web_search.invoke(input={'query': 'future of LLM Agents'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log=\"Title: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nHo w ev er/, to use suc h abstract kno wledge/, studen ts m ust learn ho w it applies to sp eci/\\x0cc\\nsituations /(Singley /& Anderson/, /1/9/8/9/)/.\\n/9/./2 Limitations of the Agen t\\nAn agen t/'s inheren t limitations constrain what it can b e taugh t/. W e ha v e dev elop ed our\\ntheory of learning from tutorial instruction within a particular computational mo del of\\nagen ts /(the PSCM/)/, and within this computational mo del/, w e implemen ted an agen t with\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nreceiv ed little atten tion in AI/, it has the p oten tial to b e a p o w erful kno wledge source for\\narti/\\x0ccial agen ts as w ell/.\\nMuc h of tutorial instruction/'s p o w er comes from its c ommunic ative /\\rexibility /: The in/-\\nstructor can comm unicate whatev er t yp e of kno wledge a studen t ma y need in whatev er\\nsituation it is needed/. The c hallenge in designing a tutorable agen t is to supp ort the\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: e ach agent has only one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achieving\\nthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c an\\nb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.\\nPro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear that\\nit migh t learn only facts ab out the p ossible initial states and b eha viors/.\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: Provably Bounded-Optimal Agents\\nChunk: /3/./2 Sp ecifying agen t implemen tations\\nW e will consider a ph ysical agen t as consisting of an arc hitecture and a program/. The\\narc hitecture is resp onsible for in terfacing b et w een the program and the en vironmen t/, and\\nfor running the program itself/. With eac h arc hitecture M /, w e asso ciate a /\\x0cnite programming\\nlanguage L\\nM\\n/, whic h is just the set of all programs runnable b y the arc hitecture/. An agent\\npr o gr am is a program l /2 L\\nM\\nArXiv ID: 9505103v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: Safra and Tennenhol tz\\n/6/./2 Multi/-Agen t Systems\\nAnother in teresting extension is concerned with the case where there is more than one agen t\\nin the system/. F or ease of exp osition/, w e will assume that there are t w o agen ts that generate\\nactions/.\\n/4\\nAn in teresting feature of the m ulti/-agen t case is that an agen t migh t not b e familiar\\nwith the goal and the initial state of the other agen t/. Hence/, Planning while Learning refers\\nArXiv ID: 9409101v1\\n\"), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log='The Future of LLM-Based Agents: Making the Boxes Bigger\\nPutting long-term plans together, with the ability for agents to adapt and reflect at each sub-goal enables them to solve higher order tasks ...\\nhttps://www.arcus.co/blog/ai-agents-pt-2\\n---\\nLLM Agents: Their Past, Present, and Future | by Saurabh Harak\\nThe future of LLM agents is not just about creating smarter machines but about enhancing human capabilities and solving real-world problems ...\\nhttps://saurabhharak.medium.com/llm-agents-their-past-present-and-future-22988c29a5f8\\n---\\nMulti-Agent LLM Systems: The Future of Collaborative AI\\nThis is the exciting world of Multi-Agent LLM Systems, where multiple AI agents powered by LLMs work together to tackle complex tasks.\\nhttps://www.linkedin.com/pulse/multi-agent-llm-systems-future-collaborative-ai-anish-agarwal-rahsc\\n---\\nThinking through the future for LLM companies... and what ...\\nIt seems inevitable that as the underlying foundation models become more powerful, the LLM players will seek to justify the enormous investment ...\\nhttps://www.sarahtavel.com/p/thinking-through-the-future-for-llm')]\n",
      "rag_search_filter.invoke(input={'query': 'future of LLM Agents', 'arxiv_id': '9511101v1'})\n",
      "run_oracle\n",
      "intermediate_steps: [AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'future of LLM Agents'}, log=\"Title: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nHo w ev er/, to use suc h abstract kno wledge/, studen ts m ust learn ho w it applies to sp eci/\\x0cc\\nsituations /(Singley /& Anderson/, /1/9/8/9/)/.\\n/9/./2 Limitations of the Agen t\\nAn agen t/'s inheren t limitations constrain what it can b e taugh t/. W e ha v e dev elop ed our\\ntheory of learning from tutorial instruction within a particular computational mo del of\\nagen ts /(the PSCM/)/, and within this computational mo del/, w e implemen ted an agen t with\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nreceiv ed little atten tion in AI/, it has the p oten tial to b e a p o w erful kno wledge source for\\narti/\\x0ccial agen ts as w ell/.\\nMuc h of tutorial instruction/'s p o w er comes from its c ommunic ative /\\rexibility /: The in/-\\nstructor can comm unicate whatev er t yp e of kno wledge a studen t ma y need in whatev er\\nsituation it is needed/. The c hallenge in designing a tutorable agen t is to supp ort the\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: e ach agent has only one go al/, if an e/\\x0ecient satisfactory multi/-agent plan for achieving\\nthese go als exists/, then ther e exists such an e/\\x0ecient satisfactory multi/-agent plan that c an\\nb e enc o de d in p olynomial sp ac e/, and b e veri/\\x0ce d in p olynomial time/.\\nPro of/: In this case eac h agen t kno ws the goal of the other agen t/, and hence it is clear that\\nit migh t learn only facts ab out the p ossible initial states and b eha viors/.\\nArXiv ID: 9409101v1\\n\\n---\\nTitle: Provably Bounded-Optimal Agents\\nChunk: /3/./2 Sp ecifying agen t implemen tations\\nW e will consider a ph ysical agen t as consisting of an arc hitecture and a program/. The\\narc hitecture is resp onsible for in terfacing b et w een the program and the en vironmen t/, and\\nfor running the program itself/. With eac h arc hitecture M /, w e asso ciate a /\\x0cnite programming\\nlanguage L\\nM\\n/, whic h is just the set of all programs runnable b y the arc hitecture/. An agent\\npr o gr am is a program l /2 L\\nM\\nArXiv ID: 9505103v1\\n\\n---\\nTitle: On Planning while Learning\\nChunk: Safra and Tennenhol tz\\n/6/./2 Multi/-Agen t Systems\\nAnother in teresting extension is concerned with the case where there is more than one agen t\\nin the system/. F or ease of exp osition/, w e will assume that there are t w o agen ts that generate\\nactions/.\\n/4\\nAn in teresting feature of the m ulti/-agen t case is that an agen t migh t not b e familiar\\nwith the goal and the initial state of the other agen t/. Hence/, Planning while Learning refers\\nArXiv ID: 9409101v1\\n\"), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'future of LLM Agents'}, log='The Future of LLM-Based Agents: Making the Boxes Bigger\\nPutting long-term plans together, with the ability for agents to adapt and reflect at each sub-goal enables them to solve higher order tasks ...\\nhttps://www.arcus.co/blog/ai-agents-pt-2\\n---\\nLLM Agents: Their Past, Present, and Future | by Saurabh Harak\\nThe future of LLM agents is not just about creating smarter machines but about enhancing human capabilities and solving real-world problems ...\\nhttps://saurabhharak.medium.com/llm-agents-their-past-present-and-future-22988c29a5f8\\n---\\nMulti-Agent LLM Systems: The Future of Collaborative AI\\nThis is the exciting world of Multi-Agent LLM Systems, where multiple AI agents powered by LLMs work together to tackle complex tasks.\\nhttps://www.linkedin.com/pulse/multi-agent-llm-systems-future-collaborative-ai-anish-agarwal-rahsc\\n---\\nThinking through the future for LLM companies... and what ...\\nIt seems inevitable that as the underlying foundation models become more powerful, the LLM players will seek to justify the enormous investment ...\\nhttps://www.sarahtavel.com/p/thinking-through-the-future-for-llm'), AgentAction(tool='rag_search_filter', tool_input={'query': 'future of LLM Agents', 'arxiv_id': '9511101v1'}, log='TBD'), AgentAction(tool='rag_search_filter', tool_input={'query': 'future of LLM Agents', 'arxiv_id': '9511101v1'}, log='Title: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nHo w ev er/, to use suc h abstract kno wledge/, studen ts m ust learn ho w it applies to sp eci/\\x0cc\\nsituations /(Singley /& Anderson/, /1/9/8/9/)/.\\n/9/./2 Limitations of the Agen t\\nAn agen t/\\'s inheren t limitations constrain what it can b e taugh t/. W e ha v e dev elop ed our\\ntheory of learning from tutorial instruction within a particular computational mo del of\\nagen ts /(the PSCM/)/, and within this computational mo del/, w e implemen ted an agen t with\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nreceiv ed little atten tion in AI/, it has the p oten tial to b e a p o w erful kno wledge source for\\narti/\\x0ccial agen ts as w ell/.\\nMuc h of tutorial instruction/\\'s p o w er comes from its c ommunic ative /\\rexibility /: The in/-\\nstructor can comm unicate whatev er t yp e of kno wledge a studen t ma y need in whatev er\\nsituation it is needed/. The c hallenge in designing a tutorable agen t is to supp ort the\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: Flexibly Instructable Agents\\nChunk: circumstances is large and v ariable o v er time /(as it will b e for a general agen t/)/, it b ecomes\\nnearly imp ossible to preprogram all of the kno wledge required/. Th us/, kno wledge m ust\\nb e added during the agen t/\\'s lifetime/. Unfortunately /, suc h kno wledge cannot b e added to\\ncurren t in telligen t systems while they p erform/; they m ust b e sh ut do wn and programmed\\nfor eac h new task/.\\nThis w ork examines an alternativ e/: in telligen t agen ts that can b e taught to p erform tasks\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nHu/\\x0bman/, S/. B/. /(/1/9/9/4/)/. Instructable autonomous agents /. Ph/.D/. thesis/, Univ ersit y of Mic hi/-\\ngan/, Dept/. of Electrical Engineering and Computer Science/.\\nHu/\\x0bman/, S/. B/./, /& Laird/, J/. E/. /(/1/9/9/2/)/. Dimensions of complexit y in learning from in teractiv e\\ninstruction/. In Eric kson/, J/. /(Ed/./)/, Pr o c e e dings of Co op er ative Intel ligent R ob otics in\\nSp ac e III/, SPIE V olume /1/8/2/9 /.\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: Flexibly Instructable Agents\\nChunk: domain kno wledge using outside guidance/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /.\\nLaird/, J/. E/./, New ell/, A/./, /& Rosen blo om/, P /. S/. /(/1/9/8/7/)/. Soar/: An arc hitecture for general\\nin telligence/. A rti/\\x0ccial Intel ligenc e /, /3/3 /(/1/)/, /1/{/6/4/.\\n/3/2/0\\nArXiv ID: 9511101v1\\n\\n---\\nTitle: Flexibly Instructable Agents\\nChunk: Huffman /& Laird\\nThis limits the instructor/\\'s abilit y to driv e the in teraction or to in terrupt the agen t/\\'s actions\\nwith instruction/: /\\\\No/! Don/\\'t push that button/!/\"\\n/1/8\\n/( I\\n/2\\n/)/: Instr ucto/-So ar pro vides /\\rexibilit y for commands/, but not for instructions that\\ncomm unicate other kinds of information/. Similar to the notion of discourse coherence /(Mann\\n/& Thompson/, /1/9/8/8/)/, a fully /\\rexible tutorable agen t needs to supp ort an y instruction ev en t\\nArXiv ID: 9511101v1\\n')]\n",
      "final_answer.invoke(input={'introduction': 'The future of Large Language Model (LLM) Agents is a topic of significant interest in the field of artificial intelligence. These agents, powered by advanced language models, are expected to revolutionize various domains by enhancing human capabilities and solving complex problems.', 'research_steps': '1. Conducted a specialized search on AI-focused databases to gather insights on the future of LLM Agents.\\n2. Performed a web search to collect diverse perspectives and recent developments related to LLM Agents.\\n3. Filtered specific ArXiv papers to extract detailed academic insights on the topic.', 'main_body': 'LLM Agents are poised to become more flexible and instructable, allowing them to adapt to a wide range of tasks and environments. This adaptability is crucial as it enables agents to learn and apply abstract knowledge to specific situations, a feature that has been relatively unexplored but holds great potential for artificial intelligence. The development of these agents involves creating systems that can be taught new tasks during their operational lifetime, rather than requiring shutdowns for reprogramming.\\n\\nThe future of LLM Agents also involves their integration into multi-agent systems, where they can collaborate to tackle complex tasks. This collaborative approach is expected to enhance the efficiency and effectiveness of AI systems, allowing them to solve higher-order problems that require coordination and communication among multiple agents.\\n\\nMoreover, the evolution of LLM Agents is not just about creating smarter machines but also about augmenting human capabilities. By working alongside humans, these agents can help solve real-world problems, making them invaluable tools in various sectors, including healthcare, finance, and education. As the underlying models become more powerful, the potential applications of LLM Agents will continue to expand, justifying the significant investments being made in this technology.', 'conclusion': 'In conclusion, the future of LLM Agents is bright, with advancements in flexibility, collaboration, and human augmentation. These agents are set to play a crucial role in the next wave of AI innovations, offering solutions to complex challenges and enhancing human productivity. As research and development continue, we can expect LLM Agents to become even more integral to our daily lives and industries.', 'sources': '1. ArXiv papers on Flexibly Instructable Agents and Multi-Agent Systems.\\n2. Articles from Arcus, Medium, and LinkedIn discussing the future of LLM Agents.\\n3. Various online resources providing insights into the development and potential of LLM Agents.'})\n",
      "\n",
      "        INTRODUCTION\n",
      "        ------------\n",
      "        The future of Large Language Model (LLM) Agents is a topic of significant interest in the field of artificial intelligence. These agents, powered by advanced language models, are expected to revolutionize various domains by enhancing human capabilities and solving complex problems.\n",
      "        \n",
      "        RESEARCH STEPS\n",
      "        --------------\n",
      "        1. Conducted a specialized search on AI-focused databases to gather insights on the future of LLM Agents.\n",
      "2. Performed a web search to collect diverse perspectives and recent developments related to LLM Agents.\n",
      "3. Filtered specific ArXiv papers to extract detailed academic insights on the topic.\n",
      "        \n",
      "        REPORT\n",
      "        ------\n",
      "        LLM Agents are poised to become more flexible and instructable, allowing them to adapt to a wide range of tasks and environments. This adaptability is crucial as it enables agents to learn and apply abstract knowledge to specific situations, a feature that has been relatively unexplored but holds great potential for artificial intelligence. The development of these agents involves creating systems that can be taught new tasks during their operational lifetime, rather than requiring shutdowns for reprogramming.\n",
      "\n",
      "The future of LLM Agents also involves their integration into multi-agent systems, where they can collaborate to tackle complex tasks. This collaborative approach is expected to enhance the efficiency and effectiveness of AI systems, allowing them to solve higher-order problems that require coordination and communication among multiple agents.\n",
      "\n",
      "Moreover, the evolution of LLM Agents is not just about creating smarter machines but also about augmenting human capabilities. By working alongside humans, these agents can help solve real-world problems, making them invaluable tools in various sectors, including healthcare, finance, and education. As the underlying models become more powerful, the potential applications of LLM Agents will continue to expand, justifying the significant investments being made in this technology.\n",
      "        \n",
      "        CONCLUSION\n",
      "        ----------\n",
      "        In conclusion, the future of LLM Agents is bright, with advancements in flexibility, collaboration, and human augmentation. These agents are set to play a crucial role in the next wave of AI innovations, offering solutions to complex challenges and enhancing human productivity. As research and development continue, we can expect LLM Agents to become even more integral to our daily lives and industries.\n",
      "        \n",
      "        SOURCES\n",
      "        -------\n",
      "        1. ArXiv papers on Flexibly Instructable Agents and Multi-Agent Systems.\n",
      "2. Articles from Arcus, Medium, and LinkedIn discussing the future of LLM Agents.\n",
      "3. Various online resources providing insights into the development and potential of LLM Agents.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "output = runnable.invoke({\n",
    "    'input': 'Create a summary about the future of LLM Agents.',\n",
    "    'chat_history': []\n",
    "})\n",
    "\n",
    "report = build_report(\n",
    "    output=output['intermediate_steps'][-1].tool_input\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c91dd655-56f4-4c1c-b412-d3e671cc0860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "        INTRODUCTION\n",
       "        ------------\n",
       "        The future of Large Language Model (LLM) Agents is a topic of significant interest in the field of artificial intelligence. These agents, powered by advanced language models, are expected to revolutionize various domains by enhancing human capabilities and solving complex problems.\n",
       "        \n",
       "        RESEARCH STEPS\n",
       "        --------------\n",
       "        1. Conducted a specialized search on AI-focused databases to gather insights on the future of LLM Agents.\n",
       "2. Performed a web search to collect diverse perspectives and recent developments related to LLM Agents.\n",
       "3. Filtered specific ArXiv papers to extract detailed academic insights on the topic.\n",
       "        \n",
       "        REPORT\n",
       "        ------\n",
       "        LLM Agents are poised to become more flexible and instructable, allowing them to adapt to a wide range of tasks and environments. This adaptability is crucial as it enables agents to learn and apply abstract knowledge to specific situations, a feature that has been relatively unexplored but holds great potential for artificial intelligence. The development of these agents involves creating systems that can be taught new tasks during their operational lifetime, rather than requiring shutdowns for reprogramming.\n",
       "\n",
       "The future of LLM Agents also involves their integration into multi-agent systems, where they can collaborate to tackle complex tasks. This collaborative approach is expected to enhance the efficiency and effectiveness of AI systems, allowing them to solve higher-order problems that require coordination and communication among multiple agents.\n",
       "\n",
       "Moreover, the evolution of LLM Agents is not just about creating smarter machines but also about augmenting human capabilities. By working alongside humans, these agents can help solve real-world problems, making them invaluable tools in various sectors, including healthcare, finance, and education. As the underlying models become more powerful, the potential applications of LLM Agents will continue to expand, justifying the significant investments being made in this technology.\n",
       "        \n",
       "        CONCLUSION\n",
       "        ----------\n",
       "        In conclusion, the future of LLM Agents is bright, with advancements in flexibility, collaboration, and human augmentation. These agents are set to play a crucial role in the next wave of AI innovations, offering solutions to complex challenges and enhancing human productivity. As research and development continue, we can expect LLM Agents to become even more integral to our daily lives and industries.\n",
       "        \n",
       "        SOURCES\n",
       "        -------\n",
       "        1. ArXiv papers on Flexibly Instructable Agents and Multi-Agent Systems.\n",
       "2. Articles from Arcus, Medium, and LinkedIn discussing the future of LLM Agents.\n",
       "3. Various online resources providing insights into the development and potential of LLM Agents.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a509c28-63f4-47aa-8c00-dff76604ba1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
