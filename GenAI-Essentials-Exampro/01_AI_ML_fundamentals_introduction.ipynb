{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70c6cbb-32d9-4bed-a6d3-395b3ce25d79",
   "metadata": {},
   "source": [
    "# AI and ML Fundamentals\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2755fc5-74bd-4b19-bedd-e4964189b6d1",
   "metadata": {},
   "source": [
    "## Jupyter AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f75d6b1-ef03-4365-ba69-eab569640de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade pip\n",
    "!pip install jupyter-ai[all]\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe846404-82cd-454e-befe-89802d1adc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3ed79f-d516-4b11-9bda-cdf083f6919f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OPENAI_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OPENAI_API_KEY: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c31ac9c-632a-4c3b-abdf-92ad28c917ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1aafe-2fd6-4400-a1b8-39d2f77bfffc",
   "metadata": {},
   "source": [
    "### Listing all available providers and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ab356d-b839-4b7e-9255-ef5e8beb354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`ai21:j1-large`</li><li>`ai21:j1-grande`</li><li>`ai21:j1-jumbo`</li><li>`ai21:j1-grande-instruct`</li><li>`ai21:j2-large`</li><li>`ai21:j2-grande`</li><li>`ai21:j2-jumbo`</li><li>`ai21:j2-grande-instruct`</li><li>`ai21:j2-jumbo-instruct`</li></ul> |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock:amazon.titan-text-express-v1`</li><li>`bedrock:amazon.titan-text-lite-v1`</li><li>`bedrock:amazon.titan-text-premier-v1:0`</li><li>`bedrock:ai21.j2-ultra-v1`</li><li>`bedrock:ai21.j2-mid-v1`</li><li>`bedrock:ai21.jamba-instruct-v1:0`</li><li>`bedrock:cohere.command-light-text-v14`</li><li>`bedrock:cohere.command-text-v14`</li><li>`bedrock:cohere.command-r-v1:0`</li><li>`bedrock:cohere.command-r-plus-v1:0`</li><li>`bedrock:meta.llama2-13b-chat-v1`</li><li>`bedrock:meta.llama2-70b-chat-v1`</li><li>`bedrock:meta.llama3-8b-instruct-v1:0`</li><li>`bedrock:meta.llama3-70b-instruct-v1:0`</li><li>`bedrock:meta.llama3-1-8b-instruct-v1:0`</li><li>`bedrock:meta.llama3-1-70b-instruct-v1:0`</li><li>`bedrock:meta.llama3-1-405b-instruct-v1:0`</li><li>`bedrock:mistral.mistral-7b-instruct-v0:2`</li><li>`bedrock:mistral.mixtral-8x7b-instruct-v0:1`</li><li>`bedrock:mistral.mistral-large-2402-v1:0`</li><li>`bedrock:mistral.mistral-large-2407-v1:0`</li></ul> |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock-chat:amazon.titan-text-express-v1`</li><li>`bedrock-chat:amazon.titan-text-lite-v1`</li><li>`bedrock-chat:amazon.titan-text-premier-v1:0`</li><li>`bedrock-chat:anthropic.claude-v2`</li><li>`bedrock-chat:anthropic.claude-v2:1`</li><li>`bedrock-chat:anthropic.claude-instant-v1`</li><li>`bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-opus-20240229-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-5-haiku-20241022-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-5-sonnet-20240620-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-5-sonnet-20241022-v2:0`</li><li>`bedrock-chat:meta.llama2-13b-chat-v1`</li><li>`bedrock-chat:meta.llama2-70b-chat-v1`</li><li>`bedrock-chat:meta.llama3-8b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-70b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-1-8b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-1-70b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-1-405b-instruct-v1:0`</li><li>`bedrock-chat:mistral.mistral-7b-instruct-v0:2`</li><li>`bedrock-chat:mistral.mixtral-8x7b-instruct-v0:1`</li><li>`bedrock-chat:mistral.mistral-large-2402-v1:0`</li><li>`bedrock-chat:mistral.mistral-large-2407-v1:0`</li></ul> |\n",
       "| `bedrock-custom` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | - For Cross-Region Inference use the appropriate `Inference profile ID` (Model ID with a region prefix, e.g., `us.meta.llama3-2-11b-instruct-v1:0`). See the [inference profiles documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html). \n",
       "- For custom/provisioned models, specify the model ARN (Amazon Resource Name) as the model ID. For more information, see the [Amazon Bedrock model IDs documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html).\n",
       "\n",
       "The model provider must also be specified below. This is the provider of your foundation model *in lowercase*, e.g., `amazon`, `anthropic`, `cohere`, `meta`, or `mistral`. |\n",
       "| `anthropic-chat` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`anthropic-chat:claude-2.0`</li><li>`anthropic-chat:claude-2.1`</li><li>`anthropic-chat:claude-3-opus-20240229`</li><li>`anthropic-chat:claude-3-sonnet-20240229`</li><li>`anthropic-chat:claude-3-haiku-20240307`</li><li>`anthropic-chat:claude-3-5-haiku-20241022`</li><li>`anthropic-chat:claude-3-5-sonnet-20240620`</li><li>`anthropic-chat:claude-3-5-sonnet-20241022`</li></ul> |\n",
       "| `azure-chat-openai` | `AZURE_OPENAI_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | This provider does not define a list of models. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`cohere:command`</li><li>`cohere:command-nightly`</li><li>`cohere:command-light`</li><li>`cohere:command-light-nightly`</li><li>`cohere:command-r-plus`</li><li>`cohere:command-r`</li></ul> |\n",
       "| `gemini` | `GOOGLE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`gemini:gemini-1.5-pro`</li><li>`gemini:gemini-1.5-flash`</li><li>`gemini:gemini-1.0-pro`</li><li>`gemini:gemini-1.0-pro-001`</li><li>`gemini:gemini-1.0-pro-latest`</li><li>`gemini:gemini-1.0-pro-vision-latest`</li><li>`gemini:gemini-pro`</li><li>`gemini:gemini-pro-vision`</li></ul> |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`gpt4all:ggml-gpt4all-j-v1.2-jazzy`</li><li>`gpt4all:ggml-gpt4all-j-v1.3-groovy`</li><li>`gpt4all:ggml-gpt4all-l13b-snoozy`</li><li>`gpt4all:mistral-7b-openorca.Q4_0`</li><li>`gpt4all:mistral-7b-instruct-v0.1.Q4_0`</li><li>`gpt4all:gpt4all-falcon-q4_0`</li><li>`gpt4all:wizardlm-13b-v1.2.Q4_0`</li><li>`gpt4all:nous-hermes-llama2-13b.Q4_0`</li><li>`gpt4all:gpt4all-13b-snoozy-q4_0`</li><li>`gpt4all:mpt-7b-chat-merges-q4_0`</li><li>`gpt4all:orca-mini-3b-gguf2-q4_0`</li><li>`gpt4all:starcoder-q4_0`</li><li>`gpt4all:rift-coder-v0-7b-q4_0`</li><li>`gpt4all:em_german_mistral_v01.Q4_0`</li></ul> |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `mistralai` | `MISTRAL_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`mistralai:open-mistral-7b`</li><li>`mistralai:open-mixtral-8x7b`</li><li>`mistralai:open-mixtral-8x22b`</li><li>`mistralai:mistral-small-latest`</li><li>`mistralai:mistral-medium-latest`</li><li>`mistralai:mistral-large-latest`</li><li>`mistralai:codestral-latest`</li></ul> |\n",
       "| `nvidia-chat` | `NVIDIA_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`nvidia-chat:playground_llama2_70b`</li><li>`nvidia-chat:playground_nemotron_steerlm_8b`</li><li>`nvidia-chat:playground_mistral_7b`</li><li>`nvidia-chat:playground_nv_llama2_rlhf_70b`</li><li>`nvidia-chat:playground_llama2_13b`</li><li>`nvidia-chat:playground_steerlm_llama_70b`</li><li>`nvidia-chat:playground_llama2_code_13b`</li><li>`nvidia-chat:playground_yi_34b`</li><li>`nvidia-chat:playground_mixtral_8x7b`</li><li>`nvidia-chat:playground_neva_22b`</li><li>`nvidia-chat:playground_llama2_code_34b`</li></ul> |\n",
       "| `ollama` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | See [https://www.ollama.com/library](https://www.ollama.com/library) for a list of models. Pass a model's name; for example, `deepseek-coder-v2`. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai-chat:gpt-3.5-turbo`</li><li>`openai-chat:gpt-3.5-turbo-1106`</li><li>`openai-chat:gpt-4`</li><li>`openai-chat:gpt-4-turbo`</li><li>`openai-chat:gpt-4-turbo-preview`</li><li>`openai-chat:gpt-4-0613`</li><li>`openai-chat:gpt-4-0125-preview`</li><li>`openai-chat:gpt-4-1106-preview`</li><li>`openai-chat:gpt-4o`</li><li>`openai-chat:gpt-4o-2024-11-20`</li><li>`openai-chat:gpt-4o-mini`</li><li>`openai-chat:chatgpt-4o-latest`</li></ul> |\n",
       "| `openrouter` | `OPENROUTER_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | This provider does not define a list of models. |\n",
       "| `qianfan` | `QIANFAN_AK`, `QIANFAN_SK` | <abbr title=\"You have not set all of these environment variables, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`qianfan:ERNIE-Bot`</li><li>`qianfan:ERNIE-Bot-4`</li></ul> |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deploy-models.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "| `togetherai` | `TOGETHER_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`togetherai:Austism/chronos-hermes-13b`</li><li>`togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2`</li><li>`togetherai:EleutherAI/llemma_7b`</li><li>`togetherai:Gryphe/MythoMax-L2-13b`</li><li>`togetherai:Meta-Llama/Llama-Guard-7b`</li><li>`togetherai:Nexusflow/NexusRaven-V2-13B`</li><li>`togetherai:NousResearch/Nous-Capybara-7B-V1p9`</li><li>`togetherai:NousResearch/Nous-Hermes-2-Yi-34B`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-13b`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-70b`</li></ul> |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:davinci-002` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `ernie-bot` | `qianfan:ERNIE-Bot` |\n",
       "| `ernie-bot-4` | `qianfan:ERNIE-Bot-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n",
       "| `openrouter-claude` | `openrouter:anthropic/claude-3.5-sonnet:beta` |\n"
      ],
      "text/plain": [
       "ai21\n",
       "Requires environment variable: AI21_API_KEY (not set)\n",
       "* ai21:j1-large\n",
       "* ai21:j1-grande\n",
       "* ai21:j1-jumbo\n",
       "* ai21:j1-grande-instruct\n",
       "* ai21:j2-large\n",
       "* ai21:j2-grande\n",
       "* ai21:j2-jumbo\n",
       "* ai21:j2-grande-instruct\n",
       "* ai21:j2-jumbo-instruct\n",
       "\n",
       "bedrock\n",
       "* bedrock:amazon.titan-text-express-v1\n",
       "* bedrock:amazon.titan-text-lite-v1\n",
       "* bedrock:amazon.titan-text-premier-v1:0\n",
       "* bedrock:ai21.j2-ultra-v1\n",
       "* bedrock:ai21.j2-mid-v1\n",
       "* bedrock:ai21.jamba-instruct-v1:0\n",
       "* bedrock:cohere.command-light-text-v14\n",
       "* bedrock:cohere.command-text-v14\n",
       "* bedrock:cohere.command-r-v1:0\n",
       "* bedrock:cohere.command-r-plus-v1:0\n",
       "* bedrock:meta.llama2-13b-chat-v1\n",
       "* bedrock:meta.llama2-70b-chat-v1\n",
       "* bedrock:meta.llama3-8b-instruct-v1:0\n",
       "* bedrock:meta.llama3-70b-instruct-v1:0\n",
       "* bedrock:meta.llama3-1-8b-instruct-v1:0\n",
       "* bedrock:meta.llama3-1-70b-instruct-v1:0\n",
       "* bedrock:meta.llama3-1-405b-instruct-v1:0\n",
       "* bedrock:mistral.mistral-7b-instruct-v0:2\n",
       "* bedrock:mistral.mixtral-8x7b-instruct-v0:1\n",
       "* bedrock:mistral.mistral-large-2402-v1:0\n",
       "* bedrock:mistral.mistral-large-2407-v1:0\n",
       "\n",
       "bedrock-chat\n",
       "* bedrock-chat:amazon.titan-text-express-v1\n",
       "* bedrock-chat:amazon.titan-text-lite-v1\n",
       "* bedrock-chat:amazon.titan-text-premier-v1:0\n",
       "* bedrock-chat:anthropic.claude-v2\n",
       "* bedrock-chat:anthropic.claude-v2:1\n",
       "* bedrock-chat:anthropic.claude-instant-v1\n",
       "* bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-opus-20240229-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-5-haiku-20241022-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-5-sonnet-20240620-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-5-sonnet-20241022-v2:0\n",
       "* bedrock-chat:meta.llama2-13b-chat-v1\n",
       "* bedrock-chat:meta.llama2-70b-chat-v1\n",
       "* bedrock-chat:meta.llama3-8b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-70b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-1-8b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-1-70b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-1-405b-instruct-v1:0\n",
       "* bedrock-chat:mistral.mistral-7b-instruct-v0:2\n",
       "* bedrock-chat:mistral.mixtral-8x7b-instruct-v0:1\n",
       "* bedrock-chat:mistral.mistral-large-2402-v1:0\n",
       "* bedrock-chat:mistral.mistral-large-2407-v1:0\n",
       "\n",
       "bedrock-custom\n",
       "* - For Cross-Region Inference use the appropriate `Inference profile ID` (Model ID with a region prefix, e.g., `us.meta.llama3-2-11b-instruct-v1:0`). See the [inference profiles documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html). \n",
       "- For custom/provisioned models, specify the model ARN (Amazon Resource Name) as the model ID. For more information, see the [Amazon Bedrock model IDs documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html).\n",
       "\n",
       "The model provider must also be specified below. This is the provider of your foundation model *in lowercase*, e.g., `amazon`, `anthropic`, `cohere`, `meta`, or `mistral`.\n",
       "\n",
       "anthropic-chat\n",
       "Requires environment variable: ANTHROPIC_API_KEY (not set)\n",
       "* anthropic-chat:claude-2.0\n",
       "* anthropic-chat:claude-2.1\n",
       "* anthropic-chat:claude-3-opus-20240229\n",
       "* anthropic-chat:claude-3-sonnet-20240229\n",
       "* anthropic-chat:claude-3-haiku-20240307\n",
       "* anthropic-chat:claude-3-5-haiku-20241022\n",
       "* anthropic-chat:claude-3-5-sonnet-20240620\n",
       "* anthropic-chat:claude-3-5-sonnet-20241022\n",
       "\n",
       "azure-chat-openai\n",
       "Requires environment variable: AZURE_OPENAI_API_KEY (not set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "cohere\n",
       "Requires environment variable: COHERE_API_KEY (not set)\n",
       "* cohere:command\n",
       "* cohere:command-nightly\n",
       "* cohere:command-light\n",
       "* cohere:command-light-nightly\n",
       "* cohere:command-r-plus\n",
       "* cohere:command-r\n",
       "\n",
       "gemini\n",
       "Requires environment variable: GOOGLE_API_KEY (not set)\n",
       "* gemini:gemini-1.5-pro\n",
       "* gemini:gemini-1.5-flash\n",
       "* gemini:gemini-1.0-pro\n",
       "* gemini:gemini-1.0-pro-001\n",
       "* gemini:gemini-1.0-pro-latest\n",
       "* gemini:gemini-1.0-pro-vision-latest\n",
       "* gemini:gemini-pro\n",
       "* gemini:gemini-pro-vision\n",
       "\n",
       "gpt4all\n",
       "* gpt4all:ggml-gpt4all-j-v1.2-jazzy\n",
       "* gpt4all:ggml-gpt4all-j-v1.3-groovy\n",
       "* gpt4all:ggml-gpt4all-l13b-snoozy\n",
       "* gpt4all:mistral-7b-openorca.Q4_0\n",
       "* gpt4all:mistral-7b-instruct-v0.1.Q4_0\n",
       "* gpt4all:gpt4all-falcon-q4_0\n",
       "* gpt4all:wizardlm-13b-v1.2.Q4_0\n",
       "* gpt4all:nous-hermes-llama2-13b.Q4_0\n",
       "* gpt4all:gpt4all-13b-snoozy-q4_0\n",
       "* gpt4all:mpt-7b-chat-merges-q4_0\n",
       "* gpt4all:orca-mini-3b-gguf2-q4_0\n",
       "* gpt4all:starcoder-q4_0\n",
       "* gpt4all:rift-coder-v0-7b-q4_0\n",
       "* gpt4all:em_german_mistral_v01.Q4_0\n",
       "\n",
       "huggingface_hub\n",
       "Requires environment variable: HUGGINGFACEHUB_API_TOKEN (not set)\n",
       "* See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`.\n",
       "\n",
       "mistralai\n",
       "Requires environment variable: MISTRAL_API_KEY (not set)\n",
       "* mistralai:open-mistral-7b\n",
       "* mistralai:open-mixtral-8x7b\n",
       "* mistralai:open-mixtral-8x22b\n",
       "* mistralai:mistral-small-latest\n",
       "* mistralai:mistral-medium-latest\n",
       "* mistralai:mistral-large-latest\n",
       "* mistralai:codestral-latest\n",
       "\n",
       "nvidia-chat\n",
       "Requires environment variable: NVIDIA_API_KEY (not set)\n",
       "* nvidia-chat:playground_llama2_70b\n",
       "* nvidia-chat:playground_nemotron_steerlm_8b\n",
       "* nvidia-chat:playground_mistral_7b\n",
       "* nvidia-chat:playground_nv_llama2_rlhf_70b\n",
       "* nvidia-chat:playground_llama2_13b\n",
       "* nvidia-chat:playground_steerlm_llama_70b\n",
       "* nvidia-chat:playground_llama2_code_13b\n",
       "* nvidia-chat:playground_yi_34b\n",
       "* nvidia-chat:playground_mixtral_8x7b\n",
       "* nvidia-chat:playground_neva_22b\n",
       "* nvidia-chat:playground_llama2_code_34b\n",
       "\n",
       "ollama\n",
       "* See [https://www.ollama.com/library](https://www.ollama.com/library) for a list of models. Pass a model's name; for example, `deepseek-coder-v2`.\n",
       "\n",
       "openai\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai:babbage-002\n",
       "* openai:davinci-002\n",
       "* openai:gpt-3.5-turbo-instruct\n",
       "\n",
       "openai-chat\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai-chat:gpt-3.5-turbo\n",
       "* openai-chat:gpt-3.5-turbo-1106\n",
       "* openai-chat:gpt-4\n",
       "* openai-chat:gpt-4-turbo\n",
       "* openai-chat:gpt-4-turbo-preview\n",
       "* openai-chat:gpt-4-0613\n",
       "* openai-chat:gpt-4-0125-preview\n",
       "* openai-chat:gpt-4-1106-preview\n",
       "* openai-chat:gpt-4o\n",
       "* openai-chat:gpt-4o-2024-11-20\n",
       "* openai-chat:gpt-4o-mini\n",
       "* openai-chat:chatgpt-4o-latest\n",
       "\n",
       "openrouter\n",
       "Requires environment variable: OPENROUTER_API_KEY (not set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "qianfan\n",
       "Requires environment variables: QIANFAN_AK (not set), QIANFAN_SK (not set)\n",
       "* qianfan:ERNIE-Bot\n",
       "* qianfan:ERNIE-Bot-4\n",
       "\n",
       "sagemaker-endpoint\n",
       "* Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deploy-models.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints).\n",
       "\n",
       "togetherai\n",
       "Requires environment variable: TOGETHER_API_KEY (not set)\n",
       "* togetherai:Austism/chronos-hermes-13b\n",
       "* togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2\n",
       "* togetherai:EleutherAI/llemma_7b\n",
       "* togetherai:Gryphe/MythoMax-L2-13b\n",
       "* togetherai:Meta-Llama/Llama-Guard-7b\n",
       "* togetherai:Nexusflow/NexusRaven-V2-13B\n",
       "* togetherai:NousResearch/Nous-Capybara-7B-V1p9\n",
       "* togetherai:NousResearch/Nous-Hermes-2-Yi-34B\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-13b\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-70b\n",
       "\n",
       "\n",
       "Aliases and custom commands:\n",
       "gpt2 - huggingface_hub:gpt2\n",
       "gpt3 - openai:davinci-002\n",
       "chatgpt - openai-chat:gpt-3.5-turbo\n",
       "gpt4 - openai-chat:gpt-4\n",
       "ernie-bot - qianfan:ERNIE-Bot\n",
       "ernie-bot-4 - qianfan:ERNIE-Bot-4\n",
       "titan - bedrock:amazon.titan-tg1-large\n",
       "openrouter-claude - openrouter:anthropic/claude-3.5-sonnet:beta\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840ef6ff-ed25-48cf-a278-b1e21173b96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n"
      ],
      "text/plain": [
       "openai\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai:babbage-002\n",
       "* openai:davinci-002\n",
       "* openai:gpt-3.5-turbo-instruct\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef5707-fa11-43f6-b609-5c268f48d75a",
   "metadata": {},
   "source": [
    "## Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5cb132-3f13-4f60-ad66-2b42d7d5a821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Understanding AI, ML, and DL\n",
       "\n",
       "Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) are interconnected fields in computer science. Below is an explanation of each term and their relationships.\n",
       "\n",
       "## Definitions\n",
       "\n",
       "- **Artificial Intelligence (AI)**:\n",
       "  - AI refers to the simulation of human intelligence in machines. It encompasses a range of technologies and methodologies that allow machines to perform tasks typically requiring human intelligence, such as understanding natural language, recognizing patterns, solving problems, and making decisions.\n",
       "\n",
       "- **Machine Learning (ML)**:\n",
       "  - ML is a subset of AI that focuses on the idea that systems can learn from data and improve their performance over time without being explicitly programmed. ML algorithms identify patterns in data and use these patterns to make predictions or decisions.\n",
       "\n",
       "- **Deep Learning (DL)**:\n",
       "  - DL is a subset of ML that employs neural networks with multiple layers (deep neural networks) to analyze various forms of data. It is particularly effective in handling large volumes of unstructured data, such as images, audio, and text. DL automates feature extraction, which distinguishes it from traditional ML approaches.\n",
       "\n",
       "## Relationship Overview\n",
       "\n",
       "- **AI** is the broadest category encompassing all intelligent behavior in machines.\n",
       "  - **ML** is a subset of AI focused specifically on learning from data.\n",
       "    - **DL** is a further subset of ML that uses deep neural networks for learning.\n",
       "\n",
       "## Venn Diagram Representation\n",
       "\n",
       "```\n",
       "          +-----------------------------+\n",
       "          |          Artificial         |\n",
       "          |        Intelligence (AI)    |\n",
       "          |                             |\n",
       "          |   +---------------------+   |\n",
       "          |   |   Machine Learning  |   |\n",
       "          |   |        (ML)        |   |\n",
       "          |   |                     |   |\n",
       "          |   |   +-------------+   |   |\n",
       "          |   |   | Deep       |   |   |\n",
       "          |   |   | Learning   |   |   |\n",
       "          |   |   | (DL)      |   |   |\n",
       "          |   |   +-------------+   |   |\n",
       "          |   +---------------------+   |\n",
       "          +-----------------------------+\n",
       "```\n",
       "\n",
       "## Summary\n",
       "\n",
       "- **AI**: Encompasses all techniques and systems that simulate human intelligence.\n",
       "- **ML**: A subset of AI dedicated to systems that learn from data.\n",
       "- **DL**: A subset of ML that utilizes deep learning algorithms to process complex data.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL). Try explaining the terms also indicating which is subsection or subset of the other. You can try using\n",
    "a venn diagram if possibele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779dc322-839c-4e36-a7b4-ba4dd6eb268d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Understanding Generative AI (GenAI)\n",
       "\n",
       "## Definition\n",
       "\n",
       "**Generative AI (GenAI)** refers to a category of artificial intelligence models and algorithms that are designed to generate new content based on the data they have been trained on. This content can include text, images, audio, video, and more. GenAI leverages various machine learning techniques, particularly deep learning, to produce outputs that resemble the training data.\n",
       "\n",
       "## Key Features\n",
       "\n",
       "- **Content Creation**: GenAI can create original content, such as articles, stories, artwork, music, and even code.\n",
       "- **Learning from Examples**: It is trained on large datasets, learning patterns, structures, and styles from the input data.\n",
       "- **Interactivity**: Many generative AI models can respond to user prompts, allowing for interactive content generation tailored to specific needs.\n",
       "\n",
       "## Applications\n",
       "\n",
       "- **Text Generation**: Tools like GPT-3 and ChatGPT can generate human-like text for applications in customer service, content creation, and more.\n",
       "- **Image Generation**: Models such as DALL-E and Midjourney can create images based on textual descriptions.\n",
       "- **Music Composition**: AI systems can compose music by learning from existing compositions.\n",
       "- **Video Generation**: Advanced models can generate or manipulate video content.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Generative AI represents a significant advancement in the field of artificial intelligence, enabling machines to create and innovate in ways that were previously thought to be exclusive to humans. Its applications are vast and continue to grow as technology evolves.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "what is GenAI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32080352-a847-41cb-bbb6-427ccca1f50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# AI vs Generative AI (GenAI)\n",
       "\n",
       "Artificial Intelligence (AI) and Generative AI (GenAI) are related concepts but serve different purposes and functionalities. Below is a comparison outlining their key differences and similarities.\n",
       "\n",
       "## Definitions\n",
       "\n",
       "- **Artificial Intelligence (AI)**:\n",
       "  - A broad field of computer science focusing on creating systems capable of performing tasks that typically require human intelligence. These tasks include understanding natural language, recognizing patterns, making decisions, and problem-solving.\n",
       "\n",
       "- **Generative AI (GenAI)**:\n",
       "  - A specialized subset of AI that focuses on generating new content—such as text, images, audio, or video—based on the patterns and structures learned from existing data.\n",
       "\n",
       "## Key Differences\n",
       "\n",
       "| Feature                   | AI                                      | Generative AI (GenAI)                       |\n",
       "|---------------------------|-----------------------------------------|---------------------------------------------|\n",
       "| **Scope**                 | Broad field encompassing various techniques to mimic human intelligence | A specific subset of AI focused on content generation |\n",
       "| **Functionality**         | Can include reasoning, decision-making, and classification tasks | Specifically generates new content based on learned patterns |\n",
       "| **Examples**              | Voice assistants (Siri, Alexa), recommendation systems, image recognition | Text generation (GPT-3, ChatGPT), image synthesis (DALL-E) |\n",
       "| **Applications**          | Customer support, fraud detection, autonomous vehicles | Creative writing, art generation, music composition |\n",
       "| **Underlying Techniques** | Various algorithms (rule-based systems, ML, DL) | Primarily relies on deep learning models, especially neural networks |\n",
       "\n",
       "## Similarities\n",
       "\n",
       "- **Machine Learning Foundation**: Both AI and GenAI can leverage machine learning techniques to improve their performance.\n",
       "- **Data Dependency**: Both require large datasets for training to learn and improve their functionalities.\n",
       "- **Goal of Automation**: Both aim to automate tasks and improve efficiency, though their specific applications may differ.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "While AI encompasses a wide range of intelligent behaviors in machines, Generative AI is a specific area within AI that focuses on creating new content based on learned data. Understanding these distinctions is essential for recognizing the capabilities and applications of each within the broader landscape of artificial intelligence.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "AI Vs Generative AI (GenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85646683-d832-488d-a4ac-c1182273f056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Understanding Natural Language Processing (NLP)\n",
       "\n",
       "## Definition\n",
       "\n",
       "**Natural Language Processing (NLP)** is a subfield of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language. The goal of NLP is to enable machines to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
       "\n",
       "## Key Components\n",
       "\n",
       "1. **Text Processing**: Involves cleaning and preparing raw text data for analysis.\n",
       "2. **Tokenization**: The process of breaking down text into smaller units, such as words or phrases.\n",
       "3. **Part-of-Speech Tagging**: Identifying the grammatical parts of speech (nouns, verbs, adjectives, etc.) in a sentence.\n",
       "4. **Named Entity Recognition (NER)**: Identifying and categorizing key entities (names, dates, locations) within text.\n",
       "5. **Sentiment Analysis**: Determining the emotional tone or sentiment expressed in a piece of text.\n",
       "6. **Machine Translation**: Automatically translating text from one language to another.\n",
       "\n",
       "## Applications\n",
       "\n",
       "- **Chatbots and Virtual Assistants**: Tools like Siri, Google Assistant, and customer support bots utilize NLP to understand and respond to user inquiries.\n",
       "- **Text Analytics**: Businesses use NLP to analyze customer feedback, social media interactions, and reviews to derive insights.\n",
       "- **Search Engines**: NLP helps improve the accuracy of search results by understanding user queries better.\n",
       "- **Content Recommendation**: NLP algorithms analyze user preferences to suggest relevant articles, products, or media.\n",
       "- **Language Translation**: Services like Google Translate use NLP to facilitate communication across different languages.\n",
       "\n",
       "## Challenges\n",
       "\n",
       "- **Ambiguity**: Natural language is often ambiguous, making it difficult for machines to interpret intent accurately.\n",
       "- **Variability**: Different dialects, slang, and contextual variations can complicate understanding.\n",
       "- **Context Understanding**: Capturing the context and nuances of human language remains a significant challenge.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Natural Language Processing is a crucial technology that bridges the gap between human communication and machine understanding. As advancements in NLP continue, the potential for applications across various sectors grows, enabling more intuitive and human-like interactions with technology.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is NLP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab20bc2d-23e1-47da-acc5-4a20e015b4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Classification and Regression in Machine Learning\n",
       "\n",
       "In Machine Learning (ML), **Classification** and **Regression** are two fundamental types of predictive modeling techniques used to analyze and predict outcomes based on input data. They both fall under the broader category of supervised learning, where a model is trained on a labeled dataset.\n",
       "\n",
       "## Classification\n",
       "\n",
       "### Definition\n",
       "Classification is a type of predictive modeling technique that categorizes input data into discrete classes or labels. The primary goal is to assign each input instance to one of the predefined categories based on its features.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Output Type**: Discrete (categorical values).\n",
       "- **Examples of Algorithms**: \n",
       "  - Logistic Regression\n",
       "  - Decision Trees\n",
       "  - Support Vector Machines (SVM)\n",
       "  - Random Forest\n",
       "  - Neural Networks\n",
       "- **Common Use Cases**:\n",
       "  - Email spam detection (spam or not spam)\n",
       "  - Image recognition (identifying objects in images)\n",
       "  - Medical diagnosis (disease present or not)\n",
       "  - Sentiment analysis (positive, negative, neutral)\n",
       "\n",
       "### Evaluation Metrics\n",
       "To evaluate the performance of classification models, several metrics can be utilized, including:\n",
       "- Accuracy\n",
       "- Precision\n",
       "- Recall (Sensitivity)\n",
       "- F1 Score\n",
       "- ROC-AUC Curve\n",
       "\n",
       "## Regression\n",
       "\n",
       "### Definition\n",
       "Regression is a predictive modeling technique used to predict continuous numerical values based on input data. The primary goal is to establish a relationship between input variables and a continuous output variable.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Output Type**: Continuous (numerical values).\n",
       "- **Examples of Algorithms**: \n",
       "  - Linear Regression\n",
       "  - Polynomial Regression\n",
       "  - Support Vector Regression (SVR)\n",
       "  - Decision Trees for Regression\n",
       "  - Neural Networks (for regression tasks)\n",
       "- **Common Use Cases**:\n",
       "  - Predicting house prices based on features (size, location, etc.)\n",
       "  - Forecasting sales numbers\n",
       "  - Estimating stock prices\n",
       "  - Analyzing trends in economic indicators\n",
       "\n",
       "### Evaluation Metrics\n",
       "To assess the performance of regression models, the following metrics are often used:\n",
       "- Mean Absolute Error (MAE)\n",
       "- Mean Squared Error (MSE)\n",
       "- Root Mean Squared Error (RMSE)\n",
       "- R-squared (Coefficient of Determination)\n",
       "\n",
       "## Conclusion\n",
       "Both classification and regression are essential techniques in machine learning that serve different purposes based on the nature of the output variable. Understanding the differences between them helps in selecting the appropriate model and evaluation metrics for a given problem."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Explain Classification and Regression in ML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d55c514-027b-4600-a2f6-ee69339bca07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Types of Machine Learning\n",
       "\n",
       "Machine Learning (ML) can be categorized into several types based on how the learning process is structured and the nature of the data being used. The primary types of ML are:\n",
       "\n",
       "## 1. Supervised Learning\n",
       "\n",
       "### Definition\n",
       "Supervised learning involves training a model on a labeled dataset, where the input data is paired with the correct output. The model learns to map inputs to outputs by minimizing the error between its predictions and the actual outputs.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Data Type**: Labeled data.\n",
       "- **Common Algorithms**: \n",
       "  - Linear Regression\n",
       "  - Logistic Regression\n",
       "  - Decision Trees\n",
       "  - Support Vector Machines (SVM)\n",
       "  - Neural Networks\n",
       "\n",
       "### Examples\n",
       "- Email classification (spam or not spam)\n",
       "- Image classification (cat or dog)\n",
       "- Predicting house prices based on features\n",
       "\n",
       "## 2. Unsupervised Learning\n",
       "\n",
       "### Definition\n",
       "Unsupervised learning involves training a model on data that is not labeled. The model attempts to learn the underlying structure or distribution in the data without any explicit guidance on what the output should be.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Data Type**: Unlabeled data.\n",
       "- **Common Algorithms**: \n",
       "  - K-Means Clustering\n",
       "  - Hierarchical Clustering\n",
       "  - Principal Component Analysis (PCA)\n",
       "  - Autoencoders\n",
       "\n",
       "### Examples\n",
       "- Customer segmentation in marketing\n",
       "- Anomaly detection in network security\n",
       "- Dimensionality reduction for data visualization\n",
       "\n",
       "## 3. Semi-Supervised Learning\n",
       "\n",
       "### Definition\n",
       "Semi-supervised learning is a hybrid approach that combines a small amount of labeled data with a large amount of unlabeled data. This method leverages the strengths of both supervised and unsupervised learning.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Data Type**: Both labeled and unlabeled data.\n",
       "- **Common Algorithms**:\n",
       "  - Semi-Supervised Support Vector Machines\n",
       "  - Graph-Based Methods\n",
       "  - Consistency Regularization\n",
       "\n",
       "### Examples\n",
       "- Text classification with a few labeled examples and a larger corpus of unlabeled text\n",
       "- Image classification where only a portion of images have labels\n",
       "\n",
       "## 4. Reinforcement Learning\n",
       "\n",
       "### Definition\n",
       "Reinforcement learning is a type of learning where an agent interacts with an environment and learns to make decisions by receiving rewards or penalties based on its actions. The goal is to learn a policy that maximizes the cumulative reward over time.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Data Type**: Feedback-based learning.\n",
       "- **Common Algorithms**: \n",
       "  - Q-Learning\n",
       "  - Deep Q-Networks (DQN)\n",
       "  - Proximal Policy Optimization (PPO)\n",
       "  - Actor-Critic Methods\n",
       "\n",
       "### Examples\n",
       "- Training robots to navigate through an environment\n",
       "- Game playing (e.g., AlphaGo)\n",
       "- Autonomous driving systems\n",
       "\n",
       "## 5. Self-Supervised Learning\n",
       "\n",
       "### Definition\n",
       "Self-supervised learning is a form of unsupervised learning where the system generates its own labels from the input data. It typically involves training a model on a pretext task to learn useful representations.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Data Type**: Unlabeled data with generated labels.\n",
       "- **Common Algorithms**: \n",
       "  - Contrastive Learning\n",
       "  - Generative Adversarial Networks (GANs)\n",
       "\n",
       "### Examples\n",
       "- Image inpainting (filling in missing parts of an image)\n",
       "- Predicting the next word in a sentence\n",
       "\n",
       "## Conclusion\n",
       "Understanding the different types of machine learning is crucial for selecting the appropriate approach and algorithms based on the problem at hand, the availability of data, and the desired outcomes. Each type has its unique applications and methodologies, making ML a versatile field."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Types of ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9fbbd73-78f3-47da-9ddd-724aa6a88446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Types of Machine Learning Based on Problem Solving\n",
       "\n",
       "Machine Learning can be categorized into different types based on the nature of the problems they solve. Here’s an overview of these categories:\n",
       "\n",
       "## 1. Learning Problems\n",
       "\n",
       "### Definition\n",
       "Learning problems focus on the task of predicting an outcome based on input data. The objective is to learn a function that maps inputs to outputs based on examples provided in the training dataset.\n",
       "\n",
       "### Subtypes\n",
       "- **Classification**: Predicting a discrete class label (e.g., spam detection in emails).\n",
       "- **Regression**: Predicting a continuous value (e.g., predicting house prices).\n",
       "- **Ranking**: Arranging items in order of relevance (e.g., search engine results).\n",
       "\n",
       "### Examples\n",
       "- **Classification**: Identifying whether an email is spam or not.\n",
       "- **Regression**: Forecasting stock prices based on historical data.\n",
       "\n",
       "## 2. Hybrid Learning Problems\n",
       "\n",
       "### Definition\n",
       "Hybrid learning problems combine different types of learning paradigms or techniques to address complex problems. These problems may leverage both supervised and unsupervised learning or integrate reinforcement learning with supervised learning.\n",
       "\n",
       "### Subtypes\n",
       "- **Semi-Supervised Learning**: Combines a small amount of labeled data with a large amount of unlabeled data to improve learning accuracy.\n",
       "- **Multi-Instance Learning**: Involves learning from sets of instances rather than individual instances, useful in scenarios where labels are only available for sets.\n",
       "\n",
       "### Examples\n",
       "- **Semi-Supervised Learning**: Text classification tasks where only a few documents are labeled, while many others are not.\n",
       "- **Multi-Instance Learning**: Medical image analysis where labels are provided for groups of images rather than for each individual image.\n",
       "\n",
       "## 3. Statistical Inference\n",
       "\n",
       "### Definition\n",
       "Statistical inference involves using statistical methods to draw conclusions about a population based on a sample of data. It focuses on understanding relationships between variables and making predictions with uncertainty quantification.\n",
       "\n",
       "### Key Concepts\n",
       "- **Hypothesis Testing**: Testing assumptions about a population based on sample data.\n",
       "- **Confidence Intervals**: Estimating the range within which a population parameter lies, with a certain level of confidence.\n",
       "\n",
       "### Examples\n",
       "- **Hypothesis Testing**: Determining if a new drug is effective compared to a placebo.\n",
       "- **Regression Analysis**: Understanding the relationship between income and spending habits.\n",
       "\n",
       "## 4. Learning Techniques\n",
       "\n",
       "### Definition\n",
       "Learning techniques refer to the specific methods and algorithms used to implement machine learning tasks. These techniques can be applied to various types of learning problems to extract patterns and insights from data.\n",
       "\n",
       "### Common Techniques\n",
       "- **Supervised Learning Techniques**: \n",
       "  - Decision Trees\n",
       "  - Support Vector Machines (SVM)\n",
       "  - Neural Networks\n",
       "\n",
       "- **Unsupervised Learning Techniques**: \n",
       "  - K-Means Clustering\n",
       "  - Principal Component Analysis (PCA)\n",
       "  - Hierarchical Clustering\n",
       "\n",
       "- **Reinforcement Learning Techniques**: \n",
       "  - Q-Learning\n",
       "  - Policy Gradients\n",
       "  - Deep Reinforcement Learning\n",
       "\n",
       "### Examples\n",
       "- **Supervised Learning Technique**: Using a neural network to classify images of handwritten digits.\n",
       "- **Unsupervised Learning Technique**: Applying K-Means clustering to segment customers based on purchasing behavior.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Understanding the different types of machine learning problems based on what they solve helps in selecting the appropriate methods and algorithms for specific tasks. Each category—learning problems, hybrid learning problems, statistical inference, and learning techniques—serves a unique role in the broader landscape of machine learning, enabling practitioners to effectively analyze data and derive meaningful insights."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Explain the types of ML based on what problem they solve as below;\n",
    "1. Learning Problems\n",
    "2. Hybrid Learning problems\n",
    "3. Statistical Inference\n",
    "4. Learning Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102a59d2-6ab4-4085-a6f3-ee19baea798c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Clustering in Machine Learning\n",
       "\n",
       "Clustering is an unsupervised learning technique in machine learning that involves grouping a set of objects in such a way that objects in the same group (or cluster) are more similar to each other than to those in other groups. It is widely used for exploratory data analysis and pattern recognition.\n",
       "\n",
       "## Key Concepts\n",
       "\n",
       "### Definition\n",
       "Clustering is the process of partitioning a dataset into distinct groups based on similarity among the data points. The goal is to identify inherent structures in the data without prior knowledge of class labels.\n",
       "\n",
       "### Types of Clustering\n",
       "1. **Hard Clustering**: Each data point belongs to exactly one cluster.\n",
       "2. **Soft Clustering**: Data points can belong to multiple clusters with varying degrees of membership (e.g., fuzzy clustering).\n",
       "\n",
       "## Common Clustering Algorithms\n",
       "\n",
       "### 1. K-Means Clustering\n",
       "- **Description**: This algorithm partitions the dataset into K clusters by assigning each data point to the nearest cluster centroid and then updating the centroids based on the mean of the points in each cluster.\n",
       "- **Pros**: Simple and efficient for large datasets.\n",
       "- **Cons**: Requires specifying the number of clusters (K) beforehand; sensitive to outliers.\n",
       "\n",
       "### 2. Hierarchical Clustering\n",
       "- **Description**: This approach builds a hierarchy of clusters either by agglomerative (bottom-up) or divisive (top-down) strategies. The result is often presented as a dendrogram.\n",
       "- **Pros**: No need to specify the number of clusters in advance.\n",
       "- **Cons**: Computationally intensive for large datasets.\n",
       "\n",
       "### 3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
       "- **Description**: DBSCAN groups together points that are closely packed together, marking as outliers points that lie alone in low-density regions.\n",
       "- **Pros**: Can identify clusters of arbitrary shapes and is robust to noise.\n",
       "- **Cons**: Requires setting parameters (minPts and ε) and may struggle with varying density clusters.\n",
       "\n",
       "### 4. Gaussian Mixture Models (GMM)\n",
       "- **Description**: GMM assumes that the data is generated from a mixture of several Gaussian distributions, each representing a cluster. It uses the Expectation-Maximization (EM) algorithm for parameter estimation.\n",
       "- **Pros**: Can model clusters with different shapes and sizes.\n",
       "- **Cons**: Computationally more intensive and requires the number of clusters to be defined.\n",
       "\n",
       "### 5. Mean Shift\n",
       "- **Description**: This algorithm identifies clusters by locating the dense areas of data points and shifting the centroid of each point towards the mean of the points in its neighborhood.\n",
       "- **Pros**: Does not require specifying the number of clusters in advance.\n",
       "- **Cons**: Computationally expensive and sensitive to bandwidth selection.\n",
       "\n",
       "## Applications of Clustering\n",
       "\n",
       "- **Customer Segmentation**: Identifying distinct customer groups based on purchasing behavior.\n",
       "- **Image Segmentation**: Dividing images into segments for object detection and recognition.\n",
       "- **Anomaly Detection**: Identifying unusual data points that do not fit well into any cluster.\n",
       "- **Document Clustering**: Grouping similar documents for information retrieval and organization.\n",
       "\n",
       "## Evaluation of Clustering\n",
       "\n",
       "Evaluating clustering results can be challenging since ground truth labels are often unavailable. Common techniques include:\n",
       "\n",
       "- **Silhouette Score**: Measures how similar an object is to its own cluster compared to other clusters.\n",
       "- **Dunn Index**: Evaluates the ratio of the minimum inter-cluster distance to the maximum intra-cluster distance.\n",
       "- **Davies-Bouldin Index**: Assesses the average similarity ratio of each cluster with its most similar cluster.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Clustering is a powerful technique in machine learning for discovering patterns and structures in unlabeled data. By grouping similar data points together, clustering provides insights that can be used in various applications, from market research to image processing, and beyond. Understanding different clustering algorithms and their characteristics is crucial for effectively analyzing and interpreting data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Explain Clustering in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b3a8f75-ad1f-425d-9052-20929aadca2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Classical Machine Learning\n",
       "\n",
       "Classical Machine Learning refers to traditional methods and algorithms used for data analysis and predictive modeling before the rise of deep learning techniques. These methods are typically characterized by their reliance on mathematical models and statistical principles to learn from data.\n",
       "\n",
       "## Key Characteristics\n",
       "\n",
       "- **Supervised and Unsupervised Learning**: Classical ML encompasses both supervised (where labeled data is used) and unsupervised (where no labels are provided) learning techniques.\n",
       "- **Feature Engineering**: Emphasis on manual feature selection and engineering to improve model performance.\n",
       "- **Interpretability**: Models are generally more interpretable than complex deep learning models, allowing practitioners to understand how decisions are made.\n",
       "- **Less Computationally Intensive**: Classical methods often require less computational power compared to modern deep learning techniques.\n",
       "\n",
       "## Common Classical ML Algorithms\n",
       "\n",
       "### 1. Linear Regression\n",
       "- **Purpose**: Used for predicting a continuous target variable based on one or more predictor variables.\n",
       "- **Key Feature**: Assumes a linear relationship between input features and the target variable.\n",
       "\n",
       "### 2. Logistic Regression\n",
       "- **Purpose**: Used for binary classification problems.\n",
       "- **Key Feature**: Outputs probabilities that can be mapped to discrete classes using a threshold.\n",
       "\n",
       "### 3. Decision Trees\n",
       "- **Purpose**: Used for both classification and regression tasks.\n",
       "- **Key Feature**: Splits the data into subsets based on feature values, creating a tree-like model of decisions.\n",
       "\n",
       "### 4. Support Vector Machines (SVM)\n",
       "- **Purpose**: Effective for classification tasks, especially with high-dimensional data.\n",
       "- **Key Feature**: Finds the optimal hyperplane that separates different classes in the feature space.\n",
       "\n",
       "### 5. K-Nearest Neighbors (KNN)\n",
       "- **Purpose**: Used for classification and regression by considering the K nearest data points to make predictions.\n",
       "- **Key Feature**: Non-parametric method that makes decisions based on local data.\n",
       "\n",
       "### 6. Naive Bayes\n",
       "- **Purpose**: Used for classification tasks based on applying Bayes' theorem.\n",
       "- **Key Feature**: Assumes independence among predictors, making it particularly efficient for large datasets.\n",
       "\n",
       "### 7. Ensemble Methods\n",
       "- **Bagging (Bootstrap Aggregating)**: Combines predictions from multiple models (e.g., Random Forest) to improve accuracy and reduce overfitting.\n",
       "- **Boosting**: Sequentially applies weak learners to correct errors made by previous models (e.g., AdaBoost, Gradient Boosting).\n",
       "\n",
       "## Applications of Classical ML\n",
       "\n",
       "- **Finance**: Credit scoring, fraud detection, algorithmic trading.\n",
       "- **Healthcare**: Disease diagnosis, patient outcome prediction, medical image analysis.\n",
       "- **Marketing**: Customer segmentation, recommendation systems, sentiment analysis.\n",
       "- **Manufacturing**: Predictive maintenance, quality control, demand forecasting.\n",
       "\n",
       "## Limitations of Classical ML\n",
       "\n",
       "- **Feature Engineering Dependency**: Requires significant domain knowledge for effective feature selection and engineering.\n",
       "- **Scalability**: May struggle with very large datasets or high-dimensional feature spaces.\n",
       "- **Complexity of Relationships**: Limited in capturing complex, non-linear relationships unless specifically modeled.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Classical Machine Learning remains a foundational aspect of data science and analytics. While modern techniques like deep learning have gained popularity, classical methods are still widely used due to their simplicity, interpretability, and effectiveness for many applications. Understanding classical ML techniques provides a solid base for tackling more advanced methodologies in machine learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Explain Classical ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51dba8f8-136e-4f69-9bd5-b79445289317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Divisions of Machine Learning\n",
       "\n",
       "Machine Learning can be categorized into several divisions, each encompassing different techniques and methodologies. Below are the primary divisions along with their subcategories and example techniques.\n",
       "\n",
       "## 1. Classical Machine Learning\n",
       "\n",
       "### Overview\n",
       "Classical Machine Learning techniques include both supervised and unsupervised learning methods that rely on statistical and mathematical foundations.\n",
       "\n",
       "### 1.1 Supervised Learning\n",
       "\n",
       "#### Definition\n",
       "In supervised learning, models are trained on labeled datasets, where the desired output is known.\n",
       "\n",
       "#### Example Techniques\n",
       "- **Linear Regression**: Used for predicting continuous values based on input features.\n",
       "- **Logistic Regression**: Ideal for binary classification tasks.\n",
       "- **Decision Trees**: Models that split data based on feature values to make predictions.\n",
       "- **Support Vector Machines (SVM)**: Finds the optimal hyperplane that separates different classes.\n",
       "- **K-Nearest Neighbors (KNN)**: Classifies data points based on the majority label among the K closest neighbors.\n",
       "\n",
       "#### Applications\n",
       "- Spam detection in emails\n",
       "- Medical diagnosis (e.g., predicting disease presence)\n",
       "- Stock price prediction\n",
       "\n",
       "### 1.2 Unsupervised Learning\n",
       "\n",
       "#### Definition\n",
       "Unsupervised learning involves training models on data without labeled outputs, focusing on discovering hidden patterns or structures.\n",
       "\n",
       "#### Example Techniques\n",
       "- **K-Means Clustering**: Groups data points into K clusters based on feature similarity.\n",
       "- **Hierarchical Clustering**: Builds a tree of clusters based on data proximity.\n",
       "- **Principal Component Analysis (PCA)**: Reduces dimensionality by transforming data to a new set of variables (principal components).\n",
       "- **t-Distributed Stochastic Neighbor Embedding (t-SNE)**: Visualizes high-dimensional data by reducing it to two or three dimensions.\n",
       "\n",
       "#### Applications\n",
       "- Customer segmentation in marketing\n",
       "- Anomaly detection in fraud detection\n",
       "- Topic modeling in text analysis\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Reinforcement Learning\n",
       "\n",
       "### Overview\n",
       "Reinforcement Learning (RL) involves training an agent to make decisions by interacting with an environment and learning from feedback in the form of rewards or penalties.\n",
       "\n",
       "#### Example Techniques\n",
       "- **Q-Learning**: A value-based learning algorithm that enables an agent to learn the quality of actions in a given state.\n",
       "- **Deep Q-Networks (DQN)**: Combines Q-Learning with deep neural networks to handle complex environments.\n",
       "- **Policy Gradients**: A method that directly optimizes the policy (the agent's strategy) for decision-making.\n",
       "\n",
       "#### Applications\n",
       "- Game playing (e.g., AlphaGo)\n",
       "- Robotics for task completion\n",
       "- Autonomous vehicles navigating real-world environments\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Ensemble Methods\n",
       "\n",
       "### Overview\n",
       "Ensemble methods combine multiple models to enhance performance, often reducing overfitting and improving accuracy compared to individual models.\n",
       "\n",
       "#### Example Techniques\n",
       "- **Bagging**: Such as Random Forests, which create multiple decision trees and aggregate their predictions.\n",
       "- **Boosting**: Techniques like AdaBoost or Gradient Boosting that sequentially train models to correct previous model errors.\n",
       "- **Stacking**: Combines predictions from multiple base learners using a meta-model for final predictions.\n",
       "\n",
       "#### Applications\n",
       "- Credit risk assessment\n",
       "- Winning solutions in data science competitions\n",
       "- Predictive maintenance in manufacturing\n",
       "\n",
       "---\n",
       "\n",
       "## 4. Neural Networks and Deep Learning\n",
       "\n",
       "### Overview\n",
       "Neural Networks and Deep Learning involve complex architectures inspired by the human brain, capable of learning representations of data through multiple layers.\n",
       "\n",
       "#### Example Techniques\n",
       "- **Convolutional Neural Networks (CNN)**: Primarily used for image processing and recognition tasks.\n",
       "- **Recurrent Neural Networks (RNN)**: Suited for sequence prediction tasks, such as time series analysis and natural language processing.\n",
       "- **Transformers**: Advanced models for handling sequential data, particularly in NLP, such as BERT and GPT.\n",
       "\n",
       "#### Applications\n",
       "- Image and video analysis (e.g., facial recognition)\n",
       "- Natural language processing (e.g., chatbots, translation)\n",
       "- Speech recognition systems\n",
       "\n",
       "---\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The divisions of Machine Learning — Classical ML (including Supervised and Unsupervised Learning), Reinforcement Learning, Ensemble Methods, and Neural Networks/Deep Learning — provide a framework for understanding the diverse techniques available for tackling various problems. Each division has its unique strengths and applications, guiding practitioners in selecting the most suitable approaches for their specific tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Explain the Divisions of ML as below and with example techniques;\n",
    "1. Classical ML\n",
    "    - Supervised\n",
    "    - Unsupervised\n",
    "2. Reinforcement Learning\n",
    "3. Ensemble methods\n",
    "4. Neural Networks and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18043127-f896-40a0-b2b7-41a25918d75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Supervised vs Unsupervised Learning in Machine Learning\n",
       "\n",
       "In Machine Learning, the two primary types of learning paradigms are **Supervised Learning** and **Unsupervised Learning**. Each serves different purposes and is suited for various applications. Below is a comparison of the two.\n",
       "\n",
       "## Supervised Learning\n",
       "\n",
       "### Definition\n",
       "Supervised learning involves training a model on a labeled dataset, where the desired output is known. The model learns to map inputs to the correct outputs.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Labeled Data**: Requires a dataset with input-output pairs.\n",
       "- **Goal**: Predict the output for new, unseen data based on learned relationships.\n",
       "- **Training Process**: The model adjusts its parameters based on the difference between predicted and actual outputs (loss).\n",
       "\n",
       "### Example Techniques\n",
       "- **Linear Regression**: Predicts continuous values.\n",
       "- **Logistic Regression**: Used for binary classification.\n",
       "- **Decision Trees**: Makes predictions based on decision rules.\n",
       "- **Support Vector Machines (SVM)**: Finds the optimal boundary between classes.\n",
       "- **Neural Networks**: Learns complex relationships in data.\n",
       "\n",
       "### Applications\n",
       "- Email spam detection\n",
       "- Image classification (e.g., identifying objects in images)\n",
       "- Medical diagnosis (e.g., predicting disease occurrence)\n",
       "\n",
       "---\n",
       "\n",
       "## Unsupervised Learning\n",
       "\n",
       "### Definition\n",
       "Unsupervised learning involves training a model on data without labeled outputs. The model tries to identify patterns or groupings within the data.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Unlabeled Data**: Does not require labeled outputs; focuses on input features only.\n",
       "- **Goal**: Discover hidden structures or patterns in the data.\n",
       "- **Training Process**: The model learns without explicit feedback on the correctness of its predictions.\n",
       "\n",
       "### Example Techniques\n",
       "- **K-Means Clustering**: Groups data points into K clusters based on similarity.\n",
       "- **Hierarchical Clustering**: Creates a tree of clusters based on data proximity.\n",
       "- **Principal Component Analysis (PCA)**: Reduces dimensionality while preserving variance.\n",
       "- **t-SNE**: Visualizes high-dimensional data in lower dimensions.\n",
       "\n",
       "### Applications\n",
       "- Customer segmentation in marketing\n",
       "- Anomaly detection (e.g., fraud detection)\n",
       "- Topic modeling in text analysis\n",
       "\n",
       "---\n",
       "\n",
       "## Summary of Differences\n",
       "\n",
       "| Feature                  | Supervised Learning                          | Unsupervised Learning                       |\n",
       "|--------------------------|---------------------------------------------|--------------------------------------------|\n",
       "| **Data Type**            | Labeled data (input-output pairs)          | Unlabeled data (only inputs)               |\n",
       "| **Goal**                 | Predict outcomes based on input data        | Find patterns or groupings in data         |\n",
       "| **Training Feedback**     | Feedback is provided based on predictions   | No feedback; learns from data structure    |\n",
       "| **Use Cases**            | Classification and regression tasks         | Clustering, association, and dimensionality reduction tasks |\n",
       "\n",
       "---\n",
       "\n",
       "Understanding the differences between supervised and unsupervised learning is essential for selecting the appropriate approach for a given problem in machine learning. Each paradigm offers unique strengths and is suited for different types of data and applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Supervised vs Unsupervised learning in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0061efef-11b0-48e8-b6d1-0730d371ff62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Supervised vs Unsupervised vs Reinforcement Learning in Machine Learning\n",
       "\n",
       "Machine Learning encompasses various paradigms, each suited for different types of problems. The three primary paradigms are **Supervised Learning**, **Unsupervised Learning**, and **Reinforcement Learning**. Below is a comparison of these three paradigms.\n",
       "\n",
       "## Supervised Learning\n",
       "\n",
       "### Definition\n",
       "Supervised learning involves training a model on a labeled dataset, where the desired output is known. The model learns to map inputs to the corresponding outputs.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Labeled Data**: Requires a dataset with input-output pairs.\n",
       "- **Goal**: Predict the output for new, unseen data based on learned relationships.\n",
       "- **Feedback Mechanism**: The model learns through feedback that indicates the correctness of its predictions.\n",
       "\n",
       "### Example Techniques\n",
       "- **Linear Regression**\n",
       "- **Logistic Regression**\n",
       "- **Decision Trees**\n",
       "- **Support Vector Machines (SVM)**\n",
       "- **Neural Networks**\n",
       "\n",
       "### Applications\n",
       "- Email spam detection\n",
       "- Image classification (e.g., identifying objects)\n",
       "- Medical diagnosis (e.g., predicting disease occurrence)\n",
       "\n",
       "---\n",
       "\n",
       "## Unsupervised Learning\n",
       "\n",
       "### Definition\n",
       "Unsupervised learning involves training a model on data without labeled outputs. The model tries to identify patterns or groupings within the data.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Unlabeled Data**: Does not require labeled outputs; focuses solely on input features.\n",
       "- **Goal**: Discover hidden structures or patterns in the data.\n",
       "- **Feedback Mechanism**: The model learns without explicit feedback on the correctness of its interpretations.\n",
       "\n",
       "### Example Techniques\n",
       "- **K-Means Clustering**\n",
       "- **Hierarchical Clustering**\n",
       "- **Principal Component Analysis (PCA)**\n",
       "- **t-SNE**\n",
       "\n",
       "### Applications\n",
       "- Customer segmentation in marketing\n",
       "- Anomaly detection (e.g., fraud detection)\n",
       "- Topic modeling in text analysis\n",
       "\n",
       "---\n",
       "\n",
       "## Reinforcement Learning\n",
       "\n",
       "### Definition\n",
       "Reinforcement learning involves training an agent to make decisions by interacting with an environment. The agent learns from feedback in the form of rewards or penalties based on its actions.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Agent-Environment Interaction**: The agent interacts with the environment and makes decisions.\n",
       "- **Goal**: Maximize cumulative rewards over time by learning optimal actions.\n",
       "- **Feedback Mechanism**: Feedback is provided based on the agent's actions, guiding future decisions.\n",
       "\n",
       "### Example Techniques\n",
       "- **Q-Learning**\n",
       "- **Deep Q-Networks (DQN)**\n",
       "- **Policy Gradients**\n",
       "- **Actor-Critic Methods**\n",
       "\n",
       "### Applications\n",
       "- Game playing (e.g., AlphaGo)\n",
       "- Robotics for task completion\n",
       "- Autonomous vehicles navigating real-world environments\n",
       "\n",
       "---\n",
       "\n",
       "## Summary of Differences\n",
       "\n",
       "| Feature                  | Supervised Learning                          | Unsupervised Learning                       | Reinforcement Learning                       |\n",
       "|--------------------------|---------------------------------------------|--------------------------------------------|---------------------------------------------|\n",
       "| **Data Type**            | Labeled data (input-output pairs)          | Unlabeled data (only inputs)               | Interaction data (agent-environment)       |\n",
       "| **Goal**                 | Predict outcomes based on input data        | Find patterns or groupings in data         | Maximize cumulative rewards through actions  |\n",
       "| **Feedback Mechanism**    | Direct feedback on predictions               | No feedback; learns from data structure    | Feedback through rewards/penalties          |\n",
       "| **Use Cases**            | Classification and regression tasks         | Clustering, association, and dimensionality reduction tasks | Game AI, robotics, and decision-making tasks |\n",
       "\n",
       "---\n",
       "\n",
       "Understanding the distinctions between supervised, unsupervised, and reinforcement learning is crucial for selecting the appropriate approach for specific problems in machine learning. Each paradigm has unique strengths and is suited for different types of data and applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Supervised vs Unsupervised vs Reinforcement in ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4736f79-57f6-40bf-8633-11c4a38d6ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Supervised Learning Models\n",
       "\n",
       "Supervised learning models are algorithms that learn from labeled data to make predictions or classifications. These models are trained on input-output pairs, where the input is a feature set and the output is the target variable. Below are some of the most commonly used supervised learning models.\n",
       "\n",
       "## 1. Linear Regression\n",
       "\n",
       "### Description\n",
       "A statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data.\n",
       "\n",
       "### Applications\n",
       "- Predicting sales based on advertising spend\n",
       "- Estimating housing prices based on features like size and location\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Logistic Regression\n",
       "\n",
       "### Description\n",
       "A regression model used for binary classification that predicts the probability of an outcome that can take one of two possible values.\n",
       "\n",
       "### Applications\n",
       "- Email spam detection (spam or not spam)\n",
       "- Customer churn prediction (will churn or not)\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Decision Trees\n",
       "\n",
       "### Description\n",
       "A tree-like model that makes decisions based on the features of the input data. Each internal node represents a decision based on a feature, each branch represents the outcome of the decision, and each leaf node represents a class label.\n",
       "\n",
       "### Applications\n",
       "- Customer segmentation\n",
       "- Fraud detection\n",
       "\n",
       "---\n",
       "\n",
       "## 4. Random Forest\n",
       "\n",
       "### Description\n",
       "An ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
       "\n",
       "### Applications\n",
       "- Predicting loan defaults\n",
       "- Feature importance analysis\n",
       "\n",
       "---\n",
       "\n",
       "## 5. Support Vector Machines (SVM)\n",
       "\n",
       "### Description\n",
       "A classification method that finds the hyperplane that best separates data points of different classes in a high-dimensional space.\n",
       "\n",
       "### Applications\n",
       "- Image classification\n",
       "- Text categorization\n",
       "\n",
       "---\n",
       "\n",
       "## 6. K-Nearest Neighbors (KNN)\n",
       "\n",
       "### Description\n",
       "A simple, instance-based learning algorithm that classifies data points based on the classes of their nearest neighbors in the feature space.\n",
       "\n",
       "### Applications\n",
       "- Recommender systems\n",
       "- Pattern recognition\n",
       "\n",
       "---\n",
       "\n",
       "## 7. Neural Networks\n",
       "\n",
       "### Description\n",
       "A computational model inspired by the human brain, consisting of layers of interconnected nodes (neurons) that can learn complex relationships in data.\n",
       "\n",
       "### Applications\n",
       "- Image and speech recognition\n",
       "- Natural language processing tasks\n",
       "\n",
       "---\n",
       "\n",
       "## 8. Gradient Boosting Machines (GBM)\n",
       "\n",
       "### Description\n",
       "An ensemble technique that builds models sequentially, each new model correcting errors made by the previous ones. Notable implementations include XGBoost and LightGBM.\n",
       "\n",
       "### Applications\n",
       "- Winning solutions in machine learning competitions\n",
       "- Risk assessment models\n",
       "\n",
       "---\n",
       "\n",
       "## 9. Naive Bayes\n",
       "\n",
       "### Description\n",
       "A family of probabilistic algorithms based on Bayes' theorem, assuming independence between predictors. It is particularly effective for large datasets.\n",
       "\n",
       "### Applications\n",
       "- Text classification (e.g., sentiment analysis)\n",
       "- Spam filtering\n",
       "\n",
       "---\n",
       "\n",
       "## Summary\n",
       "\n",
       "Supervised learning models provide a wide range of techniques for solving various predictive tasks. The choice of model depends on the nature of the data, the complexity of the relationships to be modeled, and the specific problem at hand. By understanding the strengths and weaknesses of each model, practitioners can select the most appropriate approach for their tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What are Supervised Learning Models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e772c44-3c42-4570-abc0-d8392bfa6393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Unsupervised Learning Models\n",
       "\n",
       "Unsupervised learning models are algorithms that identify patterns or groupings in data without the use of labeled outputs. These models analyze the input data to discover its inherent structure. Below are some of the most commonly used unsupervised learning models.\n",
       "\n",
       "## 1. K-Means Clustering\n",
       "\n",
       "### Description\n",
       "A partitioning method that divides a dataset into K distinct clusters based on feature similarity. The algorithm iteratively assigns data points to the nearest cluster centroid and updates the centroids.\n",
       "\n",
       "### Applications\n",
       "- Customer segmentation\n",
       "- Market basket analysis\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Hierarchical Clustering\n",
       "\n",
       "### Description\n",
       "A method that builds a hierarchy of clusters either through agglomerative (bottom-up) or divisive (top-down) approaches. It creates a dendrogram to visualize the relationships between clusters.\n",
       "\n",
       "### Applications\n",
       "- Gene expression analysis\n",
       "- Document clustering\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Principal Component Analysis (PCA)\n",
       "\n",
       "### Description\n",
       "A dimensionality reduction technique that transforms high-dimensional data into a lower-dimensional form while preserving as much variance as possible. It identifies the principal components (directions of maximum variance).\n",
       "\n",
       "### Applications\n",
       "- Data visualization\n",
       "- Noise reduction in datasets\n",
       "\n",
       "---\n",
       "\n",
       "## 4. t-Distributed Stochastic Neighbor Embedding (t-SNE)\n",
       "\n",
       "### Description\n",
       "A nonlinear dimensionality reduction technique that is particularly effective for visualizing high-dimensional data by mapping it to a lower-dimensional space (usually 2D or 3D).\n",
       "\n",
       "### Applications\n",
       "- Visualizing complex datasets (e.g., images, text)\n",
       "- Exploratory data analysis\n",
       "\n",
       "---\n",
       "\n",
       "## 5. Gaussian Mixture Models (GMM)\n",
       "\n",
       "### Description\n",
       "A probabilistic model that assumes the data is generated from a mixture of several Gaussian distributions with unknown parameters. It is used for clustering and density estimation.\n",
       "\n",
       "### Applications\n",
       "- Anomaly detection\n",
       "- Image segmentation\n",
       "\n",
       "---\n",
       "\n",
       "## 6. Autoencoders\n",
       "\n",
       "### Description\n",
       "A type of neural network used for unsupervised learning that aims to learn efficient representations (encodings) of the input data. An encoder compresses the input, while a decoder reconstructs it.\n",
       "\n",
       "### Applications\n",
       "- Dimensionality reduction\n",
       "- Anomaly detection\n",
       "\n",
       "---\n",
       "\n",
       "## 7. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
       "\n",
       "### Description\n",
       "A density-based clustering algorithm that groups together points that are closely packed together, marking as outliers points that lie alone in low-density regions.\n",
       "\n",
       "### Applications\n",
       "- Spatial data analysis\n",
       "- Identifying clusters of varying shapes and sizes\n",
       "\n",
       "---\n",
       "\n",
       "## 8. Independent Component Analysis (ICA)\n",
       "\n",
       "### Description\n",
       "A computational technique used to separate a multivariate signal into additive, independent components. It is particularly useful for blind source separation.\n",
       "\n",
       "### Applications\n",
       "- Audio signal processing (e.g., separating mixed audio signals)\n",
       "- Image processing\n",
       "\n",
       "---\n",
       "\n",
       "## 9. Self-Organizing Maps (SOM)\n",
       "\n",
       "### Description\n",
       "A type of artificial neural network that uses unsupervised learning to produce a low-dimensional representation of the input space, preserving the topological properties of the data.\n",
       "\n",
       "### Applications\n",
       "- Data visualization\n",
       "- Clustering and pattern recognition\n",
       "\n",
       "---\n",
       "\n",
       "## Summary\n",
       "\n",
       "Unsupervised learning models provide a variety of techniques for uncovering hidden structures in unlabeled data. The choice of model depends on the specific characteristics of the dataset and the goals of the analysis. By leveraging these models, practitioners can gain valuable insights and make data-driven decisions based on the underlying patterns in the data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What are Unsupervised Learning Models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82f0e810-fbaa-4b4d-9314-70559c6f579c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Reinforcement Learning Models\n",
       "\n",
       "Reinforcement learning (RL) models are a class of algorithms that learn to make decisions by interacting with an environment. Unlike supervised learning, which relies on labeled data, RL uses a reward-based system to learn optimal actions over time. The agent learns to maximize cumulative rewards by exploring different actions and receiving feedback in the form of rewards or penalties. Below are some common types of reinforcement learning models.\n",
       "\n",
       "## 1. Q-Learning\n",
       "\n",
       "### Description\n",
       "A value-based off-policy algorithm that aims to learn the value of action-state pairs (Q-values). The agent updates its Q-values based on the rewards received after taking actions in given states.\n",
       "\n",
       "### Applications\n",
       "- Game playing (e.g., board games, video games)\n",
       "- Robotics navigation\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Deep Q-Networks (DQN)\n",
       "\n",
       "### Description\n",
       "An extension of Q-learning that uses deep neural networks to approximate Q-values. DQNs can handle high-dimensional state spaces, such as images, making them suitable for complex environments.\n",
       "\n",
       "### Applications\n",
       "- Atari game playing\n",
       "- Autonomous driving\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Policy Gradient Methods\n",
       "\n",
       "### Description\n",
       "These algorithms directly optimize the policy by updating the action probabilities rather than value functions. Policy gradient methods can handle high-dimensional action spaces and are often used in continuous action environments.\n",
       "\n",
       "### Applications\n",
       "- Robotics control\n",
       "- Complex strategy games\n",
       "\n",
       "---\n",
       "\n",
       "## 4. Proximal Policy Optimization (PPO)\n",
       "\n",
       "### Description\n",
       "A popular policy optimization algorithm that strikes a balance between exploration and exploitation. PPO is known for its stability and ease of implementation, making it widely used in various RL tasks.\n",
       "\n",
       "### Applications\n",
       "- Game AI\n",
       "- Real-world robotic manipulation\n",
       "\n",
       "---\n",
       "\n",
       "## 5. Actor-Critic Methods\n",
       "\n",
       "### Description\n",
       "A hybrid approach that combines value-based and policy-based methods. The \"actor\" updates the policy, while the \"critic\" evaluates the action taken by providing feedback on its value.\n",
       "\n",
       "### Applications\n",
       "- Continuous control tasks\n",
       "- Simulated environments\n",
       "\n",
       "---\n",
       "\n",
       "## 6. Deep Deterministic Policy Gradient (DDPG)\n",
       "\n",
       "### Description\n",
       "An off-policy algorithm specifically designed for environments with continuous action spaces. DDPG uses deep neural networks for both the actor and the critic to learn policies and value functions.\n",
       "\n",
       "### Applications\n",
       "- Robotics\n",
       "- Autonomous vehicles\n",
       "\n",
       "---\n",
       "\n",
       "## 7. Soft Actor-Critic (SAC)\n",
       "\n",
       "### Description\n",
       "An off-policy algorithm that maximizes both the expected reward and the entropy of the policy, encouraging exploration. It is effective in continuous action spaces and can learn robust policies.\n",
       "\n",
       "### Applications\n",
       "- High-dimensional control tasks\n",
       "- Simulations in robotics\n",
       "\n",
       "---\n",
       "\n",
       "## 8. Multi-Agent Reinforcement Learning (MARL)\n",
       "\n",
       "### Description\n",
       "A framework where multiple agents learn simultaneously, either cooperatively or competitively. MARL can be applied in environments where multiple entities interact with each other.\n",
       "\n",
       "### Applications\n",
       "- Game theory scenarios\n",
       "- Autonomous vehicle coordination\n",
       "\n",
       "---\n",
       "\n",
       "## Summary\n",
       "\n",
       "Reinforcement learning models provide powerful tools for developing intelligent agents that learn from their interactions with an environment. The choice of model depends on the specific problem, the nature of the action space, and the complexity of the environment. By leveraging reinforcement learning techniques, practitioners can create systems that adapt and improve over time through experience."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What are Reinforcement Learning Models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44577afd-68b9-4c4a-81ea-702c5b0736ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Neural Networks and Deep Learning in Machine Learning\n",
       "\n",
       "Neural networks and deep learning are key components of modern machine learning (ML) that enable the modeling of complex patterns and relationships within data. Below is an overview of both concepts.\n",
       "\n",
       "## Neural Networks\n",
       "\n",
       "### Description\n",
       "A neural network is a computational model inspired by the way biological neural networks in the human brain process information. It consists of interconnected nodes (neurons) organized in layers that transform input data into output predictions. \n",
       "\n",
       "### Structure\n",
       "- **Input Layer**: The first layer that receives the input data.\n",
       "- **Hidden Layers**: One or more layers between the input and output layers where computations occur. Each neuron in these layers performs a weighted sum of the inputs, applies an activation function, and passes the result to the next layer.\n",
       "- **Output Layer**: The final layer that produces the output of the network, which could be a classification label, a regression value, etc.\n",
       "\n",
       "### Activation Functions\n",
       "Activation functions introduce non-linearity into the model, enabling it to learn complex patterns. Common activation functions include:\n",
       "- **Sigmoid**: Outputs values between 0 and 1.\n",
       "- **ReLU (Rectified Linear Unit)**: Outputs the input directly if positive, otherwise outputs zero.\n",
       "- **Softmax**: Normalizes outputs to a probability distribution over multiple classes.\n",
       "\n",
       "### Applications\n",
       "- Image and speech recognition\n",
       "- Natural language processing\n",
       "- Game playing (e.g., AlphaGo)\n",
       "\n",
       "---\n",
       "\n",
       "## Deep Learning\n",
       "\n",
       "### Description\n",
       "Deep learning is a subset of machine learning that utilizes deep neural networks, which have multiple hidden layers. It allows models to automatically learn hierarchical feature representations from large amounts of data.\n",
       "\n",
       "### Key Features\n",
       "- **Depth**: Deep learning models consist of many layers, enabling them to capture intricate patterns and representations.\n",
       "- **Feature Learning**: Deep networks can learn features automatically from raw data without extensive manual feature engineering.\n",
       "- **Scalability**: Deep learning models can handle large datasets and leverage parallel processing capabilities of GPUs for training.\n",
       "\n",
       "### Types of Deep Learning Architectures\n",
       "1. **Convolutional Neural Networks (CNNs)**\n",
       "   - Primarily used for image data.\n",
       "   - Employ convolutional layers to automatically extract spatial features.\n",
       "\n",
       "2. **Recurrent Neural Networks (RNNs)**\n",
       "   - Designed for sequential data (e.g., time series, text).\n",
       "   - Utilize recurrent connections to maintain information across time steps.\n",
       "\n",
       "3. **Long Short-Term Memory (LSTM) Networks**\n",
       "   - A type of RNN that addresses the vanishing gradient problem.\n",
       "   - Capable of learning long-term dependencies in sequential data.\n",
       "\n",
       "4. **Generative Adversarial Networks (GANs)**\n",
       "   - Composed of two neural networks (generator and discriminator) that compete against each other.\n",
       "   - Used for generating realistic samples (e.g., images, text).\n",
       "\n",
       "### Applications\n",
       "- Autonomous vehicles\n",
       "- Medical image analysis\n",
       "- Voice assistants and chatbots\n",
       "\n",
       "---\n",
       "\n",
       "## Summary\n",
       "\n",
       "Neural networks and deep learning have revolutionized the field of machine learning by enabling the modeling of complex data patterns and automated feature learning. Their ability to process large datasets and extract meaningful insights has led to breakthroughs in various applications, making them integral to the advancement of artificial intelligence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Explain Neural Networks and Deep learning in ML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94abaf-ffc6-4bc3-87c7-6037a1193429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae69e7b-d3d8-40dc-9a40-46244ac83de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dc01913-6781-49e2-b125-eff036101564",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "- [What is BERT?](https://h2o.ai/wiki/bert/#:~:text=BERT%2C%20short%20for%20Bidirectional%20Encoder,framework%20for%20natural%20language%20processing)\n",
    "- [BERT - Huggingface](https://huggingface.co/docs/transformers/en/model_doc/bert)`m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8d803f-5c6a-4116-9a52-17e83b172998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Simple BERT Embeddings Example\n",
       "\n",
       "In this example, we will use the Hugging Face Transformers library to generate embeddings for a given text using BERT. Follow the steps below.\n",
       "\n",
       "## Prerequisites\n",
       "\n",
       "Make sure you have the following libraries installed:\n",
       "\n",
       "```bash\n",
       "pip install torch transformers\n",
       "```\n",
       "\n",
       "## Code Example\n",
       "\n",
       "```python\n",
       "import torch\n",
       "from transformers import BertTokenizer, BertModel\n",
       "\n",
       "# Initialize the tokenizer and model\n",
       "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
       "model = BertModel.from_pretrained('bert-base-uncased')\n",
       "\n",
       "# Set the model to evaluation mode\n",
       "model.eval()\n",
       "\n",
       "# Function to get embeddings\n",
       "def get_embeddings(text):\n",
       "    # Tokenize the input text\n",
       "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
       "\n",
       "    # Forward pass through the model\n",
       "    with torch.no_grad():\n",
       "        outputs = model(**inputs)\n",
       "\n",
       "    # Get the embeddings from the last hidden state\n",
       "    embeddings = outputs.last_hidden_state\n",
       "\n",
       "    # Return the embeddings for the [CLS] token (first token)\n",
       "    return embeddings[0][0]\n",
       "\n",
       "# Example usage\n",
       "text = \"Hello, how are you?\"\n",
       "embeddings = get_embeddings(text)\n",
       "\n",
       "print(\"Text:\", text)\n",
       "print(\"Embeddings:\", embeddings)\n",
       "```\n",
       "\n",
       "## Explanation\n",
       "\n",
       "1. **Import Libraries**: We import the necessary libraries from PyTorch and Hugging Face Transformers.\n",
       "\n",
       "2. **Load BERT**: We load the pre-trained BERT tokenizer and model. Here, we use the 'bert-base-uncased' variant.\n",
       "\n",
       "3. **Prepare Input**: The input text is tokenized and converted into tensors suitable for BERT.\n",
       "\n",
       "4. **Get Embeddings**: We perform a forward pass through the model to obtain the embeddings. The embeddings for the [CLS] token are returned as a representation of the input text.\n",
       "\n",
       "5. **Example Usage**: We demonstrate how to use the `get_embeddings` function to get embeddings for a sample sentence.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "This example shows how to obtain embeddings using BERT. You can modify the input text to generate embeddings for different sentences.\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "I want to implement a simple embeddings example using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec813f5-ac05-4a76-a6f1-af6163b0dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "762ba540-4fd2-41b5-9f9e-d9f91e96394a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1deb1cb399cb44bc871f15c18011d362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39624aacd1d544c3810324d1e3ba2ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fbaab5aa6c4d4c8821ff2da970672d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc2b439bd0c4f779d2e89882ee75364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6190e413841d48eaa060cc47674ee7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hello, how are you?\n",
      "Embeddings: tensor([-8.2419e-02,  6.6673e-02, -2.8802e-01, -8.4852e-02, -2.9516e-01,\n",
      "        -3.2372e-01,  5.0952e-01,  2.5141e-01,  1.2843e-01, -1.1157e-01,\n",
      "         6.8626e-02, -4.2762e-01,  7.5996e-02,  1.7581e-01,  1.8324e-01,\n",
      "        -2.0512e-01, -1.1120e-01,  3.4889e-01,  1.0287e-01,  1.3385e-01,\n",
      "         1.3401e-02, -4.5564e-01,  3.0502e-01,  9.3698e-02, -8.8652e-02,\n",
      "        -4.8886e-01, -2.5795e-01,  1.7338e-02, -2.9773e-01, -4.0783e-01,\n",
      "        -2.1908e-01,  3.5228e-01, -5.1087e-01, -3.0496e-01,  2.6707e-01,\n",
      "         4.3032e-01,  1.8951e-01,  1.7673e-01, -1.1507e-01,  3.5343e-01,\n",
      "        -7.8026e-01, -3.2950e-02,  5.4157e-02,  3.7076e-01,  4.2680e-02,\n",
      "        -8.5279e-01, -3.0362e+00, -2.5009e-01, -2.7831e-01, -4.4224e-01,\n",
      "         2.4760e-01, -1.7025e-01,  1.2775e-01, -8.9598e-02, -2.7678e-01,\n",
      "         2.9922e-01, -5.2811e-01, -1.3484e-02, -4.5095e-02,  3.5045e-02,\n",
      "        -5.7423e-03, -1.7683e-01, -3.3304e-01,  1.7801e-01, -1.3302e-01,\n",
      "         6.7298e-01, -7.0953e-02,  4.9459e-01, -2.7355e-02,  1.0190e+00,\n",
      "        -7.4303e-01, -1.6486e-01,  5.3375e-01,  1.5994e-01, -2.3508e-01,\n",
      "        -4.8329e-01, -9.0597e-02,  6.4045e-02, -4.5346e-01,  1.0828e-01,\n",
      "        -2.8181e-01,  5.4226e-01,  6.5625e-01, -2.1988e-02,  4.3427e-01,\n",
      "         4.6088e-01, -5.8889e-01, -5.4243e-01,  2.7569e-01,  5.9186e-01,\n",
      "         1.6813e-01, -1.2035e-01,  1.1080e-01,  6.3063e-01,  1.8419e-01,\n",
      "        -9.0951e-02,  9.4165e-02,  4.4818e-01,  6.7810e-02,  4.7449e-01,\n",
      "         3.6481e-01,  2.3098e-01,  6.2579e-01, -1.7648e-01,  5.4832e-02,\n",
      "        -9.7261e-02, -7.9486e-02, -3.7384e-01,  2.7931e-02, -2.3420e+00,\n",
      "         4.6157e-01, -9.5085e-02, -2.2542e-01, -2.4634e-01, -4.9613e-01,\n",
      "         5.6861e-01,  8.6981e-01, -3.3051e-01, -1.5220e-02, -7.9627e-02,\n",
      "        -2.9342e-01, -1.9015e-01, -9.0524e-02, -4.7034e-01, -3.0441e-02,\n",
      "         5.3022e-01,  1.3261e-01, -6.0569e-01,  6.1330e-01, -7.7413e-02,\n",
      "         3.5260e-01,  5.3199e-01,  1.2844e-01, -2.7174e-01, -2.1774e-02,\n",
      "         2.1766e-01,  5.8740e-01,  1.4955e-02, -1.0697e-01, -4.6584e-01,\n",
      "        -7.3629e-01, -4.6547e-01, -2.8802e+00,  4.2471e-01,  7.3204e-01,\n",
      "         4.2717e-01, -6.9933e-01, -3.1565e-01,  2.9329e-01,  2.4337e-01,\n",
      "        -6.6525e-02,  5.3236e-03, -4.2992e-01,  3.2441e-01, -4.8727e-01,\n",
      "        -1.8653e-01, -3.8623e-01, -3.4386e-01,  2.6571e-01,  6.0045e-01,\n",
      "         5.5967e-01, -3.2796e-01,  5.1382e-02,  2.2559e-01, -6.6533e-01,\n",
      "         9.9664e-02,  4.6604e-01, -4.9556e-02,  2.3750e-01,  3.3460e-01,\n",
      "        -4.9601e-01,  9.9633e-02,  5.2060e-01,  2.8917e-01, -3.0025e-01,\n",
      "        -3.6662e-01,  5.7474e-01,  3.1569e-01, -3.8958e-02,  1.1982e-01,\n",
      "        -2.2609e-02,  3.4705e-01, -5.2076e-02,  1.4602e-01,  3.0973e-01,\n",
      "         1.7794e-01,  5.1480e-01, -1.6061e-02, -4.7265e-01,  4.3592e-01,\n",
      "        -2.1744e-02, -3.0158e-01,  6.9660e-02,  2.7697e-01,  6.5967e-01,\n",
      "         1.3252e-01,  3.5124e-01, -2.2086e-01,  2.5091e-01,  4.7226e-01,\n",
      "         4.8762e-01, -4.5549e-01, -1.3432e-01,  2.3735e-01,  1.2385e-01,\n",
      "         3.8332e+00, -6.4660e-02, -4.8740e-01,  2.1644e-01,  4.8240e-01,\n",
      "        -6.7183e-01, -1.4233e-01,  3.7976e-01, -6.3331e-02, -7.6392e-02,\n",
      "        -1.5084e-02,  7.0212e-01, -1.5034e-01, -3.7273e-01,  3.7957e-01,\n",
      "         5.3177e-01, -2.0118e-01, -3.5738e-01,  3.0925e-01, -3.3177e-01,\n",
      "        -9.4437e-02,  1.9626e-01,  3.4005e-01, -2.2082e-01, -1.4381e+00,\n",
      "        -6.0181e-02, -8.5795e-02, -1.2453e-01,  7.6109e-01, -5.7746e-01,\n",
      "        -9.8036e-02, -5.7231e-01, -6.2917e-01,  1.5995e-01, -1.9432e-01,\n",
      "         2.8791e-01,  4.5599e-01,  4.2179e-01,  2.7998e-01, -3.1724e-01,\n",
      "         4.2795e-01,  4.7234e-01, -1.2548e-01,  6.5250e-01,  1.5502e-01,\n",
      "         3.4136e-01,  8.5019e-02,  8.7320e-02, -4.9436e-01,  3.7890e-01,\n",
      "         2.8718e-01, -1.7593e-02,  4.2473e-01, -5.3724e-01,  1.9670e-01,\n",
      "        -3.0691e-01,  5.8666e-02,  4.3622e-01,  1.2565e-01, -6.5942e-01,\n",
      "        -1.3125e-01,  3.0428e-01, -7.7598e-01, -3.4869e-01, -1.4569e-01,\n",
      "         4.2988e-01, -2.1639e-01, -2.1673e-01, -3.4143e+00,  2.1104e-01,\n",
      "         7.8716e-02,  3.3360e-01,  1.1400e-01, -3.0002e-01, -2.8892e-01,\n",
      "         6.0901e-01,  4.3694e-01, -6.9780e-01,  3.5065e-01, -1.4860e-01,\n",
      "        -2.1799e-01,  5.6889e-01, -1.2315e-01,  8.2432e-02,  3.2445e-01,\n",
      "        -1.1675e-01, -4.9360e-01, -3.8923e-01,  5.1523e-01,  3.8745e-01,\n",
      "        -1.5922e-01,  6.3168e-01,  4.1697e-02, -1.2269e-01,  2.0394e-01,\n",
      "         9.1222e-02,  8.7360e-02, -4.1772e-01,  2.2285e-01, -1.7417e-01,\n",
      "         4.5361e-02,  3.9300e-01, -5.0372e-01, -2.1698e+00, -1.9950e-01,\n",
      "         3.3508e-01, -2.5577e-01, -2.3318e-01, -1.3553e-02,  2.8994e-01,\n",
      "         3.2008e-02, -3.3872e-01, -2.9426e-01,  1.7836e-01,  2.8845e-03,\n",
      "        -2.2862e-01,  3.6701e-01,  5.9432e-01, -3.7020e-01,  6.9476e-01,\n",
      "         2.4352e-01,  4.4092e-01,  3.7296e-01, -2.7485e-01,  4.4049e-01,\n",
      "         2.8971e-01, -1.1336e-01,  3.7088e-01,  1.0407e+00,  1.4922e-01,\n",
      "        -2.1161e-01, -1.9153e-01,  5.6208e-02,  3.0363e-01, -4.4176e-01,\n",
      "         1.8558e-01, -5.0197e-03, -7.4301e-01, -2.6481e-01,  4.2261e-01,\n",
      "         2.0171e-01,  7.3522e-01, -1.9570e-02,  2.7622e-01,  4.9290e-01,\n",
      "         4.9825e-01,  1.3557e-01,  5.2861e-01,  2.4679e-01, -3.1137e-02,\n",
      "        -3.0332e-02, -2.3660e-01,  2.2890e-01, -3.5365e-01, -8.8767e-02,\n",
      "         1.0993e+00, -2.2578e-01,  2.8955e-01,  7.6761e-02, -2.3186e-01,\n",
      "        -1.0257e-01,  1.2255e-01,  2.8692e-01,  1.0984e+00, -3.4471e-02,\n",
      "         2.3288e-01, -3.8721e-01,  2.9926e-01, -4.0104e-01,  1.4879e-01,\n",
      "        -6.3523e-01,  2.4268e-01,  3.1043e-01, -8.2310e-03, -1.3229e-01,\n",
      "        -1.2927e-01, -1.0934e+00, -5.2836e-01,  1.3084e-01, -2.9901e-01,\n",
      "        -1.9235e-02,  3.6882e-01, -6.3475e-01, -2.4653e-01, -4.7194e-01,\n",
      "        -3.7400e-01,  5.8534e-01, -5.2950e-01, -2.5140e-01, -6.9113e-02,\n",
      "        -2.6613e-01, -6.8614e-01, -5.7158e-03, -3.6174e-01,  4.3057e-01,\n",
      "        -2.2651e-02,  4.1463e-01, -2.9700e-01,  6.1578e-02,  1.4070e-01,\n",
      "        -7.4841e-01,  2.4940e-01,  1.2399e-01, -2.3757e-01, -3.7408e-01,\n",
      "        -5.6688e-02,  1.8949e-01,  1.4647e-01,  3.9900e-02, -5.2650e-01,\n",
      "         2.2352e-01,  2.2443e-01,  3.3884e-01, -3.3100e-01, -6.2308e-01,\n",
      "        -1.9987e-01,  1.9844e-01,  9.0928e-01,  3.7176e-02,  2.4824e-01,\n",
      "         5.8266e-01,  1.0934e-01,  4.6243e-01,  1.4282e-01,  1.6029e-01,\n",
      "         1.4688e-01,  6.3143e-02, -4.8201e-01, -2.0747e-01, -1.1736e-01,\n",
      "        -4.8743e-01, -1.1571e-01, -4.4521e-01,  5.9635e-01, -1.3527e-01,\n",
      "        -5.6675e-01, -3.9130e-01,  1.9323e-01, -2.6621e-01, -2.4453e-01,\n",
      "         2.7113e-01,  1.1515e-02,  6.8280e-02,  3.3898e-01, -3.2913e-01,\n",
      "        -5.3403e-01,  4.6651e-01,  5.8112e-02,  4.5663e-01, -1.9896e-01,\n",
      "        -3.1549e-01, -2.1814e-01,  4.0529e-01, -8.7826e-02, -5.9365e-01,\n",
      "         9.5445e-02, -5.7269e-01, -1.6077e-01,  2.8302e-01,  6.1225e-01,\n",
      "        -1.1317e-01, -1.7727e-01, -6.0160e-02,  1.5994e-01, -1.2634e-02,\n",
      "        -1.1255e+00,  7.3317e-01,  2.5392e-01,  1.3489e-01,  4.2821e-01,\n",
      "         2.8835e-01, -3.7973e-01,  6.1960e-01, -2.8244e-01,  3.2298e-01,\n",
      "        -3.1158e-01, -3.0473e-01,  1.4106e-02,  4.5284e-01,  1.1583e-01,\n",
      "         1.3135e-01,  2.3872e-01, -8.4761e-01, -5.8717e-01, -6.9733e-01,\n",
      "        -2.5592e-01,  4.8826e-01,  5.5235e-02, -3.7857e-01,  6.3542e-01,\n",
      "        -3.6004e-01, -1.8736e-01,  4.5936e-01, -1.8676e-01,  4.3412e-01,\n",
      "         7.2905e-02, -7.0758e-01, -7.1738e-01, -2.9643e-01,  1.8994e-01,\n",
      "        -2.3145e-01,  2.6564e-01, -6.1959e-02,  7.7637e-01,  3.5998e-01,\n",
      "        -3.8469e-02,  3.3594e-01,  1.4598e-01, -5.3846e-01,  4.5191e-01,\n",
      "        -1.1626e-01, -3.5528e-01,  3.3144e-01,  2.2947e-01, -6.7001e-01,\n",
      "        -1.4156e-01, -9.3535e-02, -5.1371e-02, -4.5051e-01,  3.9608e-02,\n",
      "        -6.7620e-02,  6.6277e-01, -1.8622e-01, -4.8499e-01, -2.3830e-01,\n",
      "        -1.8625e-03, -2.9900e-01, -5.0403e-01,  6.3695e-02, -5.6396e-01,\n",
      "        -5.3801e-01, -2.3642e-01, -2.0572e-01, -3.3991e-01, -1.6873e-01,\n",
      "         3.4629e-01,  3.3638e-01, -2.4538e-01,  1.8999e-01, -6.6698e-01,\n",
      "         3.1765e-01,  8.1083e-02,  3.6811e-01,  5.7885e-01, -5.9090e-02,\n",
      "         5.5800e-01, -2.3123e-01, -3.9896e-01,  7.1145e-01, -4.5477e-02,\n",
      "         4.4176e-01,  2.3755e-01, -2.0778e-01, -1.2589e-01, -5.2040e-02,\n",
      "        -4.4030e-01, -1.5791e-02,  2.2527e-01,  2.3587e-01,  6.4221e-02,\n",
      "        -1.5773e-01, -4.2193e-02,  4.6739e-01, -2.6144e-02, -3.3438e-01,\n",
      "        -9.9719e-02,  5.7659e-01,  4.7550e-01, -2.6942e-05, -4.8774e-02,\n",
      "         3.6307e-01,  7.6034e-01,  8.0685e-02, -6.0296e-01, -1.8831e-01,\n",
      "        -2.9190e-01, -5.0106e-01, -3.7258e-01, -1.3361e-01,  2.1126e-01,\n",
      "        -8.2725e-01,  4.0153e-02, -4.3165e-01,  2.0950e+00,  6.1951e-01,\n",
      "         2.0487e-01, -2.3046e-01,  7.2861e-01, -1.2273e-01, -2.4555e-01,\n",
      "        -2.6706e-02, -5.2204e-01,  5.8650e-01, -1.6616e-01, -1.0393e-01,\n",
      "        -1.7751e-01,  4.3739e-01,  8.2456e-01,  1.8969e-01, -3.7513e-01,\n",
      "        -1.9730e-02, -7.6824e-01, -5.2339e-02, -1.9362e-01,  5.5677e-01,\n",
      "         3.1446e-01, -3.6556e-02,  1.7635e-01,  5.6914e-01,  1.5901e-02,\n",
      "        -6.2703e-02,  2.5113e-01,  4.8699e-01, -5.5597e-01,  7.8046e-02,\n",
      "        -1.6917e-01,  3.9469e-01, -4.7222e-01,  5.1066e-01, -3.2092e-01,\n",
      "        -8.9582e-01, -8.1342e-01,  3.0820e-01,  4.4147e-02, -2.9036e-01,\n",
      "         5.2961e-01,  2.5055e-01,  1.3917e-01,  1.0152e+00, -3.4620e-01,\n",
      "        -3.8168e-01,  6.0431e-01,  5.8001e-01, -2.6823e-01, -1.9400e-01,\n",
      "        -4.0228e-01,  1.6579e-01, -3.2830e-01, -5.0047e-01,  3.1653e-01,\n",
      "         5.0470e-02, -4.4384e-01,  5.1893e-01, -4.7747e-02,  4.3462e-01,\n",
      "         2.3053e-01, -4.2979e-01,  1.1584e-01,  1.6327e-01, -2.7497e-02,\n",
      "        -1.1710e-01,  1.1424e-01, -6.6327e-01,  1.1400e-02,  2.4003e-01,\n",
      "         3.5897e-01,  1.9917e-02,  5.4750e-02, -2.1255e-02, -2.3406e-01,\n",
      "         4.3683e-02, -4.9819e-02, -3.0069e+00,  6.6810e-02, -5.6128e-01,\n",
      "         1.3351e-01,  7.9978e-02,  1.7455e-02,  9.3741e-02,  6.4175e-02,\n",
      "         3.0717e-01,  1.5445e-01,  2.6654e-01,  1.4365e-01,  7.3280e-01,\n",
      "         6.8494e-02,  1.6008e-01,  2.3358e-01,  4.2146e-02, -2.7523e-01,\n",
      "        -1.8772e-01, -2.5881e-01, -1.3563e-01,  3.0389e-01,  1.3175e-01,\n",
      "        -2.9955e-01, -4.6553e-01,  3.0771e-01, -1.1011e-01, -4.0489e-01,\n",
      "         8.9792e-02,  5.9914e-01, -2.4788e-01,  7.0886e-01, -2.7216e-01,\n",
      "        -9.2918e-04,  3.7520e-02, -2.6756e-01, -5.4614e-01,  1.2305e-01,\n",
      "         6.0482e-01,  4.8431e-01, -6.7303e-02,  5.0438e-01, -1.5499e-01,\n",
      "         4.3957e-01, -1.5034e-01, -2.9079e-01,  2.6303e-01, -1.0424e-01,\n",
      "         4.2339e-01, -1.2311e-01,  1.3376e-01, -1.2098e-01, -6.0401e-03,\n",
      "         2.6764e-02,  2.5564e-01,  4.6277e-01,  1.3229e-01, -1.2132e-01,\n",
      "        -2.2289e-01, -6.4075e-01,  6.9287e-02, -1.7650e-01, -2.9573e-01,\n",
      "         1.1618e-01,  3.8936e-01, -1.9710e-01,  1.9768e-01, -4.5688e-03,\n",
      "         3.8303e-02, -6.1821e-02, -2.2481e-01,  4.1396e-02,  7.7868e-01,\n",
      "         3.7060e-01, -4.1596e-01, -1.5540e-01,  7.8761e-01,  5.3985e-01,\n",
      "         1.3570e-01,  4.0553e-02, -4.4717e-01, -1.1565e-01, -5.3652e-01,\n",
      "         5.3309e-01,  8.2077e-02, -7.6162e+00, -3.0677e-01, -4.7359e-01,\n",
      "        -8.0428e-01,  1.2327e-01, -7.9172e-01,  3.0119e-01, -2.7889e-01,\n",
      "         1.1680e-01, -4.1679e-01,  5.7212e-01,  1.0306e-01, -3.4359e-01,\n",
      "        -3.5656e-01,  1.9600e-01,  5.3815e-01])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embeddings(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get the embeddings from the last hidden state\n",
    "    embeddings = outputs.last_hidden_state\n",
    "\n",
    "    # Return the embeddings for the [CLS] token (first token)\n",
    "    return embeddings[0][0]\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, how are you?\"\n",
    "embeddings = get_embeddings(text)\n",
    "\n",
    "print(\"Text:\", text)\n",
    "print(\"Embeddings:\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49257427-de0b-4709-a5e6-511737da024f",
   "metadata": {},
   "source": [
    "### [BertJapanese](https://huggingface.co/docs/transformers/en/model_doc/bert-japanese)\n",
    "\n",
    "Example of using a model with MeCab and WordPiece tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6158d04-5d6a-4b67-b8e6-66d34eb1e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install fugashi\n",
    "!pip install unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30ca0b0a-514b-4e35-b59a-858435a8e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 吾輩 は 猫 で ある 。 [SEP]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "bertjapanese = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "\n",
    "## Input Japanese Text\n",
    "line = \"吾輩は猫である。\"\n",
    "\n",
    "inputs = tokenizer(line, return_tensors=\"pt\")\n",
    "\n",
    "print(tokenizer.decode(inputs[\"input_ids\"][0]))\n",
    "\n",
    "outputs = bertjapanese(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a050e3d-573e-46a4-bc90-b3d83cadfd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1348,  0.1240,  0.1502,  ...,  0.0951,  0.2145, -0.1121],\n",
       "         [ 0.2445,  1.2341, -0.5909,  ...,  0.4571,  0.3980, -0.0478],\n",
       "         [ 0.1209,  0.3673, -0.3961,  ...,  1.0547,  0.4066,  0.2586],\n",
       "         ...,\n",
       "         [ 0.8519, -0.0191, -0.1027,  ...,  0.5163,  0.2025,  0.0164],\n",
       "         [ 0.3057,  0.0587,  0.1815,  ...,  0.9653,  0.3287,  0.8934],\n",
       "         [ 0.2922,  0.0505,  0.1648,  ...,  0.9797,  0.3315,  0.8997]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8062c-8aef-4e29-ab17-ccb7edc554a5",
   "metadata": {},
   "source": [
    "Example of using a model with Character tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb99939b-baa3-462d-8c7d-1883ec915b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5d735335d9446185667bc29e8714ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/478 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55afe0bca97f47098cfa89389e52a72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/359M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9769b471141545f38f47fb66c4841c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248a5e0c482e4e0082ae0c9ed22ca987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/15.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 吾 輩 は 猫 で あ る 。 [SEP]\n"
     ]
    }
   ],
   "source": [
    "bertjapanese = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese-char\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-char\")\n",
    "\n",
    "## Input Japanese Text\n",
    "line = \"吾輩は猫である。\"\n",
    "\n",
    "inputs = tokenizer(line, return_tensors=\"pt\")\n",
    "\n",
    "print(tokenizer.decode(inputs[\"input_ids\"][0]))\n",
    "\n",
    "outputs = bertjapanese(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "321c4e00-c88d-4056-8555-1c979996b76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1178, -0.0828,  0.2073,  ...,  0.6403,  0.0981,  0.3044],\n",
       "         [-0.4708, -0.4716, -0.0560,  ...,  0.1028, -0.0512,  0.3904],\n",
       "         [-0.3023, -0.8021,  0.0500,  ..., -0.0969,  0.1796, -0.4355],\n",
       "         ...,\n",
       "         [-0.2734, -0.7684,  0.4438,  ...,  0.0143, -0.0614,  0.2163],\n",
       "         [ 0.2961,  0.0660,  0.0623,  ...,  0.2037, -0.0923,  0.3988],\n",
       "         [ 0.3661,  0.5665, -0.1185,  ..., -0.0044, -0.3753,  0.4413]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c6082-f62a-40cb-97d0-f4c2ec020b7b",
   "metadata": {},
   "source": [
    "### Model Distillation Explained\n",
    "- https://labelbox.com/guides/model-distillation/\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/model-distillation.html\n",
    "- https://www.datacamp.com/blog/distillation-llm\n",
    "- https://labelbox.com/blog/a-pragmatic-introduction-to-model-distillation-for-ai-developers/\n",
    "- https://medium.com/aimonks/what-is-quantization-and-distillation-of-models-a67e3a2dc325\n",
    "- https://www.linkedin.com/pulse/quantization-distillation-pruning-llm-tejas-bankar-k64vf\n",
    "- https://ai.stackexchange.com/questions/43054/when-to-use-pruning-quantization-distillation-and-others-when-optimizing-speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bc637-735d-4d07-861f-f29a60cbac89",
   "metadata": {},
   "source": [
    "## Sentence Transformers (SBERT)\n",
    "- [SBERT](https://sbert.net/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28594719-d80c-4c58-b26d-1aef019ab79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Implementing Simple Embeddings with Sentence Transformers (SBERT)\n",
       "\n",
       "## What is a Sentence Transformer?\n",
       "\n",
       "Sentence Transformers (SBERT) is a modification of the popular BERT (Bidirectional Encoder Representations from Transformers) model, designed specifically for creating sentence embeddings. Unlike traditional BERT, which produces word embeddings, SBERT generates fixed-size embeddings for entire sentences or paragraphs by fine-tuning BERT on various tasks such as natural language inference (NLI) and semantic textual similarity (STS). This allows SBERT to capture the semantic meaning of sentences, making it suitable for tasks like clustering, retrieval, and semantic search.\n",
       "\n",
       "## Installing the Required Library\n",
       "\n",
       "To get started, you need to install the `sentence-transformers` library. You can do this using pip:\n",
       "\n",
       "```bash\n",
       "pip install sentence-transformers\n",
       "```\n",
       "\n",
       "## Example: Generating Sentence Embeddings\n",
       "\n",
       "Here is a simple example of how to use Sentence Transformers to generate embeddings for sentences.\n",
       "\n",
       "### Step 1: Import the Library\n",
       "\n",
       "```python\n",
       "from sentence_transformers import SentenceTransformer\n",
       "```\n",
       "\n",
       "### Step 2: Load a Pre-Trained Model\n",
       "\n",
       "You can choose from various pre-trained models available in the Sentence Transformers library. In this example, we will use the `all-MiniLM-L6-v2` model, which is smaller and faster.\n",
       "\n",
       "```python\n",
       "# Load the pre-trained model\n",
       "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
       "```\n",
       "\n",
       "### Step 3: Define Your Sentences\n",
       "\n",
       "Create a list of sentences for which you want to generate embeddings.\n",
       "\n",
       "```python\n",
       "# Define your sentences\n",
       "sentences = [\n",
       "    \"This is an example sentence.\",\n",
       "    \"Each sentence is converted to a vector.\",\n",
       "    \"Sentence Transformers are very useful for semantic search.\"\n",
       "]\n",
       "```\n",
       "\n",
       "### Step 4: Generate Embeddings\n",
       "\n",
       "Use the model to encode the sentences into embeddings.\n",
       "\n",
       "```python\n",
       "# Generate embeddings\n",
       "embeddings = model.encode(sentences)\n",
       "```\n",
       "\n",
       "### Step 5: View the Output\n",
       "\n",
       "You can inspect the generated embeddings. Each sentence will be represented as a vector.\n",
       "\n",
       "```python\n",
       "# Print the embeddings\n",
       "for sentence, embedding in zip(sentences, embeddings):\n",
       "    print(f\"Sentence: {sentence}\")\n",
       "    print(f\"Embedding: {embedding[:5]}...\")  # Print the first 5 dimensions of the embedding\n",
       "    print()\n",
       "```\n",
       "\n",
       "## Complete Code Example\n",
       "\n",
       "Here’s the complete code in one block for easy copying:\n",
       "\n",
       "```python\n",
       "from sentence_transformers import SentenceTransformer\n",
       "\n",
       "# Load the pre-trained model\n",
       "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
       "\n",
       "# Define your sentences\n",
       "sentences = [\n",
       "    \"This is an example sentence.\",\n",
       "    \"Each sentence is converted to a vector.\",\n",
       "    \"Sentence Transformers are very useful for semantic search.\"\n",
       "]\n",
       "\n",
       "# Generate embeddings\n",
       "embeddings = model.encode(sentences)\n",
       "\n",
       "# Print the embeddings\n",
       "for sentence, embedding in zip(sentences, embeddings):\n",
       "    print(f\"Sentence: {sentence}\")\n",
       "    print(f\"Embedding: {embedding[:5]}...\")  # Print the first 5 dimensions of the embedding\n",
       "    print()\n",
       "```\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "This code demonstrates how to use Sentence Transformers to generate embeddings for sentences. These embeddings can then be used for various applications like clustering, similarity search, and more. SBERT significantly enhances the capability of traditional BERT by providing a way to work with sentence-level semantics efficiently."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "I want to implement a simple embeddings example using sentence transformers (SBERT). Also expalin what a sentence transformer is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24302cbb-b652-4bfc-936d-68f2a61ef0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79459c81-7251-44e3-933e-cfd85244e80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218422e4a6a3452781db17493739ae8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9866df234c954d75b56e2a1c486626e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee84ea60dd84f2fb60d7166b6ba4019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20593a94b19240c8a772134e32871eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8166f4062204b4395066259ea6e839a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432cc0539ede4f5ea2496965f092fef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f839cdd719435a89f35d7b6d136c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a548a67baf347c693022949c1302492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938ca23a6d3248ae98e052feb1fea965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdb9063c09e40e78c1d1484791a50f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bfe586541745208fabb840d5f61625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This is an example sentence.\n",
      "Embedding: [0.09812458 0.06781267 0.06252317 0.09508479 0.0366476 ]...\n",
      "\n",
      "Sentence: Each sentence is converted to a vector.\n",
      "Embedding: [ 0.05284443  0.04435422 -0.02343617 -0.00540091  0.02552457]...\n",
      "\n",
      "Sentence: Sentence Transformers are very useful for semantic search.\n",
      "Embedding: [-0.00304123  0.00857707  0.03254057  0.02563822  0.02921927]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define your sentences\n",
    "sentences = [\n",
    "    \"This is an example sentence.\",\n",
    "    \"Each sentence is converted to a vector.\",\n",
    "    \"Sentence Transformers are very useful for semantic search.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Embedding: {embedding[:5]}...\")  # Print the first 5 dimensions of the embedding\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3cc349-821e-4730-ad85-bcccf55f826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f340f9-5c09-4725-86f9-84ddd776054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.3717, 0.2731],\n",
      "        [0.3717, 1.0000, 0.4288],\n",
      "        [0.2731, 0.4288, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7a49c3b-8624-4995-b45e-8408f7f59e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Introduction to Perceptrons\n",
       "\n",
       "A perceptron is one of the simplest forms of artificial neural networks and serves as a fundamental building block for more complex models. It was introduced by Frank Rosenblatt in the late 1950s and is primarily used for binary classification tasks.\n",
       "\n",
       "## What is a Perceptron?\n",
       "\n",
       "### Definition\n",
       "A perceptron is a type of linear classifier that makes decisions by weighing input signals, applying an activation function, and producing an output. It mimics the way a biological neuron processes information, hence the name \"perceptron.\"\n",
       "\n",
       "### Structure\n",
       "A perceptron consists of the following components:\n",
       "\n",
       "- **Inputs (Features)**: The perceptron receives multiple inputs, often represented as a feature vector \\( \\mathbf{x} = [x_1, x_2, ..., x_n] \\).\n",
       "  \n",
       "- **Weights**: Each input is associated with a weight \\( w_i \\) that determines its influence on the output. The weights are learned during the training process.\n",
       "  \n",
       "- **Bias**: An additional parameter that allows the model to shift the decision boundary. It helps in improving the model's flexibility.\n",
       "\n",
       "- **Activation Function**: A function that determines the output of the perceptron. The most commonly used activation function for a perceptron is the step function, which produces a binary output (0 or 1) based on whether the weighted sum of the inputs exceeds a certain threshold.\n",
       "\n",
       "### Mathematical Representation\n",
       "The output \\( y \\) of a perceptron can be mathematically expressed as:\n",
       "\n",
       "\\[ \n",
       "y = \n",
       "\\begin{cases} \n",
       "1 & \\text{if } \\sum_{i=1}^{n} w_i x_i + b > 0 \\\\\n",
       "0 & \\text{otherwise} \n",
       "\\end{cases} \n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( \\sum_{i=1}^{n} w_i x_i \\) is the weighted sum of inputs.\n",
       "- \\( b \\) is the bias term.\n",
       "\n",
       "### Learning Process\n",
       "The perceptron learns by adjusting the weights and bias based on the error in its predictions. The basic learning algorithm involves:\n",
       "1. Initializing weights and bias (often randomly).\n",
       "2. For each training sample, calculating the output.\n",
       "3. Updating the weights using the perceptron learning rule:\n",
       "   \\[\n",
       "   w_i \\leftarrow w_i + \\eta (y_{\\text{true}} - y_{\\text{pred}}) x_i\n",
       "   \\]\n",
       "   where \\( \\eta \\) is the learning rate.\n",
       "\n",
       "### Limitations\n",
       "- **Linearly Separable Data**: A perceptron can only classify linearly separable data. If the data cannot be separated by a straight line (or hyperplane in higher dimensions), the perceptron will fail to converge.\n",
       "- **Single Layer**: A single-layer perceptron can only solve problems that are linearly separable, limiting its application in more complex tasks.\n",
       "\n",
       "### Summary\n",
       "The perceptron is a foundational concept in machine learning and neural networks, providing insight into how artificial neurons operate. While its capabilities are limited to linear classification tasks, it laid the groundwork for the development of more advanced neural network architectures, such as multi-layer perceptrons (MLPs) and deep learning models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Introduction to Perceptrons. What is Perceptron?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a742c14-2956-4838-82a0-d322d12e3938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Basic Perceptron Network\n",
       "\n",
       "A basic perceptron network consists of a single layer of perceptrons and is used for binary classification tasks. This network architecture is the simplest form of a neural network and can be understood through its components and functioning.\n",
       "\n",
       "## Components of a Basic Perceptron Network\n",
       "\n",
       "### 1. Inputs\n",
       "The perceptron network accepts multiple input features represented as a vector \\( \\mathbf{x} = [x_1, x_2, ..., x_n] \\).\n",
       "\n",
       "### 2. Weights\n",
       "Each input is associated with a weight \\( w_i \\), which influences how much that input affects the output. The weights are adjusted during the training process to minimize classification error.\n",
       "\n",
       "### 3. Bias\n",
       "The bias term \\( b \\) is added to the weighted sum of inputs. It allows the model to better fit the data by providing an additional degree of freedom.\n",
       "\n",
       "### 4. Activation Function\n",
       "The activation function determines the output of the perceptron. In a basic perceptron, the step function is typically used, which outputs either 0 or 1 based on the threshold.\n",
       "\n",
       "## Mathematical Representation\n",
       "\n",
       "The output \\( y \\) of a perceptron in a basic network can be expressed mathematically as:\n",
       "\n",
       "\\[ \n",
       "y = \n",
       "\\begin{cases} \n",
       "1 & \\text{if } \\sum_{i=1}^{n} w_i x_i + b > 0 \\\\\n",
       "0 & \\text{otherwise} \n",
       "\\end{cases} \n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( \\sum_{i=1}^{n} w_i x_i \\) is the weighted sum of inputs.\n",
       "- \\( b \\) is the bias term.\n",
       "\n",
       "## Functioning of a Basic Perceptron Network\n",
       "\n",
       "### Training Process\n",
       "1. **Initialization**: Set initial weights and bias (often randomly).\n",
       "2. **Forward Pass**: For each input vector, compute the output using the formula mentioned above.\n",
       "3. **Error Calculation**: Compare the predicted output with the actual target label.\n",
       "4. **Weight Update**: Adjust the weights and bias using the perceptron learning rule:\n",
       "\n",
       "   \\[\n",
       "   w_i \\leftarrow w_i + \\eta (y_{\\text{true}} - y_{\\text{pred}}) x_i\n",
       "   \\]\n",
       "\n",
       "   Where \\( \\eta \\) is the learning rate.\n",
       "\n",
       "5. **Iteration**: Repeat the process for multiple epochs until the error converges or a stopping criterion is met.\n",
       "\n",
       "### Limitations\n",
       "- **Linearly Separable Data**: A basic perceptron network can only classify linearly separable data.\n",
       "- **Single Layer**: It does not capture complex patterns due to its single-layer architecture.\n",
       "\n",
       "## Example Use Case\n",
       "A basic perceptron network can be used for tasks like:\n",
       "- **AND Logic Gate**: Classifying inputs that represent the AND operation, where the output is true only if both inputs are true.\n",
       "- **OR Logic Gate**: Classifying inputs that represent the OR operation, where the output is true if at least one input is true.\n",
       "\n",
       "## Summary\n",
       "The basic perceptron network serves as an introductory model in the field of neural networks. Its simplicity makes it an excellent tool for understanding the foundational concepts of neural computation and binary classification. While limited in capacity, it sets the stage for more complex architectures and learning algorithms used in modern machine learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Basic Perceptron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44c0438f-8efe-4dca-ba47-5dfa62ef3f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Activation Functions in Neural Networks / Machine Learning\n",
       "\n",
       "Activation functions play a crucial role in neural networks and machine learning models. They determine the output of a neuron given a set of inputs and are essential for introducing non-linearity into the model, allowing it to learn complex patterns in the data.\n",
       "\n",
       "## Purpose of Activation Functions\n",
       "\n",
       "1. **Non-linearity**: Many real-world problems are non-linear in nature. Activation functions help neural networks capture complex relationships by introducing non-linearity into the model.\n",
       "  \n",
       "2. **Thresholding**: They can act as a decision boundary, helping the model decide whether a neuron should be activated or not based on the input.\n",
       "  \n",
       "3. **Gradient Descent**: Activation functions influence the backpropagation process, affecting how weights are updated during training.\n",
       "\n",
       "## Common Activation Functions\n",
       "\n",
       "### 1. Sigmoid Function\n",
       "- **Formula**: \n",
       "  \\[\n",
       "  \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
       "  \\]\n",
       "- **Range**: (0, 1)\n",
       "- **Characteristics**: \n",
       "  - Smooth gradient, making optimization easier.\n",
       "  - Outputs can be interpreted as probabilities.\n",
       "- **Limitations**: \n",
       "  - Prone to vanishing gradient problem for very high or low input values.\n",
       "\n",
       "### 2. Hyperbolic Tangent (tanh)\n",
       "- **Formula**: \n",
       "  \\[\n",
       "  \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
       "  \\]\n",
       "- **Range**: (-1, 1)\n",
       "- **Characteristics**: \n",
       "  - Zero-centered output, which can help in faster convergence.\n",
       "- **Limitations**: \n",
       "  - Also suffers from the vanishing gradient problem.\n",
       "\n",
       "### 3. Rectified Linear Unit (ReLU)\n",
       "- **Formula**: \n",
       "  \\[\n",
       "  f(x) = \\max(0, x)\n",
       "  \\]\n",
       "- **Range**: [0, ∞)\n",
       "- **Characteristics**: \n",
       "  - Computationally efficient.\n",
       "  - Helps mitigate the vanishing gradient problem.\n",
       "- **Limitations**: \n",
       "  - Can suffer from the \"dying ReLU\" problem, where neurons become inactive and only output zero.\n",
       "\n",
       "### 4. Leaky ReLU\n",
       "- **Formula**: \n",
       "  \\[\n",
       "  f(x) = \\begin{cases} \n",
       "  x & \\text{if } x > 0 \\\\ \n",
       "  \\alpha x & \\text{otherwise} \n",
       "  \\end{cases}\n",
       "  \\]\n",
       "  (where \\( \\alpha \\) is a small constant, e.g., 0.01)\n",
       "- **Range**: (-∞, ∞)\n",
       "- **Characteristics**: \n",
       "  - Allows a small gradient when the input is negative, helping to prevent the dying ReLU problem.\n",
       "\n",
       "### 5. Softmax\n",
       "- **Formula**: \n",
       "  \\[\n",
       "  \\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}\n",
       "  \\]\n",
       "  (for \\( i = 1, 2, ..., K \\))\n",
       "- **Range**: (0, 1) for each output.\n",
       "- **Characteristics**: \n",
       "  - Converts logits (raw model outputs) into probabilities.\n",
       "  - Used primarily in the output layer for multi-class classification problems.\n",
       "\n",
       "## Summary\n",
       "Activation functions are essential components of neural networks that introduce non-linearity, enabling the model to learn complex relationships within data. Choosing the appropriate activation function is crucial for the performance of the model and can significantly impact the training process and final accuracy. Understanding the characteristics, advantages, and limitations of each activation function is vital for designing effective neural network architectures."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What are Activation Functions in Neural Network / ML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa71842c-dcb9-4e07-9293-d87b4c8d8cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Linear Activation Function\n",
       "\n",
       "The linear activation function is one of the simplest activation functions used in neural networks. It is characterized by its straightforward mathematical representation and is particularly useful in specific contexts, such as regression tasks.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The linear activation function can be defined mathematically as:\n",
       "\n",
       "\\[\n",
       "f(x) = ax + b\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( f(x) \\) is the output of the activation function.\n",
       "- \\( x \\) is the input to the function.\n",
       "- \\( a \\) is the slope (weight) of the line.\n",
       "- \\( b \\) is the y-intercept (bias).\n",
       "\n",
       "In its simplest form, when \\( a = 1 \\) and \\( b = 0 \\), the function simplifies to:\n",
       "\n",
       "\\[\n",
       "f(x) = x\n",
       "\\]\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Output Range**: The output of a linear activation function can range from negative infinity to positive infinity. This means it can take any real value, making it suitable for tasks where a wide range of values is necessary.\n",
       "\n",
       "2. **Non-Nonlinearity**: The linear activation function does not introduce any non-linearity to the model. This can be both an advantage and a disadvantage, depending on the application.\n",
       "\n",
       "3. **Gradient**: The derivative of the linear function is constant:\n",
       "\n",
       "\\[\n",
       "f'(x) = a\n",
       "\\]\n",
       "\n",
       "This property makes it easy to compute gradients during the backpropagation phase of training.\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Regression Tasks\n",
       "Linear activation functions are often used in the output layer of regression models, where the goal is to predict a continuous value. In such cases, the linear output is suitable because it can represent a wide range of values.\n",
       "\n",
       "### 2. Intermediate Layers\n",
       "In some architectures, especially when combined with other activation functions, linear activation may be used in hidden layers. However, it is less common due to the lack of non-linearity.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Lack of Non-linearity**: The primary limitation of the linear activation function is its inability to model complex relationships. Since the output is a linear transformation of the input, multiple layers of linear activations will collapse into a single linear transformation. This means that stacking layers of neurons with linear activation functions does not increase the model's capacity.\n",
       "\n",
       "2. **Vanishing Gradient**: While the gradient is constant, it can lead to issues during training in deeper networks. If all layers use linear activations, the model will not learn effectively, as it cannot capture non-linear relationships in the data.\n",
       "\n",
       "## Summary\n",
       "\n",
       "The linear activation function is a simple yet powerful tool in specific contexts, particularly for regression tasks. While it provides straightforward outputs and easy gradient calculations, its lack of non-linearity limits its effectiveness in more complex neural network architectures. For most applications requiring deep learning, other activation functions (such as ReLU, sigmoid, or tanh) are preferred to capture complex patterns in data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the Linear Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae10a76f-bea6-4201-92de-5e8550b92487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Binary Step Activation Function\n",
       "\n",
       "The binary step activation function is one of the simplest activation functions used in neural networks, particularly in binary classification tasks. It serves as a threshold function that maps input values to binary outputs.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The binary step activation function can be defined mathematically as:\n",
       "\n",
       "\\[\n",
       "f(x) = \n",
       "\\begin{cases} \n",
       "1 & \\text{if } x \\geq 0 \\\\ \n",
       "0 & \\text{if } x < 0 \n",
       "\\end{cases}\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( f(x) \\) is the output of the activation function.\n",
       "- \\( x \\) is the input to the function.\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Output Values**: The binary step function outputs only two values: 0 or 1. This makes it suitable for binary classification problems, where the goal is to classify inputs into one of two classes.\n",
       "\n",
       "2. **Thresholding**: The function acts as a threshold function, activating (outputting 1) when the input is greater than or equal to zero and deactivating (outputting 0) otherwise.\n",
       "\n",
       "3. **Non-Differentiability**: The binary step function is not differentiable at \\( x = 0 \\). This can pose problems for optimization algorithms that rely on gradient descent, as gradients are needed for weight updates.\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Binary Classification\n",
       "The binary step activation function is primarily used in simple binary classification tasks where the output is either one class (1) or another (0). It can be found in early neural network models.\n",
       "\n",
       "### 2. Perceptrons\n",
       "The binary step function is closely associated with the perceptron model, which is a type of linear classifier. In perceptrons, the binary step function is used to make decisions based on whether the weighted sum of inputs exceeds a certain threshold.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Non-linearity**: The binary step function does not introduce any non-linearity to the model. This limits the ability of the network to capture complex patterns, especially in deeper networks.\n",
       "\n",
       "2. **Vanishing Gradient Problem**: Since the function outputs either 0 or 1, the gradients become zero for all inputs except at the point of discontinuity (when \\( x = 0 \\)). This leads to the vanishing gradient problem, where weights do not update effectively during training.\n",
       "\n",
       "3. **Not Suitable for Multi-Class Problems**: The binary step function can only handle binary outputs, making it unsuitable for multi-class classification tasks.\n",
       "\n",
       "## Summary\n",
       "\n",
       "The binary step activation function is a straightforward and simple activation function primarily used in binary classification tasks. While it is easy to understand and implement, its lack of differentiability and non-linearity limits its effectiveness in complex models. As a result, more advanced activation functions, such as sigmoid or softmax, are often preferred in modern neural networks for classification problems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the Binary Step Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e697097-f715-41f6-ac7f-dc6cbc4b6983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Sigmoid Activation Function\n",
       "\n",
       "The sigmoid activation function is a widely used activation function in neural networks, particularly in binary classification tasks. It is known for its characteristic \"S\" shaped curve, which maps input values to a range between 0 and 1.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The sigmoid activation function can be mathematically defined as:\n",
       "\n",
       "\\[\n",
       "f(x) = \\frac{1}{1 + e^{-x}}\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( f(x) \\) is the output of the activation function.\n",
       "- \\( x \\) is the input to the function.\n",
       "- \\( e \\) is the base of the natural logarithm, approximately equal to 2.71828.\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Output Range**: The output of the sigmoid function ranges from 0 to 1. This makes it particularly useful for models that need to predict probabilities, as it can be interpreted as the likelihood of a certain class.\n",
       "\n",
       "2. **S-shaped Curve**: The sigmoid function has an \"S\" shaped curve, which means that it can smoothly transition between 0 and 1. As \\( x \\) approaches positive infinity, the output approaches 1, and as \\( x \\) approaches negative infinity, the output approaches 0.\n",
       "\n",
       "3. **Gradient**: The derivative of the sigmoid function is given by:\n",
       "\n",
       "\\[\n",
       "f'(x) = f(x) \\cdot (1 - f(x))\n",
       "\\]\n",
       "\n",
       "This property means that the gradient is highest when the output is around 0.5, which allows for effective learning in the mid-range of inputs.\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Binary Classification\n",
       "The sigmoid activation function is commonly used in the output layer of binary classification neural networks, where it outputs the probability of the positive class.\n",
       "\n",
       "### 2. Logistic Regression\n",
       "The sigmoid function is the basis for logistic regression, which is a statistical model used for binary classification. It transforms linear combinations of input features into probabilities.\n",
       "\n",
       "### 3. Hidden Layers\n",
       "Although less common now, the sigmoid function has historically been used in hidden layers of neural networks. However, other activation functions such as ReLU are often preferred due to performance reasons.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Vanishing Gradient Problem**: One of the significant drawbacks of the sigmoid function is the vanishing gradient problem. For very high or very low input values, the gradient approaches zero, which can slow down or halt the learning process during training.\n",
       "\n",
       "2. **Output Not Zero-Centered**: The outputs of the sigmoid function are not zero-centered (ranging from 0 to 1). This can lead to inefficient gradient updates since gradients will always be positive or always negative, potentially causing issues in optimization.\n",
       "\n",
       "3. **Computationally Expensive**: Calculating the exponential function can be computationally expensive compared to other activation functions like ReLU.\n",
       "\n",
       "## Summary\n",
       "\n",
       "The sigmoid activation function is a fundamental activation function used primarily in binary classification tasks and logistic regression. While it effectively maps inputs to probabilities and has a smooth gradient, its limitations, such as the vanishing gradient problem and lack of zero-centered outputs, have led to the adoption of alternative activation functions in many modern neural network architectures."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3558bd6f-8a2d-4897-92e6-cd19f4f33a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Tanh Activation Function\n",
       "\n",
       "The hyperbolic tangent (tanh) activation function is a widely used activation function in neural networks. It is similar to the sigmoid function but outputs values in a range that is centered around zero, making it beneficial for certain types of neural network architectures.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The tanh activation function can be mathematically defined as:\n",
       "\n",
       "\\[\n",
       "f(x) = \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
       "\\]\n",
       "\n",
       "Alternatively, it can also be expressed using the exponential function:\n",
       "\n",
       "\\[\n",
       "f(x) = \\frac{2}{1 + e^{-2x}} - 1\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( f(x) \\) is the output of the activation function.\n",
       "- \\( x \\) is the input to the function.\n",
       "- \\( e \\) is the base of the natural logarithm, approximately equal to 2.71828.\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Output Range**: The output of the tanh function ranges from -1 to 1. This property allows the function to be zero-centered, which can help improve convergence during training.\n",
       "\n",
       "2. **S-shaped Curve**: The tanh function has an \"S\" shaped curve similar to the sigmoid function but is steeper, which can lead to better performance in certain scenarios.\n",
       "\n",
       "3. **Gradient**: The derivative of the tanh function is given by:\n",
       "\n",
       "\\[\n",
       "f'(x) = 1 - f(x)^2\n",
       "\\]\n",
       "\n",
       "This means that the gradient is highest when the output is near zero, which facilitates learning for inputs close to this range.\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Hidden Layers\n",
       "The tanh activation function is often used in the hidden layers of neural networks, especially in recurrent neural networks (RNNs) and deep networks. Its zero-centered output helps in faster convergence during training.\n",
       "\n",
       "### 2. RNNs and LSTMs\n",
       "In recurrent neural networks (RNNs) and Long Short-Term Memory (LSTM) networks, the tanh function is commonly used to keep the output values in a manageable range, aiding in the learning of temporal patterns.\n",
       "\n",
       "### 3. Feature Scaling\n",
       "The zero-centered nature of the tanh function is beneficial when inputs are not normalized, as it can help mitigate issues related to non-zero-centered data.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Vanishing Gradient Problem**: Similar to the sigmoid function, the tanh function can also suffer from the vanishing gradient problem. For large positive or negative input values, the gradient approaches zero, which can hinder the learning process during training.\n",
       "\n",
       "2. **Computational Complexity**: While less computationally intensive than the sigmoid due to its reduced reliance on exponentials, the tanh function still involves calculating exponentials, making it more computationally intensive than simpler functions like ReLU.\n",
       "\n",
       "3. **Not Suitable for Output Layer in Regression**: The output range of -1 to 1 makes the tanh function unsuitable for regression tasks where unbounded outputs are needed.\n",
       "\n",
       "## Summary\n",
       "\n",
       "The tanh activation function is a powerful tool in the neural network toolkit, offering a zero-centered output and improved gradient characteristics compared to the sigmoid function. While it is widely used in hidden layers and RNNs, its susceptibility to the vanishing gradient problem is a consideration when designing deep learning models. Despite these limitations, the tanh function remains a popular choice for many neural network architectures."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the Tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bc575fa-7b9c-4fee-8106-138037b186df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ReLU Activation Function\n",
       "\n",
       "The Rectified Linear Unit (ReLU) activation function is one of the most popular activation functions used in deep learning models. It is known for its simplicity and effectiveness in training deep neural networks.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The ReLU activation function can be mathematically defined as:\n",
       "\n",
       "\\[\n",
       "f(x) = \\max(0, x)\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( f(x) \\) is the output of the activation function.\n",
       "- \\( x \\) is the input to the function.\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Output Range**: The output of the ReLU function ranges from 0 to positive infinity. If the input is negative, the output is 0; if the input is positive, the output is equal to the input.\n",
       "\n",
       "2. **Sparsity**: ReLU introduces sparsity in the neural network, as it outputs zero for any negative input. This sparsity can lead to more efficient computations and reduced model complexity.\n",
       "\n",
       "3. **Computational Efficiency**: The ReLU function is computationally efficient, as it involves a simple thresholding at zero. This allows for faster training and inference compared to activation functions that involve exponential calculations, such as sigmoid and tanh.\n",
       "\n",
       "4. **Gradient**: The derivative of the ReLU function is:\n",
       "\n",
       "\\[\n",
       "f'(x) = \n",
       "\\begin{cases} \n",
       "0 & \\text{if } x < 0 \\\\ \n",
       "1 & \\text{if } x > 0 \n",
       "\\end{cases}\n",
       "\\]\n",
       "\n",
       "For \\( x = 0 \\), the gradient is typically considered to be undefined, but in practice, it is often set to zero.\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Hidden Layers\n",
       "ReLU is commonly used in the hidden layers of deep neural networks due to its ability to mitigate the vanishing gradient problem, which can occur with sigmoid and tanh activations in deep networks.\n",
       "\n",
       "### 2. Convolutional Neural Networks (CNNs)\n",
       "ReLU is extensively used in convolutional neural networks (CNNs) for image processing tasks, where it helps to introduce non-linearity without adding significant computational overhead.\n",
       "\n",
       "### 3. Deep Learning Architectures\n",
       "ReLU is a standard activation function in various deep learning architectures, including feedforward networks, convolutional networks, and deep reinforcement learning models.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Dying ReLU Problem**: One of the main issues with ReLU is the \"dying ReLU\" problem, where neurons can become inactive during training. If a neuron consistently outputs zero for all inputs, it may stop learning altogether.\n",
       "\n",
       "2. **Unbounded Output**: The unbounded nature of ReLU can lead to issues during training, such as exploding gradients, especially in deeper networks.\n",
       "\n",
       "3. **Gradient at Zero**: The gradient is zero for negative inputs, which means that neurons can become inactive and not contribute to the learning process.\n",
       "\n",
       "## Variants\n",
       "\n",
       "To address some of its limitations, several variants of ReLU have been proposed:\n",
       "\n",
       "- **Leaky ReLU**: Allows a small, non-zero gradient when the input is negative, which helps mitigate the dying ReLU problem.\n",
       "  \n",
       "  \\[\n",
       "  f(x) = \n",
       "  \\begin{cases} \n",
       "  x & \\text{if } x > 0 \\\\ \n",
       "  \\alpha x & \\text{if } x \\leq 0 \n",
       "  \\end{cases}\n",
       "  \\]\n",
       "  \n",
       "  where \\( \\alpha \\) is a small constant (e.g., 0.01).\n",
       "\n",
       "- **Parametric ReLU (PReLU)**: Similar to Leaky ReLU, but the slope of the negative part is learned during training.\n",
       "\n",
       "- **Exponential Linear Unit (ELU)**: Outputs a smooth exponential for negative inputs, which helps to maintain mean activations closer to zero.\n",
       "\n",
       "## Summary\n",
       "\n",
       "The ReLU activation function has become a cornerstone of modern deep learning due to its simplicity, efficiency, and effectiveness in training deep networks. While it has some limitations, such as the dying ReLU problem, its advantages often outweigh these drawbacks. Variants like Leaky ReLU and ELU have been developed to address these issues, further enhancing the flexibility of neural network architectures."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f27ffa24-b8b0-44af-9e4e-c80b271f22b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Leaky ReLU Activation Function\n",
       "\n",
       "Leaky Rectified Linear Unit (Leaky ReLU) is a variant of the ReLU activation function designed to address some of the limitations associated with the standard ReLU, particularly the \"dying ReLU\" problem, where neurons can become inactive and stop learning.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The Leaky ReLU activation function can be mathematically defined as:\n",
       "\n",
       "\\[\n",
       "f(x) = \n",
       "\\begin{cases} \n",
       "x & \\text{if } x > 0 \\\\ \n",
       "\\alpha x & \\text{if } x \\leq 0 \n",
       "\\end{cases}\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( f(x) \\) is the output of the activation function.\n",
       "- \\( x \\) is the input to the function.\n",
       "- \\( \\alpha \\) is a small constant (commonly set to 0.01) that determines the slope of the function for negative input values.\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Output Range**: The output of Leaky ReLU ranges from negative infinity to positive infinity, similar to the standard ReLU for positive inputs. However, for negative inputs, it produces a small, non-zero output.\n",
       "\n",
       "2. **Non-zero Gradient**: Unlike standard ReLU, which has a gradient of zero for negative inputs, Leaky ReLU has a small gradient (\\(\\alpha\\)) for negative values. This helps prevent neurons from becoming completely inactive during training.\n",
       "\n",
       "3. **Computational Efficiency**: Like ReLU, Leaky ReLU is computationally efficient, as it involves a simple linear operation for both positive and negative inputs.\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Hidden Layers\n",
       "Leaky ReLU is often used in hidden layers of neural networks to mitigate the dying ReLU problem, allowing for more neurons to remain active during training.\n",
       "\n",
       "### 2. Deep Learning Architectures\n",
       "Leaky ReLU can be beneficial in various deep learning architectures, especially in deeper networks where the risk of dying neurons is higher.\n",
       "\n",
       "### 3. Convolutional Neural Networks (CNNs)\n",
       "Leaky ReLU is also commonly applied in CNNs for image classification and other tasks, where maintaining active neurons can improve performance.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Choosing \\(\\alpha\\)**: The choice of the slope \\(\\alpha\\) for negative inputs is somewhat arbitrary and may require tuning. A value that is too high can lead to unnecessarily large negative outputs, while a value that is too low may not effectively mitigate the dying ReLU problem.\n",
       "\n",
       "2. **Unbounded Output**: Similar to ReLU, Leaky ReLU can produce unbounded outputs, which might lead to exploding gradients in certain scenarios, especially in very deep networks.\n",
       "\n",
       "3. **Non-smoothness**: The transition between the linear and leaky regions creates a kink at \\( x = 0 \\), which can make optimization less smooth compared to other activation functions like ELU or Swish.\n",
       "\n",
       "## Summary\n",
       "\n",
       "Leaky ReLU is a popular activation function that addresses some of the shortcomings of the standard ReLU by allowing a small, non-zero gradient for negative input values. This feature helps to prevent neurons from becoming inactive, promoting better learning in neural networks. While it offers advantages in maintaining active neurons, careful selection of the parameter \\(\\alpha\\) is essential for optimal performance. Leaky ReLU is widely used in various deep learning applications, including convolutional and feedforward networks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the Leaky ReLU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b5019f5-1b3a-4181-bc4c-870e0c9e7512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ELU Activation Function\n",
       "\n",
       "Exponential Linear Unit (ELU) is an activation function designed to combine the advantages of ReLU and Leaky ReLU while mitigating some of their limitations. ELUs are particularly useful in deep learning models, especially for training deep neural networks, due to their ability to maintain a smooth gradient.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The ELU activation function can be mathematically defined as:\n",
       "\n",
       "\\[\n",
       "f(x) = \n",
       "\\begin{cases} \n",
       "x & \\text{if } x > 0 \\\\ \n",
       "\\alpha (e^x - 1) & \\text{if } x \\leq 0 \n",
       "\\end{cases}\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( f(x) \\) is the output of the activation function.\n",
       "- \\( x \\) is the input to the function.\n",
       "- \\( \\alpha \\) is a hyperparameter that controls the value to which an ELU saturates for negative \\( x \\), typically set to a value greater than zero (e.g., 1).\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Output Range**: The output of ELU ranges from \\(-\\alpha\\) (for negative inputs) to positive infinity. This allows ELUs to output a negative value for inputs less than zero, unlike standard ReLU which outputs zero.\n",
       "\n",
       "2. **Smoothness**: ELU is smooth and differentiable everywhere, which can lead to more stable training and convergence compared to ReLU and Leaky ReLU.\n",
       "\n",
       "3. **Non-zero Mean**: By producing negative outputs for negative inputs, ELU can help keep the mean activations closer to zero. This property can improve the learning dynamics and speed up convergence in deep networks.\n",
       "\n",
       "4. **Gradient**: The derivative of the ELU function is given by:\n",
       "\n",
       "\\[\n",
       "f'(x) = \n",
       "\\begin{cases} \n",
       "1 & \\text{if } x > 0 \\\\ \n",
       "\\alpha e^x & \\text{if } x \\leq 0 \n",
       "\\end{cases}\n",
       "\\]\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Deep Neural Networks\n",
       "ELUs are often utilized in deep neural networks where maintaining smooth gradients and reducing the risk of vanishing gradients is crucial.\n",
       "\n",
       "### 2. Convolutional Neural Networks (CNNs)\n",
       "ELUs can be effective in CNNs for tasks such as image classification, where improved convergence rates and performance are desired.\n",
       "\n",
       "### 3. Reinforcement Learning\n",
       "In reinforcement learning models, ELUs can help stabilize training and improve the performance of agents learning from complex environments.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Computational Complexity**: Unlike ReLU, which only requires a simple threshold operation, ELU involves an exponential function for negative inputs, making it computationally more intensive.\n",
       "\n",
       "2. **Choice of \\(\\alpha\\)**: The performance of ELUs can depend on the choice of the \\(\\alpha\\) parameter, which may require tuning for optimal results.\n",
       "\n",
       "3. **Output Saturation**: While ELUs help reduce the mean of the activations, the saturation effect can still occur for large negative inputs, leading to potential issues like slow learning.\n",
       "\n",
       "## Summary\n",
       "\n",
       "The ELU activation function offers a blend of advantages from both ReLU and Leaky ReLU, providing smooth and non-zero gradients for negative inputs. This property helps in maintaining a zero-centered mean, improving training dynamics in deep neural networks. Despite being computationally more complex, ELUs are widely adopted in various deep learning applications due to their effectiveness in promoting faster convergence and better performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the ELU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ac70bc6-a852-4dcd-a160-b2aa9aa739ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Swish Activation Function\n",
       "\n",
       "Swish is an activation function proposed by researchers at Google, which is designed to improve the performance of deep learning models. It is a smooth, non-monotonic function that has shown to outperform traditional activation functions like ReLU and sigmoid in various tasks, particularly in deep neural networks.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The Swish activation function can be mathematically defined as:\n",
       "\n",
       "\\[\n",
       "f(x) = x \\cdot \\sigma(x) = \\frac{x}{1 + e^{-x}}\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( f(x) \\) is the output of the activation function.\n",
       "- \\( x \\) is the input to the function.\n",
       "- \\( \\sigma(x) \\) is the sigmoid function.\n",
       "\n",
       "Alternatively, Swish can also be expressed in terms of its variant with a learnable parameter \\( \\beta \\):\n",
       "\n",
       "\\[\n",
       "f(x) = x \\cdot \\sigma(\\beta x)\n",
       "\\]\n",
       "\n",
       "Where \\( \\beta \\) is a parameter that can be learned during training.\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Smooth and Non-monotonic**: Swish is a smooth function, meaning it is continuous and differentiable everywhere, allowing for stable gradient flow during optimization. Its non-monotonic nature (it can increase and decrease) helps capture complex patterns in data.\n",
       "\n",
       "2. **Output Range**: The output of Swish ranges from negative infinity to positive infinity, similar to linear functions, but it approaches zero more gradually for negative inputs.\n",
       "\n",
       "3. **Self-gated**: Swish is self-gated, meaning it multiplies the input by a nonlinear function of itself (the sigmoid function). This characteristic enables the function to have a non-zero output for negative inputs, which can help prevent the dying ReLU problem.\n",
       "\n",
       "4. **Derivative**: The derivative of the Swish function is given by:\n",
       "\n",
       "\\[\n",
       "f'(x) = \\sigma(x) + x \\sigma(x) (1 - \\sigma(x))\n",
       "\\]\n",
       "\n",
       "This property allows for efficient calculations during backpropagation.\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Deep Learning Models\n",
       "Swish has been successfully applied in various deep learning architectures, often leading to improved performance in tasks such as image classification, natural language processing, and reinforcement learning.\n",
       "\n",
       "### 2. Convolutional Neural Networks (CNNs)\n",
       "In CNNs, Swish can enhance the learning capacity of the model, contributing to better feature extraction and representation.\n",
       "\n",
       "### 3. Transformers\n",
       "Swish has been utilized in transformer architectures, where its smooth gradient properties can improve convergence and performance on complex tasks.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Computational Overhead**: The calculation of the sigmoid function can introduce additional computational overhead compared to simpler activation functions like ReLU.\n",
       "\n",
       "2. **Less Familiar**: Swish is less commonly used than ReLU, which may lead to less community support and fewer established best practices for its implementation.\n",
       "\n",
       "3. **Parameter Tuning**: When using the variant with a learnable parameter \\( \\beta \\), additional hyperparameter tuning may be required, which can complicate the training process.\n",
       "\n",
       "## Summary\n",
       "\n",
       "The Swish activation function is a smooth, non-monotonic function that combines the input with the sigmoid of the input, providing advantages in terms of gradient flow and performance in deep neural networks. Its ability to output non-zero values for negative inputs helps mitigate issues such as the dying ReLU problem. While it may introduce some computational overhead, Swish has been shown to enhance learning in various applications, making it a valuable option for modern neural network architectures."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the Swish Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50b52a2b-f6f6-41fa-831f-85e019ca5051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Maxout Activation Function\n",
       "\n",
       "Maxout is an activation function introduced to overcome some limitations of traditional activation functions like ReLU and sigmoid. It is particularly useful in deep learning, allowing for greater flexibility in modeling complex functions.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The Maxout activation function can be mathematically defined as follows:\n",
       "\n",
       "\\[\n",
       "f(x) = \\max(z_1, z_2, \\ldots, z_k)\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( f(x) \\) is the output of the activation function.\n",
       "- \\( z_1, z_2, \\ldots, z_k \\) are the outputs from the linear combinations of the input, typically represented as \\( z_i = w_i^T x + b_i \\) for \\( i = 1, 2, \\ldots, k \\), where \\( w_i \\) are the weights and \\( b_i \\) are the biases.\n",
       "\n",
       "In the most common implementation, \\( k \\) is set to 2, leading to:\n",
       "\n",
       "\\[\n",
       "f(x) = \\max(w_1^T x + b_1, w_2^T x + b_2)\n",
       "\\]\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Piecewise Linear**: Maxout is a piecewise linear function, meaning it is made up of linear segments. This property allows it to approximate any convex function, making it highly versatile.\n",
       "\n",
       "2. **No Saturation**: Unlike sigmoid or hyperbolic tangent functions, Maxout does not saturate; it can produce outputs in an unbounded range, mitigating the vanishing gradient problem often encountered in deep networks.\n",
       "\n",
       "3. **Flexibility**: Since Maxout can combine multiple linear functions, it can learn more complex patterns compared to traditional activations. This flexibility enables it to adapt better to various data distributions.\n",
       "\n",
       "4. **Non-Negative Outputs**: While Maxout can output negative values depending on the linear combinations, the maximum operation ensures that the output is always determined by the best-performing linear transformation.\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Deep Neural Networks\n",
       "Maxout is often used in deep neural networks to improve learning dynamics and model capacity, particularly in settings where ReLU may lead to dead neurons.\n",
       "\n",
       "### 2. Convolutional Neural Networks (CNNs)\n",
       "In CNNs, Maxout can enhance feature extraction by allowing the model to capture more complex patterns in the data.\n",
       "\n",
       "### 3. Generative Models\n",
       "Maxout has been applied in generative models, such as Generative Adversarial Networks (GANs), where the flexibility in modeling can lead to better generation of diverse outputs.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Computational Complexity**: The implementation of Maxout requires maintaining multiple linear transformations, which can introduce additional computational overhead compared to simpler activation functions like ReLU.\n",
       "\n",
       "2. **Memory Usage**: Storing multiple sets of weights and biases for the linear combinations may lead to increased memory usage in large networks.\n",
       "\n",
       "3. **Less Common**: Maxout is less widely adopted than traditional activations like ReLU or sigmoid, leading to less community support and fewer established best practices.\n",
       "\n",
       "## Summary\n",
       "\n",
       "The Maxout activation function is a flexible, piecewise linear function that can approximate complex patterns and mitigate issues like vanishing gradients. By selecting the maximum output from multiple linear transformations, Maxout provides a versatile alternative to traditional activation functions in deep learning architectures. While it may introduce some computational overhead, its ability to learn more complex relationships can lead to improved performance in various applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the Maxout Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "815f292e-ab13-4618-831e-697a935e8e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# SoftMax Activation Function\n",
       "\n",
       "The SoftMax activation function is a generalization of the logistic function that transforms a vector of raw scores (logits) into a probability distribution over multiple classes. It is widely used in the output layer of multi-class classification problems, particularly in neural networks.\n",
       "\n",
       "## Definition\n",
       "\n",
       "The SoftMax function is mathematically defined as follows:\n",
       "\n",
       "\\[\n",
       "\\sigma(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}\n",
       "\\]\n",
       "\n",
       "Where:\n",
       "- \\( \\sigma(z_i) \\) is the output of the SoftMax function for class \\( i \\).\n",
       "- \\( z_i \\) is the raw score (logit) for class \\( i \\).\n",
       "- \\( K \\) is the total number of classes.\n",
       "- The denominator sums the exponentials of all the logits, ensuring that the output probabilities sum to 1.\n",
       "\n",
       "## Characteristics\n",
       "\n",
       "1. **Probability Distribution**: The output of the SoftMax function is a vector of probabilities. Each element is in the range (0, 1), and the sum of all outputs equals 1, making it suitable for multi-class classification tasks.\n",
       "\n",
       "2. **Exponentiation**: The use of the exponential function amplifies the differences between the logits. Larger logits result in higher probabilities, while smaller logits lead to lower probabilities.\n",
       "\n",
       "3. **Sensitivity to Input Values**: SoftMax is sensitive to the relative scale of the input logits. Small changes in the input can lead to significant changes in the output probabilities, especially when one logit is much larger than the others.\n",
       "\n",
       "4. **Differentiability**: SoftMax is a smooth and differentiable function, which allows for efficient backpropagation during the training of neural networks.\n",
       "\n",
       "## Use Cases\n",
       "\n",
       "### 1. Multi-Class Classification\n",
       "SoftMax is commonly used in the output layer of neural networks for multi-class classification tasks, where the goal is to assign an input to one of several possible classes.\n",
       "\n",
       "### 2. Natural Language Processing (NLP)\n",
       "In NLP applications, such as language modeling and machine translation, SoftMax is used to predict the next word or class from a set of possible words.\n",
       "\n",
       "### 3. Reinforcement Learning\n",
       "SoftMax can also be found in reinforcement learning algorithms, where it is used to model the probability distribution over actions, allowing agents to explore different actions based on their estimated rewards.\n",
       "\n",
       "## Limitations\n",
       "\n",
       "1. **Numerical Stability**: The computation of the exponential function can lead to numerical instability, particularly when the logits are large or very close to each other. A common practice to address this is to subtract the maximum logit from each logit before applying the SoftMax function:\n",
       "\n",
       "\\[\n",
       "\\sigma(z_i) = \\frac{e^{z_i - \\max(z)}}{\\sum_{j=1}^{K} e^{z_j - \\max(z)}}\n",
       "\\]\n",
       "\n",
       "2. **Single Class Output**: While SoftMax is suitable for multi-class problems, it is not appropriate for binary classification tasks where simpler activation functions like sigmoid may be more effective.\n",
       "\n",
       "3. **Overconfidence**: SoftMax can produce overly confident predictions, where one class has a high probability while others have very low probabilities, potentially leading to poor generalization on unseen data.\n",
       "\n",
       "## Summary\n",
       "\n",
       "The SoftMax activation function is a powerful tool for transforming raw scores into a probability distribution over multiple classes, making it ideal for multi-class classification tasks. Its ability to amplify differences between logits and produce normalized probabilities is beneficial in various applications, particularly in neural networks. However, considerations regarding numerical stability and output confidence should be taken into account when using SoftMax in practice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Define and explain the SoftMax Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c70705-993c-474c-9876-7acbc9ef79fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is an Algorithm?\n",
       "\n",
       "An **algorithm** is a step-by-step procedure or a set of rules designed to perform a specific task or solve a particular problem. Algorithms are fundamental to computer science and programming, as they provide a clear and unambiguous method for computation.\n",
       "\n",
       "## Key Characteristics of Algorithms\n",
       "\n",
       "1. **Finiteness**: An algorithm must always terminate after a finite number of steps.\n",
       "  \n",
       "2. **Well-defined Inputs**: It should have defined inputs, which can be zero or more, that the algorithm will process.\n",
       "\n",
       "3. **Well-defined Outputs**: An algorithm should produce one or more outputs that are results of the input processing.\n",
       "\n",
       "4. **Effectiveness**: The steps of the algorithm should be basic enough to be carried out, in principle, by a person using paper and pencil.\n",
       "\n",
       "5. **Generality**: An algorithm should be applicable to a set of problems, not just a single instance.\n",
       "\n",
       "## Examples of Algorithms\n",
       "\n",
       "- **Sorting Algorithms**: Such as Quick Sort, Merge Sort, and Bubble Sort, which arrange elements in a specified order.\n",
       "  \n",
       "- **Search Algorithms**: Such as Binary Search and Linear Search, which are used to find an element in a collection.\n",
       "\n",
       "- **Mathematical Algorithms**: Such as the Euclidean algorithm for finding the greatest common divisor (GCD) of two numbers.\n",
       "\n",
       "## Algorithm Representation\n",
       "\n",
       "Algorithms can be represented in various forms, including:\n",
       "\n",
       "- **Natural Language**: Describing the steps in plain language.\n",
       "  \n",
       "- **Pseudocode**: A high-level description of an algorithm that uses a mixture of natural language and programming constructs.\n",
       "\n",
       "- **Flowcharts**: Visual representations of the algorithm using symbols to denote different types of actions or steps.\n",
       "\n",
       "- **Programming Code**: The actual implementation of an algorithm in a programming language.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, algorithms are essential tools in computing and problem-solving, providing systematic methods to achieve desired outcomes efficiently. Understanding algorithms helps in optimizing solutions and improving the performance of programs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is an Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07850c9f-c922-4c0d-b822-3d18ce4e1a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is an Algorithm in the Machine Learning (ML) Concept?\n",
       "\n",
       "In the context of **Machine Learning (ML)**, an **algorithm** refers to a mathematical model or a computational process that allows computers to learn from data. These algorithms analyze data, identify patterns, and make decisions or predictions based on that data without being explicitly programmed for each specific task.\n",
       "\n",
       "## Key Characteristics of ML Algorithms\n",
       "\n",
       "1. **Data-Driven**: ML algorithms learn from historical data, improving their performance as more data becomes available.\n",
       "\n",
       "2. **Adaptability**: They can adjust their internal parameters and improve over time based on new information.\n",
       "\n",
       "3. **Generalization**: The ability to make accurate predictions on unseen data based on the patterns learned from the training dataset.\n",
       "\n",
       "4. **Types of Learning**:\n",
       "   - **Supervised Learning**: The model is trained on labeled data, where the correct output is known.\n",
       "   - **Unsupervised Learning**: The model works with unlabeled data to identify patterns and structures within the data.\n",
       "   - **Reinforcement Learning**: The model learns through trial and error by receiving rewards or penalties based on its actions.\n",
       "\n",
       "## Common Types of ML Algorithms\n",
       "\n",
       "1. **Linear Regression**: Used for predicting a continuous value based on linear relationships in the data.\n",
       "\n",
       "2. **Logistic Regression**: Used for binary classification problems where the output is categorical.\n",
       "\n",
       "3. **Decision Trees**: A flowchart-like structure used for classification and regression tasks.\n",
       "\n",
       "4. **Support Vector Machines (SVM)**: A classification algorithm that finds the hyperplane that best separates classes in the data.\n",
       "\n",
       "5. **k-Nearest Neighbors (k-NN)**: A classification technique that assigns a class based on the majority class of its k nearest neighbors.\n",
       "\n",
       "6. **Neural Networks**: Models inspired by the human brain, used for complex pattern recognition tasks, including deep learning.\n",
       "\n",
       "7. **Clustering Algorithms**: Such as k-Means and Hierarchical Clustering, which group similar data points together.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, algorithms in Machine Learning are crucial for enabling computers to learn from data and make predictions or decisions. The choice of algorithm depends on the specific problem, the type of data available, and the desired outcome. Understanding these algorithms is essential for developing effective ML models and applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is an Algorithm in the ML concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf33516a-2b12-4b81-a63c-0f22468b894d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is an Algorithm and Function?\n",
       "\n",
       "## Algorithm\n",
       "\n",
       "An **algorithm** is a finite sequence of well-defined, step-by-step instructions or rules designed to solve a specific problem or perform a particular task. Algorithms are fundamental to computer science and programming, and they can be implemented in various programming languages.\n",
       "\n",
       "### Key Characteristics of Algorithms\n",
       "\n",
       "1. **Finiteness**: An algorithm must terminate after a finite number of steps.\n",
       "2. **Well-defined Inputs**: It should accept defined inputs that it will process.\n",
       "3. **Well-defined Outputs**: It should produce one or more outputs as results of processing the inputs.\n",
       "4. **Effectiveness**: The steps must be simple enough to be carried out with basic tools.\n",
       "5. **Generality**: An algorithm should be applicable to a set of problems, not just a single instance.\n",
       "\n",
       "### Example of an Algorithm\n",
       "\n",
       "- **Bubble Sort**: An algorithm to sort a list of numbers by repeatedly stepping through the list, comparing adjacent elements, and swapping them if they are in the wrong order.\n",
       "\n",
       "## Function\n",
       "\n",
       "A **function** is a self-contained block of code that encapsulates a specific task or computation. Functions take inputs (often called parameters or arguments), perform operations on them, and return an output. Functions promote reusability and modularity in programming.\n",
       "\n",
       "### Key Characteristics of Functions\n",
       "\n",
       "1. **Inputs**: Functions can accept zero or more inputs.\n",
       "2. **Processing**: Functions contain the logic to be executed.\n",
       "3. **Outputs**: Functions return a value after processing the inputs.\n",
       "4. **Reusability**: Functions can be called multiple times throughout a program, reducing code duplication.\n",
       "\n",
       "### Example of a Function\n",
       "\n",
       "```python\n",
       "def add_numbers(a, b):\n",
       "    return a + b\n",
       "```\n",
       "\n",
       "In this example, `add_numbers` is a function that takes two inputs `a` and `b`, adds them together, and returns the result.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, an **algorithm** is a sequence of steps to solve a problem, while a **function** is a specific implementation of a task that can be reused throughout a program. Both concepts are essential in programming and computer science for building efficient and organized code."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is an Algorithm and Function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b796051d-e2b6-4703-b267-9509e55d33d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is an ML Model?\n",
       "\n",
       "A **Machine Learning (ML) model** is a mathematical representation or computational framework that is trained on data to recognize patterns, make predictions, or perform decisions based on new, unseen data. It is the outcome of applying a machine learning algorithm to a dataset and is used to solve specific tasks in various applications.\n",
       "\n",
       "## Key Components of an ML Model\n",
       "\n",
       "1. **Training Data**: The dataset used to teach the model. It consists of input features (independent variables) and corresponding target outputs (dependent variables).\n",
       "\n",
       "2. **Algorithm**: The method or technique used to train the model on the training data. Examples include linear regression, decision trees, neural networks, and support vector machines.\n",
       "\n",
       "3. **Parameters**: Internal variables of the model that are adjusted during training to minimize the error in predictions. For instance, weights in a neural network.\n",
       "\n",
       "4. **Features**: The input variables used by the model to make predictions. These can be numerical, categorical, or textual data.\n",
       "\n",
       "5. **Output**: The result produced by the model after processing input data. This can be a prediction, classification, or regression value.\n",
       "\n",
       "## Types of ML Models\n",
       "\n",
       "1. **Supervised Learning Models**: Trained using labeled data. Examples include:\n",
       "   - Linear Regression\n",
       "   - Logistic Regression\n",
       "   - Decision Trees\n",
       "   - Support Vector Machines (SVM)\n",
       "\n",
       "2. **Unsupervised Learning Models**: Trained using unlabeled data. Examples include:\n",
       "   - k-Means Clustering\n",
       "   - Hierarchical Clustering\n",
       "   - Principal Component Analysis (PCA)\n",
       "\n",
       "3. **Reinforcement Learning Models**: Learn through interactions with an environment to maximize cumulative reward. Examples include:\n",
       "   - Q-Learning\n",
       "   - Deep Q-Networks (DQN)\n",
       "\n",
       "4. **Deep Learning Models**: A subset of ML models that use neural networks with many layers to learn from large amounts of data. Examples include:\n",
       "   - Convolutional Neural Networks (CNNs)\n",
       "   - Recurrent Neural Networks (RNNs)\n",
       "\n",
       "## Model Evaluation\n",
       "\n",
       "To assess the performance of an ML model, various metrics are used, such as:\n",
       "\n",
       "- **Accuracy**: The proportion of correctly predicted instances.\n",
       "- **Precision and Recall**: Metrics used for classification tasks to measure the relevance of the predictions.\n",
       "- **Mean Squared Error (MSE)**: Used in regression tasks to measure the average squared difference between predicted and actual values.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, an ML model is a trained representation of a machine learning algorithm that can make predictions or decisions based on input data. It plays a crucial role in various applications, including image recognition, natural language processing, and recommendation systems, by leveraging data to improve performance over time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is an ML Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c40d6911-84d6-4e19-9b97-0ab406163c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is a Feature in the ML Concept?\n",
       "\n",
       "In the context of Machine Learning (ML), a **feature** is an individual measurable property or characteristic of a phenomenon being observed. Features are used as input variables for ML models to make predictions or classifications. They play a crucial role in determining the model's performance and its ability to generalize to unseen data.\n",
       "\n",
       "## Key Characteristics of Features\n",
       "\n",
       "1. **Input Variables**: Features are the variables that the model uses to learn. They can represent different aspects of the data being analyzed.\n",
       "\n",
       "2. **Types of Features**:\n",
       "   - **Numerical Features**: Continuous or discrete numeric values (e.g., age, income, temperature).\n",
       "   - **Categorical Features**: Variables that represent categories or groups (e.g., gender, color, type of vehicle).\n",
       "   - **Ordinal Features**: Categorical variables with a clear ordering (e.g., rating scales like \"poor,\" \"average,\" \"excellent\").\n",
       "   - **Textual Features**: Text data that may require natural language processing techniques (e.g., reviews, comments).\n",
       "\n",
       "3. **Feature Engineering**: The process of selecting, modifying, or creating features to improve the model's performance. This can involve:\n",
       "   - Normalization or scaling of numerical values.\n",
       "   - Encoding categorical variables (e.g., one-hot encoding).\n",
       "   - Creating interaction features or polynomial features.\n",
       "   - Extracting meaningful information from textual data (e.g., using TF-IDF).\n",
       "\n",
       "4. **Feature Importance**: Some features may have a more significant impact on the model's predictions than others. Assessing feature importance can help identify which features are most relevant and may guide feature selection.\n",
       "\n",
       "## Example of Features\n",
       "\n",
       "Suppose we are building a model to predict house prices. The features might include:\n",
       "\n",
       "- **Numerical Features**:\n",
       "  - Square footage of the house\n",
       "  - Number of bedrooms\n",
       "  - Year built\n",
       "\n",
       "- **Categorical Features**:\n",
       "  - Neighborhood (e.g., urban, suburban, rural)\n",
       "  - Type of house (e.g., single-family, townhouse, condo)\n",
       "\n",
       "- **Ordinal Features**:\n",
       "  - Condition of the house (e.g., poor, fair, good, excellent)\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, a feature in the ML concept is a measurable property used as input for ML models. The selection and engineering of features are critical steps in the machine learning pipeline, as they can significantly influence the model's effectiveness and accuracy in making predictions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is a Feature in the ML concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b60916d-2d1f-4aae-a014-0d5592c8274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Inference?\n",
       "\n",
       "**Inference** in the context of machine learning refers to the process of using a trained model to make predictions or draw conclusions from new, unseen data. This phase occurs after the model has been developed and validated during the training phase.\n",
       "\n",
       "## Key Aspects of Inference\n",
       "\n",
       "1. **Input Data**: Inference begins with new input data, which consists of features that the model has been trained to understand and analyze.\n",
       "\n",
       "2. **Prediction**: The model applies its learned patterns and relationships from the training phase to the new input data to generate predictions. This could involve classifying data points into categories or estimating continuous values.\n",
       "\n",
       "3. **Output**: The result of the inference process is the predicted output, which may include:\n",
       "   - Class labels (in classification tasks)\n",
       "   - Continuous values (in regression tasks)\n",
       "   - Probabilities associated with different outcomes\n",
       "\n",
       "4. **Real-Time vs. Batch Inference**:\n",
       "   - **Real-Time Inference**: Occurs when predictions are made immediately as new data is received, often used in applications like recommendation systems and fraud detection.\n",
       "   - **Batch Inference**: Involves processing a large set of data points at once, typically used for analysis or reporting purposes.\n",
       "\n",
       "## Importance of Inference\n",
       "\n",
       "- **Decision-Making**: Inference helps organizations make data-driven decisions based on the insights provided by the model.\n",
       "- **Deployment**: The inference process is a critical component of deploying machine learning models into production, where they can interact with real-world data.\n",
       "- **Feedback Loop**: In some systems, the results of inference can be used to further refine and improve the model through retraining, creating a feedback loop.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, inference is a vital step in the machine learning pipeline that involves using a trained model to make predictions based on new data. It enables practical applications of machine learning by translating learned patterns into actionable insights."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Inference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e4cc4c7-2f06-41dd-9ddf-f3c5f6ed7598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Parameters and Hyperparameters\n",
       "\n",
       "In machine learning, **parameters** and **hyperparameters** are two distinct concepts that play crucial roles in the training and performance of models.\n",
       "\n",
       "## Parameters\n",
       "\n",
       "- **Definition**: Parameters are the internal variables of a model that are learned from the training data. They define the model's structure and behavior.\n",
       "  \n",
       "- **Examples**: \n",
       "  - In a linear regression model, the coefficients (weights) assigned to the input features are parameters.\n",
       "  - In a neural network, the weights and biases of the neurons are parameters that are adjusted during training.\n",
       "\n",
       "- **Learning Process**: Parameters are optimized during the training phase using techniques such as gradient descent, where the model iteratively adjusts its parameters to minimize the loss function.\n",
       "\n",
       "## Hyperparameters\n",
       "\n",
       "- **Definition**: Hyperparameters are external configurations of the model that are set before the training process begins. They govern the training process and the model's architecture but are not learned from the data.\n",
       "\n",
       "- **Examples**: \n",
       "  - Learning rate: Determines how much to change the model in response to the estimated error each time the model weights are updated.\n",
       "  - Number of hidden layers and units in a neural network: Defines the complexity and capacity of the model.\n",
       "  - Batch size: The number of training examples utilized in one iteration.\n",
       "  - Number of epochs: The number of complete passes through the training dataset.\n",
       "\n",
       "- **Tuning Process**: Hyperparameters are typically tuned using techniques such as grid search, random search, or more advanced methods like Bayesian optimization to find the best combination for model performance.\n",
       "\n",
       "## Key Differences\n",
       "\n",
       "| Feature        | Parameters                           | Hyperparameters                      |\n",
       "|----------------|-------------------------------------|-------------------------------------|\n",
       "| Definition     | Internal variables learned from data| External settings for model training|\n",
       "| Learning       | Learned during training              | Set before training                  |\n",
       "| Examples       | Weights and biases                  | Learning rate, batch size, epochs    |\n",
       "| Adjustment     | Adjusted through training            | Tuned through experimentation        |\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, parameters are the aspects of a model that get learned from data, while hyperparameters are the configurations that are set prior to training. Both play essential roles in defining the model's performance and the effectiveness of the learning process. Understanding and optimizing these concepts can lead to better-performing machine learning models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What are Parameters and Hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3ebf88a-77b3-45f6-b331-9693aa1bdb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Responsible AI\n",
       "\n",
       "**Responsible AI** refers to the ethical and accountable development, deployment, and use of artificial intelligence technologies. It emphasizes the importance of aligning AI systems with ethical standards, societal values, and legal frameworks to ensure that their impact is positive and fair.\n",
       "\n",
       "## Key Principles of Responsible AI\n",
       "\n",
       "1. **Fairness**:\n",
       "   - AI systems should be designed and trained to avoid biases that can lead to discrimination against individuals or groups based on attributes like race, gender, or socioeconomic status.\n",
       "\n",
       "2. **Transparency**:\n",
       "   - The processes and decision-making of AI systems should be explainable and understandable to users. This includes clarity about how models work, what data they use, and how decisions are made.\n",
       "\n",
       "3. **Accountability**:\n",
       "   - Organizations and individuals involved in the development and deployment of AI technologies should be held accountable for the outcomes of their systems. This includes ensuring that there are processes in place to address any negative impacts.\n",
       "\n",
       "4. **Privacy**:\n",
       "   - Responsible AI must respect user privacy and data protection. This involves implementing measures to protect personal information and ensuring compliance with relevant data protection laws.\n",
       "\n",
       "5. **Safety and Security**:\n",
       "   - AI systems should be designed to operate safely and securely, minimizing risks to individuals and society. This includes addressing potential vulnerabilities and ensuring robustness against malicious attacks.\n",
       "\n",
       "6. **Inclusiveness**:\n",
       "   - AI development should consider diverse perspectives and involve a wide range of stakeholders to ensure that the technology benefits all segments of society.\n",
       "\n",
       "7. **Sustainability**:\n",
       "   - The environmental impact of AI systems should be taken into account, promoting practices that reduce energy consumption and environmental harm.\n",
       "\n",
       "## Importance of Responsible AI\n",
       "\n",
       "- **Trust**: Building trust among users and stakeholders by demonstrating commitment to ethical practices.\n",
       "- **Regulatory Compliance**: Aligning with legal and regulatory requirements to avoid potential legal ramifications.\n",
       "- **Social Impact**: Ensuring that AI technologies contribute positively to society and do not exacerbate existing inequalities or injustices.\n",
       "- **Long-term Viability**: Fostering sustainable AI development that considers future implications and challenges.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, Responsible AI is about ensuring that AI technologies are developed and used in ways that are ethical, fair, and beneficial to society. By adhering to the principles of fairness, transparency, accountability, privacy, safety, inclusiveness, and sustainability, stakeholders can help shape a future where AI serves the best interests of all."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Explain the term Responsible AI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b2c2d-f6ed-4d55-b6ed-0cb01947a8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3c71e4d-75da-4c14-82ee-9adb4fabb6b4",
   "metadata": {},
   "source": [
    "## Gen AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1927dc7-e66b-46c7-981b-6315ad024b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# AI vs GenAI\n",
       "\n",
       "Artificial Intelligence (AI) and Generative AI (GenAI) are two terms that often come up in discussions about advanced technologies. While they share some similarities, they have distinct characteristics and applications.\n",
       "\n",
       "## Artificial Intelligence (AI)\n",
       "\n",
       "### Definition\n",
       "Artificial Intelligence refers to the broader field of computer science that focuses on creating systems capable of performing tasks that typically require human intelligence. This includes a variety of subfields and techniques.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Types of AI**:\n",
       "  - **Narrow AI**: Specialized systems designed to perform specific tasks (e.g., image recognition, language translation).\n",
       "  - **General AI**: Hypothetical systems that possess the ability to understand, learn, and apply intelligence across a wide range of tasks, similar to a human.\n",
       "\n",
       "- **Techniques**: Includes machine learning, deep learning, natural language processing (NLP), computer vision, and more.\n",
       "\n",
       "### Applications\n",
       "- **Chatbots**: Customer service automation.\n",
       "- **Recommendation Systems**: Suggestions for products or content based on user behavior.\n",
       "- **Image and Speech Recognition**: Identifying objects in images or transcribing spoken words.\n",
       "\n",
       "## Generative AI (GenAI)\n",
       "\n",
       "### Definition\n",
       "Generative AI is a subset of artificial intelligence focused on creating new content, such as text, images, audio, or video. These systems are designed to generate outputs that are similar to the data they were trained on.\n",
       "\n",
       "### Key Characteristics\n",
       "- **Content Creation**: GenAI models can produce original content based on patterns and structures learned from training data.\n",
       "\n",
       "- **Techniques**:\n",
       "  - **Generative Adversarial Networks (GANs)**: Models that use two competing networks (generator and discriminator) to create realistic outputs.\n",
       "  - **Transformers**: Models like GPT (Generative Pre-trained Transformer) that excel in generating human-like text.\n",
       "\n",
       "### Applications\n",
       "- **Text Generation**: Writing articles, stories, or code (e.g., ChatGPT).\n",
       "- **Image Generation**: Creating art or realistic images (e.g., DALL-E).\n",
       "- **Music Composition**: Generating original music tracks or soundscapes.\n",
       "\n",
       "## Key Differences\n",
       "\n",
       "| Feature                      | AI                                    | GenAI                                 |\n",
       "|------------------------------|--------------------------------------|--------------------------------------|\n",
       "| Scope                        | Broad field of intelligence systems   | Subset focused on content generation  |\n",
       "| Purpose                      | Task performance and automation        | Creating new and original content    |\n",
       "| Techniques                   | Machine learning, NLP, computer vision| GANs, transformers                    |\n",
       "| Examples                     | Chatbots, recommendation systems      | Text, image, and music generation     |\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In summary, while both AI and Generative AI involve advanced technologies aimed at mimicking human intelligence, they serve different purposes. AI encompasses a wide array of applications focused on automating tasks, whereas Generative AI specializes in creating new content based on learned patterns. Understanding these distinctions helps clarify the capabilities and potential applications of these technologies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "AI vs GenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bb9ef3-d81d-491c-9871-4aba11ce768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Foundational Model\n",
       "\n",
       "## Definition\n",
       "A **Foundational Model** refers to a large-scale machine learning model that is designed to serve as a base for a wide range of downstream tasks and applications. These models are typically pre-trained on extensive datasets and can be fine-tuned or adapted for specific use cases.\n",
       "\n",
       "## Key Characteristics\n",
       "\n",
       "1. **Pre-training**:\n",
       "   - Foundational models are trained on diverse and extensive datasets, enabling them to learn general patterns, structures, and representations.\n",
       "\n",
       "2. **Versatility**:\n",
       "   - Once pre-trained, these models can be fine-tuned for various tasks, such as text classification, image recognition, or even more complex applications like conversational agents.\n",
       "\n",
       "3. **Transfer Learning**:\n",
       "   - Foundational models leverage transfer learning, allowing knowledge gained from pre-training to be applied to new, often smaller datasets.\n",
       "\n",
       "4. **Scalability**:\n",
       "   - They are designed to scale effectively, accommodating increasing amounts of data and complexity in tasks.\n",
       "\n",
       "5. **Generalization**:\n",
       "   - Foundational models aim to generalize well across different tasks, making them useful in diverse applications.\n",
       "\n",
       "## Examples of Foundational Models\n",
       "\n",
       "- **BERT (Bidirectional Encoder Representations from Transformers)**: A model for natural language understanding tasks, widely used for sentiment analysis, question answering, and more.\n",
       "  \n",
       "- **GPT (Generative Pre-trained Transformer)**: A language model that excels in generating coherent and contextually relevant text.\n",
       "\n",
       "- **DALL-E**: A model designed for generating images from textual descriptions, showcasing capabilities in visual creativity.\n",
       "\n",
       "- **CLIP (Contrastive Language–Image Pre-training)**: A model that connects images and text, enabling various applications in image retrieval and understanding.\n",
       "\n",
       "## Applications\n",
       "\n",
       "- **Natural Language Processing (NLP)**: Foundational models are extensively used in chatbots, translation services, and content generation.\n",
       "  \n",
       "- **Computer Vision**: They can be adapted for tasks like image classification, object detection, and generative art creation.\n",
       "\n",
       "- **Multimodal Applications**: Many foundational models can handle tasks that involve both text and images, enhancing interactivity and user experience.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Foundational models represent a significant advancement in machine learning and AI. Their ability to learn from vast datasets and generalize across various tasks makes them powerful tools for researchers and developers. By serving as a base for numerous applications, they contribute to the ongoing evolution of intelligent systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is a Foundational Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43be15ae-d676-4431-b817-51b9202bd2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Large Language Model (LLM)\n",
       "\n",
       "## Definition\n",
       "A **Large Language Model (LLM)** is a type of artificial intelligence model designed to understand, generate, and manipulate human language. These models are characterized by their size, which typically involves billions of parameters, allowing them to capture complex patterns in language data.\n",
       "\n",
       "## Key Characteristics\n",
       "\n",
       "1. **Scale**:\n",
       "   - LLMs are trained on massive datasets, often comprising text from books, articles, websites, and other sources, which enables them to learn a wide range of language structures and nuances.\n",
       "\n",
       "2. **Deep Learning Architecture**:\n",
       "   - Most LLMs are based on deep learning architectures, particularly the transformer architecture, which allows for parallel processing and efficient handling of long-range dependencies in text.\n",
       "\n",
       "3. **Contextual Understanding**:\n",
       "   - These models excel at understanding context, allowing them to generate coherent and contextually relevant responses.\n",
       "\n",
       "4. **Fine-Tuning**:\n",
       "   - After pre-training on broad datasets, LLMs can be fine-tuned on specific datasets to adapt their performance for particular tasks or domains.\n",
       "\n",
       "5. **Few-Shot and Zero-Shot Learning**:\n",
       "   - LLMs can perform tasks with little to no task-specific training data, demonstrating strong generalization capabilities.\n",
       "\n",
       "## Examples of Large Language Models\n",
       "\n",
       "- **GPT-3 (Generative Pre-trained Transformer 3)**: A widely recognized LLM developed by OpenAI, known for its ability to generate human-like text across various topics.\n",
       "\n",
       "- **BERT (Bidirectional Encoder Representations from Transformers)**: Developed by Google, BERT is used for understanding the context of words in search queries and improving natural language understanding.\n",
       "\n",
       "- **T5 (Text-to-Text Transfer Transformer)**: A model that treats every NLP task as a text generation task, making it versatile for various applications.\n",
       "\n",
       "- **Megatron-Turing NLG**: One of the largest LLMs, developed by NVIDIA and Microsoft, known for its capabilities in natural language generation.\n",
       "\n",
       "## Applications\n",
       "\n",
       "- **Chatbots and Conversational Agents**: LLMs power customer service bots and virtual assistants, enabling natural and engaging interactions.\n",
       "\n",
       "- **Content Creation**: They are used for generating articles, stories, and other forms of written content.\n",
       "\n",
       "- **Language Translation**: LLMs improve the accuracy and fluency of machine translation systems.\n",
       "\n",
       "- **Sentiment Analysis**: They can analyze text to determine sentiment, aiding businesses in understanding customer feedback.\n",
       "\n",
       "- **Code Generation**: LLMs can assist in writing and debugging code, enhancing software development processes.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Large Language Models represent a significant advancement in natural language processing and artificial intelligence. Their ability to understand and generate human language with high accuracy opens up numerous possibilities across various industries. As they continue to evolve, LLMs are likely to play an increasingly crucial role in enhancing human-computer interaction and driving innovation in language-related applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is a Large Language Model (LLM)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4767e0-cfc0-4e44-bea8-e16aafe629f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Transformer Architecture\n",
       "\n",
       "The Transformer architecture, introduced in the paper \"Attention is All You Need\" by Vaswani et al. in 2017, is a neural network design primarily used for natural language processing tasks. It has revolutionized the field by enabling efficient parallelization and improving performance on a wide range of tasks.\n",
       "\n",
       "## Key Components\n",
       "\n",
       "### 1. **Input Embedding**\n",
       "- Converts input tokens (words or subwords) into dense vector representations.\n",
       "- Positional encoding is added to the embeddings to retain the order of the sequence.\n",
       "\n",
       "### 2. **Positional Encoding**\n",
       "- Since transformers do not inherently understand the order of sequences, positional encodings are added to input embeddings to provide information about the position of tokens in the sequence.\n",
       "- Commonly implemented using sine and cosine functions.\n",
       "\n",
       "### 3. **Encoder**\n",
       "- Composed of multiple identical layers (often 6 or more).\n",
       "- Each layer has two main components:\n",
       "  - **Multi-Head Self-Attention Mechanism**\n",
       "    - Allows the model to focus on different parts of the input sequence simultaneously.\n",
       "    - Computes attention scores to weigh the importance of other tokens in the sequence.\n",
       "  - **Feed-Forward Neural Network**\n",
       "    - A fully connected network applied to each position separately and identically.\n",
       "- Each sub-layer has residual connections followed by layer normalization.\n",
       "\n",
       "### 4. **Decoder**\n",
       "- Also composed of multiple identical layers, similar to the encoder.\n",
       "- Each layer includes three main components:\n",
       "  - **Masked Multi-Head Self-Attention**\n",
       "    - Prevents attending to future tokens in the sequence during training.\n",
       "  - **Multi-Head Attention over Encoder Outputs**\n",
       "    - Attends to the encoder's output to incorporate context from the input sequence.\n",
       "  - **Feed-Forward Neural Network**\n",
       "- Like the encoder, each sub-layer has residual connections and layer normalization.\n",
       "\n",
       "### 5. **Output Layer**\n",
       "- Produces the final output probabilities for the next token in the sequence, typically using a softmax function over the vocabulary.\n",
       "\n",
       "## Self-Attention Mechanism\n",
       "\n",
       "### 1. **Scaled Dot-Product Attention**\n",
       "- Given a set of queries \\( Q \\), keys \\( K \\), and values \\( V \\):\n",
       "  - Compute the attention scores: \\( \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\)\n",
       "  - Here, \\( d_k \\) is the dimension of the keys, and the scores are scaled to prevent overly large values that can affect the softmax function.\n",
       "\n",
       "### 2. **Multi-Head Attention**\n",
       "- Instead of performing a single attention function, multiple attention heads are used:\n",
       "  - Each head learns different representations by using different learned linear transformations.\n",
       "  - The outputs of all heads are concatenated and linearly transformed.\n",
       "\n",
       "## Advantages of Transformer Architecture\n",
       "\n",
       "- **Parallelization**: Unlike RNNs, transformers can process entire sequences at once, enabling faster training.\n",
       "- **Long-Range Dependencies**: Self-attention allows the model to capture relationships between distant tokens effectively.\n",
       "- **Scalability**: The architecture scales well with data and model size, leading to improved performance with larger models.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The Transformer architecture has become the backbone of many state-of-the-art models in NLP, including BERT, GPT, and many others. Its innovative use of self-attention and parallelization has set new standards for efficiency and effectiveness in machine learning tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Explain the Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6cfa4cf-fc5d-4c0f-adaa-511bd8aafa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Transformer Architecture?\n",
       "\n",
       "The Transformer architecture is a type of neural network design that has fundamentally changed the landscape of natural language processing (NLP) and other sequence-related tasks. Introduced in the paper \"Attention is All You Need\" by Vaswani et al. in 2017, this architecture leverages self-attention mechanisms to process input data in parallel, allowing it to capture complex relationships within the data more efficiently than previous models, such as recurrent neural networks (RNNs).\n",
       "\n",
       "## Key Characteristics\n",
       "\n",
       "1. **Self-Attention Mechanism**\n",
       "   - Enables the model to weigh the importance of different tokens in a sequence based on their relationships to each other.\n",
       "   - Allows the model to focus on various parts of the input sequence when generating outputs.\n",
       "\n",
       "2. **Parallelization**\n",
       "   - Unlike RNNs, which process data sequentially, transformers can process entire sequences simultaneously.\n",
       "   - This leads to significantly faster training times and the ability to handle larger datasets.\n",
       "\n",
       "3. **Positional Encoding**\n",
       "   - Since transformers do not inherently capture the order of tokens, positional encodings are added to input embeddings to provide information about the sequence order.\n",
       "   - Commonly implemented using sine and cosine functions.\n",
       "\n",
       "4. **Multi-Head Attention**\n",
       "   - Instead of a single attention mechanism, multiple attention heads are used to allow the model to learn different representations of the input data.\n",
       "   - Each head processes the input separately, and their outputs are concatenated for the final representation.\n",
       "\n",
       "5. **Feed-Forward Networks**\n",
       "   - Each layer of the transformer contains a feed-forward neural network that processes each position independently and identically.\n",
       "   - This helps in capturing complex patterns in the data.\n",
       "\n",
       "6. **Layer Normalization and Residual Connections**\n",
       "   - Residual connections help in training deeper networks by mitigating the vanishing gradient problem.\n",
       "   - Layer normalization is applied to stabilize and accelerate training.\n",
       "\n",
       "## Structure of the Transformer\n",
       "\n",
       "The Transformer consists of an **Encoder** and a **Decoder**:\n",
       "\n",
       "- **Encoder**: Composed of multiple identical layers, where each layer consists of a multi-head self-attention mechanism followed by a feed-forward neural network.\n",
       "  \n",
       "- **Decoder**: Similar to the encoder but includes additional multi-head attention layers that attend to the encoder's output, allowing it to incorporate context from the input sequence. The decoder also uses masked self-attention to prevent peeking at future tokens during training.\n",
       "\n",
       "## Applications\n",
       "\n",
       "Transformers have been widely adopted in various applications beyond NLP, including:\n",
       "\n",
       "- **Machine Translation**\n",
       "- **Text Summarization**\n",
       "- **Question-Answering Systems**\n",
       "- **Image Processing** (Vision Transformers)\n",
       "- **Audio Processing**\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The Transformer architecture represents a significant advancement in machine learning, enabling models to learn from data more effectively and efficiently. Its mechanisms of self-attention, parallelization, and flexibility have made it the foundation of many state-of-the-art models in various domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Transformer Architecture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f3581e-e803-4325-8788-ff5b57faa476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Tokenization?\n",
       "\n",
       "Tokenization is the process of converting a sequence of text into smaller units called tokens. These tokens can be words, subwords, characters, or other meaningful elements, depending on the specific tokenization strategy used. Tokenization is a crucial step in natural language processing (NLP) as it prepares raw text data for further analysis or modeling.\n",
       "\n",
       "## Key Concepts\n",
       "\n",
       "### 1. **Tokens**\n",
       "- **Definition**: Tokens are the individual pieces of text obtained after the tokenization process. They can represent:\n",
       "  - Whole words (e.g., \"cat\")\n",
       "  - Subwords (e.g., \"un-\", \"happiness\")\n",
       "  - Characters (e.g., \"c\", \"a\", \"t\")\n",
       "  \n",
       "### 2. **Types of Tokenization**\n",
       "- **Word Tokenization**: Splits text into words, often based on spaces and punctuation.\n",
       "  - Example: \"Hello, world!\" → [\"Hello\", \"world\"]\n",
       "  \n",
       "- **Subword Tokenization**: Breaks down words into smaller units, which can help handle out-of-vocabulary words and reduce the vocabulary size.\n",
       "  - Example: \"unhappiness\" might be tokenized as [\"un\", \"happi\", \"ness\"]\n",
       "  \n",
       "- **Character Tokenization**: Treats each character as a separate token.\n",
       "  - Example: \"cat\" → [\"c\", \"a\", \"t\"]\n",
       "\n",
       "### 3. **Importance of Tokenization**\n",
       "- **Preprocessing**: Tokenization is essential for transforming raw text into a structured format suitable for machine learning algorithms.\n",
       "- **Vocabulary Management**: Helps in building a vocabulary of tokens, which is critical for models to understand and generate text.\n",
       "- **Handling Variability**: By breaking text into tokens, models can better handle variations in language, including morphology, syntax, and semantics.\n",
       "\n",
       "## Tokenization Techniques\n",
       "\n",
       "### 1. **Whitespace Tokenization**\n",
       "- Splits text based on whitespace characters (spaces, tabs, newlines).\n",
       "  \n",
       "### 2. **Regex Tokenization**\n",
       "- Uses regular expressions to define patterns for splitting text into tokens.\n",
       "\n",
       "### 3. **Byte Pair Encoding (BPE)**\n",
       "- A subword tokenization method that merges the most frequent pairs of characters or subwords iteratively to create a fixed-size vocabulary.\n",
       "\n",
       "### 4. **WordPiece**\n",
       "- Similar to BPE, this method builds a vocabulary of subwords by maximizing the likelihood of the training data, commonly used in models like BERT.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Tokenization is a fundamental step in NLP that transforms text into manageable units for analysis and modeling. By choosing appropriate tokenization strategies, practitioners can enhance the performance of NLP models and effectively handle the complexities of human language."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Tokenization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb62b5b6-1c6d-415c-924f-bbc73c54b10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Tokens and Capacity\n",
       "\n",
       "## Tokens\n",
       "\n",
       "### Definition\n",
       "Tokens are the individual pieces of data that result from the process of tokenization. In the context of natural language processing (NLP), tokens can represent various elements of text, including:\n",
       "\n",
       "- **Words**: The most common form of tokens, representing complete words in a sentence.\n",
       "  - Example: \"The cat sat on the mat.\" → [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
       "  \n",
       "- **Subwords**: Smaller units that make up words, useful for handling rare or out-of-vocabulary words.\n",
       "  - Example: \"unhappiness\" might be tokenized as [\"un\", \"happi\", \"ness\"]\n",
       "  \n",
       "- **Characters**: Each character in a text can serve as a token.\n",
       "  - Example: \"cat\" → [\"c\", \"a\", \"t\"]\n",
       "\n",
       "### Importance of Tokens\n",
       "- **Data Representation**: Tokens serve as the fundamental units of input for machine learning models, enabling them to understand and process text.\n",
       "- **Vocabulary Building**: Through tokenization, a model can create a vocabulary that maps tokens to unique identifiers, facilitating the translation of text into numerical formats.\n",
       "- **Handling Variability**: Tokens help manage linguistic variability by breaking down text into recognizable components, aiding in the representation of different languages and dialects.\n",
       "\n",
       "## Capacity\n",
       "\n",
       "### Definition\n",
       "In the context of machine learning and natural language processing, \"capacity\" refers to the ability of a model to learn from and generalize to data. It encompasses several aspects:\n",
       "\n",
       "- **Model Capacity**: The complexity of the model, often determined by its architecture, including the number of parameters, layers, and the type of algorithms used.\n",
       "  \n",
       "- **Vocabulary Capacity**: The size of the vocabulary that a tokenization method can accommodate, which impacts the model's ability to understand and generate language.\n",
       "  \n",
       "- **Feature Capacity**: The range of features that a model can capture from the input data. A higher capacity allows for a more nuanced understanding of the input.\n",
       "\n",
       "### Importance of Capacity\n",
       "- **Overfitting vs. Underfitting**: A model with too much capacity may overfit to the training data, capturing noise rather than generalizable patterns. Conversely, a model with insufficient capacity may underfit, failing to learn important relationships in the data.\n",
       "  \n",
       "- **Scalability**: Understanding capacity helps in designing models that can scale effectively with increasing amounts of data or complexity in the data.\n",
       "\n",
       "- **Performance**: The right balance of capacity ensures optimal performance on tasks, allowing models to achieve better accuracy and reliability in predictions.\n",
       "\n",
       "## Conclusion\n",
       "Tokens are the building blocks of text data in NLP, while capacity refers to the model's ability to learn and generalize from that data. Understanding both concepts is essential for developing effective machine learning models capable of processing and understanding human language."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What are Tokens and Capacity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77c438f-fd73-4d7e-9d08-37fe4fbbe585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Tokens and Model Capacity in Terms of Memory and Compute\n",
       "\n",
       "## Tokens\n",
       "\n",
       "### Memory\n",
       "- **Storage Requirements**: Each token requires memory for storage, particularly in the form of unique identifiers (indices) and their associated embeddings. The total memory used can be calculated as:\n",
       "  \\[\n",
       "  \\text{Memory} = \\text{Number of Tokens} \\times \\text{Size of Each Token Representation}\n",
       "  \\]\n",
       "  \n",
       "- **Vocabulary Size**: A larger vocabulary increases memory usage since each unique token must be stored. For example, if a model has a vocabulary of 50,000 words, it will require more memory to store embeddings for each word compared to a model with a vocabulary of 10,000 words.\n",
       "\n",
       "### Compute\n",
       "- **Processing Overhead**: The number of tokens in the input affects the computational requirements of the model. More tokens mean more operations during forward and backward passes through the neural network.\n",
       "  \n",
       "- **Batch Processing**: The compute cost also scales with the number of tokens processed in a batch. Larger batches with more tokens will require more computational resources, impacting training and inference speed.\n",
       "\n",
       "## Model Capacity\n",
       "\n",
       "### Memory\n",
       "- **Parameter Storage**: The capacity of a model is often defined by the number of parameters it contains. More parameters require more memory to store the model weights. For example:\n",
       "  \\[\n",
       "  \\text{Memory for Parameters} = \\text{Number of Parameters} \\times \\text{Size of Each Parameter}\n",
       "  \\]\n",
       "  \n",
       "- **Intermediate Activations**: During training, models also need memory to store intermediate activations for each layer, which can be considerable for deep networks.\n",
       "\n",
       "### Compute\n",
       "- **Forward and Backward Passes**: Higher model capacity increases the computational burden during both forward and backward passes. More parameters mean more calculations are necessary to compute gradients and update the weights.\n",
       "\n",
       "- **Training Time**: Larger models with higher capacity generally require more compute power and time to train effectively, often necessitating the use of specialized hardware like GPUs or TPUs.\n",
       "\n",
       "## Relationship Between Tokens and Model Capacity\n",
       "\n",
       "- **Trade-offs**: There is a trade-off between the number of tokens and the model's capacity. A model with a high capacity can better learn from a large number of tokens but will also demand significant memory and compute resources.\n",
       "  \n",
       "- **Scaling**: As the number of tokens increases (e.g., processing larger datasets), models with higher capacity may perform better but will require more memory and compute power to maintain efficiency and accuracy.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Tokens and model capacity are intricately linked to memory and compute resources. Understanding these relationships is essential for optimizing model performance, managing resource allocation, and ensuring efficient training and inference in machine learning applications. Balancing the number of tokens and model capacity with available memory and compute resources is critical for achieving desired outcomes in NLP and other domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Explain Tokens and Model Capacity in terms of Memory and Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c73ceadf-86e5-4f0d-8815-b395c5678c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What are Embeddings?\n",
       "\n",
       "Embeddings are a type of representation that transforms discrete objects, such as words or phrases, into continuous vector spaces. They are widely used in natural language processing (NLP) and machine learning to capture semantic meanings and relationships between items in a lower-dimensional space.\n",
       "\n",
       "## Key Concepts\n",
       "\n",
       "### 1. **Vector Representation**\n",
       "- **Definition**: An embedding is a dense vector of real numbers that encodes information about an object. For example, words can be represented as vectors in a high-dimensional space.\n",
       "  \n",
       "- **Dimensionality**: The dimensionality of embeddings can vary, but common sizes range from 50 to 300 dimensions for word embeddings.\n",
       "\n",
       "### 2. **Semantic Relationships**\n",
       "- **Capturing Meaning**: Embeddings allow models to understand the relationships between words based on their meanings. For instance, the vectors for \"king\" and \"queen\" may be close together in the embedding space, reflecting their related meanings.\n",
       "  \n",
       "- **Arithmetic Properties**: Embeddings can exhibit interesting properties, such as vector arithmetic. For example:\n",
       "  - \\( \\text{vector(\"king\")} - \\text{vector(\"man\")} + \\text{vector(\"woman\")} \\approx \\text{vector(\"queen\")} \\)\n",
       "\n",
       "## Types of Embeddings\n",
       "\n",
       "### 1. **Word Embeddings**\n",
       "- **Word2Vec**: A popular method developed by Google that uses neural networks to learn word associations from large corpora. It includes two models: Continuous Bag of Words (CBOW) and Skip-Gram.\n",
       "\n",
       "- **GloVe (Global Vectors for Word Representation)**: Developed by Stanford, GloVe generates embeddings by aggregating global word-word co-occurrence statistics from a corpus.\n",
       "\n",
       "- **FastText**: An extension of Word2Vec that considers subword information, allowing it to generate embeddings for out-of-vocabulary words.\n",
       "\n",
       "### 2. **Sentence and Document Embeddings**\n",
       "- **Sentence Embeddings**: Represent entire sentences as vectors, capturing their meaning. Examples include Universal Sentence Encoder and Sentence-BERT.\n",
       "\n",
       "- **Document Embeddings**: Extend the concept to entire documents, capturing the context and relationships within longer texts.\n",
       "\n",
       "### 3. **Other Embeddings**\n",
       "- **Graph Embeddings**: Represent nodes and edges in a graph as vectors, preserving the graph's structure and relationships.\n",
       "\n",
       "- **Image and Audio Embeddings**: Represent features of images and audio signals in vector form for use in computer vision and audio processing tasks.\n",
       "\n",
       "## Applications\n",
       "\n",
       "- **Natural Language Processing**: Used for tasks like text classification, sentiment analysis, and machine translation.\n",
       "- **Recommendation Systems**: Embeddings can represent user preferences and item characteristics to improve recommendations.\n",
       "- **Search Engines**: Enhance search capabilities by allowing semantic search based on the meanings of words rather than exact matches.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Embeddings play a crucial role in modern machine learning and NLP by providing a powerful way to represent complex data in a continuous vector space. This enables models to capture semantic relationships and perform better on a variety of tasks, making embeddings an essential tool in the toolkit of data scientists and machine learning practitioners."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What are Embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "850e84a7-3157-4d7c-9524-95723689f51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Positional Encoding?\n",
       "\n",
       "Positional encoding is a technique used in transformer models to incorporate information about the position of tokens in a sequence. Unlike recurrent neural networks (RNNs) that process sequences in order, transformers operate on all tokens simultaneously, which means they lack an inherent sense of order. Positional encodings help to mitigate this issue by providing a way to encode the position of each token within the input sequence.\n",
       "\n",
       "## Importance of Positional Encoding\n",
       "\n",
       "- **Sequence Order**: In many tasks, the order of tokens is crucial for understanding context (e.g., in sentences, the meaning can change based on word order).\n",
       "- **Attention Mechanism**: Transformers rely on attention mechanisms that evaluate relationships between all tokens in a sequence. Positional encodings ensure that the model can differentiate between tokens based on their sequential positions.\n",
       "\n",
       "## Types of Positional Encoding\n",
       "\n",
       "### 1. **Sinusoidal Positional Encoding**\n",
       "- **Formula**: The original transformer architecture by Vaswani et al. used sinusoidal functions to generate positional encodings. The encoding for a position \\( pos \\) and dimension \\( i \\) is defined as:\n",
       "  \\[\n",
       "  \\text{PE}(pos, 2i) = \\sin\\left(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}\\right)\n",
       "  \\]\n",
       "  \\[\n",
       "  \\text{PE}(pos, 2i+1) = \\cos\\left(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}\\right)\n",
       "  \\]\n",
       "  where \\( d_{model} \\) is the dimensionality of the embedding.\n",
       "\n",
       "- **Properties**: This encoding generates unique values for different positions and ensures that the distance between positions can be captured by the model.\n",
       "\n",
       "### 2. **Learned Positional Encoding**\n",
       "- **Learned Parameters**: An alternative approach involves learning positional encodings as parameters during model training. Each position in the input sequence has a corresponding embedding that the model learns over time.\n",
       "\n",
       "- **Flexibility**: This method allows the model to optimize positional representations based on the specific data it is trained on, potentially leading to improved performance.\n",
       "\n",
       "## Incorporating Positional Encoding\n",
       "\n",
       "Positional encodings are typically added to the input embeddings at the beginning of the transformer model. The combined representation is:\n",
       "\\[\n",
       "\\text{Input Embedding} + \\text{Positional Encoding}\n",
       "\\]\n",
       "This sum allows the model to leverage both the token's semantic meaning (from the embedding) and its positional context (from the positional encoding).\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Positional encoding is a critical component of transformer architectures that allows models to account for the order of tokens in a sequence. By providing a structured way to represent token positions, it enhances the model's ability to learn and understand sequential data, making it essential for tasks in natural language processing and beyond."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Positional Encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a62c66f-e0f3-4dd4-a41e-22d95e78733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Attention?\n",
       "\n",
       "Attention is a mechanism in neural networks that allows models to focus on specific parts of the input data when making predictions or generating outputs. It has become a fundamental component of various architectures, particularly in natural language processing (NLP) and computer vision.\n",
       "\n",
       "## Key Concepts\n",
       "\n",
       "### 1. **Intuition**\n",
       "- Attention mechanisms enable a model to weigh the importance of different input elements based on their relevance to a particular task or context.\n",
       "- Instead of processing all input elements equally, attention allows the model to prioritize certain elements over others.\n",
       "\n",
       "### 2. **Types of Attention**\n",
       "- **Soft Attention**: Computes a weighted average of all input elements, where the weights reflect the importance of each element. It is differentiable and can be trained using standard backpropagation.\n",
       "  \n",
       "- **Hard Attention**: Selects a subset of input elements to attend to, making it non-differentiable and often requiring reinforcement learning techniques for training.\n",
       "\n",
       "### 3. **Self-Attention**\n",
       "- Self-attention is a specific form of attention where the input sequence attends to itself. Each element in the sequence can consider all other elements, allowing the model to capture dependencies regardless of their distance in the sequence.\n",
       "  \n",
       "- This is particularly useful in tasks like language modeling, where understanding the relationship between words, regardless of their position, is crucial.\n",
       "\n",
       "## Attention Mechanism in Detail\n",
       "\n",
       "### Steps Involved\n",
       "\n",
       "1. **Input Representation**: Given an input sequence, each element is represented as a vector (e.g., word embeddings in NLP).\n",
       "\n",
       "2. **Scoring**: For each element in the sequence, a score is computed against all other elements to determine their relevance. This can be done using dot products or learned functions.\n",
       "\n",
       "3. **Weight Calculation**: Scores are passed through a softmax function to convert them into a probability distribution, producing attention weights.\n",
       "\n",
       "4. **Weighted Sum**: The input elements are then combined using these weights to produce a context vector that emphasizes the most relevant parts of the input.\n",
       "\n",
       "### Mathematical Formulation\n",
       "\n",
       "For a sequence of input vectors \\( X \\):\n",
       "1. Compute attention scores for each pair \\( (i, j) \\):\n",
       "   \\[\n",
       "   \\text{Score}(X_i, X_j) = X_i \\cdot W_a X_j\n",
       "   \\]\n",
       "   where \\( W_a \\) is a learned weight matrix.\n",
       "\n",
       "2. Normalize the scores to obtain attention weights:\n",
       "   \\[\n",
       "   a_{ij} = \\frac{\\exp(\\text{Score}(X_i, X_j))}{\\sum_{k=1}^{n} \\exp(\\text{Score}(X_i, X_k))}\n",
       "   \\]\n",
       "\n",
       "3. Compute the context vector:\n",
       "   \\[\n",
       "   C_i = \\sum_{j=1}^{n} a_{ij} X_j\n",
       "   \\]\n",
       "\n",
       "## Applications\n",
       "\n",
       "- **Natural Language Processing**: Attention mechanisms are widely used in models like Transformers, enabling tasks such as translation, summarization, and language understanding.\n",
       "  \n",
       "- **Computer Vision**: Attention can help models focus on specific parts of images, improving performance in tasks like image captioning and object detection.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Attention is a powerful mechanism that enhances the capacity of neural networks to focus on relevant information within input data. By allowing models to weigh the importance of different elements dynamically, attention mechanisms have significantly improved performance across a variety of tasks in machine learning and artificial intelligence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Attention?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b082e82-b52d-403b-a85d-003e6fc60882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Fine-Tuning LLMs?\n",
       "\n",
       "Fine-tuning large language models (LLMs) refers to the process of taking a pre-trained model and adapting it to a specific task or domain by training it further on a smaller, task-specific dataset. This approach leverages the knowledge already acquired by the model during its initial training phase while customizing it to improve performance on particular applications.\n",
       "\n",
       "## Key Concepts\n",
       "\n",
       "### 1. **Pre-trained Models**\n",
       "- LLMs are typically trained on vast amounts of text data from diverse sources, allowing them to learn grammar, facts, reasoning abilities, and even some level of common sense.\n",
       "- Examples of popular pre-trained LLMs include GPT (Generative Pre-trained Transformer), BERT (Bidirectional Encoder Representations from Transformers), and T5 (Text-to-Text Transfer Transformer).\n",
       "\n",
       "### 2. **Fine-Tuning Process**\n",
       "Fine-tuning generally involves the following steps:\n",
       "\n",
       "1. **Select a Pre-trained Model**: Choose an appropriate pre-trained LLM based on the task requirements.\n",
       "\n",
       "2. **Prepare Task-Specific Data**: Curate a dataset relevant to the specific task (e.g., sentiment analysis, named entity recognition, question answering).\n",
       "\n",
       "3. **Modify the Model**: Adapt the architecture if necessary (e.g., adding a classification head for a classification task).\n",
       "\n",
       "4. **Training**: Train the model on the task-specific data, often using a lower learning rate to avoid overwriting the knowledge gained during pre-training.\n",
       "\n",
       "5. **Evaluation**: Assess the model's performance on a validation dataset to ensure it generalizes well to unseen data.\n",
       "\n",
       "### 3. **Transfer Learning**\n",
       "Fine-tuning is a form of transfer learning, where knowledge gained while solving one problem is applied to a different but related problem. This allows LLMs to be highly efficient in learning new tasks with relatively small datasets.\n",
       "\n",
       "## Benefits of Fine-Tuning LLMs\n",
       "\n",
       "- **Improved Performance**: Fine-tuning can significantly enhance a model's performance on specific tasks, achieving higher accuracy compared to using the pre-trained model alone.\n",
       "  \n",
       "- **Reduced Training Time**: Starting from a pre-trained model generally requires less computational resources and time than training a model from scratch.\n",
       "\n",
       "- **Customization**: Fine-tuning allows practitioners to tailor models to specific industries or applications, accommodating unique vocabulary, style, and context.\n",
       "\n",
       "## Challenges\n",
       "\n",
       "- **Data Requirements**: While fine-tuning can be done with smaller datasets, the quality and representativeness of the data are crucial for achieving good results.\n",
       "\n",
       "- **Overfitting**: There's a risk of overfitting to the fine-tuning dataset, especially if it is small or not diverse.\n",
       "\n",
       "- **Resource Intensity**: Even fine-tuning can be computationally intensive, requiring substantial hardware resources.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Fine-tuning LLMs is a powerful technique that enables the adaptation of pre-trained models to specific tasks, improving their performance and utility in a wide range of applications. By leveraging transfer learning, fine-tuning allows for efficient and effective utilization of large language models in various domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Fine-Tuning LLMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b4674-3455-44ef-b1c4-19d31f4e7e4a",
   "metadata": {},
   "source": [
    "## Data and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d6732a-54a7-4364-8cb8-7ff45e85572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Data Labeling?\n",
       "\n",
       "Data labeling is the process of annotating or tagging data to make it understandable for machine learning algorithms. This process involves adding meaningful labels or metadata to various types of data such as images, text, audio, and video, allowing machines to learn from this labeled data during training.\n",
       "\n",
       "## Importance of Data Labeling\n",
       "\n",
       "- **Training Machine Learning Models**: Labeled data is essential for supervised learning algorithms, which rely on known outcomes to make predictions.\n",
       "- **Improving Accuracy**: High-quality labeled data helps improve the accuracy and performance of machine learning models by providing clear examples of what to learn from.\n",
       "- **Facilitating Understanding**: Data labeling helps in organizing and categorizing information, making it easier for systems to interpret and process.\n",
       "\n",
       "## Types of Data Labeling\n",
       "\n",
       "1. **Image Labeling**: Assigning labels to objects within images, often used in computer vision tasks (e.g., bounding boxes, segmentation masks).\n",
       "2. **Text Labeling**: Identifying entities, sentiments, or categories within text data (e.g., spam detection, sentiment analysis).\n",
       "3. **Audio Labeling**: Annotating audio clips with relevant tags, such as transcriptions or speaker identification.\n",
       "4. **Video Labeling**: Tagging actions or objects in video frames for tasks like activity recognition.\n",
       "\n",
       "## Methods of Data Labeling\n",
       "\n",
       "- **Manual Labeling**: Human annotators review and label data, ensuring high accuracy but can be time-consuming and costly.\n",
       "- **Automated Labeling**: Using algorithms or AI tools to generate labels, which can speed up the process but may require human verification for accuracy.\n",
       "- **Crowdsourcing**: Engaging a large group of people through platforms to collectively label data, balancing cost and efficiency.\n",
       "\n",
       "## Challenges in Data Labeling\n",
       "\n",
       "- **Quality Control**: Ensuring the accuracy and consistency of labels can be difficult, especially with large datasets.\n",
       "- **Bias**: Human annotators may introduce biases that can affect model performance.\n",
       "- **Scalability**: As datasets grow, the demand for labeled data increases, making it challenging to keep up with the required volume.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Data labeling is a critical component in the development of effective machine learning systems. By providing structured and annotated data, it enables algorithms to learn and make informed predictions, ultimately driving advancements in artificial intelligence and data-driven decision-making."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Data Labeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e01a06e3-4f32-433a-857f-b81efcf269b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Data Mining?\n",
       "\n",
       "Data mining is the process of extracting valuable information and patterns from large sets of data using various techniques from statistics, machine learning, and database systems. It aims to discover previously unknown relationships, trends, and insights that can inform decision-making and drive business strategies.\n",
       "\n",
       "## Key Objectives of Data Mining\n",
       "\n",
       "- **Pattern Recognition**: Identifying patterns and correlations within data that can help predict future outcomes.\n",
       "- **Knowledge Discovery**: Transforming raw data into useful information and knowledge that can guide business decisions.\n",
       "- **Anomaly Detection**: Detecting unusual data points or outliers that may indicate fraud, errors, or significant changes in trends.\n",
       "\n",
       "## Common Techniques in Data Mining\n",
       "\n",
       "1. **Classification**: Assigning items in a dataset to target categories or classes based on input features (e.g., spam detection in emails).\n",
       "2. **Clustering**: Grouping similar data points together based on their characteristics without predefined labels (e.g., customer segmentation).\n",
       "3. **Regression**: Predicting a continuous outcome variable based on one or more predictor variables (e.g., forecasting sales).\n",
       "4. **Association Rule Learning**: Discovering interesting relationships between variables in large datasets (e.g., market basket analysis).\n",
       "5. **Time Series Analysis**: Analyzing time-ordered data points to uncover trends and seasonal patterns (e.g., stock price forecasting).\n",
       "\n",
       "## Applications of Data Mining\n",
       "\n",
       "- **Marketing and Sales**: Understanding customer behavior, segmenting markets, and optimizing marketing campaigns.\n",
       "- **Finance**: Risk assessment, fraud detection, and stock market analysis.\n",
       "- **Healthcare**: Predicting disease outbreaks, patient diagnosis, and treatment effectiveness analysis.\n",
       "- **Manufacturing**: Quality control, predictive maintenance, and supply chain optimization.\n",
       "- **Social Media**: Sentiment analysis, trend monitoring, and user engagement insights.\n",
       "\n",
       "## Challenges in Data Mining\n",
       "\n",
       "- **Data Quality**: Ensuring the accuracy, completeness, and consistency of data is crucial for effective analysis.\n",
       "- **Scalability**: Managing and processing large volumes of data can be computationally intensive and require advanced tools.\n",
       "- **Privacy Concerns**: Handling sensitive data responsibly while complying with regulations and ethical standards.\n",
       "- **Interpretability**: Making the results of data mining understandable to stakeholders and decision-makers.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Data mining plays a pivotal role in transforming vast amounts of data into actionable insights across various industries. By leveraging advanced algorithms and techniques, organizations can uncover hidden patterns, enhance decision-making, and gain a competitive edge in the market."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Data Mining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b2e8d8-f90b-4b5c-99b9-b5427aa4cca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Data Mining Methods\n",
       "\n",
       "Data mining employs a variety of methods to extract meaningful information and patterns from large datasets. Below are some of the most commonly used data mining methods:\n",
       "\n",
       "## 1. Classification\n",
       "\n",
       "Classification involves assigning items in a dataset to predefined categories or classes based on their attributes. It is commonly used for tasks such as spam detection, credit scoring, and medical diagnosis.\n",
       "\n",
       "- **Techniques**: Decision Trees, Random Forest, Support Vector Machines (SVM), Neural Networks.\n",
       "- **Example**: Classifying emails as \"spam\" or \"not spam.\"\n",
       "\n",
       "## 2. Clustering\n",
       "\n",
       "Clustering is the process of grouping similar data points together based on their characteristics. Unlike classification, clustering does not require predefined labels, making it useful for exploratory data analysis.\n",
       "\n",
       "- **Techniques**: K-Means, Hierarchical Clustering, DBSCAN (Density-Based Spatial Clustering of Applications with Noise).\n",
       "- **Example**: Segmenting customers based on purchasing behavior.\n",
       "\n",
       "## 3. Regression\n",
       "\n",
       "Regression is used to predict a continuous outcome variable based on one or more predictor variables. It helps understand relationships between variables and forecast future trends.\n",
       "\n",
       "- **Techniques**: Linear Regression, Polynomial Regression, Logistic Regression, Regression Trees.\n",
       "- **Example**: Predicting house prices based on various features like size and location.\n",
       "\n",
       "## 4. Association Rule Learning\n",
       "\n",
       "Association rule learning aims to discover interesting relationships and patterns among variables in large datasets. It is commonly applied in market basket analysis to identify product purchase correlations.\n",
       "\n",
       "- **Techniques**: Apriori Algorithm, FP-Growth (Frequent Pattern Growth).\n",
       "- **Example**: Identifying that customers who buy bread are also likely to buy butter.\n",
       "\n",
       "## 5. Anomaly Detection\n",
       "\n",
       "Anomaly detection, also known as outlier detection, focuses on identifying unusual data points that deviate significantly from the norm. This method is crucial for fraud detection, network security, and quality assurance.\n",
       "\n",
       "- **Techniques**: Statistical Tests, Isolation Forest, One-Class SVM.\n",
       "- **Example**: Detecting fraudulent transactions in banking.\n",
       "\n",
       "## 6. Time Series Analysis\n",
       "\n",
       "Time series analysis involves analyzing data points collected or recorded at specific time intervals. It seeks to identify trends, seasonal patterns, and cyclic behaviors over time.\n",
       "\n",
       "- **Techniques**: ARIMA (AutoRegressive Integrated Moving Average), Exponential Smoothing, Seasonal Decomposition.\n",
       "- **Example**: Forecasting stock prices based on historical data.\n",
       "\n",
       "## 7. Text Mining\n",
       "\n",
       "Text mining focuses on extracting valuable insights from unstructured text data. It employs various techniques to analyze and derive meaning from textual information.\n",
       "\n",
       "- **Techniques**: Natural Language Processing (NLP), Sentiment Analysis, Topic Modeling.\n",
       "- **Example**: Analyzing customer reviews to determine overall sentiment toward a product.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Data mining methods provide powerful tools to uncover insights from complex datasets. By selecting appropriate methods based on the data and objectives, organizations can effectively leverage their data for informed decision-making and strategic initiatives."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Data Mining Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a661909-928c-4694-8712-c89a09dbf50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Knowledge Mining?\n",
       "\n",
       "Knowledge mining is the process of extracting valuable insights, patterns, and knowledge from various types of data, including structured, semi-structured, and unstructured data. It combines techniques from data mining, machine learning, artificial intelligence, and information retrieval to transform raw data into actionable knowledge.\n",
       "\n",
       "## Key Objectives of Knowledge Mining\n",
       "\n",
       "- **Knowledge Discovery**: Identifying and extracting meaningful information that can be used for decision-making.\n",
       "- **Data Integration**: Combining data from different sources to provide a comprehensive view and context for analysis.\n",
       "- **Insight Generation**: Producing insights that can inform strategies, policies, and actions within an organization.\n",
       "\n",
       "## Components of Knowledge Mining\n",
       "\n",
       "1. **Data Sources**: Knowledge mining can utilize a variety of data sources, including databases, documents, web content, and sensor data.\n",
       "  \n",
       "2. **Data Preprocessing**: This involves cleaning, transforming, and organizing data to prepare it for analysis. Techniques may include normalization, deduplication, and feature extraction.\n",
       "\n",
       "3. **Knowledge Extraction**: Using various algorithms and models, knowledge is extracted from data. This can include pattern recognition, classification, and association rule mining.\n",
       "\n",
       "4. **Knowledge Representation**: Once knowledge is extracted, it must be represented in a way that is understandable and usable. This may involve visualization, summaries, or structured formats like ontologies.\n",
       "\n",
       "5. **Application of Knowledge**: The extracted knowledge is then applied to real-world problems, enabling informed decision-making, process optimization, and innovation.\n",
       "\n",
       "## Techniques Used in Knowledge Mining\n",
       "\n",
       "- **Natural Language Processing (NLP)**: Analyzing and understanding human language in texts to extract meaningful information.\n",
       "- **Machine Learning**: Employing algorithms to identify patterns and make predictions based on data.\n",
       "- **Data Mining**: Using statistical and computational techniques to discover patterns in large datasets.\n",
       "- **Information Retrieval**: Finding relevant information from unstructured data sources, such as documents and web pages.\n",
       "\n",
       "## Applications of Knowledge Mining\n",
       "\n",
       "- **Business Intelligence**: Enhancing decision-making through insights derived from data analysis.\n",
       "- **Healthcare**: Improving patient outcomes by extracting knowledge from medical records and research data.\n",
       "- **Customer Relationship Management**: Understanding customer behavior and preferences to optimize marketing strategies.\n",
       "- **Fraud Detection**: Identifying patterns indicative of fraudulent activities by analyzing transaction data.\n",
       "\n",
       "## Challenges in Knowledge Mining\n",
       "\n",
       "- **Data Quality**: Ensuring that the data used is accurate, complete, and relevant.\n",
       "- **Scalability**: Managing and processing large datasets efficiently.\n",
       "- **Interpretability**: Making the insights derived from knowledge mining understandable to stakeholders.\n",
       "- **Privacy and Ethical Concerns**: Handling sensitive data responsibly while adhering to regulations.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Knowledge mining is an essential process for transforming data into valuable insights that can drive innovation and enhance decision-making across various sectors. By leveraging diverse techniques and technologies, organizations can unlock the potential of their data and gain a competitive advantage."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Knowledge Mining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc49c0c8-78f0-447f-bb1d-39fded304009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Data Wrangling?\n",
       "\n",
       "Data wrangling, also known as data munging, is the process of transforming and mapping raw data into a format that is suitable for analysis. It involves a series of data preparation steps that make it easier to work with and derive insights from datasets. The goal of data wrangling is to ensure that data is clean, organized, and usable for various analytical tasks.\n",
       "\n",
       "## Key Steps in Data Wrangling\n",
       "\n",
       "1. **Data Collection**: Gathering data from various sources, which can include databases, APIs, spreadsheets, web scraping, and more.\n",
       "\n",
       "2. **Data Cleaning**: Identifying and correcting errors or inconsistencies in the data. This may involve:\n",
       "   - Removing duplicates\n",
       "   - Handling missing values\n",
       "   - Correcting formatting issues\n",
       "   - Filtering out irrelevant data\n",
       "\n",
       "3. **Data Transformation**: Modifying data to make it more suitable for analysis. This can include:\n",
       "   - Normalizing or scaling numerical values\n",
       "   - Converting data types (e.g., strings to dates)\n",
       "   - Aggregating data (e.g., summing values by category)\n",
       "   - Reshaping data (e.g., pivoting or unpivoting tables)\n",
       "\n",
       "4. **Data Integration**: Combining data from multiple sources into a cohesive dataset. This can involve:\n",
       "   - Merging datasets\n",
       "   - Joining tables based on common keys\n",
       "   - Resolving conflicts between data from different sources\n",
       "\n",
       "5. **Data Enrichment**: Enhancing the dataset by adding additional information or features. This may include:\n",
       "   - Merging with external datasets\n",
       "   - Calculating new variables (e.g., ratios, averages)\n",
       "\n",
       "6. **Data Validation**: Ensuring that the transformed data meets the necessary quality standards and is ready for analysis. This can involve checking for data integrity and consistency.\n",
       "\n",
       "## Importance of Data Wrangling\n",
       "\n",
       "- **Improved Data Quality**: Ensures that the data used for analysis is accurate, complete, and reliable.\n",
       "- **Efficiency**: Saves time in the analysis phase by preparing data in advance, reducing the need for repeated cleaning and formatting.\n",
       "- **Better Insights**: Allows analysts to focus on deriving insights rather than spending time on data preparation.\n",
       "- **Facilitates Collaboration**: Standardizing data formats and structures makes it easier for teams to work together and share analyses.\n",
       "\n",
       "## Tools for Data Wrangling\n",
       "\n",
       "Several tools and programming languages are commonly used for data wrangling, including:\n",
       "\n",
       "- **Programming Languages**: Python (with libraries like Pandas and NumPy), R (with packages like dplyr and tidyr).\n",
       "- **ETL Tools**: Talend, Apache Nifi, Alteryx.\n",
       "- **Data Visualization Tools**: Tableau, Power BI (often have built-in data preparation capabilities).\n",
       "- **Spreadsheet Software**: Microsoft Excel, Google Sheets.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Data wrangling is a critical step in the data analysis process that lays the groundwork for effective data-driven decision-making. By transforming raw data into a clean and structured format, organizations can unlock valuable insights and enhance their analytical capabilities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Data Wrangling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "644a2cd5-e88d-41bf-a8a4-66488643a4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Data Modeling?\n",
       "\n",
       "Data modeling is the process of creating a visual representation of a data system or database. It involves defining and organizing data elements and their relationships, which serves as a blueprint for how data is stored, accessed, and manipulated within a system. Data modeling is a critical step in database design, data management, and data architecture.\n",
       "\n",
       "## Key Objectives of Data Modeling\n",
       "\n",
       "- **Structure Definition**: To define how data is organized and structured within a database.\n",
       "- **Relationship Mapping**: To illustrate how different data entities relate to one another.\n",
       "- **Data Integrity**: To ensure data consistency and accuracy through predefined rules and constraints.\n",
       "- **Communication**: To provide a clear representation of data requirements that can be easily understood by stakeholders, including developers, analysts, and business users.\n",
       "\n",
       "## Types of Data Models\n",
       "\n",
       "1. **Conceptual Data Model**:\n",
       "   - Provides a high-level overview of the data and its relationships.\n",
       "   - Focuses on identifying the entities and their relationships without detailing how they will be implemented.\n",
       "   - Useful for discussing requirements with stakeholders.\n",
       "\n",
       "2. **Logical Data Model**:\n",
       "   - Offers a more detailed view of the data structure without considering physical implementation.\n",
       "   - Defines entities, attributes, and relationships while specifying data types and constraints.\n",
       "   - Serves as a bridge between the conceptual model and the physical implementation.\n",
       "\n",
       "3. **Physical Data Model**:\n",
       "   - Represents how the data will be physically stored in a database.\n",
       "   - Includes details about tables, columns, data types, indexes, and storage considerations.\n",
       "   - Tailored to a specific database management system (DBMS).\n",
       "\n",
       "## Key Components of Data Modeling\n",
       "\n",
       "- **Entities**: Objects or concepts that can have data stored about them (e.g., customer, product).\n",
       "- **Attributes**: Characteristics or properties of entities (e.g., customer name, product price).\n",
       "- **Relationships**: Connections between entities that define how they interact with each other (e.g., a customer places an order).\n",
       "- **Constraints**: Rules that govern the data (e.g., uniqueness, referential integrity).\n",
       "\n",
       "## Data Modeling Techniques\n",
       "\n",
       "- **Entity-Relationship Diagram (ERD)**: A diagrammatic representation of entities and their relationships, commonly used in conceptual and logical data modeling.\n",
       "- **Unified Modeling Language (UML)**: A standardized modeling language that provides a way to visualize the design of a system, including data structures.\n",
       "- **Normalization**: A technique used to organize data to reduce redundancy and improve data integrity through a series of rules and forms.\n",
       "\n",
       "## Benefits of Data Modeling\n",
       "\n",
       "- **Enhanced Data Quality**: Helps identify and eliminate data redundancy and inconsistency.\n",
       "- **Improved Communication**: Provides a clear framework for stakeholders to discuss data needs and requirements.\n",
       "- **Facilitated Database Design**: Streamlines the process of creating and implementing databases.\n",
       "- **Better Decision Making**: Supports data-driven decision-making by providing a clear understanding of data relationships and structures.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Data modeling is a fundamental aspect of data management and database design that helps organizations structure their data effectively. By creating clear and detailed representations of data systems, organizations can improve data quality, enhance communication, and support informed decision-making."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Data Modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "480cf0ed-5e54-4045-a59d-10311c601b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is Data Analytics?\n",
       "\n",
       "Data analytics is the systematic computational analysis of data to uncover patterns, draw conclusions, and support decision-making. It involves various techniques and tools to transform raw data into meaningful insights, enabling organizations to make informed strategic choices. Data analytics can be applied across various industries and sectors to enhance performance, optimize operations, and improve customer experiences.\n",
       "\n",
       "## Key Components of Data Analytics\n",
       "\n",
       "1. **Data Collection**: Gathering data from various sources, such as databases, surveys, websites, and sensors, to create a dataset for analysis.\n",
       "\n",
       "2. **Data Cleaning**: Ensuring the data is accurate, complete, and formatted correctly by identifying and correcting errors or inconsistencies.\n",
       "\n",
       "3. **Data Processing**: Transforming raw data into a structured format suitable for analysis, which may involve data wrangling and normalization.\n",
       "\n",
       "4. **Data Analysis**: Applying statistical and analytical techniques to explore and interpret the data. This can include:\n",
       "   - Descriptive Analytics: Summarizing historical data to understand trends and patterns.\n",
       "   - Diagnostic Analytics: Investigating past performance to understand why certain outcomes occurred.\n",
       "   - Predictive Analytics: Using statistical models and machine learning to forecast future events based on historical data.\n",
       "   - Prescriptive Analytics: Recommending actions based on data analysis to achieve desired outcomes.\n",
       "\n",
       "5. **Data Visualization**: Presenting the analysis results through visual representations, such as charts, graphs, and dashboards, to make insights accessible and understandable.\n",
       "\n",
       "6. **Reporting**: Communicating findings and insights to stakeholders through reports or presentations, highlighting key takeaways and actionable recommendations.\n",
       "\n",
       "## Types of Data Analytics\n",
       "\n",
       "- **Descriptive Analytics**: Focuses on summarizing historical data to provide insights into what has happened. It answers questions like \"What were our sales last quarter?\"\n",
       "\n",
       "- **Diagnostic Analytics**: Explores data to determine the causes of past events, answering questions like \"Why did sales drop last quarter?\"\n",
       "\n",
       "- **Predictive Analytics**: Uses statistical models to forecast future trends and behaviors, addressing questions such as \"What are our expected sales for the next quarter?\"\n",
       "\n",
       "- **Prescriptive Analytics**: Provides recommendations for actions based on data analysis, answering questions like \"What actions should we take to improve sales?\"\n",
       "\n",
       "## Tools and Technologies for Data Analytics\n",
       "\n",
       "- **Programming Languages**: Python, R, and SQL for data manipulation and analysis.\n",
       "- **Data Visualization Tools**: Tableau, Power BI, and Looker for creating interactive dashboards and reports.\n",
       "- **Statistical Software**: SAS, SPSS, and MATLAB for advanced statistical analysis.\n",
       "- **Big Data Technologies**: Apache Hadoop, Spark, and NoSQL databases for handling large volumes of data.\n",
       "\n",
       "## Benefits of Data Analytics\n",
       "\n",
       "- **Informed Decision-Making**: Provides organizations with data-driven insights to guide strategic choices.\n",
       "- **Enhanced Efficiency**: Identifies inefficiencies and areas for improvement within processes and operations.\n",
       "- **Competitive Advantage**: Enables organizations to leverage data insights to stay ahead of competitors.\n",
       "- **Improved Customer Experience**: Helps organizations understand customer behavior and preferences, leading to better-targeted offerings.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Data analytics is a vital discipline that empowers organizations to harness the power of data. By transforming raw data into actionable insights, data analytics supports informed decision-making and drives business success across various sectors. As data continues to grow in volume and complexity, the importance of effective data analytics will only increase."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Data Analytics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad87dc3-3860-4e38-805e-4b7ab927e904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# What is a Data Scientist?\n",
       "\n",
       "A data scientist is a professional who uses scientific methods, algorithms, processes, and systems to extract knowledge and insights from structured and unstructured data. Data scientists combine expertise in statistics, mathematics, programming, and domain knowledge to analyze complex data sets and solve real-world problems. They play a crucial role in helping organizations make data-driven decisions.\n",
       "\n",
       "## Key Responsibilities of a Data Scientist\n",
       "\n",
       "1. **Data Collection and Preparation**:\n",
       "   - Gather data from various sources, including databases, APIs, and external datasets.\n",
       "   - Clean and preprocess data to ensure it is accurate and usable for analysis.\n",
       "\n",
       "2. **Data Exploration and Analysis**:\n",
       "   - Perform exploratory data analysis (EDA) to identify patterns, trends, and anomalies in the data.\n",
       "   - Use statistical methods to derive insights and validate hypotheses.\n",
       "\n",
       "3. **Model Development**:\n",
       "   - Build and implement machine learning models to predict outcomes or classify data.\n",
       "   - Select appropriate algorithms and techniques based on the problem at hand.\n",
       "\n",
       "4. **Data Visualization**:\n",
       "   - Create visual representations of data and analysis results to communicate findings effectively.\n",
       "   - Use tools like Tableau, Power BI, or Matplotlib to present insights to stakeholders.\n",
       "\n",
       "5. **Collaboration and Communication**:\n",
       "   - Work closely with cross-functional teams, including business analysts, engineers, and domain experts.\n",
       "   - Translate complex analytical findings into actionable business recommendations.\n",
       "\n",
       "6. **Continuous Learning and Improvement**:\n",
       "   - Stay updated with the latest trends, tools, and techniques in data science and machine learning.\n",
       "   - Experiment with new approaches and refine existing models based on feedback and new data.\n",
       "\n",
       "## Skills Required for a Data Scientist\n",
       "\n",
       "- **Statistical Analysis**: Proficiency in statistical methods and techniques to analyze data.\n",
       "- **Programming**: Strong skills in programming languages such as Python, R, or SQL.\n",
       "- **Machine Learning**: Knowledge of machine learning algorithms and frameworks (e.g., TensorFlow, Scikit-learn).\n",
       "- **Data Manipulation**: Experience with data manipulation libraries like Pandas and NumPy.\n",
       "- **Data Visualization**: Ability to create effective visualizations to communicate insights.\n",
       "- **Domain Knowledge**: Understanding of the specific industry or domain to contextualize data analysis.\n",
       "\n",
       "## Education and Background\n",
       "\n",
       "Data scientists typically have a strong educational background in fields such as:\n",
       "\n",
       "- **Computer Science**\n",
       "- **Statistics**\n",
       "- **Mathematics**\n",
       "- **Data Science**\n",
       "- **Engineering**\n",
       "\n",
       "Many data scientists hold advanced degrees (Master's or Ph.D.) in these areas, although practical experience and skills can also be significant indicators of capability.\n",
       "\n",
       "## Importance of Data Scientists\n",
       "\n",
       "Data scientists are essential in today's data-driven landscape. They help organizations to:\n",
       "\n",
       "- Make informed decisions based on data analysis and insights.\n",
       "- Optimize operations and improve efficiency through data-driven strategies.\n",
       "- Innovate and develop new products or services based on customer data and trends.\n",
       "- Gain competitive advantages by leveraging data effectively.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Data scientists are pivotal in transforming raw data into actionable insights. Their expertise in analysis, modeling, and communication allows organizations to harness the full potential of their data, driving innovation and strategic decision-making in various industries. As data continues to grow in importance, the role of the data scientist will remain crucial in navigating the complexities of data analysis and interpretation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is a Data Scientist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0df9b7f0-cda1-49bb-a3ca-007a10022efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Data Role Comparisons\n",
       "\n",
       "This document outlines the key differences between various data roles within organizations, focusing on their responsibilities, required skills, and typical use cases.\n",
       "\n",
       "| **Data Role**                       | **Key Responsibilities**                                        | **Required Skills**                          | **Typical Use Cases**                        |\n",
       "|-------------------------------------|---------------------------------------------------------------|----------------------------------------------|----------------------------------------------|\n",
       "| **Data Scientist**                  | - Analyze complex datasets<br>- Develop predictive models<br>- Communicate findings effectively | - Statistical analysis<br>- Machine learning<br>- Data visualization | - Forecasting trends<br>- Customer segmentation |\n",
       "| **Data Analyst**                    | - Collect and process data<br>- Generate reports<br>- Identify trends and insights | - SQL proficiency<br>- Excel skills<br>- Data visualization tools | - Business intelligence<br>- Performance tracking |\n",
       "| **Data Engineer**                   | - Design and maintain data pipelines<br>- Ensure data quality<br>- Manage databases | - Programming (Python, Java)<br>- ETL processes<br>- Database management | - Data integration<br>- Data warehousing |\n",
       "| **Data Architect**                  | - Design data architecture<br>- Ensure data governance<br>- Oversee data storage solutions | - Data modeling<br>- Database design<br>- Cloud technologies | - System integration<br>- Data strategy development |\n",
       "| **Business Intelligence Analyst**   | - Analyze business data<br>- Create dashboards and reports<br>- Support decision-making | - BI tools (Tableau, Power BI)<br>- Data analysis<br>- Communication skills | - Strategic planning<br>- Operational reporting |\n",
       "\n",
       "## Conclusion\n",
       "Understanding the distinct roles in data management is essential for organizations aiming to effectively utilize their data resources. Each role contributes uniquely to data analysis, engineering, and strategic decision-making.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Data Role Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600f6c23-f8ed-4e7b-bc29-609da8fe70d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Train vs Test Validation Dataset\n",
       "\n",
       "## Overview\n",
       "In machine learning, dividing the dataset into training and testing subsets is essential for evaluating the model's performance. This document outlines the differences between training, testing, and validation datasets.\n",
       "\n",
       "## Dataset Types\n",
       "\n",
       "| Dataset Type    | Purpose                                              | Description                                                                                       | Typical Size Percentage |\n",
       "|------------------|-----------------------------------------------------|---------------------------------------------------------------------------------------------------|--------------------------|\n",
       "| **Training Set** | - Train the model                                   | Used to fit the model; the model learns patterns and relationships from this data.                | 60-80% of the dataset    |\n",
       "|                  | - Adjust model parameters                           | The training process involves adjusting weights and parameters to minimize error.                  |                          |\n",
       "|------------------|-----------------------------------------------------|---------------------------------------------------------------------------------------------------|--------------------------|\n",
       "| **Validation Set** | - Tune model hyperparameters                       | Used to evaluate the model during training; helps in tuning and selecting the best model.        | 10-20% of the dataset    |\n",
       "|                  | - Prevent overfitting                              | Provides an unbiased evaluation of the model's performance on unseen data during training.        |                          |\n",
       "|------------------|-----------------------------------------------------|---------------------------------------------------------------------------------------------------|--------------------------|\n",
       "| **Test Set**     | - Final evaluation of the model                    | Used to assess the model's performance after training and validation; provides an unbiased estimate of model accuracy. | 10-20% of the dataset    |\n",
       "|                  | - Check generalization ability                     | Helps in understanding how well the model generalizes to new, unseen data.                       |                          |\n",
       "\n",
       "## Key Differences\n",
       "\n",
       "| Aspect                  | Training Set                         | Validation Set                    | Test Set                        |\n",
       "|-------------------------|-------------------------------------|----------------------------------|----------------------------------|\n",
       "| **Purpose**             | Fit the model                       | Tune hyperparameters              | Evaluate model performance       |\n",
       "| **Usage**               | Used in the training process        | Used during training for validation | Used after training is complete  |\n",
       "| **Data Leakage**        | Avoided through cross-validation    | Must be separate from training   | Must be completely independent   |\n",
       "| **Feedback Loop**       | Model learns from this data        | Provides feedback for adjustments | No feedback; purely evaluative   |\n",
       "\n",
       "## Conclusion\n",
       "Understanding the roles of training, validation, and test datasets is crucial for building robust machine learning models. Properly splitting the data helps ensure that the model generalizes well to new data and performs reliably in real-world scenarios.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Train vs Test Validation DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a200b358-f489-400a-b8bf-2dd9ce7afba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# What is a Corpus?\n",
       "\n",
       "## Definition\n",
       "A **corpus** (plural: corpora) is a large and structured set of texts (written or spoken) that are used for linguistic analysis, research, and natural language processing tasks. It serves as a comprehensive resource for studying language patterns, linguistics, and various applications in computational linguistics.\n",
       "\n",
       "## Types of Corpora\n",
       "1. **Written Corpus**: A collection of written texts, such as books, articles, reports, and essays.\n",
       "2. **Spoken Corpus**: A collection of spoken language data, including transcripts of conversations, interviews, and speeches.\n",
       "3. **Specialized Corpus**: A corpus focused on a specific subject area or genre, such as legal texts, medical literature, or technical manuals.\n",
       "4. **Parallel Corpus**: A set of texts that are translations of each other, useful for translation studies and multilingual applications.\n",
       "5. **Annotated Corpus**: A corpus that includes additional information, such as part-of-speech tags, syntactic structures, or semantic annotations.\n",
       "\n",
       "## Uses of a Corpus\n",
       "- **Linguistic Research**: Analyzing language use, grammar, and syntax across different contexts and genres.\n",
       "- **Natural Language Processing (NLP)**: Training machine learning models for tasks such as text classification, sentiment analysis, and language translation.\n",
       "- **Lexicography**: Creating dictionaries and thesauri based on real usage examples.\n",
       "- **Language Teaching**: Developing teaching materials and curricula based on authentic language use.\n",
       "\n",
       "## Characteristics of a Good Corpus\n",
       "- **Representativeness**: Should adequately represent the language or dialect being studied.\n",
       "- **Size**: Large enough to provide reliable statistical analysis.\n",
       "- **Well-structured**: Must be organized in a way that facilitates easy access and retrieval of information.\n",
       "- **Annotated**: Ideally includes metadata and annotations for enhanced analysis.\n",
       "\n",
       "## Conclusion\n",
       "A corpus is a vital tool in linguistics and NLP, providing a rich source of language data for analysis and model training. Its diverse forms and applications make it an essential resource for researchers, educators, and technology developers alike.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef48b34-238e-4e1e-b355-02c20b288e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# What is a Data Type?\n",
       "\n",
       "## Definition\n",
       "A **data type** is a classification that specifies the kind of value a variable can hold in programming and data management. It determines the operations that can be performed on that data and the way it is stored in memory. Data types are fundamental to programming languages, databases, and data analysis.\n",
       "\n",
       "## Common Data Types\n",
       "\n",
       "### 1. Primitive Data Types\n",
       "These are the basic data types provided by programming languages:\n",
       "\n",
       "- **Integer**: Represents whole numbers (e.g., -1, 0, 42).\n",
       "- **Float (or Double)**: Represents decimal numbers (e.g., 3.14, -0.001).\n",
       "- **Character**: Represents single characters (e.g., 'a', 'Z').\n",
       "- **Boolean**: Represents truth values (e.g., `true`, `false`).\n",
       "\n",
       "### 2. Composite Data Types\n",
       "These are built from primitive data types:\n",
       "\n",
       "- **String**: Represents a sequence of characters (e.g., \"Hello, World!\").\n",
       "- **Array**: A collection of elements of the same type, arranged in a fixed-size structure (e.g., `[1, 2, 3]`).\n",
       "- **List**: An ordered collection of items, which can be of different types (e.g., `[1, \"two\", 3.0]`).\n",
       "- **Object**: A collection of properties and methods, typically used in object-oriented programming.\n",
       "\n",
       "### 3. User-defined Data Types\n",
       "These are defined by the user to create more complex data structures:\n",
       "\n",
       "- **Structures (Structs)**: A composite data type that groups related variables (e.g., a `Person` structure with `name` and `age`).\n",
       "- **Classes**: A blueprint for creating objects, encapsulating data and methods (e.g., a `Car` class with attributes like `make`, `model`, and methods like `drive()`).\n",
       "\n",
       "## Importance of Data Types\n",
       "- **Memory Management**: Data types determine how much memory is allocated for variables.\n",
       "- **Type Safety**: Helps prevent errors by enforcing rules about what operations can be performed on data.\n",
       "- **Code Clarity**: Improves code readability and maintainability by indicating the intended use of a variable.\n",
       "\n",
       "## Conclusion\n",
       "Understanding data types is crucial for effective programming and data manipulation. They provide the foundation for data structures and algorithms, allowing developers to write efficient and error-free code.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Data Type?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45708e5-2c6d-4dac-a04b-ab2782cec70b",
   "metadata": {},
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad331f1a-291c-414c-867a-b3287890a342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Prompt, Prompting, and Prompt Engineering\n",
       "\n",
       "## Prompt\n",
       "A **prompt** is a piece of text or an instruction given to an AI model that guides its response. It serves as the input that initiates the model's output generation process. Prompts can vary in complexity, from simple questions to detailed scenarios.\n",
       "\n",
       "### Examples of Prompts:\n",
       "- \"What are the benefits of regular exercise?\"\n",
       "- \"Write a short story about a dragon and a princess.\"\n",
       "- \"Explain the theory of relativity in simple terms.\"\n",
       "\n",
       "## Prompting\n",
       "**Prompting** refers to the process of creating and using prompts to elicit desired responses from an AI model. It involves crafting the prompt in such a way that it effectively communicates the user's intent and yields useful or relevant outputs.\n",
       "\n",
       "### Techniques in Prompting:\n",
       "- **Clarity:** Ensuring that the prompt is clear and unambiguous.\n",
       "- **Specificity:** Providing specific details to guide the model's response.\n",
       "- **Context:** Including context to help the model understand the situation better.\n",
       "\n",
       "## Prompt Engineering\n",
       "**Prompt engineering** is the practice of designing and refining prompts to optimize the performance of AI models. This involves experimenting with different prompt structures, formats, and content to achieve the best possible results. Prompt engineering is crucial for maximizing the effectiveness of language models in various applications.\n",
       "\n",
       "### Key Aspects of Prompt Engineering:\n",
       "- **Iterative Testing:** Continuously testing and modifying prompts based on output quality.\n",
       "- **Understanding Model Behavior:** Gaining insights into how the model interprets prompts and what types of prompts yield better results.\n",
       "- **Domain-Specific Adjustments:** Tailoring prompts to suit specific fields or industries for more relevant outputs.\n",
       "\n",
       "## Conclusion\n",
       "Prompts, prompting, and prompt engineering are integral components of working with AI language models. Mastering these concepts can significantly enhance the quality and relevance of the generated content.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Prompt, Prompting, and Prompt Engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "088828de-5087-4148-a54c-5b045baf65cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Zero-Shot Prompting\n",
       "\n",
       "## Definition\n",
       "**Zero-shot prompting** refers to the technique of asking a language model to generate responses to tasks or questions without providing any specific examples or prior context. In this approach, the model is expected to understand and perform the task based solely on the prompt itself.\n",
       "\n",
       "## Characteristics\n",
       "- **No Prior Examples:** Unlike few-shot prompting, which includes examples to guide the model, zero-shot prompting relies entirely on the prompt to convey the task.\n",
       "- **Generalization:** The model must generalize from its training data to understand the prompt and provide a relevant response.\n",
       "- **Flexibility:** Zero-shot prompts can be applied to a wide range of tasks, making them versatile for various use cases.\n",
       "\n",
       "## Examples\n",
       "1. **Question Answering:** \n",
       "   - Prompt: \"What is the capital of France?\"\n",
       "   - Model Response: \"The capital of France is Paris.\"\n",
       "\n",
       "2. **Summarization:**\n",
       "   - Prompt: \"Summarize the main points of this article about climate change.\"\n",
       "   - Model Response: \"The article discusses the effects of climate change, its causes, and potential solutions.\"\n",
       "\n",
       "3. **Translation:**\n",
       "   - Prompt: \"Translate 'Hello, how are you?' into Spanish.\"\n",
       "   - Model Response: \"Hola, ¿cómo estás?\"\n",
       "\n",
       "## Advantages\n",
       "- **Efficiency:** Reduces the need for extensive examples, making it quicker to generate responses.\n",
       "- **Adaptability:** Can be used across multiple tasks without the need for extensive fine-tuning or training.\n",
       "\n",
       "## Challenges\n",
       "- **Accuracy:** Responses may vary in accuracy, as the model must infer the task without explicit guidance.\n",
       "- **Complexity:** For more complex tasks, zero-shot prompting may not yield the desired results compared to methods that provide more context.\n",
       "\n",
       "## Conclusion\n",
       "Zero-shot prompting is a powerful technique that leverages the capabilities of language models to perform tasks without prior examples, showcasing their ability to generalize and adapt to new challenges.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Zero-Shot prompting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f255bb69-debc-4734-9caa-d4ab83791d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Few-Shot Prompting\n",
       "\n",
       "## Definition\n",
       "**Few-shot prompting** is a technique used with language models where a small number of examples or demonstrations are provided within the prompt to guide the model's responses. This approach helps the model understand the task better by showing it concrete instances of the desired output.\n",
       "\n",
       "## Characteristics\n",
       "- **Minimal Examples:** Few-shot prompting typically includes a few (usually 2-5) examples that illustrate the task or format required, helping the model learn the pattern.\n",
       "- **Task-Specific Guidance:** By providing examples, users can specify exactly how they want the model to perform a certain task.\n",
       "- **Enhanced Performance:** Including examples generally leads to improved accuracy and relevance in the model's responses compared to zero-shot prompting.\n",
       "\n",
       "## Examples\n",
       "1. **Text Classification:**\n",
       "   - Prompt: \n",
       "     ```\n",
       "     Classify the following sentences as either positive or negative:\n",
       "     1. \"I love this product!\" - Positive\n",
       "     2. \"This is the worst experience I've ever had.\" - Negative\n",
       "     3. \"The service was okay.\" - \n",
       "     ```\n",
       "   - Model Response: \"Neutral\"\n",
       "\n",
       "2. **Translation:**\n",
       "   - Prompt:\n",
       "     ```\n",
       "     Translate the following English sentences into French:\n",
       "     1. \"I am happy.\" - \"Je suis heureux.\"\n",
       "     2. \"What is your name?\" - \"Comment vous appelez-vous?\"\n",
       "     3. \"I would like a coffee.\" - \n",
       "     ```\n",
       "   - Model Response: \"Je voudrais un café.\"\n",
       "\n",
       "3. **Summarization:**\n",
       "   - Prompt:\n",
       "     ```\n",
       "     Summarize the following paragraphs:\n",
       "     1. \"The novel explores themes of love and betrayal. The protagonist faces numerous challenges...\"\n",
       "     2. \"In the end, the main character learns valuable lessons about trust.\"\n",
       "     3. \"The story concludes with a twist that leaves readers surprised.\" - \n",
       "     ```\n",
       "   - Model Response: \"The novel deals with love, betrayal, and trust, culminating in a surprising twist.\"\n",
       "\n",
       "## Advantages\n",
       "- **Improved Accuracy:** Providing examples helps the model better understand the desired output, leading to more precise responses.\n",
       "- **Contextual Understanding:** Examples offer context that can clarify ambiguous instructions, enhancing the model's comprehension.\n",
       "\n",
       "## Challenges\n",
       "- **Limited Scalability:** The need to provide examples can make few-shot prompting less efficient for tasks requiring a large variety of outputs.\n",
       "- **Example Selection:** Choosing the right examples is crucial, as poorly selected examples can lead to misleading or incorrect model responses.\n",
       "\n",
       "## Conclusion\n",
       "Few-shot prompting harnesses the power of examples to guide language models in performing specific tasks, improving response quality and relevance while maintaining a balance between providing guidance and keeping the prompt concise.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Few-Shot prompting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447f4c4c-ba29-4770-a477-6a42a0dcfa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Prompt Chaining\n",
       "\n",
       "## Definition\n",
       "**Prompt chaining** is a technique used in natural language processing (NLP) where multiple prompts are linked together in a sequence to build on previous outputs, allowing for more complex interactions and a step-by-step approach to problem-solving or task execution.\n",
       "\n",
       "## Characteristics\n",
       "- **Sequential Interaction:** Each prompt in the chain builds on the output of the previous one, allowing for a more nuanced conversation or task completion.\n",
       "- **Modular Approach:** Tasks can be broken down into smaller, manageable components, making it easier to handle complex queries or workflows.\n",
       "- **Iterative Refinement:** The model can refine its outputs based on earlier responses, leading to more accurate and contextually relevant results.\n",
       "\n",
       "## Examples\n",
       "1. **Story Generation:**\n",
       "   - Prompt 1: \"Generate the first paragraph of a fantasy story.\"\n",
       "   - Model Response: \"In a land where dragons soar above the clouds, a young hero named Elara embarks on a quest...\"\n",
       "   - Prompt 2: \"Continue the story where Elara encounters a dragon.\"\n",
       "   - Model Response: \"As Elara approached the cave, the ground trembled beneath her feet, and the mighty dragon emerged...\"\n",
       "\n",
       "2. **Complex Question Answering:**\n",
       "   - Prompt 1: \"What are the benefits of exercise?\"\n",
       "   - Model Response: \"Exercise improves physical health, boosts mental well-being, and enhances mood.\"\n",
       "   - Prompt 2: \"Can you provide more details on how exercise boosts mental well-being?\"\n",
       "   - Model Response: \"Regular exercise releases endorphins, which help reduce stress and anxiety...\"\n",
       "\n",
       "3. **Data Analysis:**\n",
       "   - Prompt 1: \"Analyze the following sales data: [data]. What trends do you see?\"\n",
       "   - Model Response: \"There is a noticeable increase in sales during the holiday season.\"\n",
       "   - Prompt 2: \"Based on that trend, what recommendations can you provide for the next holiday season?\"\n",
       "   - Model Response: \"I recommend increasing marketing efforts and stock levels prior to the holiday season.\"\n",
       "\n",
       "## Advantages\n",
       "- **Enhanced Context:** By linking prompts, the model maintains contextual continuity, which improves the coherence of responses.\n",
       "- **Problem Decomposition:** Complex tasks can be broken down into simpler steps, making it easier to tackle challenging problems incrementally.\n",
       "\n",
       "## Challenges\n",
       "- **Dependency on Prior Outputs:** The quality of the final output may heavily depend on the accuracy of earlier responses in the chain.\n",
       "- **Increased Complexity:** Managing multiple prompts can introduce complexity in structuring the interaction, requiring careful planning.\n",
       "\n",
       "## Conclusion\n",
       "Prompt chaining is a powerful technique that enables more sophisticated interactions with language models by connecting multiple prompts and their responses. This approach allows for deeper exploration of topics, iterative refinement of outputs, and improved handling of complex tasks.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Prompt chaining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d188f15-5b0f-4465-843f-e25ba6866581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Chain-of-Thought (CoT) Prompting\n",
       "\n",
       "## Definition\n",
       "**Chain-of-Thought (CoT) prompting** is a technique used in natural language processing (NLP) where the model is encouraged to generate intermediate reasoning steps or explanations before arriving at a final answer. This approach helps enhance the model's logical reasoning, problem-solving abilities, and overall understanding of complex tasks.\n",
       "\n",
       "## Characteristics\n",
       "- **Intermediate Steps:** CoT prompting involves breaking down a problem into smaller, logical steps, allowing the model to articulate its thought process.\n",
       "- **Enhanced Reasoning:** By explicitly stating the reasoning path, the model can avoid common pitfalls and arrive at more accurate conclusions.\n",
       "- **Structured Output:** The output is often more organized, as the model provides a clear sequence of thoughts leading to the final answer.\n",
       "\n",
       "## Examples\n",
       "1. **Mathematical Problem Solving:**\n",
       "   - Prompt: \"What is 23 multiplied by 17? Show your reasoning.\"\n",
       "   - Model Response:\n",
       "     1. \"First, I calculate 20 multiplied by 17, which is 340.\"\n",
       "     2. \"Next, I calculate 3 multiplied by 17, which is 51.\"\n",
       "     3. \"Finally, I add these two results: 340 + 51 = 391.\"\n",
       "     - Final Answer: \"Thus, 23 multiplied by 17 is 391.\"\n",
       "\n",
       "2. **Logical Reasoning:**\n",
       "   - Prompt: \"If all cats are mammals and all mammals are animals, what can we infer about cats?\"\n",
       "   - Model Response:\n",
       "     1. \"Since all cats are mammals, they belong to the category of mammals.\"\n",
       "     2. \"Additionally, since all mammals are animals, it follows that cats must also be animals.\"\n",
       "     - Final Answer: \"Therefore, cats are animals.\"\n",
       "\n",
       "3. **Complex Decision Making:**\n",
       "   - Prompt: \"Should I invest in stocks or bonds? Explain your reasoning.\"\n",
       "   - Model Response:\n",
       "     1. \"First, I consider the risk tolerance: stocks are generally riskier than bonds.\"\n",
       "     2. \"Next, I evaluate the potential returns: stocks offer higher returns over the long term.\"\n",
       "     3. \"Lastly, I think about the investment horizon: if I need short-term liquidity, bonds would be a better choice.\"\n",
       "     - Final Answer: \"If I am willing to take risks for higher returns, I should consider stocks; otherwise, bonds may be safer.\"\n",
       "\n",
       "## Advantages\n",
       "- **Improved Accuracy:** By explicitly reasoning through a problem, the model can reduce errors and improve the quality of its answers.\n",
       "- **Transparency:** CoT prompting allows users to see the model's reasoning process, making it easier to understand and trust its conclusions.\n",
       "\n",
       "## Challenges\n",
       "- **Increased Complexity:** Generating intermediate reasoning steps can make the output longer and more complex, potentially overwhelming for some users.\n",
       "- **Dependence on Prompt Clarity:** The effectiveness of CoT prompting relies on well-structured prompts that clearly guide the model's reasoning process.\n",
       "\n",
       "## Conclusion\n",
       "Chain-of-Thought prompting is a valuable technique in NLP that enhances a model's reasoning capabilities by encouraging it to articulate its thought processes. This approach leads to more accurate, transparent, and structured outputs, particularly for complex tasks that require logical reasoning.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Chain-of-Thought (CoT) Prompting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f25b70-649e-41d4-bff8-95b04ba46658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Tree-of-Thought (ToT) Prompting\n",
       "\n",
       "## Definition\n",
       "**Tree-of-Thought (ToT) prompting** is a sophisticated method in natural language processing (NLP) that enhances the model’s reasoning capabilities by facilitating the exploration of multiple interconnected thought processes. Unlike traditional linear reasoning methods, ToT prompting allows the model to generate and evaluate various potential solutions or reasoning paths simultaneously, creating a branching structure that resembles a tree.\n",
       "\n",
       "## Characteristics\n",
       "- **Branching Structure:** ToT prompting organizes thoughts into branches, where each branch represents a different line of reasoning or potential solution to a problem.\n",
       "- **Exploratory Approach:** This method encourages the model to explore multiple avenues of thought, fostering a deeper understanding and comprehensive solution generation.\n",
       "- **Comparative Analysis:** The model can assess the viability of different branches, leading to a more informed and nuanced conclusion.\n",
       "\n",
       "## Examples\n",
       "1. **Mathematical Problem Solving:**\n",
       "   - **Prompt:** \"Solve the equation 3x - 7 = 2. Show different methods.\"\n",
       "   - **Model Response:**\n",
       "     - **Branch 1:** \"Add 7 to both sides: 3x = 9, then divide by 3: x = 3.\"\n",
       "     - **Branch 2:** \"Rearranging gives x = (2 + 7) / 3, which also results in x = 3.\"\n",
       "   - **Final Answer:** \"Both methods confirm that x = 3.\"\n",
       "\n",
       "2. **Creative Writing Ideas:**\n",
       "   - **Prompt:** \"Generate concepts for a dystopian novel.\"\n",
       "   - **Model Response:**\n",
       "     - **Branch 1:** \"A society where thoughts are monitored to eliminate crime.\"\n",
       "     - **Branch 2:** \"A world where climate change has led to extreme resource scarcity.\"\n",
       "     - **Branch 3:** \"A future where technology has replaced human interaction.\"\n",
       "   - **Final Answer:** \"Each concept presents unique themes and challenges for exploration.\"\n",
       "\n",
       "3. **Decision Making:**\n",
       "   - **Prompt:** \"What strategies can I use to improve my health?\"\n",
       "   - **Model Response:**\n",
       "     - **Branch 1:** \"Adopt a balanced diet focused on whole foods.\"\n",
       "     - **Branch 2:** \"Establish a regular exercise routine.\"\n",
       "     - **Branch 3:** \"Prioritize mental health through mindfulness practices.\"\n",
       "   - **Final Answer:** \"A combination of these strategies may yield the best results for overall health improvement.\"\n",
       "\n",
       "## Advantages\n",
       "- **Thorough Exploration:** The ToT approach allows for a more comprehensive examination of problems, leading to richer insights and solutions.\n",
       "- **Enhanced Creativity:** By exploring multiple branches of thought, the model can generate innovative ideas and creative solutions.\n",
       "\n",
       "## Challenges\n",
       "- **Complexity of Output:** The branching nature can lead to intricate outputs that may be difficult to interpret or follow.\n",
       "- **Increased Resource Demand:** Evaluating and processing multiple branches can require more computational resources and time.\n",
       "\n",
       "## Conclusion\n",
       "Tree-of-Thought prompting is an innovative technique that significantly enhances the reasoning capabilities of NLP models by enabling them to explore multiple interconnected thought processes. This approach fosters comprehensive problem-solving, creativity, and nuanced decision-making, making it a valuable tool for tackling complex tasks.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is Tree-of-Thought (ToT) Prompting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6bf5b0-2295-4573-9ffa-65b3185306f1",
   "metadata": {},
   "source": [
    "### Tree-of-Thought Prompting Lab\n",
    "- [Prompt Engineering Guide](https://www.promptingguide.ai/techniques/tot)\n",
    "- [PromptHub](https://www.prompthub.us/blog/how-tree-of-thoughts-prompting-works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "109efe03-026f-4522-9c11-c0a09c43320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# Movie Recommendation Using Tree-of-Thought (ToT) Method\n",
       "\n",
       "## Step 1: Understanding the Friends' Preferences\n",
       "\n",
       "### Unique Movie Characteristics\n",
       "- **Alex**  \n",
       "  - **Favorite Genres:** Action, Thriller  \n",
       "  - **Preferred Actors/Directors:** Keanu Reeves, Christopher Nolan  \n",
       "  - **Specific Elements:** Intense action sequences, strong protagonists, high stakes\n",
       "\n",
       "- **Jordan**  \n",
       "  - **Favorite Genres:** Action, Sci-Fi, Thriller  \n",
       "  - **Preferred Actors/Directors:** Bruce Willis, Liam Neeson, Christopher Nolan  \n",
       "  - **Specific Elements:** Clever plots, mind-bending twists, action-packed sequences\n",
       "\n",
       "- **Taylor**  \n",
       "  - **Favorite Genres:** Action, Superhero, Sci-Fi  \n",
       "  - **Preferred Actors/Directors:** Chris Evans, Chadwick Boseman, James Cameron  \n",
       "  - **Specific Elements:** Superhero themes, epic battles, advanced technology\n",
       "\n",
       "## Step 2: Brainstorming Movie Options\n",
       "\n",
       "### Potential Movie Options\n",
       "1. **Mad Max: Fury Road** (2015) - Action, Adventure\n",
       "2. **John Wick** (2014) - Action, Thriller\n",
       "3. **The Dark Knight** (2008) - Action, Crime\n",
       "4. **Die Hard** (1988) - Action, Thriller\n",
       "5. **Inception** (2010) - Sci-Fi, Action\n",
       "6. **Avengers: Endgame** (2019) - Action, Superhero\n",
       "7. **Casino Royale** (2006) - Action, Thriller\n",
       "8. **Terminator 2: Judgment Day** (1991) - Action, Sci-Fi\n",
       "9. **The Matrix** (1999) - Sci-Fi, Action\n",
       "10. **Black Panther** (2018) - Action, Superhero\n",
       "\n",
       "## Step 3: Evaluating Movie Options\n",
       "\n",
       "### Evaluation Scores (1-10)\n",
       "| Movie Title                          | Alex | Jordan | Taylor | Total Score |\n",
       "|--------------------------------------|------|--------|--------|-------------|\n",
       "| Mad Max: Fury Road                  | 10   | 7      | 8      | 25          |\n",
       "| John Wick                            | 10   | 6      | 7      | 23          |\n",
       "| The Dark Knight                      | 9    | 5      | 7      | 21          |\n",
       "| Die Hard                             | 8    | 10     | 6      | 24          |\n",
       "| Inception                            | 8    | 10     | 7      | 25          |\n",
       "| Avengers: Endgame                   | 7    | 8      | 10     | 25          |\n",
       "| Casino Royale                        | 9    | 7      | 6      | 22          |\n",
       "| Terminator 2: Judgment Day          | 7    | 6      | 9      | 22          |\n",
       "| The Matrix                           | 6    | 10     | 7      | 23          |\n",
       "| Black Panther                        | 6    | 5      | 10     | 21          |\n",
       "\n",
       "## Step 4: Selecting the Best Movie\n",
       "\n",
       "### Top Scores\n",
       "- **Mad Max: Fury Road** - 25\n",
       "- **Inception** - 25\n",
       "- **Avengers: Endgame** - 25\n",
       "- **Die Hard** - 24\n",
       "- **John Wick** - 23\n",
       "- **The Matrix** - 23\n",
       "\n",
       "Since multiple movies scored equally high, we can consider the genres and preferences to determine the most suitable choice.\n",
       "\n",
       "## Step 5: Providing the Recommendation\n",
       "\n",
       "### **Recommended Movie: Inception (2010)**\n",
       "\n",
       "**Description:**  \n",
       "*Inception* is a mind-bending thriller directed by Christopher Nolan that follows a skilled thief who specializes in corporate espionage through the use of dream-sharing technology. The film features high-stakes action, intricate plot twists, and stunning visuals, making it a perfect fit for all three friends who appreciate clever storytelling and intense action sequences.\n",
       "\n",
       "**Why This Movie?**  \n",
       "- **Action and Thrills:** It has intense sequences that Alex and Jordan enjoy.\n",
       "- **Mind-Bending Plot:** Appeals to Jordan's love for clever narratives.\n",
       "- **Sci-Fi Elements:** Contains advanced technology, aligning with Taylor's interests.\n",
       "\n",
       "This recommendation promises to captivate the group and ensure an exhilarating movie night!\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "\n",
    "You are a super intelligent movie recommender AI! Here is your task: {{ task }}. \n",
    "\n",
    "Your goal is to leverage this information and use the Tree of Thoughts method to come to an optimal conclusion. \n",
    "\n",
    "Step 1: Understanding the Friends' Preferences\n",
    "Review the hardcoded movie preferences provided for each friend. Create a list of their unique movie characteristics, including favorite genres, preferred actors, and any specific movie elements they enjoy.\n",
    "\n",
    "Step 2: Brainstorming Movie Options\n",
    "Using the gathered preferences, generate a list of potential movie options that align with each friend's interests. The thoughts here should consist of movie titles, genres, or specific actors/directors that match their preferences.\n",
    "\n",
    "Step 3: Evaluating Movie Options\n",
    "Evaluate the potential movie options based on each friend's preferences. You can assign a value (1-10) to each movie, representing how well it matches their interests. Consider their individual tastes and try to find movies that score high for each friend.\n",
    "\n",
    "Step 4: Selecting the Best Movie\n",
    "Now that you have a list of movies with their corresponding scores, review the evaluations and select the movie that received the highest overall score, considering the combined preferences of all friends.\n",
    "\n",
    "Step 5: Providing the Recommendation\n",
    "Finally, reveal the perfect movie choice! Output the selected movie title as your recommendation for the movie night. Make sure to include a brief description or highlight some interesting aspects of the movie to pique their curiosity.\n",
    "\n",
    "With your knowledge of their preferences and the ToT method at your disposal, you are bound to impress your friends with the ultimate movie recommendation!\n",
    "\n",
    "---\n",
    "Instructions:\n",
    "Use the Tree of Thoughts (ToT) method to navigate through the steps and generate the best movie recommendation for the group of friends based on their hardcoded movie preferences. Enjoy the movie night!\n",
    "\n",
    "\n",
    "```Task\n",
    "Here are three friend names and the five action movies each likes:\n",
    "\n",
    "1. **Alex**  \n",
    "   - John Wick (2014)  \n",
    "   - Mad Max: Fury Road (2015)  \n",
    "   - The Dark Knight (2008)  \n",
    "   - Mission: Impossible – Fallout (2018)  \n",
    "   - Gladiator (2000)  \n",
    "\n",
    "2. **Jordan**  \n",
    "   - Die Hard (1988)  \n",
    "   - The Matrix (1999)  \n",
    "   - Taken (2008)  \n",
    "   - Inception (2010)  \n",
    "   - The Bourne Ultimatum (2007)  \n",
    "\n",
    "3. **Taylor**  \n",
    "   - Avengers: Endgame (2019)  \n",
    "   - Terminator 2: Judgment Day (1991)  \n",
    "   - Black Panther (2018)  \n",
    "   - The Raid: Redemption (2011)  \n",
    "   - Casino Royale (2006) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478c5ba3-d1b1-4d0d-bb6a-cee19f933457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# CO-STAR Prompting Framework in Prompt Engineering\n",
       "\n",
       "The CO-STAR prompting framework is a structured method utilized in prompt engineering, particularly for developing effective prompts for AI models. It helps in crafting clear, context-rich prompts that guide the AI's responses, ensuring relevant and accurate outputs.\n",
       "\n",
       "## Components of CO-STAR in Prompt Engineering\n",
       "\n",
       "1. **C - Context**\n",
       "   - Provide background information that situates the prompt. This can include relevant details about the topic, previous interactions, or specific scenarios that inform the AI's understanding.\n",
       "\n",
       "2. **O - Objective**\n",
       "   - Clearly state the purpose of the prompt. Define what you want to achieve with the AI's response, whether it is to generate information, summarize content, or answer a specific question.\n",
       "\n",
       "3. **S - Specifics**\n",
       "   - Specify the details or requirements of the response. This may involve outlining particular aspects that the AI should focus on, such as tone, format, or length of the output.\n",
       "\n",
       "4. **T - Task**\n",
       "   - Define the task that the AI is expected to perform. This could be generating text, providing a solution, or analyzing information based on the context provided.\n",
       "\n",
       "5. **A - Audience**\n",
       "   - Identify the target audience for the response. Understanding who will be reading or using the output can help tailor the AI's tone and style accordingly.\n",
       "\n",
       "6. **R - Response**\n",
       "   - Encourage the AI to generate a thoughtful and relevant response based on the provided context, objectives, specifics, task, and audience considerations.\n",
       "\n",
       "## Benefits of the CO-STAR Framework in Prompt Engineering\n",
       "\n",
       "- **Clarity**: Ensures that prompts are clear and well-defined, leading to more accurate responses from the AI.\n",
       "- **Focus**: Helps maintain focus on the desired outcomes, reducing ambiguity in AI interactions.\n",
       "- **Contextual Relevance**: Improves the relevance of the output by providing necessary background and specifications.\n",
       "- **Enhanced Engagement**: Encourages richer interactions with AI by prompting it to consider various aspects of the task at hand.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The CO-STAR prompting framework is a valuable tool in prompt engineering, facilitating the creation of effective prompts that yield high-quality responses from AI models. By focusing on context, objectives, specifics, tasks, audience, and response, users can optimize their interactions with AI systems for better outcomes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is CO-STAR prompting framework in the context of prompt engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025d56df-7fce-48c8-a679-2479ffe1d88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# ReAct Prompting\n",
       "\n",
       "ReAct Prompting is a prompting strategy used in the context of AI language models to enhance their performance on tasks requiring reasoning, action, or decision-making. It is particularly effective for complex tasks that involve multi-step reasoning or require the model to provide structured outputs.\n",
       "\n",
       "## Components of ReAct Prompting\n",
       "\n",
       "1. **Reasoning**\n",
       "   - This component encourages the model to engage in logical reasoning before generating a final response. It involves breaking down the problem, analyzing the information, and considering different perspectives or solutions.\n",
       "\n",
       "2. **Action**\n",
       "   - In this part, the model is prompted to take specific actions based on the reasoning conducted. This could involve generating a response, making a decision, or suggesting a course of action that follows logically from the reasoning stage.\n",
       "\n",
       "3. **Output**\n",
       "   - Finally, the model produces a structured output that reflects the reasoning and actions taken. The output should be clear, coherent, and relevant to the task at hand.\n",
       "\n",
       "## Benefits of ReAct Prompting\n",
       "\n",
       "- **Improved Accuracy**: By encouraging reasoning before action, ReAct prompting can lead to more accurate and contextually appropriate responses.\n",
       "- **Structured Responses**: It helps in generating outputs that are not only correct but also logically organized and easy to understand.\n",
       "- **Enhanced Problem-Solving**: This approach is particularly useful for tasks that require critical thinking, as it prompts the model to consider various factors before arriving at a conclusion.\n",
       "\n",
       "## Applications of ReAct Prompting\n",
       "\n",
       "- **Complex Problem Solving**: Ideal for situations requiring detailed analysis and step-by-step reasoning.\n",
       "- **Decision-Making Tasks**: Useful in scenarios where the model needs to evaluate options and suggest actions.\n",
       "- **Creative Writing**: Can enhance storytelling by prompting reasoning about character motivations and plot developments.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "ReAct Prompting is a powerful strategy for leveraging AI models in tasks that require thoughtful reasoning and structured action. By integrating reasoning and action into the prompting process, users can achieve higher-quality outputs and more effective interactions with AI systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "What is ReAct Prompting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006754f-39db-43f6-878b-eb4d695fa8d9",
   "metadata": {},
   "source": [
    "### Example ReAct prompting LLM app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd1ea1f1-521c-463c-b6a0-1a4536043cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To provide the current weather in Thunder Bay, Ontario, Canada, I will need to check a reliable weather source for up-to-date information. \n",
      "\n",
      "Action: CheckWeatherAPI with the location \"Thunder Bay, Ontario, Canada\". \n",
      "\n",
      "Observation: (Assuming this action retrieves the relevant weather information for today, such as temperature, conditions, etc.)\n",
      "\n",
      "Final Answer: The weather in Thunder Bay, Ontario, Canada today is [insert current weather conditions here].\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "system_prompt = '''\n",
    "You are an AI assistant who can perform the following steps:\n",
    "1. Reason through the problem by describing your thoughts in a \"Thought:\" section.\n",
    "2. When you need to use a tool, output an \"Action:\" section with the tool name and its input.\n",
    "3. After the tool call, you'll see an \"Observation:\" section with the tool's output.\n",
    "4. Continue this cycle of Thought → Action → Observation as needed.\n",
    "5. End with a concise \"Final Answer:\" that answers the user's query.\n",
    "\n",
    "Note:\n",
    "- The chain of thought in \"Thought:\" sections is only visible to you and not part of your final answer.\n",
    "- The user should only see your \"Final Answer:\".\n",
    "'''\n",
    "\n",
    "user_prompt = '''\n",
    "What is the weather in Thunder Bay, Ontario, Canada Today?\n",
    "'''\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",\"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "text = completion.choices[0].message.content\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7a5ed97-55bb-4114-84a5-60aee807af52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import re\n",
       "\n",
       "# Given text\n",
       "text = \"\"\"Thought: To provide the current weather in Thunder Bay, Ontario, Canada, I will need to check a reliable weather source for up-to-date information.\n",
       "\n",
       "Action: CheckWeatherAPI with the location \"Thunder Bay, Ontario, Canada\".\n",
       "\n",
       "Observation: (Assuming this action retrieves the relevant weather information for today, such as temperature, conditions, etc.)\n",
       "\n",
       "Final Answer: The weather in Thunder Bay, Ontario, Canada today is [insert current weather conditions here].\"\"\"\n",
       "\n",
       "# Regular expression to extract Action and its parameters\n",
       "action_pattern = r\"Action:\\s*(\\w+)\\s+with\\s+the\\s+location\\s+\\\"([^\\\"]+)\\\"\"\n",
       "\n",
       "# Search for the pattern in the text\n",
       "match = re.search(action_pattern, text)\n",
       "\n",
       "if match:\n",
       "    action = match.group(1)\n",
       "    parameters = match.group(2)\n",
       "    print(f\"Action: {action}\")\n",
       "    print(f\"Parameters: {parameters}\")\n",
       "else:\n",
       "    print(\"No action found.\")\n",
       "```\n",
       "\n",
       "### Output\n",
       "\n",
       "When you run the above code, the output will be:\n",
       "\n",
       "```\n",
       "Action: CheckWeatherAPI\n",
       "Parameters: Thunder Bay, Ontario, Canada\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "\n",
    "Write a python program using regular expressions to extract the Action and it's parameters for the given text {{ text }}\n",
    "\n",
    "```text\n",
    "Thought: To provide the current weather in Thunder Bay, Ontario, Canada, I will need to check a reliable weather source for up-to-date information. \n",
    "\n",
    "Action: CheckWeatherAPI with the location \"Thunder Bay, Ontario, Canada\". \n",
    "\n",
    "Observation: (Assuming this action retrieves the relevant weather information for today, such as temperature, conditions, etc.)\n",
    "\n",
    "Final Answer: The weather in Thunder Bay, Ontario, Canada today is [insert current weather conditions here].\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9da6d34b-02fd-4e5f-8af7-e16d43a51984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: CheckWeatherAPI\n",
      "Parameters: Thunder Bay, Ontario, Canada\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression to extract Action and its parameters\n",
    "action_pattern = r\"Action:\\s*(\\w+)\\s+with\\s+the\\s+location\\s+\\\"([^\\\"]+)\\\"\"\n",
    "\n",
    "# Search for the pattern in the text\n",
    "match = re.search(action_pattern, text)\n",
    "\n",
    "if match:\n",
    "    action = match.group(1)\n",
    "    parameters = match.group(2)\n",
    "    print(f\"Action: {action}\")\n",
    "    print(f\"Parameters: {parameters}\")\n",
    "else:\n",
    "    print(\"No action found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caaf71fd-810a-4bb7-977f-3832428c2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"\"\"Thought: To provide the user with the current weather in Thunder Bay, Ontario, Canada, I need to check a reliable source for up-to-date weather information. \n",
    "\n",
    "Action: CheckWeather(\"Thunder Bay, Ontario, Canada\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86b3579b-0825-4493-bd84-4bafe8525de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match found.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = r'Action:\\s*(\\w+)\\(\"([^\"]+)\"\\)'\n",
    "\n",
    "match = re.search(pattern, text)\n",
    "if match:\n",
    "    tool_name = match.group(1)    # 'GetWeather'\n",
    "    tool_input = match.group(2)   # 'Thunder Bay, Ontario, Canada'\n",
    "    print(\"Tool name:\", tool_name)\n",
    "    print(\"Tool input:\", tool_input)\n",
    "else:\n",
    "    print(\"No match found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2d09fa2-e63f-4ebc-8355-77e2f4b30239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def get_current_weather(city_name):\n",
    "    #base_url = \"https://api.openweathermap.org/data/3.0/onecall\"\n",
    "    #params = {\n",
    "    #    \"lat\": 48.3809,\n",
    "    #    \"lon\": 89.2477,\n",
    "    #    \"appid\": os.environ.get('OPENWEATHERMAPS_API_KEY'),\n",
    "    #    \"units\": \"metric\"  # use \"imperial\" for Fahrenheit\n",
    "    #}\n",
    "\n",
    "    # Make the GET request\n",
    "    #response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Raise an exception if there's an HTTP error\n",
    "    #response.raise_for_status()\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    #data = response.json()\n",
    "\n",
    "    # Extract relevant fields from the response\n",
    "    #weather_info = {\n",
    "    #    \"city\": data[\"name\"],\n",
    "    #    \"temperature\": data[\"main\"][\"temp\"],\n",
    "    #    \"description\": data[\"weather\"][0][\"description\"],\n",
    "    #    \"humidity\": data[\"main\"][\"humidity\"]\n",
    "    #}\n",
    "    weather_info = {\n",
    "        \"city\": \"Thunder Bay\",\n",
    "        \"temperature\": -5.2,   # in Celsius\n",
    "        \"description\": \"snow\",\n",
    "        \"humidity\": 85         # in percentage\n",
    "    }   \n",
    "    return weather_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a26786e-42eb-4ae1-ad0c-114f6eabe7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'Thunder Bay', 'temperature': -5.2, 'description': 'snow', 'humidity': 85}\n"
     ]
    }
   ],
   "source": [
    "if tool_name == 'CheckWeather':  #'GetWeather'\n",
    "    weather_info = get_current_weather(tool_input)\n",
    "    print(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "719054ca-dae0-48b1-9a8c-cf53e9bea755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To provide the current weather in Thunder Bay, Ontario, Canada, I will need to check a reliable weather source for up-to-date information. \n",
      "\n",
      "Action: CheckWeatherAPI with the location \"Thunder Bay, Ontario, Canada\". \n",
      "\n",
      "Observation: (Assuming this action retrieves the relevant weather information for today, such as temperature, conditions, etc.)\n",
      "\n",
      "Final Answer: The weather in Thunder Bay, Ontario, Canada today is [insert current weather conditions here].\n",
      "\n",
      " Observation: {'city': 'Thunder Bay', 'temperature': -5.2, 'description': 'snow', 'humidity': 85}\n"
     ]
    }
   ],
   "source": [
    "updated_text = text + f\"\\n\\n Observation: {weather_info}\"\n",
    "print(updated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4164cba6-95b1-41ce-b14b-ac6c304eb8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",\"content\": user_prompt},\n",
    "        {\"role\": \"assistant\",\"content\": text},\n",
    "        {\"role\": \"user\",\"content\": updated_text}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f0e442a-4421-41fd-9ff3-f3d1feefe5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer: The weather in Thunder Bay, Ontario, Canada today is -5.2°C with snow and a humidity of 85%.\n"
     ]
    }
   ],
   "source": [
    "text2 = completion.choices[0].message.content\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b32b3091-f4cb-4390-aef0-aeaabb70d35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Example LLM Application with OpenAI Using ReAct Prompting and LlamaIndex\n",
       "\n",
       "## Overview\n",
       "\n",
       "In this example, we will demonstrate how to use ReAct prompting with OpenAI's language model (LLM) in conjunction with LlamaIndex to enhance information retrieval and decision-making tasks. LlamaIndex helps manage and query large datasets, making it easier for the LLM to provide contextually relevant responses based on the data.\n",
       "\n",
       "## Use Case\n",
       "\n",
       "Let's consider a scenario where we want to analyze customer feedback data to improve a product. We will fetch relevant feedback using LlamaIndex and then apply ReAct prompting to derive insights and actionable steps.\n",
       "\n",
       "## Step-by-Step Implementation\n",
       "\n",
       "### Step 1: Set Up LlamaIndex\n",
       "\n",
       "First, ensure that you have LlamaIndex installed and set up with your dataset containing customer feedback.\n",
       "\n",
       "```python\n",
       "from llama_index import Document, SimpleDocumentIndex\n",
       "\n",
       "# Example customer feedback data\n",
       "feedback_data = [\n",
       "    Document(text=\"This product is great! I love the battery life.\"),\n",
       "    Document(text=\"The user interface is confusing and not user-friendly.\"),\n",
       "    Document(text=\"Excellent customer service, but the product quality could be improved.\"),\n",
       "]\n",
       "\n",
       "# Create an index with the feedback data\n",
       "index = SimpleDocumentIndex(documents=feedback_data)\n",
       "```\n",
       "\n",
       "### Step 2: Query the Index\n",
       "\n",
       "Next, we will query the index to retrieve relevant feedback that pertains to product usability and quality.\n",
       "\n",
       "```python\n",
       "# Query the index for feedback related to usability\n",
       "query = \"user interface\"\n",
       "results = index.query(query)\n",
       "\n",
       "# Retrieve the feedback texts\n",
       "relevant_feedback = [doc.text for doc in results]\n",
       "```\n",
       "\n",
       "### Step 3: Prepare ReAct Prompt\n",
       "\n",
       "Now, we will prepare a ReAct prompt that incorporates reasoning, action, and output based on the retrieved feedback.\n",
       "\n",
       "```python\n",
       "# Construct the ReAct prompt\n",
       "react_prompt = f\"\"\"\n",
       "### Reasoning\n",
       "Based on the following customer feedback, analyze the usability and quality of the product:\n",
       "- {relevant_feedback[0]}\n",
       "- {relevant_feedback[1]}\n",
       "- {relevant_feedback[2]}\n",
       "\n",
       "### Action\n",
       "Identify key issues and suggest actionable steps to improve the product.\n",
       "\n",
       "### Output\n",
       "\"\"\"\n",
       "```\n",
       "\n",
       "### Step 4: Call OpenAI API\n",
       "\n",
       "Using the constructed prompt, we will call the OpenAI API to generate a response.\n",
       "\n",
       "```python\n",
       "import openai\n",
       "\n",
       "# Call OpenAI's API with the ReAct prompt\n",
       "response = openai.ChatCompletion.create(\n",
       "    model=\"gpt-3.5-turbo\",\n",
       "    messages=[\n",
       "        {\"role\": \"user\", \"content\": react_prompt}\n",
       "    ]\n",
       ")\n",
       "\n",
       "# Extract the output from the response\n",
       "output = response['choices'][0]['message']['content']\n",
       "print(output)\n",
       "```\n",
       "\n",
       "### Example Output\n",
       "\n",
       "The output from the model might look something like this:\n",
       "\n",
       "```\n",
       "### Key Issues Identified:\n",
       "1. **User Interface Confusion**: Multiple users have expressed that the interface is not intuitive, which can lead to frustration.\n",
       "2. **Product Quality Concerns**: While customer service is praised, there are concerns regarding overall product quality.\n",
       "\n",
       "### Suggested Actionable Steps:\n",
       "1. **Conduct Usability Testing**: Organize sessions with users to identify specific pain points in the interface.\n",
       "2. **Revise User Interface Design**: Based on feedback, simplify the navigation and improve visual cues to enhance user experience.\n",
       "3. **Quality Control Review**: Implement a more rigorous quality control process to address concerns about product durability.\n",
       "4. **Customer Feedback Loop**: Establish a continuous feedback mechanism to keep improving both product and service.\n",
       "```\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In this example, we demonstrated how to effectively combine LlamaIndex for data querying with ReAct prompting for insightful analysis and actionable recommendations using OpenAI's language model. This approach enhances the decision-making process by leveraging the strengths of both tools."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "\n",
    "Show an example llm application with openai using ReAct prompting and llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2bbc80-6ba1-4561-9835-18a2cca9e4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6563583-8af3-4d1e-a917-c85cc6cff7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Example LLM Application with OpenAI Using ReAct Prompting and LangChain\n",
       "\n",
       "## Overview\n",
       "\n",
       "In this example, we will demonstrate how to use ReAct prompting with OpenAI's language model (LLM) in conjunction with LangChain to facilitate complex tasks such as data retrieval, reasoning, and decision-making. LangChain provides a framework to connect LLMs with external data sources, making it easier to create applications that require structured interactions.\n",
       "\n",
       "## Use Case\n",
       "\n",
       "Let's consider a scenario where we want to analyze and summarize product reviews from an external API and provide actionable insights based on the analysis. We will use LangChain to fetch reviews and apply ReAct prompting to derive insights.\n",
       "\n",
       "## Step-by-Step Implementation\n",
       "\n",
       "### Step 1: Set Up LangChain\n",
       "\n",
       "First, ensure that you have LangChain installed and configured to interact with an external API (e.g., a product review API).\n",
       "\n",
       "```bash\n",
       "pip install langchain openai\n",
       "```\n",
       "\n",
       "### Step 2: Import Libraries and Initialize Components\n",
       "\n",
       "Next, we will import the necessary libraries and set up the components for fetching data and interacting with the OpenAI API.\n",
       "\n",
       "```python\n",
       "from langchain.chains import LLMChain\n",
       "from langchain.prompts import PromptTemplate\n",
       "from langchain.llms import OpenAI\n",
       "from langchain.agents import create_openai_functions_agent\n",
       "import requests\n",
       "\n",
       "# Initialize OpenAI LLM\n",
       "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
       "\n",
       "# Define the API endpoint and fetch product reviews\n",
       "def fetch_reviews(product_id):\n",
       "    # Simulating an API call. Replace this with the actual API request.\n",
       "    response = [\n",
       "        \"The product is fantastic, great value for money!\",\n",
       "        \"I found the setup process to be quite complicated.\",\n",
       "        \"Excellent customer service but the product failed after a week.\",\n",
       "        \"Very user-friendly and intuitive to use.\"\n",
       "    ]\n",
       "    return response\n",
       "```\n",
       "\n",
       "### Step 3: Construct ReAct Prompt\n",
       "\n",
       "Now, we will create a ReAct prompt that incorporates reasoning and action based on the reviews retrieved.\n",
       "\n",
       "```python\n",
       "# Function to create the ReAct prompt\n",
       "def create_react_prompt(reviews):\n",
       "    reviews_text = \"\\n- \".join(reviews)\n",
       "    \n",
       "    react_prompt = f\"\"\"\n",
       "    ### Reasoning\n",
       "    Analyze the following product reviews to identify strengths and weaknesses:\n",
       "    - {reviews_text}\n",
       "\n",
       "    ### Action\n",
       "    Provide actionable recommendations for improvement based on the analysis.\n",
       "\n",
       "    ### Output\n",
       "    \"\"\"\n",
       "    return react_prompt\n",
       "```\n",
       "\n",
       "### Step 4: Fetch Reviews and Generate Insights\n",
       "\n",
       "We will fetch the reviews, create the ReAct prompt, and then call the OpenAI API to generate insights.\n",
       "\n",
       "```python\n",
       "# Fetch reviews for a specific product\n",
       "product_id = '12345'\n",
       "reviews = fetch_reviews(product_id)\n",
       "\n",
       "# Create the ReAct prompt\n",
       "react_prompt = create_react_prompt(reviews)\n",
       "\n",
       "# Call the OpenAI LLM with the ReAct prompt\n",
       "response = llm(react_prompt)\n",
       "\n",
       "# Print the generated output\n",
       "print(\"Generated Insights:\")\n",
       "print(response)\n",
       "```\n",
       "\n",
       "### Example Output\n",
       "\n",
       "The output from the model might look something like this:\n",
       "\n",
       "```\n",
       "### Strengths:\n",
       "1. **Value for Money**: Many users appreciated the product's affordability and quality.\n",
       "2. **User-Friendliness**: Several reviews highlighted how intuitive the product is to use.\n",
       "\n",
       "### Weaknesses:\n",
       "1. **Complicated Setup**: Users expressed frustration over the complexity of the setup process.\n",
       "2. **Durability Issues**: There are concerns regarding the product's reliability over time.\n",
       "\n",
       "### Actionable Recommendations:\n",
       "1. **Simplify Setup Instructions**: Create detailed, easy-to-follow setup guides or video tutorials to assist users.\n",
       "2. **Enhance Quality Control**: Review manufacturing processes to ensure product durability and reliability.\n",
       "3. **User Feedback Loop**: Implement a system for continuous user feedback to monitor satisfaction and areas for improvement.\n",
       "```\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "In this example, we demonstrated how to effectively use LangChain to fetch data and combine it with ReAct prompting for insightful analysis and actionable recommendations using OpenAI's language model. This approach allows for structured interactions that enhance decision-making processes based on real-world data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "\n",
    "Show an example llm application with openai using ReAct prompting and langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39484141-8c1c-4764-8e27-db207833eca8",
   "metadata": {},
   "source": [
    "### Open Weather MAP API\n",
    "- [OpenWeatherMap](https://openweathermap.org/api)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb386f5-30af-45aa-b944-5db78aa252eb",
   "metadata": {},
   "source": [
    "#### Find current weather of any city using OpenWeatherMap API in Python\n",
    "- [GeeksforGeeks](https://www.geeksforgeeks.org/python-find-current-weather-of-any-city-using-openweathermap-api/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1caab225-acf1-4bfd-8833-fd2f5a3b3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de47c85b-a88b-45ec-8b68-c623a7ff69b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your open weather map api key:  ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENWEATHERMAP_API_KEY\"] = getpass.getpass(\"Enter your open weather map api key: \")\n",
    "openweathermap_api_key = os.getenv(\"OPENWEATHERMAP_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733c22c7-5480-4175-aff7-889e683b1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(openweathermap_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cc84e93-80a7-485b-ac97-aca08c0f4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_city_weather():\n",
    "    api_key = openweathermap_api_key\n",
    "     \n",
    "    # base_url variable to store url\n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "     \n",
    "    # Give city name\n",
    "    city_name = input(\"Enter city name : \")\n",
    "     \n",
    "    # complete_url variable to store\n",
    "    # complete url address\n",
    "    complete_url = base_url + \"appid=\" + api_key + \"&q=\" + city_name\n",
    "     \n",
    "    # get method of requests module\n",
    "    # return response object\n",
    "    response = requests.get(complete_url)\n",
    "     \n",
    "    # json method of response object \n",
    "    # convert json format data into\n",
    "    # python format data\n",
    "    x = response.json()\n",
    "     \n",
    "    # Now x contains list of nested dictionaries\n",
    "    # Check the value of \"cod\" key is equal to\n",
    "    # \"404\", means city is found otherwise,\n",
    "    # city is not found\n",
    "    if x[\"cod\"] != \"404\":\n",
    "     \n",
    "        # store the value of \"main\"\n",
    "        # key in variable y\n",
    "        y = x[\"main\"]\n",
    "     \n",
    "        # store the value corresponding\n",
    "        # to the \"temp\" key of y\n",
    "        current_temperature = y[\"temp\"]\n",
    "     \n",
    "        # store the value corresponding\n",
    "        # to the \"pressure\" key of y\n",
    "        current_pressure = y[\"pressure\"]\n",
    "     \n",
    "        # store the value corresponding\n",
    "        # to the \"humidity\" key of y\n",
    "        current_humidity = y[\"humidity\"]\n",
    "     \n",
    "        # store the value of \"weather\"\n",
    "        # key in variable z\n",
    "        z = x[\"weather\"]\n",
    "     \n",
    "        # store the value corresponding \n",
    "        # to the \"description\" key at \n",
    "        # the 0th index of z\n",
    "        weather_description = z[0][\"description\"]\n",
    "     \n",
    "        # print following values\n",
    "        print(\" Temperature (in kelvin unit) = \" +\n",
    "                        str(current_temperature) +\n",
    "              \"\\n atmospheric pressure (in hPa unit) = \" +\n",
    "                        str(current_pressure) +\n",
    "              \"\\n humidity (in percentage) = \" +\n",
    "                        str(current_humidity) +\n",
    "              \"\\n description = \" +\n",
    "                        str(weather_description))\n",
    "     \n",
    "    else:\n",
    "        print(\" City Not Found \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c24c1be-1070-4586-859d-c91133c96ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter city name :  London\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Temperature (in kelvin unit) = 273.33\n",
      " atmospheric pressure (in hPa unit) = 1003\n",
      " humidity (in percentage) = 94\n",
      " description = overcast clouds\n"
     ]
    }
   ],
   "source": [
    "get_current_city_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04604d9a-770f-4f4e-972b-8c7196b071a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter city name :  Kampala\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Temperature (in kelvin unit) = 304.93\n",
      " atmospheric pressure (in hPa unit) = 1009\n",
      " humidity (in percentage) = 24\n",
      " description = scattered clouds\n"
     ]
    }
   ],
   "source": [
    "get_current_city_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "444cbf6d-2b13-4e36-ba8a-d323b57675fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter city name :  Nairobi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Temperature (in kelvin unit) = 298.08\n",
      " atmospheric pressure (in hPa unit) = 1012\n",
      " humidity (in percentage) = 41\n",
      " description = broken clouds\n"
     ]
    }
   ],
   "source": [
    "get_current_city_weather()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11faa145-0cab-489d-9082-b3dd86eacd96",
   "metadata": {},
   "source": [
    "#### Find current weather of any city using OpenWeatherMap API in Python using PyOWM\n",
    "- [PyOWM - OpenWeatherMap](https://openweathermap.org/examples#python)\n",
    "- [PyOWM - Github](https://github.com/csparpa/pyowm)\n",
    "- [PyOWM - Youtube](https://www.youtube.com/watch?v=123Vz_3E0Zs&feature=youtu.be)\n",
    "- [PyOWN - Code recipes](https://pyowm.readthedocs.io/en/latest/v3/code-recipes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df829691-990a-4a57-b97d-ef15f78c49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip -q install pyowm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b3b953f-c267-41a3-8167-61d55a2768a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyowm import OWM\n",
    "from pyowm.utils import config\n",
    "from pyowm.utils import timestamps\n",
    "\n",
    "\n",
    "def pyown_current_city_weather(city_country):\n",
    "    # ---------- FREE API KEY examples ---------------------\n",
    "    \n",
    "    owm = OWM(openweathermap_api_key)\n",
    "    mgr = owm.weather_manager()\n",
    "    \n",
    "    \n",
    "    observation = mgr.weather_at_place(city_country)\n",
    "    w = observation.weather\n",
    "    print(f\"Weather details: {w.__dict__}\")\n",
    "    \n",
    "    print(f\"Weather detailed status: {w.detailed_status}\")  # 'clouds'\n",
    "    print(f\"Wind: {w.wind()}\") # {'speed': 4.6, 'deg': 330}\n",
    "    print(f\"Humidity: {w.humidity}\")  # 87\n",
    "    print(f\"Temperature: {w.temperature('celsius')}\")  # {'temp_max': 10.5, 'temp': 9.7, 'temp_min': 9.0}\n",
    "    print(f\"Rain: {w.rain}\")  # {}\n",
    "    print(f\"Heat index: {w.heat_index}\")  # None\n",
    "    print(f\"Clouds: {w.clouds}\")  # 75\n",
    "    \n",
    "    # Will it be clear tomorrow at this time in Milan (Italy) ?\n",
    "    # forecast = mgr.forecast_at_place('Milan,IT', 'daily')\n",
    "    # answer = forecast.will_be_clear_at(timestamps.tomorrow())\n",
    "    \n",
    "    # ---------- PAID API KEY example ---------------------\n",
    "    \n",
    "    # config_dict = config.get_default_config_for_subscription_type('professional')\n",
    "    # owm = OWM('your paid OWM API key', config_dict)\n",
    "    \n",
    "    # What's the current humidity in Berlin (Germany) ?\n",
    "    # one_call_object = mgr.one_call(lat=52.5244, lon=13.4105)\n",
    "    # one_call_object.current.humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63bc186b-4a4c-444e-aaa3-d58897394e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather details: {'ref_time': 1736333199, 'sset_time': 1736352604, 'srise_time': 1736323438, 'clouds': 99, 'rain': {}, 'snow': {}, 'wnd': {'speed': 1.54, 'deg': 0}, 'humidity': 93, 'pressure': {'press': 1002, 'sea_level': 1002}, 'temp': {'temp': 274.09, 'temp_kf': None, 'temp_max': 275.1, 'temp_min': 273.13, 'feels_like': 272.41}, 'status': 'Clouds', 'detailed_status': 'overcast clouds', 'weather_code': 804, 'weather_icon_name': '04d', 'visibility_distance': 10000, 'dewpoint': None, 'humidex': None, 'heat_index': None, 'utc_offset': 0, 'uvi': None, 'precipitation_probability': None}\n",
      "Weather detailed status: overcast clouds\n",
      "Wind: {'speed': 1.54, 'deg': 0}\n",
      "Humidity: 93\n",
      "Temperature: {'temp': 0.94, 'temp_max': 1.95, 'temp_min': -0.02, 'feels_like': -0.74, 'temp_kf': None}\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Clouds: 99\n"
     ]
    }
   ],
   "source": [
    "# Search for current weather in London (Great Britain) and get details\n",
    "pyown_current_city_weather('London,GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "475d7eb0-1365-45de-a88f-7c5794c3fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather details: {'ref_time': 1736333331, 'sset_time': 1736351953, 'srise_time': 1736308385, 'clouds': 39, 'rain': {}, 'snow': {}, 'wnd': {'speed': 0.85, 'deg': 116, 'gust': 2.3}, 'humidity': 24, 'pressure': {'press': 1008, 'sea_level': 1008}, 'temp': {'temp': 305.23, 'temp_kf': None, 'temp_max': 305.23, 'temp_min': 305.23, 'feels_like': 303.47}, 'status': 'Clouds', 'detailed_status': 'scattered clouds', 'weather_code': 802, 'weather_icon_name': '03d', 'visibility_distance': 10000, 'dewpoint': None, 'humidex': None, 'heat_index': None, 'utc_offset': 10800, 'uvi': None, 'precipitation_probability': None}\n",
      "Weather detailed status: scattered clouds\n",
      "Wind: {'speed': 0.85, 'deg': 116, 'gust': 2.3}\n",
      "Humidity: 24\n",
      "Temperature: {'temp': 32.08, 'temp_max': 32.08, 'temp_min': 32.08, 'feels_like': 30.32, 'temp_kf': None}\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Clouds: 39\n"
     ]
    }
   ],
   "source": [
    "# Search for current weather in Kampala (Uganda) and get details\n",
    "pyown_current_city_weather('Kampala,UG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7f4b14a-2fb9-4215-bd3c-92c652674e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather details: {'ref_time': 1736333099, 'sset_time': 1736351094, 'srise_time': 1736307211, 'clouds': 75, 'rain': {}, 'snow': {}, 'wnd': {'speed': 2.57, 'deg': 90}, 'humidity': 36, 'pressure': {'press': 1010, 'sea_level': 1010}, 'temp': {'temp': 299.08, 'temp_kf': None, 'temp_max': 299.08, 'temp_min': 299.08, 'feels_like': 298.67}, 'status': 'Clouds', 'detailed_status': 'broken clouds', 'weather_code': 803, 'weather_icon_name': '04d', 'visibility_distance': 10000, 'dewpoint': None, 'humidex': None, 'heat_index': None, 'utc_offset': 10800, 'uvi': None, 'precipitation_probability': None}\n",
      "Weather detailed status: broken clouds\n",
      "Wind: {'speed': 2.57, 'deg': 90}\n",
      "Humidity: 36\n",
      "Temperature: {'temp': 25.93, 'temp_max': 25.93, 'temp_min': 25.93, 'feels_like': 25.52, 'temp_kf': None}\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Clouds: 75\n"
     ]
    }
   ],
   "source": [
    "# Search for current weather in Nairobi (Kenya) and get details\n",
    "pyown_current_city_weather('Nairobi,KE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a58f24-6e42-49d2-bab7-6102bba0f3eb",
   "metadata": {},
   "source": [
    "### OpenWeatherMap Langchain\n",
    "\n",
    "- [Langchain](https://python.langchain.com/docs/integrations/tools/openweathermap/)\n",
    "- [Notebook](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/integrations/tools/openweathermap.ipynb#scrollTo=bf4f6854)\n",
    "\n",
    "This notebook goes over how to use the `OpenWeatherMap` component to fetch weather information.\n",
    "\n",
    "First, you need to sign up for an `OpenWeatherMap API` key:\n",
    "\n",
    "1. Go to OpenWeatherMap and sign up for an API key [here](https://openweathermap.org/api/)\n",
    "2. pip install pyowm\n",
    "\n",
    "Then we will need to set some environment variables:\n",
    "1. Save your API KEY into OPENWEATHERMAP_API_KEY env variable\n",
    "\n",
    "#### Use the wrapper OpenWeatherMapAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ba386ee-4930-4e94-8789-eb3cd861ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b04b7af9-911a-46aa-96b1-9c5d60571d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your open weather map api key:  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
    "\n",
    "os.environ[\"OPENWEATHERMAP_API_KEY\"] = getpass.getpass(\"Enter your open weather map api key: \")\n",
    "\n",
    "weather = OpenWeatherMapAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4d98241-6355-4c6c-be31-62c7029db18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In London,GB, the current weather is as follows:\n",
      "Detailed status: overcast clouds\n",
      "Wind speed: 0.51 m/s, direction: 0°\n",
      "Humidity: 94%\n",
      "Temperature: \n",
      "  - Current: 1.0°C\n",
      "  - High: 1.95°C\n",
      "  - Low: 0.01°C\n",
      "  - Feels like: 1.0°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 99%\n"
     ]
    }
   ],
   "source": [
    "weather_data = weather.run(\"London,GB\")\n",
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02bac58-b7ea-4424-8c68-c22834bcf58e",
   "metadata": {},
   "source": [
    "#### Use the Agent tool and ReAct Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f23aaf2e-d1fc-40a6-ae99-50a63b7bca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your openai api key:  ········\n",
      "Enter your open weather map api key:  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_409/2933552868.py:13: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  agent_chain = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your openai api key: \")\n",
    "os.environ[\"OPENWEATHERMAP_API_KEY\"] = getpass.getpass(\"Enter your open weather map api key: \")\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools([\"openweathermap-api\"], llm)\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c354e563-2ddf-4a7a-b4c8-56e79852723b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the open_weather_map tool to get the current weather information for London.\n",
      "Action: open_weather_map\n",
      "Action Input: London,GB\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn London,GB, the current weather is as follows:\n",
      "Detailed status: overcast clouds\n",
      "Wind speed: 0.51 m/s, direction: 0°\n",
      "Humidity: 94%\n",
      "Temperature: \n",
      "  - Current: 1.0°C\n",
      "  - High: 1.95°C\n",
      "  - Low: 0.01°C\n",
      "  - Feels like: 1.0°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 99%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The current weather in London is overcast with a temperature of 1.0°C and high humidity of 94%.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the weather like in London?\",\n",
       " 'output': 'The current weather in London is overcast with a temperature of 1.0°C and high humidity of 94%.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"What's the weather like in London?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edb19db2-7bed-4005-84c4-7cf8d9d34b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the open_weather_map tool to fetch current weather information\n",
      "Action: open_weather_map\n",
      "Action Input: Kampala\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Kampala, the current weather is as follows:\n",
      "Detailed status: scattered clouds\n",
      "Wind speed: 0.85 m/s, direction: 116°\n",
      "Humidity: 24%\n",
      "Temperature: \n",
      "  - Current: 32.08°C\n",
      "  - High: 32.08°C\n",
      "  - Low: 32.08°C\n",
      "  - Feels like: 30.32°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 39%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current weather in Kampala is scattered clouds with a temperature of 32.08°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the weather like in Kampala?\",\n",
       " 'output': 'The current weather in Kampala is scattered clouds with a temperature of 32.08°C.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"What's the weather like in Kampala?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "787cc227-444e-43e7-9e06-58c93657eb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the open_weather_map tool to get the current weather information for Nairobi.\n",
      "Action: open_weather_map\n",
      "Action Input: Nairobi\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Nairobi, the current weather is as follows:\n",
      "Detailed status: scattered clouds\n",
      "Wind speed: 3.16 m/s, direction: 118°\n",
      "Humidity: 31%\n",
      "Temperature: \n",
      "  - Current: 27.46°C\n",
      "  - High: 27.46°C\n",
      "  - Low: 27.46°C\n",
      "  - Feels like: 26.76°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 46%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The current weather in Nairobi is scattered clouds with a temperature of 27.46°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the weather like in Nairobi?\",\n",
       " 'output': 'The current weather in Nairobi is scattered clouds with a temperature of 27.46°C.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"What's the weather like in Nairobi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "122d1d1f-e46a-4e16-847f-d2a311d7d813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the open_weather_map tool to fetch current weather information for Lagos.\n",
      "Action: open_weather_map\n",
      "Action Input: Lagos\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Lagos, the current weather is as follows:\n",
      "Detailed status: few clouds\n",
      "Wind speed: 1.27 m/s, direction: 173°\n",
      "Humidity: 40%\n",
      "Temperature: \n",
      "  - Current: 35.26°C\n",
      "  - High: 35.26°C\n",
      "  - Low: 35.26°C\n",
      "  - Feels like: 37.7°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 18%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The current weather in Lagos is few clouds with a temperature of 35.26°C and a humidity of 40%.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the weather like in Lagos?\",\n",
       " 'output': 'The current weather in Lagos is few clouds with a temperature of 35.26°C and a humidity of 40%.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"What's the weather like in Lagos?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e77a702-3e27-4c20-9f61-359d12edbec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the open_weather_map tool to get the current weather information for Nigeria.\n",
      "Action: open_weather_map\n",
      "Action Input: Nigeria\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Nigeria, the current weather is as follows:\n",
      "Detailed status: clear sky\n",
      "Wind speed: 4.36 m/s, direction: 64°\n",
      "Humidity: 13%\n",
      "Temperature: \n",
      "  - Current: 30.01°C\n",
      "  - High: 30.01°C\n",
      "  - Low: 30.01°C\n",
      "  - Feels like: 28.14°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 6%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The current weather in Nigeria is clear and sunny with a temperature of 30.01°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the weather like in Nigeria?\",\n",
       " 'output': 'The current weather in Nigeria is clear and sunny with a temperature of 30.01°C.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"What's the weather like in Nigeria?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b5299b1-4bc9-452e-bc1e-989d1dd99e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the open_weather_map tool to fetch current weather information for a specified location.\n",
      "Action: open_weather_map\n",
      "Action Input: Nigeria, Abuja\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Nigeria, Abuja, the current weather is as follows:\n",
      "Detailed status: clear sky\n",
      "Wind speed: 4.36 m/s, direction: 64°\n",
      "Humidity: 13%\n",
      "Temperature: \n",
      "  - Current: 30.01°C\n",
      "  - High: 30.01°C\n",
      "  - Low: 30.01°C\n",
      "  - Feels like: 28.14°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 6%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The current weather in Nigeria, Abuja is clear and sunny with a temperature of 30.01°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the weather like in Nigeria, Abuja?\",\n",
       " 'output': 'The current weather in Nigeria, Abuja is clear and sunny with a temperature of 30.01°C.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"What's the weather like in Nigeria, Abuja?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05bed899-7dbe-4c17-8344-291fc22be4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the open_weather_map tool to fetch current weather information for Abuja, Nigeria.\n",
      "Action: open_weather_map\n",
      "Action Input: Abuja, Nigeria\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Abuja, Nigeria, the current weather is as follows:\n",
      "Detailed status: clear sky\n",
      "Wind speed: 0.63 m/s, direction: 121°\n",
      "Humidity: 11%\n",
      "Temperature: \n",
      "  - Current: 33.81°C\n",
      "  - High: 33.81°C\n",
      "  - Low: 33.81°C\n",
      "  - Feels like: 31.3°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 6%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The current weather in Abuja, Nigeria is clear and hot with a temperature of 33.81°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the weather like in Abuja, Nigeria?\",\n",
       " 'output': 'The current weather in Abuja, Nigeria is clear and hot with a temperature of 33.81°C.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"What's the weather like in Abuja, Nigeria?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ab99857-cc2b-439b-ba93-4c64502f3dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the open_weather_map tool to fetch current weather information for Berlin, German\n",
      "Action: open_weather_map\n",
      "Action Input: Berlin, German\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Berlin, German, the current weather is as follows:\n",
      "Detailed status: few clouds\n",
      "Wind speed: 8.05 m/s, direction: 236°\n",
      "Humidity: 80%\n",
      "Temperature: \n",
      "  - Current: 3.89°C\n",
      "  - High: 4.99°C\n",
      "  - Low: 2.41°C\n",
      "  - Feels like: -1.29°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 20%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current weather in Berlin, German is few clouds with a temperature of 3.89°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the weather like in Berlin, German?\",\n",
       " 'output': 'The current weather in Berlin, German is few clouds with a temperature of 3.89°C.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"What's the weather like in Berlin, German?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac2d3732-b866-45b5-bde9-3f3c4a1bc8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the open_weather_map tool to get the current weather information for each location.\n",
      "Action: open_weather_map\n",
      "Action Input: London,GB\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn London,GB, the current weather is as follows:\n",
      "Detailed status: overcast clouds\n",
      "Wind speed: 0.51 m/s, direction: 0°\n",
      "Humidity: 93%\n",
      "Temperature: \n",
      "  - Current: 1.0°C\n",
      "  - High: 1.95°C\n",
      "  - Low: 0.01°C\n",
      "  - Feels like: 1.0°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 99%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should repeat the same action for Paris,FR and Berlin,DE.\n",
      "Action: open_weather_map\n",
      "Action Input: Paris,FR\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Paris,FR, the current weather is as follows:\n",
      "Detailed status: moderate rain\n",
      "Wind speed: 5.14 m/s, direction: 110°\n",
      "Humidity: 96%\n",
      "Temperature: \n",
      "  - Current: 4.05°C\n",
      "  - High: 4.49°C\n",
      "  - Low: 3.77°C\n",
      "  - Feels like: 0.08°C\n",
      "Rain: {'1h': 1.19}\n",
      "Heat index: None\n",
      "Cloud cover: 100%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should repeat the same action for Berlin,DE.\n",
      "Action: open_weather_map\n",
      "Action Input: Berlin,DE\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn Berlin,DE, the current weather is as follows:\n",
      "Detailed status: few clouds\n",
      "Wind speed: 8.05 m/s, direction: 236°\n",
      "Humidity: 80%\n",
      "Temperature: \n",
      "  - Current: 3.9°C\n",
      "  - High: 4.99°C\n",
      "  - Low: 2.41°C\n",
      "  - Feels like: -1.27°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 20%\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The weather in London, Paris, and Berlin is currently overcast clouds, moderate rain, and few clouds respectively. The temperatures are 1.0°C, 4.05°C, and 3.9°C and the humidities are 93%, 96%, and 80% in each location.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the weather like in London, Paris, and Berlin? Also state the temperature and humidity in these places.\",\n",
       " 'output': 'The weather in London, Paris, and Berlin is currently overcast clouds, moderate rain, and few clouds respectively. The temperatures are 1.0°C, 4.05°C, and 3.9°C and the humidities are 93%, 96%, and 80% in each location.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"What's the weather like in London, Paris, and Berlin? Also state the temperature and humidity in these places.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364b8a4-bd36-4137-ab37-aa0d31cd29f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
