{
    "xmsmJf-NRm8": "Welcome to the Real Python Podcast. This is episode 4 and my name is Christopher Bailey, your host. This week, I speak with Martin Royce. Martin creates video courses for Real Python. We discuss his course on getting started with Django and how to learn Python through errors, and how errors really are your friends. He talks about his work with Coding Nomads, teaching Python around the world. He also provides some tips on debugging and writing good questions. \n\nThis episode was recorded at an earlier date, and because of recent events, Martin wanted to come back to discuss a new stay-at-home mentorship program he's working on meant not only for learners but also for those who want to mentor. You'll hear all about it near the end of the program. We also answer our first audio question submission, so let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. Interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey, welcome Martin. \n\nHey, hey, good welcome to the podcast. Thanks, excited to be here. \n\nWhere are you talking to me from? \n\nI'm currently in Ukraine in Odessa. Oh, wow, which is where I just moved to only about a week ago. So, we're reliving before that. Originally, I'm from Austria. I was born and grew up there, but in the past three years, by now, I've been moving around the world quite a bit. \n\nWhat are some places you've been? \n\nI spent quite a while in the US on both ends of the coast and I was in the middle and spent some time in Thailand, spent some time in Vietnam, spent quite a bit of time in Indonesia. That was professionally related because it was teaching courses there. I taught a course in Barcelona, so I spent some time in Spain, spent half a year in Australia, and a little stopover in New Zealand, a little time in Germany and in Austria as well back home. So, I think mostly those were the places and always just a couple of months at a time essentially. \n\nOkay, you get an idea of like where you want to live and travel that far all over the world, get lots of choices. \n\nYeah, you get maybe you get a bit of an idea of what feels nice to you and what doesn't. But you know, a lot of time I was just spent on my computer because that's where I do work. \n\nThat's essentially it's the same. It's some of the perks and disadvantages of working remotely, right? \n\nYeah, sometimes you get out to see what's going on, yeah, but there's, you know, like this obviously, you still get a lot of the different places that you in because things work differently. You got to go shopping, and you do have like times off when you can go around and see some new things. This is all related to the job. We'll talk about a little bit more as we get into here with Coding Nomads, right? \n\nRight, yeah, that's a lot of it is related to that because I've been teaching these boot camps in different places with Coding Nomads. So that's the reason I'm traveling professionally, and then partly it's also because my girlfriend is from the United States so we have some visa situations to figure out because it's always that if you have different passports, it's not so easy to have a place that you can stay in for an extended amount of time. \n\nYeah, when I was thinking about you saying that you're in Ukraine right now, I tried to do a podcast out of four or five years ago, and the idea was a streaming film studies. We watched, I think it was even on Netflix at the time, \"Battleship Potemkin.\" So I was like, oh, yeah, and we have our current places just a couple of minutes walk away from the Potemkin stairs. So we went there the first day and checked it out. Yeah, and he ruined it for me. He said they're not there's like movie magic happening even back in whatever year that was that they faked the length of the stairs. It's just like the shots are cut in a way that it just feels like people keep running down the stairs and walking down the stairs forever, and they're kind of long, but they're not that long. Like you can't walk down for five minutes or ten, right? That scene is pretty long. It's also got an interesting like it ends with the road at the bottom, and then there's the porch station afterwards. So it's not like a classical how you'd imagine like a classical tourist location, right? But it feels just more part of the city, and they just needed a street down there, and there's the Port Authority, so that's the way it went. And I kind of like that it has a nice charm to it. \n\nHow did you get into programming and then in the Python? \n\nI was thinking about it for a while, and I just I had a little bit of pretext which is which I want to mention sure because I have the feeling there's a lot of people out there that have these stories of getting this Commodore from when they were five, and then they started programming and then they've been doing it since ever since then forever. March this degree and all, and I really didn't have anything to do with programming into my late mid-twenties, I guess. Sure, okay.I studied a bunch of humanistic topics mostly, but finished my degree in biology without any programming involved. The first time I got acquainted with programming was when MOOCs became a thing in 2012.\n\nThere was a famous machine learning MOOC by Andrew Ng and Peter Norvig, which I took with a couple of friends. It was exciting, even though I didn't understand much since it was about machine learning.\n\nI have an idealistic interest in learning, which got me really interested in university. I was excited about having options to learn something, unlike in school where you just sit it out. However, I got disappointed in university when it seemed like people were just there to get a degree and move on.\n\nMOOCs were different because people were there to gain new knowledge, not just for a certificate. The community in MOOCs was great, everyone was interested in learning.\n\nI got hooked on programming after taking more programming MOOCs and getting involved with Udacity. Teaching and mentoring others has been a part of my programming journey from the start. Peer learning and mentoring are important to me.\n\nProgramming can be lonely, spending a lot of time alone in front of a screen. Finding a community through MOOCs is a great way to share the experience with others who are also learning.\n\nI believe in opening up programming to people who may not feel predisposed to learning in that way. Some people learn better socially, and there are ways to do that for programming as well.\n\nI got into Python at the beginning and started with a MOOC by Rice University on interactive programming with Python. We did game programming, which was fun and a great way to learn programming concepts.\n\nGaming is a fun way to learn because you create things and see the results of your code. You can share what you've created with others who may not be interested in just looking at lines of code. It's pretty cool.How did you get involved with Real Python? I think I signed up for one of Dan's newsletters when he was sending out little Python code snippets at some point. I was using the resource for my own learning. It's been a great resource for a while with lots of interesting tutorials. I was familiar with it and then started to want to expand using video as well. I sent out an email regarding that I had built a Python course by that time and did a couple of videos, so I was familiar with the process of creating videos for programming screencasts. I applied and sent in my example video, and he liked it. That's how I got involved and started doing video courses.\n\nWhat are some of the courses you've done already at Real Python? I did an intro to Jupyter notebooks and a really long one about Django, introducing Django. I also did one about reasons for using different editors. Another one just came out recently.\n\nWhy did you pick the Django course? I have a job where I teach coding to people in a couple of different capacities. One of them is instructing at boot camps where we go from beginners to people who have tried to learn coding online but haven't gotten far into web development. My language of choice was Python, and the framework I was using for web development is Django. I had some experience teaching Django to people, and I think it's a cool framework. I wanted to condense the knowledge I got from teaching it to people into a short intro experience that would help people continue on their own.\n\nThere are a lot of benefits to Django for beginners. It has a lot of stuff already included, which can be both a benefit and a distraction. It's helpful because you don't have to think about every piece separately when you're just starting with web development. It can feel like there's just one thing you have to learn, rather than cobbling together different technologies. Django abstracts how you interact with the database, so you don't have to write SQL code.\n\nORM stands for Object Relational Mapper. It's the piece of code that interacts between your Python code and the database code. Django has its own ORM, which helps you write code that interacts with the database without needing to write actual SQL code. It cuts down on the complexity for beginners, making it easier to get started and stay excited.\n\nI think Django is rapid to get a hello world webpage going. It's one of the things people come to Python for, especially on the web development side. Most people come through Python for data analysis, but Django and Flask are popular for web development.\n\nIn your course, you talk about how errors can teach you about programming and make you a better programmer. Can you expand on that? I think it's important to see error messages not as enemies but as new friends that are helping you out to do what you want to do.I think that in a framework that's as complex as Django, you're definitely going to keep running into error messages here and there. That's just part of development in general, I think. So, if you're going to give up or if you get afraid when you see an error message and you just get stopped in your heels and you don't know how to continue, then you're not going to get very far.\n\nYeah, that's a common reaction, right? It's like an error appears because it's called a Value Error or a method not found. I don't know. And then it's usually not very friendly. I think, why even call them errors? Call them, I don't know, code feedback or something. Yeah, that's funny. I just find it important that you understand that this is not a criticism of what you're doing. It's just your computer essentially trying to communicate with you in a way like as if the computer is a buddy and it's telling you, \"Hey, something's not working as we expected. Here's what I know. Let's try to figure it out together.\" Yeah, I was thinking of Mr. Robot, going, \"Hello, friend,\" trying to give you a clue as to what you're supposed to be doing next, right?\n\nYeah. Is there some tricks to reading the errors? Yeah, sorry. I guess what you can think about is that if you're looking at these stack traces, which is also what errors are called sometimes, one thing I do is look at the last line, which is usually the one that's going to help you move forward. So, look at the last line first, and then just paste it, put it into Google, and look up a couple of answers. That's the first step, I think, you can do with an error message.\n\nSo, that term \"stack traces,\" where does that come from? It's just another name for error messages. I think it's the complete thing of all of the lines you get when there's an error. You usually don't just get one line, but you get this whole thing that fills up your whole terminal. Yeah, it's all layered. There. You're saying you need to read that not top-down, exactly. Yeah, like you wouldn't start where it starts spitting that stuff out to you. It's actually in reverse. It kind of tells you something went wrong here. That's how I imagine it. I might be wrong about it.\n\nRight. So, how I imagine it is kind of like the uppermost level where the error happens, that's the lowest line. Okay. And then it kind of digs down deeper into the program. That's the stack trace further up. That's how I think about it. So, like if an error appears, you'd see at the very bottom, in the case of Python, and they would say, \"Type error\" or something invalid. And then as you look upward, you start to see, yeah.\n\nAnd often, you don't need to go very far up. If you just look at the lowest line and think about what's going on there, Google it and read a couple of answers, you can probably figure out what's going on. Cool. Just what everyone does if you do programming, you're going to encounter them a lot. You kind of develop a bit of a feeling of other places that you can maybe look, right? And then above that last line, it actually might point to an actual line number in your code, right?\n\nYeah. I was wondering about, as we were talking about Django, since it's a web framework, there's often the errors you may see would appear on the actual website that you're looking at. What do those errors kind of look like? Yeah, okay. So, you see them also in your console, in the terminal. But Django has this server, the live server that displays it and formats it nicely like a webpage, essentially. Then, they're a bit easier to look at and they have this, I don't know if this changed in the new versions, but you have this big yellow bar at the top. It gives you the error message, that's your last line, so to say, in Django. That's where the main error message lies. And then it's got a couple of sections down that you can expand. They get pretty detailed sometimes because it's such a big complex framework. I guess it also points you to the files sometimes. So, it tells you, like, in this file, probably at that point, something went wrong. So, that's the place that you can go and check. It's pointing you to a section of your code. In that case, it's pointing you to a section in a file.\n\nOkay. If you create a new Django project, right, I think that shows something about how intimidating this can be at the beginning, right? If you use Django, there's a command called start project that you can run that builds a skeleton project for you automatically. And if you run this command, you get a folder with a bunch of folders in it, with a bunch of files in it, and there's code in some of these files. Other files don't have code.So, it's already feeling some complexity when you look at that. Right now, you own all this stuff and everything needs to interact with each other for this whole thing to function. Let's get started. That can seem daunting, but if you keep in mind that it's easy to break something, it's not a big deal. The computer is on your side, trying to help you resolve any issues. Error messages are just a way of communicating that. Are you also diving into the documentation? Is that useful? The Django docs are often hailed as very resourceful and good documentation for a framework. I personally find them not very easy to read. It feels overwhelming, especially for beginners. It's not the most fun way to get into something, in my opinion. \n\nThat's a common answer on Stack Overflow, the kind of rude answer of just reading the docs. If you're not an engineer and you're a beginner, it's hard to even parse what's happening there. Do you have techniques that help you with that? If you're already in a complex framework and the instructions seem complex, it can be demotivating. Filter through the information and focus on the specific part you need. Don't try to understand everything at once. It's probably better to go through tutorials rather than reading through the docs. Django itself has an example project that introduces you to its features. \n\nI do a mix of teaching. I do video courses on Real Python. I also do remote training. My main gig is with a company called Coding Nomads. We do boot camps and online courses in the programming education field. The idea is to travel and work at the same time, earning a living on the go. It's a good way to see the world and earn well if you're good at it. Coding Nomads started with boot camps in different locations around the world, promoting language exchange through programming. It's an intensive and effective way of learning.\n\nI've taught boot camps with Coding Nomads, and it was a lot of fun and work. Common areas that students get stuck on include understanding web development from scratch.Okay, I think that a big step that people sometimes struggle with is transitioning from learning programming and a language to reaching a point where they understand Python. Understanding Python and being able to do something with code is one thing, but moving on to using a web framework like Django introduces additional complexities. Learning programming concepts related to a specific language feels contained, but once you grasp the basics, you can start doing more with it.\n\nLearning the vocabulary, syntax, and basics is just the first step. To have a conversation with someone or write a program, you need to take it further and use a framework. Web development adds complexity with additional parts like HTML and CSS that you need to know.\n\nOur course structure includes a month online, six to eight weeks on-site, and another month for projects. We aim to ensure that participants understand programming basics before the on-site portion for a smoother transition into using programming tools like a framework.\n\nResponding to comments and questions on the Real Python course has been a positive experience for me. I have experience as a forum mentor at Udacity, where I moderated and responded to student questions in text-based formats.\n\nThe format of comments on the course differs from a forum, as it's not a threaded discussion. It can be challenging to ensure comments end up in the right place within the course structure. I aim to help people figure things out by guiding them in the right direction rather than giving them the answers outright.\n\nIn mentoring students, I focus on understanding the issue at hand, asking questions to clarify, and then nudging them in the right direction to figure out the solution themselves. Encouraging students to think in a certain direction through comments is my approach to mentoring effectively.Okay, going back to the beginning of the process, is asking the right question. They may see something in front of them and want to do the same thing they would do on Google, just paste their error code without any context. Are there good ways to help them think about asking the right type of questions? Tips for asking the right kind of questions when asking for help.\n\nMaybe we should have something like that sitting around. Like when setting up a forum, it's one of the first things you write and put there so that it's easy to link to. In your experience, unlike Udacity and such, it's like, \"Hey, before writing your question, here's what to think about.\" \n\nI set this up for our forums, decoding them. There are introductions on how to ask a question and how to format your code because there are things you don't know about, and there are so many different platforms. You just learn somewhere, you try to do something, it doesn't work, and then it's nice to have a link to help people figure it out for next time.\n\nWhat kind of things go into that document you mentioned? Code formatting and tips for asking a question. Trying to be as complete as possible with what you want to say, providing context for your question. Depending on what it is, specifics about the operating system could be important to understand what's going on.\n\nIn the case of Python, it gets complex quickly with multiple versions and different installations. It's important to provide information about your Python environment before asking questions. For example, when helping out with Arduino, knowing if someone is using a Raspberry Pi changes things dramatically due to the lower-powered machine and specific version of Linux.\n\nIt's important to recreate the problem and provide information about the operating system, editor, and Python version when asking a question. Giving context and narrowing down the question can make it easier to answer. It's not helpful to just say something is not working without providing more details. Debugging code is the step after getting an error and not being afraid of it. Techniques for debugging code involve figuring out what to do next.It's your friend, just trying to help you. It's waving there, hey look, this happened. Yeah, let's try to figure it out together. What tools, like, it depends on the complexity of the program you're working with. I think the good old print statement can often be very helpful if you're working on a smaller program. In Django, I guess when you think about a web framework like that, try to think of the screen, the pages that get rendered. That's somewhat like your output. You can more or less do something similar to a print statement by just including a variable and printing it out on the screen. Depending on which editor you're working with, there are pretty good and pretty cumbersome debuggers as well. I've been working with PyCharm and Python has a pretty good debugger included, where you can get the program to run and then figure out what the current variables that are defined are and just inspect them in more detail.\n\nIn the case of PyCharm, the debugger there, in order to show you what's going on, you have to run it in debug mode. So, you're running your existing script or program in debug mode? Yes, and then what happens? And then you can set breakpoints, which just means you mark a certain piece of code. You say, stop here debugger, and then once it hits that line of code, it stops execution and gives you a window into how your program looks at the moment. Different ways of showing it, different levels of complexity of debuggers as well. I think of it like getting insight into the current state of your program and then you can play around with it and figure out what's going on. Cool, in the course that you just released, it's about the different editor tools. What types of editors were you showing?\n\nWhat I tried to do was look at those editors in a more type of manner. So, what type of editors exist categorically? The ones that I made up for this thing are an editor, just an editor that's always there for you, doesn't matter where you're working. It comes with the operating system. The advantage there is that even in virtual machine work with AWS, they typically have a small distribution of Linux with an editor like Vim already there. I'm using Vim as a simple tool that I know will be there and can work with essentially. I think it's useful for that. Then I was looking at Dany, actually, as a beginner-friendly editor. Have you worked with it a bit? I have dabbled very briefly. It was the one thing that was on the Raspberry Pi, and so I was kind of dabbling with it a little bit. There are some good resources on Real Python for it. I started in Sublime, which I kind of came from doing some HTML and CSS stuff. That was the one that kept coming out to me, and then I got introduced to a lot of Dany's stuff because he had a course on customizing it to work better with Python.Yeah, I actually started with Sublime as my first editor. I did more work with it and still enjoy working with it. In the course, I'm not talking about Sublime specifically, but instead about VS Code. I think that VS Code, Sublime Text, and Adam are somewhat in the same category for me - lightweight text editors with some IDE features, but not full-blown IDEs. IDE stands for integrated development environment, which integrates various features to make it a different level.\n\nYes, PyCharm, for example, has a terminal, debugger, database features, and tons of text editor features. The big IDEs really have a lot to offer, and I know only a small percentage of what's possible with these tools. I've also dabbled with Xcode, which tries to be an all-in-one solution.\n\nMoving on to Jupyter Notebooks, it's a whole other thing - an online tool that can hold anything. I really enjoy working with Jupyter Notebooks as well. It's explorative and feels like telling a story while coding. There are potential pitfalls with working in Jupyter Notebooks, such as not being aware of the state of things when running cells in different orders.\n\nThere's a tricky aspect to working with code blocks in Jupyter Notebooks, as everything ultimately contributes to one big pile of code. Python as a language excites me due to its versatility, making it relatively easy to learn and applicable in various fields. It's great for building websites, automating tasks, and creating small scripts for daily use.\n\nI'm excited about the possibilities Python offers for automation and efficiency in different fields. I'm currently working on a script to automate the calculation of video durations for my courses. It's exciting to see how programming can simplify tasks that would otherwise be done manually.\n\nOn a related note, I recently acquired a Leap Motion device, a hand motion sensor that connects via USB. It measures hand movements, and I'm exploring its potential in music and programming-related activities. It's fascinating to see how technology can enhance creative and technical pursuits.I think they use it a lot in VR devices and maybe they have it included in some of the newer headsets. This is just like a little box that you put down and then your computer can recognize all sorts of intricate movements of your hands, essentially position and whether they're open, are you moving them up or down, or forward, etc. So it's not a glove per se, it's a device that your hands are free. Okay, yeah, it just looks at your hands, it's like a camera that figures out your hands. I don't know how exactly but it's accurate. Okay, and someone made a software for it called Gecko that allows you to control synthesizers with it. \n\nYou can assign patterns to different hand movements and then interact essentially with your software or hardware synthesizers through moving your hands. Super cool. I definitely got a, we'll have the links to that and the show notes, I'll get that from you. Yeah, that's pretty fun. I've been trying to play around with that a bit but got stopped because I updated my operating system, maybe S2, to the newest one and all of the audio software broke. So is that Catalina or whatever it is? Yeah, yeah, so if you're trying to do something with audio, don't do Catalina. \n\nYeah, it does some weird stuff too. Here's a big warning to other Python people out there, it does some really strange stuff to your Python installation too, will break the ability to compile stuff. Like a common thing people ask me about when they watch my videos is this REPL replacement I use called B Python and it has to basically do a real simple compilation, and there's some commands that you can do to fix it and I'll put a link in the show notes. But yeah, that's one of the issues with the latest version of the Mac OS, it changes some of the behaviors. I had heard that they were going to not include Python with it at all, but that isn't true, they actually are still including it, but I think maybe the next version or future versions, they're trying to decouple it because they were really tied to Python. \n\nAnd is it still Python 2 and is it included within you? I don't know, I haven't run Catalina cause I know it's gonna break my audio stuff. I could check it out, you should find out. Yeah, if you type Python, does it do 2 or does it do 3? Well, I got it mapped differently with, you know, pip and pipenv and pip3 and already from before, so my Python is like some shim pip and calls it. Okay, so it's ready to go. Yeah, it's working, but that means I don't know exactly what's the system Python version. \n\nAnd I guess the other curse I had is something new I'm trying, what kind of music do you listen to when you code? Yeah, so I'm kind of a listen and repeat kind of person if that's the thing, so I get like a song stuck in my head, and it just loops in my head anyway. Sometimes I just put it on and then loop it in audio, you could offload some of the processing to doing that. So yeah, that's something I do sometimes, and then I just listen to the same song for an hour or something. \n\nWhat kind of music is that? That really depends, like whatever pops in my head, I don't know, it's quite varied I guess, but I also like to listen to just some ambient sounds like there's this nice page called Noisily that I sometimes use where you can switch on different types of like fire crackling or water trickling, etc., and that's very nice. That's cool, but in terms of actual music, I guess I have like sometimes I listen to like classical music playlists or this chill hop stuff is this disc, well it's and studies forever. I don't know if you've seen that, there's this lo-fi hip and it's just a radio that keeps running, okay, if a girl sitting and studying and she moves her pen a little bit, so it's like a YouTube thing, yeah, yeah, that's on YouTube. \n\nBoth of those, I also just switch on some classical playlists on YouTube sometimes. So this is the point where we said our goodbyes originally but as I was mentioning in the intro Martin wanted to come back to discuss the stay-at-home mentorship program he's working on with Coding Nomads and how you can become a part of it, and we also get the chance to answer our first listener-submitted audio question. So here's the rest of the conversation. Thanks for the idea of recording this or adding bits on, I think it's a good idea. \n\nWell, I think it's good timing, a lot of people are in sort of lockdown kind of situation working from home, not working from an office, and maybe they have extra time where they really want to learn more about coding. So tell me about what's going on. So with the lockdowns happening and me listening to the news like I guess everyone does, I've just had this feeling that I wanted to try to do something from my end to help a little, and I know it's not much and I don't have to feel like it's a big deal or anything.I just try to spin up some kind of mentorship programs for people to get the chance to use the time they're in lockdown to start a few steps on the path of getting into a position where they have more chance to work remotely or in the tech sector.\n\nFor me personally, in the work situation, nothing much has changed during lockdown because I've been lucky enough to have been working remotely already. But there's a huge change for millions of people out there in really bad situations, not being able to go to work and not being able to make the income they need to pay their debts and keep things running.\n\nIn the tech sector, there are opportunities that make it easier to get into remote work than in other industries like working in a restaurant. I work in programming education and mentorship, so I want to connect volunteers to help people in different situations take their first steps in a new direction.\n\nThis program aims to have mentors willing to share their knowledge and connect with those in need. It's about making connections and providing resources to help those less fortunate.\n\nTo find out more or apply, fill out the form on GitHub at comments.github.bio/stay-at-home-mentorship. The goal is to help students in financial need due to lockdowns who have lost work and aren't getting the support they need.\n\nIn my experience, the social network provided by the government in Austria helps prevent the situation from escalating, unlike in the US where the lack of a safety net exacerbates the crisis. It's interesting to see how different countries handle these situations.\n\nThere's not much of a safety net in place, especially in wealthy countries like the US, where people struggle to self-isolate without losing access to healthcare and income. It's clear that the system isn't set up to support people in crisis situations well.Yeah, it's nice to see people like yourself trying to come up with ways to help people out. Some of these people may be wanting to shift careers or be interested in programming, and Python is such a great language to start with, as we've already discussed throughout the rest of the episode earlier, right? We're hoping to use some of these tools. I mean, that's real Python recently had not only all the articles that are on the site but some free courses, which was kind of a neat deal. Totally, I think there's a lot, like, I mean, that's the nice thing to see also in such a situation - there's a lot of people who are trying to do something, they want to help because we feel for like other people do. And we're gonna do something useful, right? Alright. Yeah, and I guess that's just it depends on what industry you're in, what you can do, and as long as you don't have the feeling that you're saving the world with what you're doing, but have some kind of humility in understanding that it's probably not a lot in terms of the grand scale of things, but it doesn't mean it's you. Yeah, but you're making a difference, yeah, you're doing a little bit, and maybe it helps a couple of people. It's been nice, like since we launched this program. I've started it off as a simple form and went on to build a Django app for it in the Django Rest Framework API to better handle the data. Cool. Since we launched it, which was about a week ago, I guess we already got 40 mentors that signed up, and we've got, I think, 75 slots for students that we can connect these people with and give them a chance to get started on the path into a direction of doing something technical work or some design. Yeah, so it's also not necessarily limited to programming or Python. The idea is really just to get professionals or people who have some knowledge together with people who want to start on that path. And great, I think from my experience, having someone that you can speak to and being part of the community really makes a big difference in the motivation and just sticking with something and having the feeling that you can do it, you know, not just being overwhelmed with it. Cool. That's great. I really appreciate what you're doing there. That's awesome, and we have links for all that information for anybody interested in being a mentor or would like to get a little more mentorship. And again, like you said, it's not specifically just Python-based but generally technological kind of stuff. So all that will be on the show notes. That's a quick, like, so if you're interested in this at all, the idea is just if you have some skills to do that, it can provide. Are you ready to spend just an hour per week per student essentially? It's what we're thinking really just to be this person that they can check in with and that they can learn from a little bit of what's going on and ask some questions when they're stuck. That's really like what we'd ask you to provide for this, and we're gonna offer likes. I have this mentorship talks that have a lot of information about how you can mentor a person in a good way if you're interested in reading up and stuff, and we will provide you this. We provide access to content for Java and Python courses for four months for free for students and also for the mentors, obviously, and also we have this community forum that everyone is free to join and that you can use to connect with your students and help them connect with the community because I think that that's a great thing. If you feel that you get someone to a point that they feel they're part of the community where they can ask questions and they're welcome and they can keep learning, I think that's a great way to get someone started on a path of success to actually moving forward. That may make this connection, maybe that would be great. And I'm there to contact if there's if people have questions or if they want to reach out and talk about mentorship. I'm very happy to do that anytime. Are the meetings using video chat kind of thing? Yeah, it's just the media chat there. So there's information, some possible ways that you can do this in this mentorship talks. I have a lot of tools listed out that are useful for that, but essentially you're free to use whatever, and I'm not a designer myself, but we have designed on there also because it's a useful skill to have. Yeah, if someone's a professional designer, they probably know what's a good way to learn, like what's the good online resource, and they can just use that resource and whatever works best, right? And I'm happy to help someone figure that out through the documentation and also just in communication with them. Alright, that's great. So I mentioned in episode 2, I was talking with John Fincher that I was excited about setting up this way for listeners of the podcast to submit questions as audio.And then we could play them on there. Well, I have my first question from Sean Tibor of the Teaching Python Podcast, which is a great podcast if you're interested in learning not only more about Python but also about being a teacher and teaching your students about Python. We're doing a lot of that in this episode, so he had a question for us. \n\nHey Christopher, this is Sean and Kelly from the Teaching Python Podcast. First, we want to say congratulations for launching your podcast. We're really excited that there's another Python podcast out here. It's such a fast-growing language, and there's definitely room for more voices in the Python sphere. We're just really excited that you're joining us. My question is, and I guess it's for you Christopher or for any of the guests that are on your show this week, if you had to start learning Python again from scratch, if you didn't know anything about the language, where would you start or what would you do differently than what you did when you actually learned it for the first time? We're curious because a lot of our students are trying to figure out the same question for themselves about what to learn and where to go and how far to go. So for us, it's a really fascinating topic to learn about those first few steps in how to learn Python. Thanks very much, congratulations again, and we can't wait to hear more. \n\nAlright, so there's a nice question for them. So I'll post it to you first Martin, do you have suggestions for Sean and Kelly? \n\nYeah, it's related a bit to what I was talking about throughout this whole episode, I think. But what I think I would do differently is I would really look for connections in a community of people that are learning or teaching, just the community of people that are doing Python on a regular basis. Maybe even more specifically, if there's maybe I'm interested in music production with Python, I would just try to find a community that does that specific thing with the programming language and then just get involved there. Because for me at least as a person, and I know people learn different ways, but for me, it's very engaging to be in contact with people and it helps me to stay engaged and keep having fun while I learn. Just being able to talk it over with someone, I think that's what I would do instead of just trying to learn by myself online. There are different ways of doing that, there's boot camps, there's forums, there's lots of different ways, but just to not isolate much and to try to get it all by myself, just by designing people and interact with them about it. Yeah, I think that would be my advice. \n\nYes, I was thinking about that, like the forum that you were just talking about, but also Real Python has a Python ICAFE, just a neat community site which is friendly in there. Obviously, Real Python itself has a huge footprint and if you join, then there's also the whole forums and slack channels to talk to people. But there's lots of solutions out there in these sort of microcosms of the internet. It takes a little bit to learn them, but in general, when I've tried to reach out, people have usually been pretty friendly about that. It makes me think about the idea of sharing as a musician. It's so hard to take a piece of music that you've created and share it with say your family or even other people that are at your school. They may not be interested at all, especially my family, they could care less about anything I do musically. It's, \"Oh, that's nice,\" and so forth. So it's so much better to have a way to take a piece of art or something you've poured your heart and soul into, programming, to have somebody else in a similar world or even a similar level and share it with them and have a conversation about it. It's so much more useful. \n\nI find that great. I've had to start to try to do that with podcasts, and the idea of sharing this new idea with other people that are out there. I have a friend who I knew back from Arizona who is a guru about podcasting, and so I wanted to reach out to him to ask him questions. The community can be a really big thing, so yeah, that's great. If I was going to answer the question, I feel like I'm still in the throes of learning, and so I have always been a person who buries myself in a subject, so I'm gonna learn Python great.So I go and I find a ton of books. I started doing like the Humble Bundle thing where they offer a whole set of books. I start collecting lots of different things and having all those resources around me is always useful. I have always been a person who went out and found all the different Python podcasts and tried to listen up, kind of like a form of immersion. I think something that was a little missing is having a little bit more of a community, somebody to talk to back and forth as I develop and create things. \n\nOne of the things that I did initially was tons and tons of tutorials, but they were all from the book or the website, and I could share them with a handful of people, but it wasn't really my own work. It wasn't until I started to shift that thinking, thinking about problems that I have in my own life and struggles that we were speaking about earlier in the episode. It's about scratching that own itch and saying, hey, I need a tool to do this or I'm interested in data visualizations, so I want to create this. Having projects, even small ones, and having constraints on your project and building up from there is important. It just needs to be able to do this initially, and that's fine. \n\nI have a problem with perfectionism, and I don't start because of that. It's hard to break that, but you have to realize that you do have to start, and if it's not perfect, that's okay. Just get past that hurdle and keep creating. I would have spent more time building more projects and trying to make what I learned in tutorials my own. Another resource is something called Project Euler, where you solve problems and learn from the solutions in various languages. \n\nIf you're interested in a particular topic, like games, going up on GitHub and seeing open-source projects can help. I wanted to create a contact management system, kind of scratching my own itch, and learning from other tools that exist. Immersion seems like a good way to get into something, as motivation is a huge factor. Learning something new is about putting in the time and focus. Motivation is key, and as long as you can keep that high, you're on a good path to keep learning.Yeah, I thought about another thing that I used when I was actually learning. I would find these apps for my phone that were really snippet-based Python things. Like you said, I would be happy to finish these little badges if, like, okay, I learned loops and I learned this. Checking those things off. So, Uncle links to a lot of the resources. This episode is gonna be long, and links, which is gonna be awesome. So please check that stuff out. Everything, yeah. It's basically all that stuff at realpython.com/podcast. You can see all the links. \n\nOne thing that's come up is if you want to be able to jump around in the episode, we started publishing the episode with time codes. So you can actually go in, and if you have a player, I use Overcast, but there are all these different players now that have the ability. You can tap on the time code, and it'll jump to that subject in that area. I have chapter markers, and some people don't have a tool to listen to, so we have been publishing it on YouTube also on our YouTube channel for Real Python. That has the time codes in the notes, so you can actually jump around if you want to repeat something or you want to go back and listen to something. \n\nThat's awesome. Oh yeah, which kind of takes a little more time, but I think it's worth it. Well, I really want to thank you for coming on or actually coming back on. Oh, you're welcome, and I'm excited to learn more about your mentoring project. It's great. So I'll have to keep in touch on that. Yeah, I hope it's gonna help a couple of individuals in this situation and just maybe make me a bit of a tighter net in the programming community. Maybe also connecting to a bunch of other people that are not yet in there. \n\nGreat, and remember, if you have questions out in the audience and you want to send them in, we'll play them on the podcast. We're talking about eventually doing some panel shows and answering those types of questions with a wider group. So thanks again, thanks to you as well, and have a nice day. All right, bye. I want to thank Mark Royce for being my guest this week, and I want to thank you for listening to the Real Python podcast. Make sure you subscribe to the podcast in your favorite player, and if you like the show, leave us a five-star rating and a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey. I look forward to talking to you soon.\n\n[Music]\n\nThank you. \n\n[Music]",
    "ZvypJ5OTeXM": "Welcome to the Real Python Podcast. This is episode 7. Do you want to learn more about async I/O in Python? How about with an example where you can see and hear events being triggered in real-time?\n\nThis week, I talked with Wikus Longa. He has created a talk for PyCon 2020 about using async I/O with music. In this talk, he shows examples of coroutines gathering the event loop and events being triggered to create a live piece of music. \n\nWe talked about his role as the release manager for Python 3.8 and 3.9. He also provides background on the origins of his very popular uncompromising code formatter, Black, and the types of problems it can solve inside an organization. \n\nWikus previously worked for Facebook, which is where he started Black. He talks about recently moving back to Poland and discusses his current work for EdgeDB, building a new generation object-relational database.\n\nLet's get started. \n\n[Music]\n\nMy name is Christopher Bailey, your host. The Real Python Podcast is a weekly conversation about using Python in the real world. Interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nWelcome, Wikus. I was wondering if you could give us a little bit of your background.\n\nCool. I'm happy to be here. I'm the release manager for Python 3.8 and 3.9. Currently, I work with all sorts of stuff for Python, but mostly typing-related things these days. Making sure that you can actually check your program and document and enforce types. The latest PEP that I've been working on for Python 3.9 is definitely the usability PEP. I'm getting paid by EdgeDB to work on their product, which is a really good relational object database that is a more high-level approach to our database than regular relational data stores. However, it does give you all the guarantees that traditional relational data stores give you, which NoSQL databases really do not. It is based on Postgres but gives you a more high-level query language for it and integrates craftily. Essentially, it is like a web framework integrated inside your database for you with migrations and all sorts of niceties. So, feel free to try this out as well.\n\nYeah, like I don't know what else you want to know. I am based in Poland at this point. I used to be in the United States for quite a bit and in Vancouver, British Columbia before that, working for Facebook. That's behind me now. I am kind of sheltered in place in Poznan, Poland. That's western Poland, pretty close to Berlin, in fact. Just looking at the map on that. I've talked to a couple of people in that area of Europe. One of the authors is from Oslo, and then one of the video course creators is down in Odessa, Ukraine. I was just kind of looking at the map and based on time zones, that's pretty cool.\n\nYeah. When did you move back to Poland?\n\nWell, it was a two-step process, actually. Back then, being in the Bay Area was very good to me. I enjoyed it immensely. But it kind of dawned on me and my wife that if we actually want to spend some significant time with our parents, we really have to go back right now and not in ten years. Our son is still a nice grandson for them, he's still a kid and whatnot. It was the good time, so we decided at the end of the school year to just move to Europe. But Facebook wanted to keep me around, so I decided that instead of just quitting and quickly moving, what we can do and we did was to do this month-long road trip coast-to-coast from the Bay Area to New York, across all sorts of national parks and whatnot, visiting quite a few of our Python friends as well, which was amazing. People that live off the beaten track, and we still managed to visit them in their houses, which was really nice. \n\nYes, we did that. Then my wife with my son moved directly to Poland, too, while I worked for Facebook for another six months from London, trying to set up this remote gig for myself for a longer period of time. But ultimately, that fell flat. If Facebook corporate was not willing to have a full-time remote worker from a different time zone than everybody else. So, I simply quit. I decided not to have this kind of stressful situation by Christmas. So, for Christmas 2018, I was a free spirit. That took me possibly nine months of just decompressing and dealing with being a dad, renovating the house.Taking it easy until approached about working on the HDB project sounded interesting enough to grab my attention. The product is written in modern Python 3/8 with async IO and typing, showcasing the best of Python. The user perspective of the product is very promising, prompting me to set up a company and work together for over six months now.\n\nThe database is rooted in Postgres, which makes sense in 2020 to leverage existing knowledge rather than reinventing the wheel. The code base provides valuable experience, allowing us to focus on usability and integration. HQL, the native query language, offers more expressiveness compared to GraphQL, allowing for advanced and expressive queries.\n\nComing from a SQL background, the advantages of EdgeQL include thinking in terms of high-level schema with objects, links, and properties. This approach eliminates the need for transactional DDL statements and provides optimized queries. EdgeQL is more efficient than traditional ORMs, as it doesn't map directly to native objects, resulting in better performance.\n\nThe target market for EdgeDB, a powerful database similar to what powers Facebook, includes those looking for a robust database solution with advanced query capabilities. It offers a write-through cache to MySQL and a better query language compared to traditional options.So, it was a database created from scratch. It was also building on building blocks that were already there, but again, having a graph database, an object database where they have objects and associations between them allowed regular programmers at Facebook, of which there are thousands, to write very expressive queries without worrying whether those queries are going to kill the database because they're going to take two seconds to complete every time.\n\nIn the products that they were able to ship due to this, like to this day, just work and people don't even think about how complicated the things that happen are. Any two Facebook users can just talk with each other essentially in real-time, comment on each other's posts at any given time, and it just works almost real-time. So, pretty much, this is a globally distributed database, and I've seen this technology work. I worked on the cache invalidation for it. It was a tricky part for quite a while, and I always wished for a product like this to be available to the small guy, to somebody who doesn't have a globally distributed system but still would like the expressivity.\n\nYou would still like for even a smaller system to just be able to not worry about whether the query is too advanced, should I do this in Python instead, should I denormalize my schema, and those kinds of silly questions that you should not even think about if you are not having petabytes of data in your dataset.\n\nThis product really is like we're thinking of it as a dot to be stuck, so it's like Postgres, you understand it's good, but just a powerup for this to the point where you're no longer thinking of it as a relational database because what you're operating with are objects that have links between each other. You mentioned that it has a lot of the advantages of Python 3.8 and also async IO in it.\n\nThat kind of brought me to the idea of your talk that you were going to be doing at PyCon. I guess you actually are still doing it, but you're going to record it in advance and put it on the PyCon YouTube channel. Yes, I'm actually recording it as we speak, so I'm in the process of fighting with OBS to make sure that you can see both my face in the presentation. I'm stubborn, I'll get it to work, but so far, my presentation is flickering, it's frustrating to me. I already gave it two times today, and every time, something is wrong, so I'm going to have to give it the third time, have it really well oiled and practiced at that point.\n\nIt's kind of an interesting presentation. I was very proud of it when I was working on it because it is not your typical PowerPoint slides and a guy talking. There's hardware involved, actual audio done in real-time, some small kind of live coding involved. It is kind of different in the video because you can make a few allowances that are not really hard if you're giving the presentation live, but it's still essentially the same thing.\n\nWhat I wanted for people to perceive in a live setting is that, hey man, from scratch, we're doing this thing, and it makes sounds like as we are here, and you can see it happen, there's some randomness to it, so you know that the thing that you're watching is unique in the scale of the universe. It is an interesting presentation in that case. I found it to be just a more interesting way to introduce async IO to people, to maybe get people hooked on it because it's very easy to just draw graphs with web requests and tell people, hey, you can handle 10,000 requests a second with this thing.\n\nBut if you are actually showing people sequencing with async IO, there's one drum here and another drum here, there's a baseline, and yet some kind of overtones on that same baseline, and all of that actually you can hear happen in virtually real-time, that speaks volumes to people. They can actually perceive that, oh yeah, this is actually cool that would be impossible without async IO. So, once you already get some of the background on it, but maybe from a high level, just introduce what the talk was about to give them an idea.\n\nFor the longest time, I did a bunch of teaching on async IO. It is a thing that changed how I program Python. I use async IO even for applications that don't involve networking. In fact, Black, the formatter, does use async IO scenarios in it.Wow, it makes sense because it's just like a very good sub-processing API. You can actually run multiple subprocesses very easily with async IO and have the results of those subprocesses gathered for you. Even if that's not what you're working on, I think I can still help you. What I had trouble with is getting through this stage of async IO with people. When you first introduce this concept, it's way different than anything else you've seen before in Python. With coroutines, it's like calling a function doesn't do anything, you have to await on it. The more I thought of examples of how async IO works, the more I realized that even if you have a graphical console showing things happening at the same time, it doesn't make people suddenly click and understand what they're seeing. \n\nI am a hobbyist musician, so I had this idea to make coroutines push buttons on my synthesizers or play sounds through MIDI. You can actually achieve this by sequencing hardware synthesizers with simple coroutines. The presentation demonstrates production-grade sequencing, which you could easily use in a live act without worrying about it failing. It's based on asyncio, which is well battle-tested and used in production in many corporations. \n\nI think it's admirable that you're struggling to explain this concept to people in different ways. Most tutorials on async IO use the example of time.sleep, which isn't very practical. Async IO involves waiting for specific events, like networking through MIDI, which is a simple protocol. Teaching async IO can be confusing, especially when it comes to concurrency versus parallelism. \n\nWhile working on the async IO and music talk, I felt constrained by the time slot for the conference. I was rushing through concepts because of the limited time available. It's challenging to cover both MIDI sequencing and async IO in a short talk. I realized that splitting the content into separate videos might be a better approach, assuming some level of knowledge in each. This way, I can delve deeper into each topic without rushing through them.Okay, where I actually take my time and introduce async I/O in a slower pace, actually going through the motions of explaining why this is a good idea and later showing this is the event loop without any coding yet, just becoming familiar with it. Then, introducing coroutines and just playing with them as a construct that we don't know how it works but we just learn to use it right. Later on, just have an episode where you show it under the hood and explain how this magic actually comes to happen, then connect the dots increasingly while the async I/O and music talk is really kind of starting already from some familiarity level and just allow ourselves to go deeper in this direction.\n\nThe reason why I'm kind of doing all of this intro for you now is that while working on those other videos for HTV just introducing async I/O, I found this amazing analogy of concurrency and parallelism. The analogy is the analogy of a bartender. A single bartender can only produce one beverage at a time, however, they can take care of multiple customers at the same time, so that is concurrency without parallelism. If you wanted parallelism, you would need to have multiple bartenders, but still, you are achieving concurrency already. You have multiple people at the bar, everybody's served, everybody's happy. This is exactly what we are achieving in async I/O with an event loop on a single thread. We are never doing more than one thing at the same time, however, we are dealing with multiple things at the same time.\n\nI think about a restaurant example also when I was thinking about how I could try to create a question around it. The idea that we're normally things there's having like if you had a waiter that received this order and then went to the kitchen to have the kitchen create it, if the waiter just sat there until the kitchen completed it and didn't do anything else. That's pretty similar. In the idea that they could have this spinning ticket thing that you'd see like at a diner or something like that, they can put these multiple events in there and then as they have time to work on them, they could grab the next one, and the idea of asynchronous nests of that.\n\nYeah, because some things you can have pre-computers, you can have a beverage that is already there, you just take it out of the fridge and you can present it like it's the customer right away without even hitting the kitchen, so it's actually a pretty good analogy as well. So, I was thinking about the event loop that is the async I/O loop that you're setting things up inside of, and I wonder if in some ways it could be similar to a game loop. I know you're into games also, I know it may be different in say something like Pygame or Arcade, which are popular Python libraries for that, but would you agree that that's a potential similarity in there?\n\nIn fact, it all goes back to the 80s, to the Select statement, essentially all of it is around the fact that you have multiple things to deal with in terms of input and output. Now, with networking and online gaming, there's even more. For a single game, there's multiple things that can happen in each frame, but for a game, the event loop that you're gonna be using is rather different from networking event loops. In a game, you have this concept of a tick, you want things to happen in consistent timing, you want 60 FPS but you don't want it to just float all the time because if it does then it is not a great experience for people. And if you allow this graphically, you will have to compensate it in different ways so that things don't just magically speed up or whatever. In fact, there is always a tick, especially with online gaming, you have to agree when a given thing happened, especially with network latency.\n\nYou know, this is how people actually survive playing online games together when there is latency because otherwise, a simple ping will take you multiple tens of milliseconds, maybe over a hundred milliseconds. How can you play an action game with somebody, how can you play an FPS? You'll never know who shot first, you'll have to ask George Lucas. The tick is very important there.So it's kind of like a harder loop to write because the amount of things that you agree to put in a single loop iteration is finite. You cannot just decide to have an arbitrary amount of things to execute. In fact, there's a fascinating series of posts by John Carmack about this. One of the surprising things that he recommends for game development is that your loop events should always compute everything with every iteration and then you just throw away the things that you're not using at the time.\n\nIt almost sounds like a toss waste ball but now it's consistent. So it is less likely for you to get surprised when things get really busy. Within the most important and emotionally engaging moments in the game, you are less likely to disappoint your user because you were ready for this all along. You were computing all of this heavy factor all along. That's impressive. It goes against everything you learn from software development. Gaming is efficiency-wise, but it's almost like a different industry in this sense. There are different trade-offs and you're optimizing for a different kind of thing.\n\nI was thinking about that, and one of the things as I was watching the previous one you did on code, I learned a lot about this concept that as you create these coroutines and gather them, it's like pre-processing or staging it to make those events ready to go so they can be triggered. Maybe that's what's unique about it, am I right in my explanation? Does that make sense?\n\nWith async IO, the thing you're supposed to get at some point is that while most of the time you're writing a wait and calling a coroutine as if it were a function, you can actually create coroutines by calling them and just store them for a while. You can pass them somewhere else, and someone else in a different place will await them because they're first-class objects, just like regular functions in Python. This enables you to set up multiple coroutines and call them so they're ready to go but not starting yet. Only later you gather them so they go at the same time, which is immensely useful. The returned shape of those multiple coroutines can be exactly what you need at a given point in time. \n\nYou can make them wait for tasks, use gather, or put a thing as something to be run in the background. There are multiple patterns you can use for this, all based on creating a coroutine by calling it, making it ready to go. But without awaiting, nothing will happen. You can compose using different aggregates, like gather, which is simple and visual.\n\nThe example you're creating by another definition is a truly synchronous thing, like a sequencer following the clock from the drum machine, hitting events very specifically at time intervals. MIDI being serial and only one event at a time, but still cool. You can change the tempo, and it's a synchronous thing.\n\nThat was an issue I had from the start. If it weren't for talking with Glyph, the original creator of Twisted back in 2000, who told me not to do music with Twisted because the event loop doesn't have real-time guarantees. You don't know if you put too many things there, things will go out of sync. MIDI is a sync protocol, so as soon as you send a message, it's supposed to be played on the receiving instrument. There's no scheduling, no delays, it plays. It's a pipe sending one message at a time.So how can we play with 128 notes of polyphony as my stage piano allows? How is this possible? Well, if you send 128 of them within one microsecond, then effectively what a person is going to hear is all of those notes pressed at the same time. The resolution you are looking at is the important factor. If you are not trying to synthesize audio in real time, then you would need tremendously higher resolution, like 44 kilohertz or even higher. It would be hard to accomplish with Python, but we have plenty of headroom for crazy sequencing.\n\nThe amazing thing is that there are plenty of hardware and software sequencers now, like digital audio workstations, that cater to different users. There's even a Polish company called Polyend recreating the traditional 8-bit tracker. They are producing a hardware synthesizer that is a tracker, sampler, and can track MIDI hardware. Whatever suits your preference, you can have it.\n\nBut all of it falls short compared to the power of a programming language like Python. With Python, you can do sequencing that is unheard of in those simplistic sequencers. You are leagues ahead of anything else those sequencers can do.\n\nI was talking with Thea Flowers last week, and she mentioned an environment called Orca, a visual interface using letters to create MIDI generators. It wouldn't be a stretch to create something similar in Python and have control over the whole stack, which is pretty cool.\n\nMy original plan for the talk was to do a take on MIDI, but it didn't go much further. At some point, I had this idea of adding a server on top of the sequencing, making it more powerful. You could have multiple people sequencing synthesizers together, creating something bigger than imagined.\n\nIt would be cool to have this, but it's hard to achieve everything in 45 minutes. I believe I got far enough to show that this can evolve into something bigger in the future. You can still play with it and create something more significant.\n\nI got to try out your code with a circuit, and it was pretty fun. I haven't delved into the MIDI library you're using or UV loop, which you mentioned on a previous podcast. I was wondering what the advantages of using that library are.The event loop in async I/O to a large extent is our reference implementation. Its goal is not to be the most performant event loop in the industry, as that would be a goal it cannot achieve just by being implemented in Python. However, it serves an important goal by being the reference implementation because it shows the expected behavior and allows us to test the entirety of async I/O with an event loop that is easy to debug if things go wrong. \n\nMore importantly, it also works in practice. There are all sorts of other advantages to it being pure Python, but when you actually move into a space where you are running async I/O in production, you no longer care about teaching async I/O with our reference event loop in Python. Now, you want one percent available performance. \n\nRiding a very performant event loop is surprisingly tricky, so there are not many implementations that are very battle-tested. One of them is libuv, which is used in Node.js and these days also in Gevent. Having this technology already available, Yuri Sullivan thought, \"Hey, could we actually make this power async I/O?\" He made it work by connecting libuv with async I/O, serving as an interface of an asyncio event loop. By importing UV loop and calling install on it, you can replace the reference implementation pure Python event loop in asyncio with a version that is way faster, allowing you to use it in production. \n\nFor me, in particular, I probably didn't even have to use this for many purposes, but what I was absolutely petrified by and afraid of the most is that in this talk, it's not just PowerPoint and me. It is really live running code on stage in front of people. I gave this talk at multiple conferences, and that was my biggest worry always. It would be super embarrassing if what I had to show them didn't work. \n\nYeah, and usually those things tend to happen right in their own moment where your laptop starts running some upgrade or you're running low on disk space, or it starts throttling because your battery is 20% or lower. There are just multiple bad things that can happen. So I wanted, for that crucial piece of code, the event loop, to have the fastest available so at least this one variable goes away, and it did its job wonderfully. \n\nHTTP also uses it, and it's part of the reason why you can have a database server with good performance written in Python. That's cool. This is kind of a side question. I don't know if you're familiar with it, but I saw some basics about it. MIDI is actually finally coming to version 2.0. Yes, I looked at this. It's at the same time I'm very excited about it. Like you know this already, I first the Roland kind of keyboard controller that ships with it, and it shouldn't even be very hard to just adopt whatever we're doing for MIDI 2.0. \n\nIt is still very much in the same spirit, including really like part of MIDI 2.0 is the old MIDI, so every MIDI 2.0 hardware will understand MIDI 1.0 messages as well. All of this is pretty cool, but at the same time, I had this kind of impression when I last looked at it that it doesn't really matter what the spec says. What is actually going to matter is what the manufacturers do. \n\nThe reason why I mention this is that even in the two pieces of hardware that I'm showing during the talk, which is Novation Circuit and Novation Mono Station by the same manufacturer, you have differences in the MIDI implementation. So it is not exactly the same, and then you want to interface with your Moog synthesizer, and it's going to behave differently. The point I'm trying to make here is that again, it is interesting, but it's kind of hard to say what we should be doing with it now without the hardware being there already. \n\nI'm not part of any major hardware manufacturer, so I don't really know whether this is of any use for me. One example why I'm not terribly excited by this is that one of the things that MIDI 2.0 is solving is that control change messages in MIDI 1.0 are 8-bit. So at best, they can give you 128 different values, which may seem like plenty.Right, well not really because if you have a knob that is analog on your synthesizer and you suddenly quantize it to just 100 steps, you will audibly hear the steps if that knob does something really drastic, like you might have resonance on your filter or something. MIDI 2.0 solves this problem amazingly. But we already did have a solution for this in MIDI 1.0, which were another group of control change messages that work in tandem. So instead of using one byte, you were using two bytes. Using two bytes is already just bumping the possible number of values enough for the quantization not to be heard anymore. Yet most hardware synthesizer manufacturers ignore this and don't implement it. For example, the high-level Moog synthesizers do, like the Subsequent 37 or even the Voyagers. They can do all those lush sweeps on the filters and sound amazing, and it's MIDI cool. But the innovation bits that I have ignore this, so there is just no way to control it.\n\nWell, with what I'm trying to say, use the full resolution, exactly without hearing the steps. You know, we didn't discuss it much, but the whole idea of a Musical Instrument Digital Interface of MIDI was to get all these manufacturers to agree on a standard back in the eighties because every company was making their own different thing. Companies like Sequential Circuits and Moog were using some analog tools like control voltage. But in general, all these things are literally a keyboard with a very similar human interface. They couldn't talk to each other, so it was kind of neat that they actually did form some form of a union and create this MIDI Manufacturers Association. At the time, I agree that to a large extent, that was successful.\n\nThe fact that you actually can have a third-party digital audio station like Ableton Live and replace it with Logic whenever you want, and you can just go on a Windows box and try something different like Cubase and have all the hardware work exactly the same with you, so that is the dream that has been fulfilled as one of the protocols that were really well implemented. The problem, though, is that the manufacturers of those digital audio workstations and whoever wants to fully integrate with any piece of hardware will find that there is a basic set of commands of many MIDI messages that everybody agrees on what they mean and implement them exactly the same. Even things like which channel do you put percussion on and what do you do with the high channels is surprisingly weird. If you actually want to have the full MIDI implementation for a given piece of hardware, you have to get their spec sheet and see which are the control change messages that they use for a given feature.\n\nI used to be in the habit of going to the back of the manual and looking at that chart if they did a good job of it because it was fairly readable if you knew the standards. So I wonder about that too with MIDI 2.0 if they'll embrace it and look at more channels and all these other higher-level things. When you get down to it, it's always a meeting of the mind. That's the one thing that maybe we don't know yet, maybe they actually did the right thing here and it's all going to be fine. What I wanted to see when they announced it was ready wasn't just a Roland keyboard that is now disconnected from the world. I wanted to see this declaration of all the manufacturers going full in on MIDI 2.0 and releasing new models that have MIDI 2.0 and talk perfectly with one another. And then I'd be on board with that, make sure it works. But now with a single Roland keyboard, I'm like, we'll see when we have at least three manufacturers who implemented the same.I wanted to talk to you about your project Black. I was wondering what you could tell me about the origins of it. Back in 2018, it was rather unorthodox to start a new formatter for Python, considering Python has been around since 1990. What made you think anybody needed a new formatter in 2018?\n\nAt the time, I was working for Facebook, which employs many people with differing opinions. Despite this, there was a focus on the most important things at all times, leaving the nice-to-have things for later. Code reviews often got derailed by discussing trivial things like missing spaces, commas, or the number of blank lines.\n\nWe tried adopting Google's C++ style guide, but found it challenging to implement company-wide. The tool is highly configurable and approaches formatting as a dynamic programming problem. It aims to minimize penalty scores for a given formatting based on user-defined configurations.\n\nWhile this approach works well, it can be challenging to understand why a specific formatting decision was made. Users can adjust penalty numbers in the configuration, but this may lead to inconsistencies in formatting across the codebase. Most users weren't seeking perfect formatting, as automated tools inevitably fall short in understanding symmetry and aesthetics.\n\nIn conclusion, achieving perfect formatting with an automated tool like Black is a lofty goal that may not always align with user expectations.Right, so instead, what people would rather see is just some measure of consistency. Even if it's not perfect, at least you know why. Right, so you can just kind of shrug your shoulders and say, who cares, let's move on.\n\nIn fact, we've had a more ambitious kind of project at Facebook for a while, and that failed. So, at some point, I just thought in 2018, I would like to have as a birthday present for myself, just for my team and maybe a few other teams, just the simplest formatter I can ever write. That just almost kind of looks like JSON, does the same thing all over the place, regardless of what brackets pair that is, it does the same thing everywhere, and just run with it. Weirdly, that was the right time for this for me, but at the initial alpha I pulled off in like six weeks, I think it's still in the repo history so you can follow that. But I obviously missed my birthday because as a programmer, you're not supposed to hit your deadlines, it's just the rules. I don't make the rules.\n\nBut what I did actually make is Pi Day of 2018, and that was a cute date. You know, I managed to just release the first alpha then, and by the end of that day, I had like 500 stars on my repo. Wow, and I didn't understand what just happened. I didn't understand why. I did have this manifesto style sort of readme that actually explained why I wanted to have an opinionated formatter that makes everything look consistent, and how this makes things better. And in a very short time, I had plenty of people coming to me saying, you know, if you only change this one thing because it doesn't work. And sometimes I would listen to them, sometimes I'm like, no, that's literally why I wrote this, this stays. So we have conversations like this, and something I've heard like, hey, Virtual NF is formatted with black. Oh, like PI test is formatted with black, and suddenly bigger and bigger projects adopted it. And finally, I kind of bit the bullet and said, hey, Facebook, are we doing this or not? And we reformatted 20 million lines with black. You know, we just did it over the weekend. Some people, I'm pretty sure to this day, I don't work there anymore, like to this day, probably are not happy with everything that black is doing. And I acknowledge they're probably right, you know, they're smart people. But what I've heard later from most users actually is how happy they are not to have this conversation anymore about, you know, oh, you should do this in a different way, you should format this in a different way, especially the continuations, right? Like, you know, when you have the body of a bracket pair inside, you know, it's like, what do you do with that? So with black, you always do the same thing.\n\nWell, soon enough, there's gonna be the 10th anniversary of me getting my commit bit to Python, right? There's multiple PEPs in my name in the language, and I've been the release manager for a while now. And yet, yeah, there's very few people who acknowledge this to any extent, but what everybody knows before and what so many people thank me for is like, hey man, you solved so much heartbreak with this tool for our team. We use it now, things are easier. So I'm like, I never expected this to become anything more than my local tool that maybe a bunch of friends are gonna be using. You know, it became a big thing way faster than I ever expected it to, to the point where now I'm kind of terrified to declare it stable, because I understand stable as being a tool that will not screw you over and change its formatting significantly later, right? Because one of the points of black is that, hey, I don't want part of the file to be formatted like this and another part to be formatted way differently, you know? So it doesn't support, as a design decision, partial formatting. It's just, you know, either your entire file is like this or it's not at all. So that is kind of a burden in the sense that we need to be really careful about changing the style later on, even if those are good changes, even if those are fixes, they're gonna be noise for people, they're gonna be annoying. So, yeah, at this point, there's a bunch of acknowledged problems that we have on the issue tracker that we need to fix before we declare stable.\n\nAnd as soon as I'm done with this async IO talk and OBS and a bunch of other things related to this quarantine and everything else, you know, I have this on my list. I feel the responsibility. In fact, Sentry did sponsor black with a grant of 5 grand that was a super nice move on their end. I never contacted them for it, you know, I just received this out of the blue, it was awesome.We sponsored a bug bounty for it. We have another one in the works, and this time it's a bit more substantial than the first one. Having money involved is helpful, but we really need time to do it and be emotionally ready for it. This is hard in the current world. Some people are pushing for just declaring what we have now stable and being done with it, but that is not my ambition. I want to fulfill the promise that now that we're stable, we won't make any crazy changes. There may be some annoying changes, but they shouldn't be significant. There won't be a complete reversal of any previous decisions, but there are some fixes that need to be made, which may cause some churn.\n\nCreativity is hard right now. Finding the extra energy to muster it is a challenge. As I'm trying to create new courses, I understand the many things you're juggling as the release manager. The most important thing for a release manager is to remind everyone of the time and what needs to be done at that moment. Users of Python depend on the release cadence, so it's crucial to release at the right time.\n\nThe job is harder now with the current world events. The schedule was set up to finish work at Sprints after PyCon, right before beta. Beta is a self-inflicted freeze where we stabilize the release for the release candidate and the final release. Missing the beta deadline means waiting another year, which delays usability for users. Annual releases work better with human brains, so the release cycle was changed to a year. Missing a feature means waiting another year for it to be usable by users.\n\nThe team is adapting to not having the PyCon sprint by continuing the language summit. Anthony Shaw asked how the team is adapting to not having the PyCon sprint, and this is one way we are still engaging.Right, so the language summit is a very important event. I'm organizing this with Mariotta for the second time now. The first time was a challenge because it was our first time after Barry and Larry had done it for many years. With the current situation, we felt we could easily cancel it along with the rest of PyCon, and people would be fine with it. However, canceling it would be bad for the project. We had already invited people to speak on certain subjects at the language summit, and canceling it would mean we have no forum for those discussions. It's not just core developers, but also representatives from external projects like Beware and other interpreters.\n\nI felt bad about giving up on this, so Mariotta and I discussed it and decided to make it an online event. It will now be a 2-day event instead of the usual single full-day event to accommodate different time zones. We wanted to make it inclusive and productive, considering participants from Australia, Eastern and Western Europe, and other places. We split it into two days to make it more manageable and avoid an eight-hour Zoom meeting.\n\nDay one will be friendly towards the US and Europe, while day two will be friendly towards the US and Australia. It will be a challenge for me as day two starts at 1 a.m. for me, but it's important for the community. There won't be sprints, as those are easier to organize, but for the language summit, we needed talks prepared and discussions with participants.\n\nMost people reacted with enthusiasm, which was encouraging. The team is used to working online, but real-time connections are crucial at times. I pushed for dedicated sprints every year, but they were canceled this year due to travel restrictions. The language summit will happen tomorrow, despite the current situation. The beta one is on schedule, regardless of the circumstances. Industries depend on Python, so there are higher responsibilities at play.It's super important in data science, AI, and machine learning now, especially given the global situation. You don't want to cause any stagnation. Maybe we'll have a release that is a bit more laid back in terms of new features. The reason the build may be smaller than usual, but it will be there. There are already implemented things waiting for our release, so beta 1 is not shifting. It will be shipped as planned. Of course, there have been situations like with 3.8 where not all releases happen on the scheduled day. Sometimes things happen, like someone being sick or on vacation, or someone checking in something that breaks everything the day before.\n\nSome leeway is allowed, we're not real-time scheduling here. However, we'll do our best to adhere to the schedule as written in the PEP. \n\nAnother quick question is how did you get involved with becoming a release manager? The group of release managers is small, and it's not a role that is assigned very often. I'm aware that I will be the release manager for Python 3.10 as well. We should be looking for someone to shadow me with 3.10 so we can have a new release manager for 3.11. \n\nThere are certain expectations for release managers, the most important being that you won't disappear midway. You should be someone who has already contributed and is known for your work. You gain a certain amount of trust and power in this role, with admin rights on GitHub. It's also a responsibility for how you deal with your own data and hardware. My experience with Facebook where care was important professionally trained me for this role. A release manager doesn't have to code much but needs to decide what to do when things go wrong. You can either fix it yourself or decide if it's a breakage that should stop the release. If so, you can either postpone it or revert the change, which is a heavy decision.Right, you also don't want to overdo it because then everybody hates you. Just reverting their stuff all the time because they broke something that is not actually that important in the grand scheme of things. For example, introducing a memory leak in the alpha stage. Yes, we should fix it, but maybe it's not so important to just remove somebody's important feature just because of that. So, there's a certain amount of judgment that you have to do every time and to make that judgment, sometimes you have to dive into the C code and see, \"Oh yeah, okay, I see where this is going, at least.\" So, just a certain breadth of your Python experience that is expected, I guess. \n\nYeah, but how I got chosen and not somebody else, like who were the other candidates and what that was like, you know, that I will never know. Maybe I don't want to know. I actually decided enough. But what did happen was that at some point, I just received an email, just casually like, \"Hey, we're thinking of a bunch of people for this, you know, like, should we put you on the list for that or not?\" And I thought about this for a while, and I'm like, \"No, because you've never told me what that means. You never told me what is involved.\" And they were like, \"Okay, so you passed the first test. I'm now, like, you know, we're gonna tell you and then you'll decide.\" So, I kind of had a few conversations with Larry Hastings and with Mythili and Barry, so I think, and they essentially all told me that, like, you know, it's just annoying work for eight years for free. And I thought, like, \"Awesome,\" and here I am. \n\nI have just a couple last questions. These are kind of like repeating questions that I try to ask everybody who comes on. The first one is, what are you excited about in the world of Python? This could be an event or coding tools or packages, just something that you're excited about that's happening in the world of Python. \n\nWell, so first of all, I come from this kind of world where I kind of connect a bunch of things and maybe they do a thing, maybe they don't work, and then you kind of beat at it until it actually works as intended. So, kind of less theoretical than most people maybe, but at the same time, you know, I do have some interest in this kind of composability area. And I always was fascinated by what Python actually is. Like, what does it mean for something to be Python? If you started a new project and just put it in the browser and just call it by, you know, some Python variant, what would it need to do for it to still be Python? What could you strip for it to be absolutely like, \"Oh yeah, it's kind of a new language, kind of Python-like, but it's definitely not Python.\" But what could you strip and still have it called Python? \n\nAn amazing example of this is CircuitPython, or in general, like MicroPython. So, a project that runs on hardware, which is amazingly close to what we understand as Python coding on the big machines. CircuitPython, in particular, is cool because it is a variant of MicroPython that you can just plug in via USB, and it just becomes a drive, and you can put files there. It will restart your device, and you can just run it right away. Yeah, so the growth of CircuitPython is something that I'm really excited about because, of course, the talk that I'm just recording and failing with OBS, ME OBS is Async I/O and music, so kind of sequencing MIDI with Python. \n\nSo, obviously, I'm thinking of packaging this somehow and just, you know, kind of using it in a hardware fashion. And in fact, what I did first thing in the morning yesterday was to order both modules of Tii's new company Winterbloom, which are Eurorack synthesis modular synthesis modules that you can reprogram in CircuitPython. And once I receive them, I'm rather excited to try out the things that I cover in my talk just to put them in actual hardware where you don't even have to start your laptop to know that, \"Hey, I'm doing music with Python now.\" So, that's one thing I'm excited about. \n\nThe other thing that I'm excited about, and that's actually really fresh, is Starlette. You know, just for the kind of leading example of the videos that I'm doing for the HDP YouTube channel now. Like, I was like, we really need some small web app, and I'm gonna show the connecting bits with something as you mentioned, smarter than just I'm sleep, right? Because I'm sleep just feels off. It's like, this is useless. This doesn't look like a real thing, right? So, I wanted something to be kind of nicer than this, and I started playing with Starlette, and it kind of feels like the early days of Django all over again. Like, you know, I have all the fields. It just feels just right. So, if you haven't tried Starlette.I highly encourage trying Circuit Python. It can be a lot of fun and you can progress quickly. While it is opinionated, it is also pluggable, allowing you to replace parts as needed. For example, you can use HTTP for the back-end database, but you can also use Postgres if you prefer. \n\nI'm pretty excited about Circuit Python and Starlett these days. If you had to start learning Python from scratch, what would you change in your approach? It's hard to say what I would do differently, as my discovery of Python was quite random. I stumbled upon Python when the Ruby installer failed on my Windows XP. If the Ruby installer had worked that day, we might not be having this conversation now. \n\nI found practical projects to be effective in learning Python. Even with little knowledge, you can accomplish something worthwhile with Python. Practical projects lead to better retention of knowledge compared to just going through tutorials. I agree with the idea of creating projects that solve real problems. \n\nCircuit Python allows you to do impressive things even with limited Python knowledge. You can create projects like LED displays or plant watering systems. It's not difficult to create something impressive with Python these days. In data science, you can easily draw graphs from a CSV file and share your findings with others. \n\nWhen I started contributing to Python, I realized that some things that seem easy from a distance are actually quite complex. One example is the absence of a do-while loop in Python. While it may seem like a simple addition, there are challenges in implementing it due to the language's significant indentation. \n\nOverall, there is always something practical you can do with Python, regardless of your level of knowledge. It's important to dive in and start creating projects to gain experience. Despite encountering challenges in Python, there are always solutions to be found.And it was very quickly proven to me that there are many reasons why we cannot just approach problems where, if you don't know the entire context, was probably something that I was doing rather badly at first. I had plenty of solutions, and the closer you looked, the more you discovered that things are hard. The longer you're at it, you also value the boring parts the most. \n\nThe biggest innovation of Python 3 was actually something that a lot of people hate Python 3 for. But the 10 years of absolute stability of Python 2.7 was an amazing time for Python developers. They had a language that they could run with, knowing that the language is not going to significantly change under them and become incompatible suddenly. There was Python 3, which was already incompatible, but for Python 2.7, they were golden. There were no 2.8 or 2.9 releases. This actually taught us a bit that maybe even in Python 3, we should be way more gradual about changes and way more conservative.\n\nThere were proposals to remove dead batteries, and I agree that some of them are bad practice and should be removed. But for others, there may be a new, better way to do things, but why remove the old one and break a 10-year-old program? There's little reason to do so. The respect for backwards compatibility is something that I'm learning slowly, especially in a language like Python where you don't really have a compiled artifact that you can keep running even if the interpreter runs away from you and looks different later on. You run on the latest interpreter, so it's better to accept your old code.\n\nThat was probably one thing. I don't know if that satisfies your question. It does. It's a different take on it, but I get where you're coming from, and it definitely relates to your experience as a release manager for Python 3.8 and all those considerations going forward. I really want to thank you for taking so much time away from all the things you're doing to talk to me. It's been really awesome.\n\nI also enjoyed it. It's not very often that I actually meet somebody who has deep knowledge of MIDI and a similar background in that sense, so that was a pleasure. Great, thanks again. Thank you.\n\nI want to thank Lucas Laga for being my guest this week, and I want to thank you for listening to the Real Python Podcast. Make sure you subscribe to the podcast in your favorite player, and if you liked the show, leave us a 5-star rating and a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon. [Music]",
    "ytY753acKFU": "Welcome to the Real Python podcast. This is episode 10. Do you know someone in the Python community who was recently let go from their job due to the pandemic? What does the job landscape currently look like, and what are the skills and techniques that will help you in your job search?\n\nThis week, we have Kyle Stratus on the show to discuss how he's managing his job search after being let go from his data engineering job. Kyle is a member of the Real Python team and has written several articles for the site. We discussed Kyle's career and the skills that he's developed, which are currently helping him in his job search.\n\nKyle left academia to work as a data engineer. His background helps him communicate between teams of scientists and engineers. We also talk about Kyle's recent article on combining data and pandas, and he shares some tips on pandas efficiency and hints at some lesser-known features of Python generators.\n\nAlright, let's get started.\n\n[Music]\n\nMy name is Christopher Bailey, your host. The Real Python podcast is a weekly conversation about using Python in the real world. Interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Hey Kyle, welcome to the podcast.\n\nHey, I'm glad to be here. I wanted to have you come on the show, partly because I saw that you were let go from your job recently and you were looking for work. I thought maybe that would be a good opportunity to talk about searching for work in general as a Python developer, but also just what things are like out in the world right now looking for jobs. If you can give me a little background on what's going on.\n\nYeah, sure. So on Friday, I was pulled into a meeting early in the morning. I almost woke up late for it. I was rushing into my workspace 15 minutes beforehand, getting dressed and everything. Still, because of the pandemic, I was going to be let go from my position. I was working at a computer vision startup called Affectiva, focused on bringing emotion AI to the world. It's still a fascinating mission to me. I'm still very friendly with everyone there. I've been getting a lot of support from my former coworkers, which is one of the best things about working at a small, tight-knit company where we're all struggling through the pains of being a startup together. Unfortunately, basically everyone that was hired around the time I was, right after a big fundraising event, was let go. A lot of brilliant scientists, engineers like myself, were let go as part of a plan to extend the runway. \n\nWow, yeah. I hear about these zoom calls and I've just been looking on Twitter occasionally and seeing other people talking about it. I just feel for the people out there having to go through that, hoping that it's just an announcement of what's going on, and it's totally something else.\n\nYeah, this was actually the first one in my career that I didn't successfully dodge by seeing the signs and getting out. It's such a weird time, but you don't really know what's going on. They've been fairly transparent about things and the financial situation didn't seem so bad or dire. And then this happens, and it blindsides you. It kind of shocked me, but the news was delivered with what I felt was a great deal of empathy, especially considering how people were let go. We were an emotion AI company, so there was a lot of focus on emotion and empathy. It's unique in the engineering space. Despite everything, I'm thankful that I have the network and people that I've known throughout my career and in life in general who have been there for me during this time, which has been mind-blowing.\n\nI was wondering about that. Maybe we could get into a little bit of your background and how that's relating to those connections you've built up over time. You have a little bit of a different background as a Python developer. You went to school originally for neuroscience, is that right?\n\nNeuroscience, but yeah. Similar thing, different department from biology. I've always been kind of an engineering nerd, but I was really interested in brain-machine interfaces in college. I started in electrical engineering, didn't do well the first couple of years. They have the weed-out classes. I was also just adjusting to life in college and having to study for the first time ever with no study habits whatsoever, easily distracted by going to a school that was a lot of fun. I graduated from the University of Florida. Go Gators! It was a really good time, but I struggled trying to get into that flow.And then I realized it's a switch so I decided to get on the other side of the brain-machine interface problem and look at the brain. So I switched into psychology, which at the time was just whether you want to do neuroscience, behavior, therapy, or social psychology - all in the same program. I was able to tweak my classes to be very heavy on biology and things like that. \n\nI was recruited into this lab for grad school and, having a more quantitative background, I worked with one other colleague who actually had a master's in electrical engineering. We were doing a good bit of coding at an academic level, kind of that sort of dialectic coding. A lot of our equipment we had actually programmed directly, and our data analysis was all done by writing a script to actually do the analysis. That's where I rediscovered my love for programming. \n\nI had started talking to a friend of mine who was working at a financial services company. He was telling me about his 35-hour work weeks and his pay, while I was talking about my stipend and my 60 to 80 hour work weeks. I realized I needed to make a change because my student loans were piling up. \n\nThis friend of mine, who I'm still in contact with, gave me the first guide on how to switch careers. For the next academic year, I was all in on making that switch, on top of being a TA, grading exams, running a lab full-time, and writing my master's thesis. It was a lot, but it made me realize how much I could manage my time. \n\nHe gave me information that changed my life, and I made it a mission to pay it forward as much as I could. I could never directly pay him back, but I wanted to help others in the same way. Over the years, people have wanted to know about my story and how I made the switch from neuroscience to coding. It meant a lot to me to be able to help others in the same way. \n\nI hate the term \"network\" because it sounds so clinical, but for me, it's just a group of friends and colleagues who have been a huge support network for me. They have helped me land on my feet many times, and I hope I've done the same for them. \n\nWhen I decided to exit academia, I started applying to jobs. I applied to around 130-140 jobs with very little experience. I only got one callback, and I started working for a company in Tallahassee, Florida. It was my foot in the door, and I was happy to be coding and getting paid for it. \n\nI stayed in Tallahassee for about four years, working at a company that was a client management system for law firms. I worked on interesting problems around thinking and deployment across networks.Okay, I think it's time to make a change. That was my first dodged layoff, by the way. It was two months after that they laid off almost all of their developers.\nOh wow, yeah. Yeah, so like, oh wow, like I picked up on something and I shifted over to Holmes.com also in Tallahassee. That's where I learned about data engineering. I didn't even know that was a thing. But when I walked in for the in-person interview and I looked at the whiteboard, they had a diagram of the whole ETL pipeline that was the main focus of that team. It powered the entire homes.com website and all the related websites they had at the time. I was like, okay, this is what I really want to do. There's no UI stuff, graphical user interface stuff to worry about. Everything's really predicated on performance, uptime, logging into the servers, deploying kind of manually, and all this. And it was a lot of fun. That introduced me to the world of data engineering.\n\nTo take on that for just a second, you talked about what does ETL stand for here. So ETL stands for Extract, Transform, Load. These are pipelines that basically have the overall goal to take one source of data, take all the data, do something to it, and put it somewhere else. It sounds really simple, but business constraints that get put on top of that and the environments you work in make it even more interesting. So you have to deal with a lot of data, you have things like one of the business constraints was that we needed uptime like crazy. Homes.com, the way the pipeline worked, was that our data sources were these independent MLS (Multi Listing Service), this is like a real estate thing. There are all these feeds that were XML, not standardized whatsoever. There were a few different attempts that were all competing at standardizing their feeds. So you have all these different styles and things like that, and all these MLS's will have overlapping listings and updates. These are really interesting problems to solve, and I just fell in love with that. Our pipeline would take in this really messy data, clean it off, put it into a really nice data model, and put it into different databases. So we got familiar with a few different database technologies. We were using MongoDB for some things, various forms of SQL for the more relational data, and using Solar for document storage search. We got to play with all these really cool technologies, and then the language we used for the ETL pipeline was Perl, believe it or not. This was, you know, 2015. They were still using Perl, but that happened to be the right tool for the job.\n\nPerl has some really powerful text manipulation tools behind it, so that was a lot of what we did. Yeah, I really just enjoyed that sort of thing and continued on with that. Well, after that, I got married. Shortly after that, my grandfather passed away up here in Massachusetts where I am now. I started working towards moving back up here to be closer to my grandparents and most of my family. Eventually, after I think in 2017, I started applying to different places. I got a job up here at a health tech startup as the data engineer. But then I started doing a lot of work with building tooling around the various needs of the science team that I was part of. We were a small three-person data engineering team as a part of the science team. So we were kind of the interface between our data that came in both from the website and the other cool thing that PLM was doing at the time was getting blood data from people. I was on the team of computational biologists, more traditional data scientists, traditional biologists that were used to wet bench work. It was really cool being back in that very academic setting. It reminds me a lot of the things I loved about Grassville with very few of the things I can stand about it.\n\nYou mentioned the acronym, but was it Patients Like Me? Is that what it's called, Patients Like Me? Yeah, so this is actually still around. They ended up being bought by, I think it was United Health Group. It started as a website where people with chronic illnesses could get together and share their experiences. What they started doing was having people fill out these different surveys that were clinically validated. There was a lot of transparency on why they were collecting this data. It was purely optional. When we moved into biological data collection, that was the computer program. These people wanted to learn more about their illnesses and advance the science of understanding their illness. They also wanted to meet other people who were similar to them and share their experiences. There was a really powerful community that was built there. That was really cool. So we used Python professionally.I've used it all the talk like from when I started this whole journey I'd been using it for projects and for interviews and things like that because it's such an easy language to rapidly build stuff. Before that, I had a stereotype of it as a rapid prototyping tool, but then I saw the stuff we had built already in Python and started building more complex things, learning about the power that Python has. Sometimes, especially then, and the people I was around, Python didn't get the credit it deserved.\n\nWhen you talked about getting into Python and moving from role to role, developing skills in problem-solving for domains like science, and being able to communicate in a language that those people understand, it stuck with you. You translate it into working with data and being able to work with all the teams in an organization.\n\nMy passion exponentially grew in that position, and I think there are times in your career where you look back, and it's like a light switch is flipped. You're not the same person anymore, and there's a sense of leveling up, like in a video game. I felt that at pretty much all my positions, discovering new potentials and being able to communicate between teams and take a lead position on projects.\n\nIt's been a joy to go back and see how much I've changed from the beginning to the end of each experience, bridging the gap between science and engineering. It can be challenging in the job search because not every company is looking for that skill set, but I love playing in that area and hope to find something similar in my search.\n\nThe skill I'm building is the ability to solve problems, communicate effectively, and turn scientific prototypes into reusable structures for business. It's about taking what scientists build and making it functional for the business. It translates well because I'm willing to learn new tools and languages to adapt to the changing landscape of technology.Hey, there's this new database technology, and that's part of it. The curiosity and excitement to learn, yeah. It's funny you mentioned having different languages and things like this. Every job, up until I came back to Akiba, every single job I had was a new language to me. So, at Rand, it was C-sharp and the whole dotnet framework. Perl was common. It was kind of going way deeper than I ever thought I would get with Python. Part of that, too, is that I actually love learning languages, human languages. Having that interest, that curiosity, translates really well to programming. You start to see parallels to language features. Some languages I've worked on learning in the past, for example, Japanese. I was in high school taking Japanese and Spanish at the same time. I really liked some of the features of Japanese, like the particles that denote what part of speech the previous word was. To me, it was so much easier than conjugating a verb. I'm also learning modern Greek now because I grew up around it. My family's from Greece, and my grandmother, unfortunately, has suffered from dementia. She's forgetting a lot, her English language skills. To communicate better with her, I've been getting back to learning Greek. It has interesting features, but it's also kind of difficult, like denoting the part of speech of a word. There are a lot of parallels with programming languages. If you're interested in language and communication, programming is a great thing to get into.\n\nIt's important to understand and appreciate the connection between language and programming. Learning about different languages can show cool overlap and analogies that you might find fun to play with. I studied French in high school and college, but then realized Spanish would make more sense living in Arizona. My wife is from Hawaii, so I started learning Japanese. Structurally, it's very different from romance languages, but I didn't get too far. I've had jobs that didn't require it, but I still have enough in my head to think about it and translate it.\n\nFinding projects at your reading level in programming is important. Get out of your comfort zone and put your nose to the grindstone until it clicks. I've been fortunate in that it pretty much always has. It's important to advance your reading level in programming by tackling areas you're having a hard time with, like decorators or typing. Once you get the structural stuff down, you can build on top of it. Getting out of your comfort zone and pushing yourself is key to advancing in programming.It's been exhausting at times, but getting out of your comfort zone always helps. It's like working out or any athletic pursuit. You need to do things that are harder for you to grow. Your brain works the same way skills work generally. I would suggest finding projects that are well-architected. It's hard to judge that on your own, so be part of a community like the Real Python team. Getting room in Slack for the members and asking about it will get you great answers.\n\nI love using Wylie, which is a tool from the Real Python team. It's like a blueprint for my projects. If you find well-written code, especially in Python, it shouldn't be hard to read. You'll encounter things that are out of your comfort zone, and that's where you'll grow. Look out for mature, well-built products in areas that interest you. Staying interested will help you understand and learn.\n\nI have a strong belief in going beyond your comfort zone and trying to understand things. It may be difficult at first, but reading more advanced code or learning a more advanced language will make you a better developer or speaker. Immersion works for language learning, where you're surrounded by advanced language, fast speakers, and specialized signs.\n\nThinking about going back to your journey, getting involved in different projects, like the one based around memes, was fun. Anywhere you work, you'll learn a lot, but there's always room to learn more or start a project that could become a business. Flex your wings and learn something new.\n\nBefore I got married in October 2016, I saw meta memes popping up on Reddit, which I found hilarious. A subreddit called \"Meme Economy\" was created where people role-played as stock traders buying and selling memes based on popularity. I met some people there and we decided to take the joke further. We started building a stock market game for dank memes, using our skills in data engineering, design, and gaming. It was a fun project with the potential to be educational for those interested in finance.We started working on it and all of this attention from the media, so one of the first articles on us was by Motherboard, which is a Vice publication. We started getting attention from Motherboard, and they had an article where Steena interviewed us. It was wild and made us realize there was something real here. So, we started learning about how to legally create a business and how to monetize it to keep it running, as it was expensive to run out of our pockets.\n\nI started going to a local startup incubator in Tallahassee called Domi Station. Through that project, I learned the power of your network and the people you have in your corner. I went through a class with a group of people doing different businesses, and it was a fun environment where everyone looked out for each other. I recently caught up with someone from that class, John, who shared some great wisdom with me.\n\nIn particular, with TuneSnake, we focused on the business side and building the analysis engine. The engine was like an ETL pipeline that read data live from Twitter, Facebook, and a Reddit source in real-time. We tracked images in tweets using a database and a fuzzy search algorithm. We developed an algorithm to determine popularity scores and aggregated them to determine a meme's price in the game.\n\nWe had a stock market on the front end where users could trade using \"GBP\" or \"goodboy points.\" We built a community around the game, and people still ask when TuneSnake will come back. We pitched for funding to go full-time on it but faced challenges due to the conservative ecosystem in Florida regarding tech funding.\n\nThere was a lack of understanding of the value of games and how they could be used for other purposes. Games like TuneSnake could be used for ad campaigns to measure real-time reactions and virality on social media. The ecosystem around meme creation and usage is fascinating and has a significant impact on social media trends.I mean the idea of a meme is kind of a general concept of a mutable factious culture and the Internet has only accelerated that. So it's a really interesting space to be in from a nerdy academic standpoint, which is where I kind of come in and also just from someone who uses the Internet. The frivolity of it is what drove the interest because we were like let's take this way too far, just the stupid joke, and make it into something. Unfortunately, we weren't able to get the funding for it and it kind of petered out. I would love to get back to and rebuild it and modernize some of the things that we did. But as of right now, it's unfortunately not in the cards.\n\nFrom that whole experience, and this was another kind of guiding philosophy for me, always build things I learned stuff that was directly applicable to my job, specifically in using MongoDB and aggregate queries. I was able to actually use that knowledge I used in building this to go back and say, hey, we have this issue with a query that was taking just too long and wouldn't finish. Well, this whole process, when we actually calculated it out how long it should take theoretically, if we couldn't run for that long, it would have taken 140 days every week. Oh my god, that's not gonna work. It was not gonna work out at all.\n\nSo I used some of the tricks I learned at building the analysis engine from Nasdaq, and I was eventually able to have an article from like 2017 on my personal blog, KyleStratus.com, about how I actually went about solving these problems. I think I have an idea of what I can do to handle this. I used these aggregate queries, and we were able in this kind of stage sense so we do run chains and see an improvement, we do the next one, see an improvement, then we hit a roadblock. We need to kind of be architects of data and we had a measurement kind of on our side to where we could go to management and say, hey, if we redid how we were ingesting this data, then we can get this query to run a little bit faster. So we went through this iterative process, and I think after about six or seven rounds of it, we were finally able to get this process done in four and a half hours.\n\nThat's good, I mean, a little bit of it was how many hours was it originally, it was like a ridiculous amount. But yeah, so building that was directly applicable and that also kind of opened my eyes and working on the business side of it to the power of networks and people. You know, doing things for them because I'd be at the workspace and if someone might have a question and I would go and help them for a while, and these people come around later, hey, I actually think I might have a job you can look into or this for you. It's really cool seeing how that pays off. But you know, there's also kind of a joy in just helping people for the sake of it.\n\nSo that petered out and then towards the end was kind of the nail in the coffin when I got this letter from Nasdaq. They discovered I changed the name, we're gonna sue the pants off of you for the rest of your lives. I was in some negotiations with a lawyer and then I had a lawyer in Tallahassee that was a really big part of the local ecosystem there, Jake Hiker. He took it on for free and was like, yeah man, unfortunately the best we can probably do is have you guys change the name. And then I started the process of moving and it just, unfortunately, we ran out of funding and everything. So that just kind of petered out but we still have the code. There's still hopes that we will revive it one day and be ready to trade dankmemes on the market.\n\nYeah, you changed the name, right? You have a new version. Yeah, we switched to dank apps for a dank exchange. Do we want to keep that kind of history of the da and Q sort of thing? Yeah, it still feels like one of the exchanges, exactly. Cool, through this process as you're out there looking right now, how would you say the job landscape is looking right now like how is it different from say a couple years ago? What's happening in the last couple months?\n\nYes, so I have the benefit of being in a tech hub now, so I live in Boston. The landscape is definitely different. It's not as vibrant, there aren't as many people hiring. Obviously, there are layoffs happening, some big ones happened here very recently with companies like Toast and TripAdvisor. Health tech is huge here, there are a lot of areas still thriving, and it's still a vibrant place to be.And then there's the increased acceptance of remote work. So at least right now, I'm still in the very early stages. I'm pretty optimistic. There are a lot of very talented engineers out there looking for jobs right now. The market is different, so there's proposition. But I still think at least over right now, there's enough room for people. I think we'll see a lot of innovation. We are lucky to have a lot of large tech companies here that can more easily weather the storm. There are options. The startups are still there. Many of them have frozen hiring. I work with a third-party recruiter that got me the original job at PatientsLikeMe. Jaime Chephul has been amazing and a great guide to the landscape in Boston. Whether I've actually used his roles or not, it was a warm introduction from someone I worked with at PatientsLikeMe.\n\nIt's different. Even the leads I've gotten from him have been different, not as much volume. Even on LinkedIn, I see less recruiter feelers being put out there. But I have seen a lot of people coalescing around alternative ways of finding jobs. There are people on LinkedIn whose whole thing is to use it as a job board. From the relationships I've formed over my career, I've had people make wonderful introductions for me. The ecosystem here is geared towards people who are good connectors. I try to do that myself because if you're producing those connections and making use of them, they strengthen. It's like how your brain works, going back to my neuroscience background. The more you use certain neural networks, the stronger and more efficient they get.\n\nThe more you form connections and work on relationships, the more you get to know people on a personal level. Making friends is important because those people will look out for you, and you will do the same for them. Having people in your corner who are willing to vouch for you is a powerful thing. In the midst of uncertainty and fear, seeing people band together and help each other is encouraging. I've had different career paths, including in the music world. Every gig I got, from being a recording engineer to eventually teaching about recording, was all word of mouth. It was all based on reputation and people talking about me. Building connections and relationships takes work, but it's essential.\n\nYou have to meet people and do work that people would want to share with you. People need to like you, and being a team player is important. Engineering is prone to the false idea of the lone genius or the 10x engineer. You can't rest on that your whole career.Maybe it'll get you through somewhere for a little while, but generally if people don't want to work with you or are intimidated by you and you're not someone that's giving back, you're not always going to be able to rely on being the smartest person in the room. I mean, personally, I want to be the dumbest person in the room because that's where I get to learn and ramp up my skills. And also, at the same time, there is always a personality component to it, no matter what field you're in. But for some reason, engineering has the stereotype of the lone genius that doesn't need anybody and can be temperamental, and all that. You really can't be. I don't care what kind of organization you work for, some people will be like that, and I've encountered those people, thankfully very rarely. That's the other thing too, I don't think it actually bears out in real life as often as maybe media or stereotypes might act like it does, but it's still out there.\n\nI see young engineers thinking that they're the smartest person at all times and they don't necessarily understand the business aspect of things or the importance of that. There are so many facets to it. I frequent a subreddit for career questions that's mostly early career people. There are a lot of questions about management teams being stupid for certain reasons, not realizing the business constraints they are working under. It's not all objective black-and-white decision-making. If it was, you wouldn't need managers or product managers. You wouldn't need a lot of that. So, if you're going to stay in the industry, you need to disabuse yourself of that notion pretty quickly.\n\nBeing able to understand and know people, being empathetic, is something that I see more in this industry than I thought I would. But I don't think it's fully where it should be. There are a ton of great people in this field, and a lot of the culture comes from open-source software. The general philosophy is one of helping and sharing knowledge for free, giving up the ego of being the best. Of course, there are exceptions, but for the most part, people will grow out of that idea or end up leaving the industry frustrated because they think it's their way only, which is not how it works in the real world.\n\nPython has a welcoming community around it, interested in helping each other compared to other languages and environments. It feels like an easier language for new people to come into. I find satisfaction in programming, I find it calming, meditative, and fun. I enjoy programming a lot, it's something I do for fun, and I'm fortunate that my field is something I enjoy doing. I feel for musicians because I understand the struggle of wanting to create and get their art out there. It's harder for musicians, and I'm grateful that I don't have to struggle as much in my field.\n\nI'm a big music geek, a metalhead, and I used to go to shows every weekend before covid. I know a lot of local bands and concert promoters, and there's a great metal scene here. I've seen great musicians struggle for their art, and I'm thankful that I don't have to struggle as much in programming. There are struggles in this field, but I never felt like I had to be a starving artist to practice my craft and make beautiful code. I tried starving for a while, it's overrated. I traveled the US in my 20s in a Sentra and a pickup truck with a little trailer.We toured the US and actually played some places in Boston back in the nineties. It was interesting times, but yeah, I grew fond of having a paycheck and other things coming in. I still want to create. Definitely, there's a lot of crossover there. Part of the creativity process is still enjoyable. \n\nI got involved with writing for Real Python when Dan first purchased it from the original founders. He put out a call for writers, and I reached out to him with some writing samples. I joined up and started writing articles and doing technical reviews. The review process at Real Python is multi-tiered, ensuring high quality and communicability in the articles.\n\nI've been doing this since early to mid-2018. My most recent article is about pandas and merging data frames. It was challenging to write but rewarding in the end. It's powerful and intimidating, but I learned a lot from the process of writing it. Thank goodness for the patience of the editors during the delays.\n\nOverall, the experience of writing for Real Python has been enjoyable and rewarding. It's fascinating to see how authors grow and improve over time. The technical and didactic reviews help ensure the quality of the articles. I look forward to continuing this journey of writing and learning.Okay, we're just putting two things together. But then you start looking at all the different options and use cases, and how people are using those tools and expressing their data with it. It's like, \"Oh, this is going to be a long article. How do I make it readable for people and keep their attention, but also help communicate the power behind it?\" Those types of articles are super difficult to write, but they're also some of the most rewarding, I think. \n\nThat's probably been one of the more popular ones that I've written. You might say, \"Okay, this is similar to something that I have a background in, which is SQL.\" But, in general, there are all kinds of weird little rough edges that you're going to run into. How pandas indexes stuff is really kind of funky and unique. When you throw in things like multi-index and hierarchical, it just makes it more difficult by an order of magnitude. \n\nYou kind of cover three key concepts of merging, joining, and concatenating. Most people start with the idea of merging and use keywords like inner, outer, left, and right joins. What are some of the key things you have to pay attention to? \n\nActually starting with merges is a very conscious choice. I want to start with the more difficult part. This goes back to what we were talking about earlier, if you want to ramp up your reading abilities, you go beyond your level. I think merge itself, whether you're doing it in pandas, SQL, or whatever, that's going to be the more difficult one because there are so many different options and a lot of set theory behind it, which is why I want to start with this. \n\nStructure is such an important part of writing, especially when you're teaching others. I thought this was the right way to go, starting with the most difficult part. When you go to join and concatenate, it almost feels like there's an error to it. You have all these different options, like inner, outer, left, and right joins. When I see those, I think of Venn diagrams. If you look up SQL join Venn diagrams, that actually made some for this article to try to illustrate what the joins will result in. \n\nI think if you think about it that way, the whole idea of an inner join versus an outer join or a left outer join starts to become clearer. In the SQL world, it's never going to be clear because different databases like PostgreSQL, MySQL, or Oracle's PL SQL can mean different things. Even a left join could actually be a left inner join or a left outer join. There are some weird things that happen. At least in pandas, the vocabulary is unified, so you have a lot of options with merge that allow you to do a lot of neat things.\n\nIn this article, a lot of projects are built around climate data from the National Oceanic and Atmospheric Administration. It's real-world data that you can play with and understand, making it easy to demonstrate the different types of joins you can do. It's super relational, which is important when putting together datasets, especially with merging. There has to be some kind of connection, obviously. \n\nYou can easily see the results of outer joins, full outer joins versus left outer joins, and when you might want to use those different things. That's only one of the options, and it's the most important one that I think anyone using pandas and merging will encounter. The next one would be on index. This tells if you want to merge on a certain column, make that your merge key, then use this index. Otherwise, it will use basically every column that has the same name to merge on, which you don't always want. There's a lot of power behind all the options available to you, but with that power comes responsibility. You have to know your data really well. \n\nThe examples used in this article help better visualize what the results look like without using data that you're not familiar with. If you're not familiar with the data and you look at it thinking, \"That looks right,\" you could be completely wrong. You might accidentally drop columns or rows by doing an inner join instead of the outer join you meant to do. Getting familiar with set theory and how you can apply it in the real world pays off in spades.Cool. I think that having a really good set of data, if you will, to start with is crucial. It goes back to what you're talking about with ETL stuff, cleaning data, and getting prepared to do this sort of stuff. One of the things I struggled with in this article was finding a really good, clean data set to work with. I was using data.gov, which is a good jumping-off point for data that various government agencies collect at the local and federal levels in the U.S. There's a lot of cool data that are fun to play with. Traffic data, for example, is super interesting to me, probably from playing way too much Sim City growing up. Traffic data and how it maps to the idea of a graph is super cool to me. Routing things, infrastructure pipelines, and data steering are all fascinating to me because how you route things is important at every level of life. There's a lot of really cool data about traffic flow in data.gov, but finding two sets that have some relations that they can join on and demonstrate this with is a lot harder. It took me probably a couple of weeks of just looking at these raw CSV files and squinting at it to see if I could do something useful and see something with this.\n\nI was tracking to build a cool project with it, but will it communicate what I want to communicate, right? That whole skill, I had no idea how important that skill was. It bled into everything else in my career when it comes to mentorship and teaching others or even just showing my work. I agree with that too, having concrete examples to share when working in environments with owners or managers who are removed from the teams you're part of, like scientists and engineering data teams. Having to share something that makes sense to them, that is usable, and why resources should be invested is a unique skill set. By teaching, it's a huge part of it, going back to what you're saying with building in the article.\n\nTeaching is one of the best ways to learn because you have to know what you're teaching very well. The questions you get are stimulating and reinforce what you've learned on the whole path of creating the material. It allows you to look at it from someone else's perspective and understand how someone else might perceive your work. The more perspectives you understand and empathize with, the better whatever you create becomes. Your code is communication, really good code can communicate your intention to both the machine and the person reading your code. If you can't communicate it to another person, it's worthless. These QA sessions with articles or talks help refine your code as a craft that you practice as part of your life. It's exciting to have people listen, pay attention, and ask questions based on what you've shared.It's kind of frustrating when you put something out there and then it's just silent. Exactly, it's very frustrating. So, you know how well you're performing? Yeah, I actually gave the talk back in October. A team every year puts on this emotion day summit, which is a really fun time. I gave a talk about the platform that we started to build out, which was to manage our whole data life cycle. At Factiva, we actually collected our own data. We have a warehouse out in one of the suburbs of Boston where we take people, put them in a car with all these cameras and stuff, drive around, and record how they react to things and find out when they're frustrated. So, we collect this data and driving in Boston is really frustrated. Yeah, that was one funny thing. When we were there, it has to be the city that I've heard the most horn honking in the Emerald. I mean, maybe not in the world, but like in the US that I've been to. And to give you a flip side of that, if you were to honk your horn in Hawaii, it's gonna be a fight. No one does that. Exactly. I'm originally from this area, but I moved to a little beach town in North Florida when I was eleven. It's kind of that same thing, right? It's very laid-back, slow kind of life that's kind of island-wise. And then on top of that, you're in the South where things are kind of slower and more relaxed in general. And this part of Florida was still culturally like a rural south area. So, yeah, honking and all that thing I've heard. And then you come here, and like if you don't speak the dialect of horns, you're not getting around. Not in Boston, exactly. So, yeah, we collect all this really interesting data. We have internal labelers, we interact with third-party labelers to actually understand people's facial expressions. So, we create this training data for the scientists to actually create the models. I would predict, you know, given a video feed of someone, we track their face and predict what they're feeling at the time as they're driving around. So, we started building this whole platform to manage this because it was kind of ad hoc and the teams were kind of siloed off from each other, which caused a lot of slowdowns and all these problems. I gave a talk on how we were planning on building that and what we wanted to build, why we were gonna build it, the struggles that we've faced, and how we were gonna go about actually solving those. When I got up there, I mean, I was super nervous for like a week beforehand. Are we giving a talk as always? Yeah, stress-inducing, even more so when you've only been at a job for a couple of months and now you're talking about this huge platform that you and a couple of other people on Tiger team are gonna build. But I got up there, and the room had filled in. I saw, as soon as I was about to start, my entire team had filed in, and that was something. I got a little emotional because I saw all these people that I have worked with. Half of our, actually probably three-quarters of the team at the time, was in Cairo, Egypt, and a lot of them came to America to Boston for the conference. And I saw them all file in, and you know, they enjoyed it. I had a lot of good questions from them and from the audience in general. Like people are super interested in what I had to say. And that's when you know, I think you can feel like your work and what you're doing is really validated when it captures that attention, that interested people on it. Yeah, it's super rewarding, especially for someone like me that puts so much stock into what I build and what I create. You know, it's probably the same thrill as if you were a musician, would have. You get up on stage, and then after, people are coming up and talking to you about your music and buying your back should I use, you know, all that fun stuff. Absolutely, yeah. And you know, I get, I see that same excitement when I go to a show and start talking to some of the bands I see. Or, you know, I've become friendly with a lot of the local bands and their members and stuff. And, you know, there's just this excitement that people, I think anyone that creates anything, gets people to actually interact and enjoy and get something or just have any passing interest even in their work. Yeah, there's just a connection that's made there that's super cool. And I think that's something that I, and you can probably confirm her tonight, this like that's something that drives the artist or the craftsman to kind of sacrifice her for what they create. Yeah, absolutely. I'm already seeing it with the podcast, you know, putting out the idea of like, hey, you know, I have the whole thing where you can ask a question and send stuff in and topics that I want to cover. And just even the handful of ones that we received so far have been just so meaningful for me and Dan to look at more like, oh yeah.We have some questions, even little things like interacting with the audience. I don't really think about the audience because it can be distracting, but interacting with the people who are consuming and getting value out of what you're creating. Being on the other side of that as the audience, for me as a music geek who loves live shows, it means a lot to the fan or audience to have that sort of interaction and feel heard by people they look up to. I see musicians who are around my age or even younger or older, and I admire their stage presence and creativity. I look up to that. I think it means a lot for both the Creator and the consumer or fan to have that interaction and connection.\n\nI have a couple of regular podcast questions. What are you excited about in the world of Python? For me, I've been thrilled to see how much Python has grown and penetrated every industry, especially in research, data science, and machine learning. Python has become a lingua franca of science, taking over from languages like MATLAB and R. It's exciting to see how Python is being taken more seriously at every level and enabling more people to get into programming and discover the love of it. Python allows more people to have fun programming and is a great tool for mentorship and teaching.\n\nWhat is something you thought you knew about Python but turned out you were wrong about it? I was wrong about Python being just a rapid prototyping language. Python has enabled advancements in science and open-source tools like PI test, TensorFlow, and pandas. I was wrong to underestimate Python's capabilities when I first started using it. Python is a great language that allows me to easily get into a flow state when I'm coding, and it has advanced many fields in a short amount of time.\n\nDo you have a trick or technique about Python that some people may be unaware of? Two things come to mind, although they may not be hidden for those who read the documentation.Right, so the first one, this kind of relief is more specific to pandas. I've seen it a lot in this code that I've read. There's a lot of times there's just instinct, but just as programmers, we kind of think in loops and iterations and things like that, sure. So, with pandas dataframes, there's this instinct. I mean, I'm still very guilty of this myself too, iterate over the data frame to make the changes row by row and all this. Pandas itself has these very powerful tools where you don't need to iterate over a data frame. You can do things over an entire data frame in one go without the slowness of iterating or even worse, having nested for-loops. Nine times out of ten, you don't need to. There's a way to work across the entire data frame in one go. So if you're someone working with pandas, whether you're new or old to it and you're thinking of iterating through your data frame, chances are you don't need to. I would recommend digging into how to reframe the problem you're working on to make the changes you need across the data frame as a whole.\n\nMy second point is another thing that's not quite hidden but the kind of advanced functionality in generator functions. I actually learned about these writing my Real Python article about generator functions and generator expressions and the yield statement. With generators, you get a few cool methods like send, throw, and close. They let you do really powerful things. As a data engineer, chaining together these functions is really cool. You can build a pipeline in just a few lines of code that will be the same as an ETL pipeline. You can create an ETL pipeline in pure Python using generator expressions. Using send to control the flow of your generator, throw to throw errors, or close for co-routines, you can create really neat functionality that sometimes gets taken for granted. I recommend playing with these functions and using generator expressions efficiently.\n\nI enjoyed your article on that. I hadn't played around with that functionality before, but I found it cool. Before that article, I hadn't either. I picked up the article on our Trello board. I work with a lot of data, so it should be pretty easy. I was going through the Python documentation and looking at more advanced ways of using generators because I wanted it to be comprehensive. Writing that article was enlightening, as it introduced me to features I had never used before. It was super cool to discover those new features.\n\nThank you for taking the time to talk to me. It was a pleasure. This is the first podcast I've ever recorded, so it's been a lot of fun. Good luck with your search, I hope everything turns out well for you in Boston. Thank you, Kyle Stratus, for being my guest this week.I want to thank you for listening to the Real Python podcast. Make sure you subscribe to the podcast in your favorite player. If you liked the show, leave us a 5-star rating and a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "saW18UvYLQg": "Welcome to the Real Python Podcast. This is episode 18. This week on the show, we have Armand Drona here to talk about the first ten years of Flask. Armand talks about the origins of Flask and the components that make up the framework. He discusses what goes into documenting a framework or API and the community working on the ongoing development of Flask. Armand also shares his thoughts about Python in contrast with languages like Rust and TypeScript. He talks about what he would do differently if he were to start development of a project like Flask now.\n\nAlright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nWelcome to the broadcast, Armand. Hello, I wanted to ask you a little bit before we get into the history of Flask, a little bit about what you're doing currently at Sentry. So, what am I doing currently? My current role is called Target of Engineering, and more or less what I'm doing is actually, in a way, running the Viennese branch that we have. Okay, so Sentry is at the core of it. It's an open-source project, a crash reporting tool, or application monitoring tool. It started as an open-source project and it still is. We have a base in San Francisco where most of the development happens, and then we have a subsidiary in Vienna where we do most of the SDK development and what we call interest and processing. I'm making sure that all of those things work well. It's actually quite an interesting area to be working on because we basically make sure that your crash makes it so a service so that we can show you why your stuff crashed. Okay, but we also have to support a wide range of platforms like C, C++, probably some Pep assembly, and there's a lot of interesting engineering that happens to make that work. I can imagine it sounds pretty complex that you can support so many different languages and frameworks kind of underneath that. Yeah, it's a really interesting field, specifically because if you have an audio processing problem and it's a simple audio processing problem, you can probably Google your solution. There are probably enough people that are into audio processing that Googling is an option. But with crash reporting, for some odd reason, it seems like a lot of people really like having crash reporting tools but they don't really care about how it works. So a lot of the problems are just very hard to Google or there are only ever the same three or four people showing up that have the same problem. It's a very tight-knit community of people that seem to care about debug formats and stack unwinding and memory dumps and all of that stuff. Yeah, it's a really interesting thing. I feel like almost every company in the last couple of years has built in-house crash reporting tools but typically not really sharing it outside. There have only been a handful of companies that venture into the open with their problems. I think with businesses, there's that same kind of problem with trained employees and they get to know the whole stack of your software and everything like that and then they eventually leave and all that institutional knowledge goes away. In a way, this is analogous to what you're talking about. Yeah, it's super common that we are in a conversation with a larger company and they're like, \"Yeah, we have this crash reporting tool but the guy left, you know, we don't know how it works.\" Right, yeah. And just the idea of maybe having a way to share it across a service like that sounds pretty cool. And there's also, you know, that I really like open source and one of the interesting developments has been that when we started with specifically C++ crash reporting, we started using a lot of stuff from Mozilla because they wrote Firefox. And Mozilla actually used a bunch of stuff that Google wrote. So, we were really standing on giants in the beginning and now it's really nice to see that some of the improvements that we made through that stack specifically, we are writing a new library in Rust which does a lot of this, has now been picked up by Mozilla again. So, it's really nice to see that once you start actually working in that space and provide something for other people, all of a sudden contributions go in the opposite direction, which is very nice. Yeah, and if somebody wanted to get involved in using Sentry, it looks like it's possible because it's open source. If you're like an individual developer, you can use the tool too, right? Yeah, specifically for crash reporting, we also have a separate open source project with the nitty-gritty details of how it works. So, if you don't want the crash reporting solution but you really like working with crashes, we also have the underlying open source libraries which are usable and hackable by itself.Cool, I was listening to a previous interview you did with Rock Python, Michael Kennedy, about five years ago. It sounded like that was right when you were starting at Sentry, is that correct? I don't remember when it was, but I started at Sentry five years ago, I think.\n\nWell, Moya, okay. At the time, you were also working in the video game world a little bit with the Fire Team, yeah? Building communication services and online services for games, is that right? \n\nYeah, so I worked a couple of years in London, directly employed by a company called Fire Team, which was a part of Splash Damage, a game development company. Splash Damage had contracts with other game companies, not necessarily outsourcing, but on a contract basis. At that time, I mostly did networking for games, but then I also helped with the last project I worked on, which was the Halo Master Chief Collection for Microsoft. We tried to fix the matchmaking and do some stuff there. Not doing much with games these days, but at the moment at Sentry, working with gaming companies quite a bit to improve their crash reporting experience.\n\nOkay, crash reporting experience. So, this year, probably going to be heading a little bit back into games because we're trying to get console support going. \n\nWould that be for the new consoles that are coming out soon, the PS5 and the weirdly named one? I think just generally because this is a field that I have a custom interest in.\n\nOne of the reasons I wanted to have you on the podcast is to talk about the history of Flask and the anniversary date. It was in May of 2010. So, you're at 10 years. Couple questions on that. First, how involved are you with Flask currently?\n\nIt's an interesting question because Flask became popular in a gradual way where I didn't really see it happen. Similar to how community maintenance took over. I'm doing very little these days. In fact, I mostly disassociate myself from things happening there for a variety of reasons. I still hang out in the discourse and check up on issues, but I'm not that active in Flask development. I've moved more into the rust community, but not because I don't like Flask anymore, just that my focus has shifted.\n\nYou were talking about Rust a lot in the previous interview, and I was wondering if you're still moving back and forth between Rust and Python. Primarily, I use every language for the purpose that I think they're good at. Rust is great for many things, but Django is what most of Sentry is built on. So, on a day-to-day basis, there's a lot of Python code I'm still touching. My focus has shifted, and the community around Flask is different now than it was 10 years ago.\n\nThe advantages Rust has are very obvious - it's fast, concurrent, parallel, and type-checked. It feels like a good language for the specific problem we have, which is getting a lot of data into the system very fast. It may not be the most productive language, but most people touching the Rust code base at Sentry really like working with the language. It feels like a well-rounded language, a pretty good choice for this type of thing.That's the second part of it, which is that it's a new language, so it had the ability to learn from a lot of mistakes from other languages, which is really nice because it's not just fast and all of those things. It has a perfect package manager and has solved many things that other languages haven't even after years. That just makes it overall really nice, but again, it has much more cognitive overhead. It's harder to get started, so it's a different beast altogether. It's not comparable in any way.\n\nGoing back to the origins of Flask and knowing that it was built on several of your own projects as a starting point, maybe we could talk a little bit about that. I think it's reasonable to talk about why does this thing exist in the first place. If we go all the way back to probably 2004, I learned and probably earlier, but in any case, I discovered Linux, specifically Ubuntu Linux. I was living in Austria, and the language of choice was German. There was a German community for Ubuntu people, and it ran PHP BB. That's how it all started because I started hacking around in this PHP installation, and I had this idea. It would be really nice to have a Python API forum software. Unlike with PHP, where you can just have a file called foo.php, echo hello world in there, and put it there, and it opens that file by the browser through the interaction of Apache, and the code runs. In Python, there were maybe CGI scripts and stuff, but it was very different, and the Python web ecosystem was not very developed at that time. Around that time, there was this thing called WSGI, which was a specification about how to abstract across different deployment scenarios, but there was no real implementation. Shingo was about to be released, and Django just completely ignored WSGI. I wanted to have my own version of this and write the base implementation for that, so the first thing I built was a bunch of WSGI tools. A couple of iterations later, this thing landed as this thing called Werkzeug, which is literally toolkit in German. I built that one, and since I really liked the template, I wanted to make a better version of that. I built Jinja, and those two things together, I used for my own purposes. Eventually, something was building up, and you built up this framework all the time yourself, and not everybody appreciated that. A lot of people didn't want to build a framework around this and implement the tools that you'd built, to configure them together to make it easy to do a little bit more complex things than hello world. There were a bunch of frameworks developing in addition to Django, like Web2py and Bottle. Some of them had this thing in common, especially Web2py and Bottle, is this one file thingy where all dependencies are in there. I was just confused by this idea that no dependencies are a feature. I found it not understanding because the kind of monolithic all-in-one packaging was not so broken that there was a necessity. So I just for a joke bundled Werkzeug and Jinja into a zip archive, coded it into a Python file, and built a mini-framework around it. So you had this one file, which was a framework plus the two dependencies bundled. If you imported it, it's just imported into this embedded zip file, and then you import the other stuff out of it.I made a fake screencast, Freud. They had a friend of mine record the audio for it, and it just had this April Fool's version of one field framework that bundled my other libraries. I can make the same thing kind of thing, but the thing that I learned through this really ridiculous April Fool's joke is that there were actually the libraries people said they're pretty good, but they're too hard to use. So, actually building this framework around to make it easier to use, even though I didn't feel the necessity for it, actually helped other people use it.\n\nThat's really how I started Flask, just a way to make the underlying libraries easier to work with. Initial uses were, as you were saying, sort of a bulletin board forum kind of thing to be able to build something like that and not have so that was my use. But the reason why I always felt like this framework thing to be ridiculous was that I came with this idea into the son of software development, like I would like to build something like PHP, be some software that you can install and you put it on your server and then you run your own installer. You have your own configuration system. You don't want the framework. It was always my idea. Like I also, for a while, contributed to a system called Trac. I don't know if people still notice it. It was a bug tracker. And there was this time where you build software that other people would install on their servers. And in all of those cases, having a framework sounded like that's not what you want. You don't want this massive Django thing. You don't want this massive Flask thing, which has its own config system, its own everything. So I felt like, hey, like there must be a lot of other people that have this problem, but it turns out most people don't actually have this problem. Most people don't build software that other people install. Most people build something for themselves that they're going to install on one server, and they don't care if there's a framework. So that realization really only came after I didn't just consider my own problems, which were centered around things that people really don't really have as a massive problem. In a way, it's kind of funny because Sentry has that problem, right? I work at a company out at that does have Django, mostly seen as an inconvenience when it comes to the configuration aspect because it wasn't built for the tool. No, it's not that Django is a problem, but okay, you have a Django settings module, you have this Django config thing. In a way, it would be nicer if there was like a Sentry specific config, and all of this Django stuff just is abstracted. The way we in fact build a custom config system around it and everything, right? So you don't really see Django much in this Sentry setup if you run it yourself.\n\nAll these early realizations, as you put it out there, change your focus for your development at that time then. I'm not sure. I think at one point, I just started really appreciating the people who used Flask. So, okay, I think for two years or so, I started just working to solve other people's problems. What kind of problems? Like, I think it was like composability a bit, just improving, he liked quite a bit of work. I find improving the error messages that you would get if you do something wrong or I worked on improving this debugger that you have when something happens. Like, there was a bunch of work that went into making it easy to serialize chasing out and stuff like that. The interesting part is that like time change problems around you change a lot of what okay work that went into Flask, especially a couple of years ago. I'm not sure it's like dead relevance to know it is, right? Because people build so much more JavaScript UI. So all the in-cause innovations that went into the change your templating engine may not be so useful anymore. But yeah, I just spent a lot of time trying to in a way like this couple problems people have and then also trying to figure out how to solve them. And to be quite honest, I mean, it sounds really boring, but a lot of what I did back then was just learning how to build stuff. Ginger, for instance, is like I don't know, be how many ass person of a templating engine I wrote. I guess I didn't just build a pipe in tablet and channels. I wrote the PHP templating engine and right because I wrote Ginger and then I felt like, oh, and I know I would do it differently. And then wrote a slightly different version for PHP, which actually got surprisingly popular in the PHP world. And then I came with some of the learnings from them and I went back to fix a little bit more in Ginger.\n\nWasn't it primarily, you know, I think of Ginger being used inside of Django? I'm sure it's used in lots of other web very much so the most so it finds if it take like what did the community move to, right.So the Flask community moved a lot into the data sense world. But then, if you take Flask and Jinja, where did Jinja move to? Well, as people in the Flask world maybe still ran the template, but as they moved into doing a lot of stuff in React, there was suddenly a completely new user of Jinja, which was the ops world. Both Salt and Ansible for server configuration started using Jinja as a programming language for configuring servers, which was something the development of it didn't really foresee when it was originally written. \n\nI like a lot of the changes that later on went into Jinja. For instance, they actually came out of this newly found world of server configuration, which was not envisioned originally. There's like a whole subset of syntax that sends these instructions. It's not that the syntax changed much, but for instance, if someone wanted to evaluate a Jinja expression and get the result back, that was not really something that Jinja was optimizing for. Eventually, Jinja gained this ability to evaluate an expression and get the result back. It was designed to be more one way before, like a display kind of thing. \n\nFlask was primarily used for very basic tasks like having some stuff in a database and doing some calculations on it to give a response via JSON API. Flask also saw a lot of use in data visualization and data science situations, serving up machine learning models and consuming TensorFlow things. There were also little microservices built using Flask for various infrastructure tasks. \n\nThe term \"Pallets Projects\" originated from an official project called \"Buku\" which was originally named for the bulletin board service that was supposed to be built. Eventually, the name was repurposed for Flask, Jinja, and other projects that the developers were working on. \n\nA colleague and I built Flask and Jinja, along with other projects like Pigments and Sphinx. When this project went independent ways, we both felt like we didn't have the right to the \"Puku\" name anymore. So, we stopped contributing to each other's projects and moved on.So this needs a new name kind of arrangement because I want to get other people involved in it. There were obviously, I was not just flashed, it was flask, in fact, a second changer and it's dangerous. One of the other libraries that sits on top. So it felt like, okay, it needs a new name. Since I was still very much convinced that what was nice about flask is that it's built on top of these other utility libraries that can be used independently, I was looking for things that play a role in shipping stuff.\n\nOne thing that conceptually is very interesting because I like economics, I really like, is your pallets. Your pallets are basically standardized wooden pallets that you can stack stuff on top. What makes your pallets interesting is they work like a currency. I found that concept so fascinating that I felt like, okay, that's a pretty reasonable name to describe software that you use to ship things. It's used in shipping your software because it messes with your currencies. And that's a complete aside, has nothing to do with software engineering. When you buy, I don't know, a flower or something like this in bulk, you don't just buy the flower, you indirectly also buy the pallets that it's standing on top of because the pallet has some value. So the pallets, when you then ship something else back, there is no expectation that you're going to send the same pallet, you can send another pallet. People trade these pallets across as part of what to ship this stuff with, it's really quite fascinating. So I found this an interesting concept and I found that to be worthy of naming another thing.\n\nIt's kind of funny, it kind of becomes a meta when you think about the container architecture of Docker. So container with a fennec good name but that was already used. But I mean in the sense that you're shipping software that is used as pallets inside of these container objects inside of Docker. As far as the metaphor goes, I'm sorry, maybe I'm stretching. Like you built your own stuff on top of a pallet called flask, that's cool. Did you study economics or is it just a side hobby? It's a side hobby, it's a big hobby of mine. I didn't study anything but yeah, okay, cool.\n\nYes, maybe a weird question, but I was just wondering about the development of flask and the versioning number. It's become a bit of a trend in the Python world at least of having versioning numbers of zero point whatever to a certain point and then eventually hitting like a 1.0. Was there a specific reasoning or a specific point for 1.0? Yeah, there was. I wouldn't say that was a specific point for 1.0 but there was a reasoning why I stated zero point something for a very long time. When I started doing open-source development, it felt different and I feel like open-source development is happening now in the sense that I didn't really in any way consider this to be professional. To be putting it bluntly, when I released my first open-source libraries, I think I was seventeen or something and it didn't feel like I wanted to communicate that this is something that you should build yourself on top. It felt like, oh, I'm just experimenting here, I want to keep myself to freedom just to change my mind. Eventually I realized that you have to guarantee stability even if it's a zero point something because otherwise, you just annoy a couple of people that are willing to use it. And if you don't have users, then it loses the fun. But in my mind, I still felt like for a long time, hey, this is just me doing stuff, so just keep it there just for safety. And then eventually, it was just like, oh, it's staying there for like a year and I've almost not changed anything, so might as well get it done. That's literally the only thing that happened.\n\nOkay, it's like, okay, now it's stable, I guess. And then the 1.0 release broke a whole ton of stuff, but it's kind of because flask is now maintained by a community and I know that the community thinks about things differently than me. I learned not to break things and I understand that this is an outsider's opinion in the Python community, but I was always super careful with breaking stuff. When I misused an API, I wouldn't break things unless I had a really good reason for breaking it. Sometimes I wrote scripts to automate a whole bunch of stuff to do that, largely because I understood that if you build something that's not just a dependency of the end-user but it's also the dependency of a dependency, then you really don't have a choice to have that dependency be a different version. So you need to be consistent, you need to have something that works for everybody. I was always super careful to do that.I know that especially with this move to Python 3, that sort of thinking is a lot less. I don't know if it has majority support anymore in the community. Okay, so that's definitely different now. You feel that Python 3, in some ways, is moving fast, not necessarily faster, but willing to potentially make breaking changes to move things forward.\n\nI think the community as a whole just doesn't care anymore about compatibility as the primary driver of stuff. It's not just Python 3, it's like many of the pillars of the Python ecosystem are in the mood right now to just change a whole bunch of stuff. Probably it's necessary, but I always felt super uncomfortable for this, sure, and the versioning, for sure, exemplified this quite a bit. Okay, that makes sense. That kind of brings up a thought I had.\n\nI'm sorry I didn't do the research on it, but I wanted to learn a little more about Python 2.7 still being supported in current versions of Flask. Is that right? So, I don't know if the release version supports it, but the master version doesn't. There's also one thing that I'm for sure not in agreement with because it's not that I think people should be using 2.7, but I was always willing to extend the support for older versions for a really long time. I remember I supported Python 2.4 for a major one because they added decorator syntax. Okay, but I always felt like that's something that I cared for and I was even appreciating sort of the constraints that were put on me.\n\nIn a way, the effort it cost to build code that worked across a bunch of versions, especially when working with the standard library. There were often times when you had to be quite clever in how you can use the same library so that you get the same output independent of the Python version. Yeah, but the community now thinks differently. It only supports a bunch of Python versions at this point.\n\nThis week, I want to shine a spotlight on another Real Python video course. It's about an important step in the development and sharing of your code. The course is titled \"Documenting Python Code: A Complete Guide.\" The course is based on a Real Python article by author James Mertz. In the course, instructor Andrew Steven takes you through the reasons that documenting your code is so important, the differences between commenting and documenting, best practices for docstrings, and additional tools, references, and documentation projects. I think it's a worthy investment of your time to learn the best practices for documenting your code and to learn about tools like Sphinx, which we discussed during this week's episode. Like most of the video courses on Real Python, the course is broken into easily consumable sections and you get code examples for the techniques shown. Check out the video course, you can find the link in the show notes or you can find it using the newly enhanced search tool on realpython.com.\n\nSo, you mentioned the community a couple of times now, do you have an idea of the size of the current community working on Flask? In terms of actual active maintainers that contribute to the project, I think it's about 10 people. And then, the wider community of people have absolutely no overview of what it is. I know that we used to have this IRC channel, which was pretty active, and at one point it was one of the largest ones on Freenode. Now, I'm not even on IRC anymore, I just hang out on the Discord sometimes, and there's about 200 people that hang out in there. It doesn't seem too significant in the Discord, but then I look at how many people actually use it in the world, and it seems to be a pretty big number.\n\nI had Doug Ferro on the show, he's an author who writes at Real Python but he works for Shutterfly, are you familiar with that? It's a printing company that not only prints photographs but they print your photographs on stuff. So, he uses Flask internally for lots of these machines where it's never even going to the wider web, it's just for these machines to talk to through internets to other things like that. So, he's building these really simple APIs and he definitely uses it a lot for those kind of purposes. I think that there's a lot of hidden architecture that's using it just because of some of the simplicity of setting it up.\n\nNow, I noticed that you guys are using Black now as a code formatter for Flask. Are you a fan of using code formatters? I would say I do think it's a good idea to have code formatters and I enforce it vigorously on the front-end JavaScript code that I'm working on. I also really like Black and I enforce it on the Python codebase now that we have. But I think there's a mixed bag.The thing is that I never felt like the Python code, code formatting matters a whole lot in languages like Rust, in particular, Go or Java. I never really felt like code formatting matters that much in Python because you kind of structure via indentation based anyways. So, for as long as they agree on four spaces, that's kind of key. What I'd never could agree on was like capitalization of anything, classes are lowercase sometimes. So, I really wish the community would have started linting API names, that felt like that's where the focus should have been. The code formatting is also nice to have but in comparison, I think it feels a little bit less important. So, I wish Python would start enforcing its naming scheme somehow.\n\nThat kind of maybe leads into something that you like a lot about Rust, which is type checking. I know that there are movements in Python in general, and Guido's obviously involved in this with his involvement in mypy and a lot of the newer peps that are coming along with Python 3.8 and Python 3.9 involving type checking. What are your thoughts on that, adding more type checking? I like type checking, I think it's a great thing. I just completely disagree with Python in how it does it. When it comes to dynamic languages and type checking, I think it's hard to beat TypeScript. TypeScript's type erasure kind of approach is amazing for this type of language.\n\nIf you take TypeScript as a language, what it does is it adds a bunch of type annotations that sit on top of the JavaScript language. You can add types to anything, even if it's untyped by itself, and all the types that you add in TypeScript, they're compile time only, with the exception of enum classes. It means that you can have really complex circular dependencies of types easily, you can express things without any runtime impact. Python can't do that because Python decided that types should be runtime reflected. It's just a mess of stuff, very hard to understand and incredibly slow. MyPy type checking, I don't know if you can make it any slower.\n\nOne of the things that I really appreciate about Flask is the documentation on the website. It seems really detailed with examples and so forth. I was wondering how much you were involved in that. I like documenting and I worked with Giek on the original strings tool for documenting stuff. So, that was always something that I cared about, and more so after Flask was initially released. My qualities of documenting stuff went up a little bit. There are definitely some things that I have some relatively complex thoughts about how documentation should be structured now. For a long time, I really felt like prose is how you should do most of it. I think I did a better job with the Click documentation, where I structured it based on common topics which are loosely following the API with interspersed examples. So, it reads more pros like.I was not a huge fan of API documentation back then because I felt like the data can have too much surface area. How do you know which one to look for? I still think that's largely true, but that's also because Python doesn't have a good way to shape the API. Everything is public, so I felt like in Python, you better not start authoring documentation because you might accidentally expose things you didn't want to. I still think API documentation is terrible.\n\nI saw with TypeScript and Rust recently that you can shape your API to reduce the total surface area, making API documentation somewhat acceptable. Are you saying that as you write the API itself, you're potentially going to use a tool to help you auto-document it in some ways? That's one part, but how do you communicate the relationship between different functions or classes in the documentation? That's the documentation problem.\n\nFor a long time, I felt like if you have to solve a documentation problem, maybe the API was already bad to begin with. Nowadays, I feel like most libraries expose too much API, and it would be better to expose less. This would make documenting the API less of a challenge. My thoughts on documentation have evolved, and I now feel that API documentation is more defensible.\n\nAs I started documenting, my thinking on API documentation evolved, and I feel it's closer to where I would go now. API design and documentation belong closer together. I used to believe in the idea of onion APIs, but now I would logically separate them further apart. I would still give access to the underpinnings but with less stability.\n\nI think Flask is in a pretty good spot right now. If I were to develop Flask or a similar project from scratch in 2020, I wouldn't do it again. My first problems aren't necessarily solved by Flask anymore, especially since I'm working with more data at my current company. If I were to start again, I would focus on solving the types of problems I have now.You probably also want to solve something that's on the site-geist, those are the problems you need to solve. The type of problems that people have at that point in time and the problems that people have in 2020 are just different than the problems that people had in 2010. \n\nI feel like if I look now at what the world needs, the world doesn't need another patent framework, there are plenty of them to choose from. I probably would look elsewhere and I probably wouldn't build a pipe family. I feel like at this point, I would probably want to build something like a framework, a system that helps you build more distributed data processing problems like data pipelines, and probably in more than one language at the same time. Because nowadays, it's unlikely that people just build stuff in one language only. \n\nThat's something you see with the usage of Flask, as you were saying earlier, that so many people are using it as a basis and then connecting it to JavaScript. I'm just really excited about where Assembly's going. I feel like maybe there's a future where almost all of our languages are going to have some sort of pep assembly interpreter in them and we're going to load common pep assembly modules and have a bunch of our logic outsourced into that. I think it's not an unlikely future for a lot of what we're doing. \n\nI had a listener question a little while back that was interesting, and I don't know if you have a perspective on it. You can refuse to answer if you don't want to get into it, but I thought because you had a little background in PHP or actually probably quite a bit of background and then moved into these other languages. So this person works in WordPress and is kind of a beginner and then was very interested in how they could implement Python with WordPress. I thought to myself, I don't really know of a way to do that for PHP that feels especially like a system like WordPress, it feels kind of difficult to connect it to frameworks like Python. But I don't know if you had thoughts on it.\n\nThe thing is that the first thought that comes to mind is that there are no stupid questions. I remember when I started doing a bunch of these things, I was just generally negative on these types of thoughts because instinctively it felt like they don't fit together. But I think this is just a lot more ambivalent now because there are a lot of people that do things like that. For instance, a relatively popular thing now is to use WordPress as an editor for content that is then consumed by a separate system, possibly written in Python, to serve static pages. Another common setup is using Drupal to render content with Gatsby, a JavaScript static website generator that uses React. \n\nI know there are a lot of hosting options out there for things like DigitalOcean where you can get your Python installation going, but WordPress comes with many of these solutions. If you want to do a website, it's kind of like the first installation that they have.So I think that's where a lot of people are potentially sitting right now. It's kind of a cool solution. I think one of the really positive developments over the last couple of years has been as people realize that tourism are IsIs, that people realized that you can basically just take one tool to some degree and then stop using a tool at a certain point. There's this idea that you can use WordPress for editing, but then it's okay to not use WordPress for rendering. This idea, it used to be really frowned upon that one would sort of scrape screen grab some stuff. It's like, \"Oh, I have this tool and now it's render some stuff,\" and then you go with regular expressions over it to get some data or to do something else with it. That was like really, really frowned upon.\n\nThere's like I ran them a lot of PHP projects that just made HTTP requests on other websites and then just repackaged the data. Really, that's their own like a news aggregator or something. But nowadays, actually considering how the web works, that's pretty much what the web is now. It's like Google goes to Wikipedia to scrape some stuff out and then render it in their own box. Or if Siri goes to everywhere to scrape the stuff and do it like and get things out for you. All right, this is no longer bad, this is just how stuff works. And there are lots of websites just our front to a wide range of back-end APIs and some of those back-end APIs are literally just static JSON files produced through some things. Yeah, right, this is no longer ugly and terrible, this is just acceptable.\n\nSo I think this is a reasonable development. What kind of in the data science world, like a lot of the government sites, at least the one for I live in Colorado, in the Colorado government site, they serve a lot of the data that if you're interested in it as just JSON, like you're saying. This is actually one of the best developments of JavaScript on the front end. Especially during the coronavirus times, I went to like a lot of websites to get to their data because I was really curious and typically they're just in that JSON file somewhere. It's great, way better than the days where you had to scrape and then do for exists to extract data from a HTML page. It's already rendered out in HTML and then having to like completely, yeah, and then maybe there's like pagination where you have to like this Lex Luthor, huh.\n\nI have a question about just general about gaming. Do you play video games? I don't know if that was probably why you got into that world selectively. I would say I appreciate the technology of what games always more than playing single-player games, this kind of thing. I do really like multiplayer games like Dota, League of Legends, Quake, Counter-Strike, that sort of stuff. Battlefield, but I play so little recently. Yeah, I just don't have the time anymore. No, I understand. It's kind of surprising, my wife is totally into video games and when I said you had worked on art, you know, portions of the Halo Master Chief collection, she's like, \"What?\" Yes, that's like her way of kind of relaxing at the end of the day is going and playing Destiny and just like.\n\nWhat I actually really liked about working on that project in particular is because when it again released on the Xbox, it was actually just all the individual games into individual executors, was added this master executable round is just swapped out for the individual ones and we were busy just tasked with making sure that this swapping experience at the matchmaking and then calling into the in passing all the statement Adina once works. But I remember I spent like probably like a couple of weeks all the evenings just reading through all the source code of the old Halos because I found it just fascinating where it came from because like they were built on top of each other and that like years and years of experience. I actually got more joy out of studying the source code than from playing the games even though they're great.\n\nThat was a question I had recently from somebody that they said they were like an intermediate developer and they used this analogy of a child having reader books that are designed for certain levels of reading and he was wondering if there were certain projects that I could suggest that would be at a specific reader level that would be good for him to continue to develop his skills. I mentioned Flasks, but you know, there are other projects and stuff like that. And I don't know if you had a suggestion of like Python projects that you could think of it would be a good read for someone to go through the source code. It's a tough question because like Flasks is pretty boring, Django is pretty boring, K is even more boring. These are all just not very optimal libraries for learning because you learn something but I don't know if that's valuable. It's probably more into. I don't know.I feel like you have to read something with a purpose. Either you read a story, and then the purpose is learning what's coming behind, what's on the next page. But typically, there is no narrative in a Python project, so that falls away. Then they have to go through actually learning something specific like how seasons work or something like this. Once you figure out what interests you, you should pick the most compact implementation of the thing that interests you and not the most fancy one. It's just a super generic answer, but I really don't know anything right now that I can suggest here. \n\nDid we cover what you want to recover in Flask? You had a question earlier, which was like what would I have done differently. I don't think I would have done anything technically different, probably some things, but that's debatable. For sure, I would have done one aspect of it, which is the community around it. I underrepresented how big it gets and also how much time and effort an open-source project can take when it gets to a certain size. Size is not measured by the number of lines of code, but just the amount of people using it. I never really wanted to spend time on this, which is a big fault. I also didn't spend time on even thinking that I would have to deal with this eventually. This kind of problem doesn't go away unless your users go away. So I didn't handle very well how this transition from \"I hacked around on this thing\" to other people hacked around on this thing actually went. \n\nI think that's one of the biggest changes that I would do, understanding that you need to spend time on figuring out how stuff is supposed to work when you're not involved to help direct it in some ways. Or at least have directives, at least, maybe communicate why was it built in the way it was built so that other people can understand why it does that and then find out how to give it to other people so that they can do something with it. There's a relatively calm mission statement, but kind of that sort of something like this. Paired with that, I would have, that's a car like interviewing people but like have a conversation with people, like, \"Hey, why does it interest you? Would you want to work on this?\" \n\nBuilding a community of like-minded people like the Django framework did a really good job in doing that and I just never felt like that's something that I feel very inspired in doing. But not doing it also doesn't lead to a satisfying situation. So it took Flask really a couple of attempts to build this sort of Paris community around the tent. And now it's there. I feel like sometimes maybe I should have done certain things differently to have ingrained some ideas more. But then maybe it's like it shouldn't have to be my choice anyways to see how it should go. \n\nThis is something you want to refocus now or no? No, I think it's fine how it's doing now. It's just there. I probably would feel less detached from it if I would have communicated some ideas more. It's like I feel like it's no longer my fight to make it more backward-compatible, for instance. The community sees this differently than I do, and that's fine. \n\nI actually have a question about Python in general, and we talked a little bit about type-checking. What are your thoughts as far as the current trajectory of the language? I feel like Python is one of the languages that I wasn't wrong early on about predicting what the core problems are. I feel like the core problems that I felt like the language had when I started using it are exactly the same core problems that it has now, which is just that the core implementation is ridiculously slow. There is only so much you can do to fix that, and as time goes on, that becomes a more and more pressing thing. \n\nSince that's kind of unfixable, it's going to further move into areas where these problems are less of an issue. I think that's probably also why data science or data processing, in general, is something where Python is holding strong. When it comes to number crunching, you're kind of moving out of the slow language anyways into things like numpy, Scipy, the C libraries, or even moving into the chip you. Then it just becomes sort of a combining things together kind of area. Many languages in that environment like MATLAB and so forth, they're not particularly fast in the language either. They're just fast when it comes to the numeric kernels.I feel like I'm more and more convinced that's where the language leads. I hope, sorry, I don't think the language has particularly bright features outside of those communities. I don't think people are going to build massive online services in the future, for instance, because they probably have better languages to pick from nowadays. But I do hope that, in the same way as their language is inspired by, if you take Rust as a language, Rust didn't come out of nothingness. It was inspired by a lot of other languages. I think many of the ideas that made Python such an amazing language are not really acknowledged for many other languages. So, a lot of other languages have designed completely different things to focus on. \n\nYeah, the ideas that Python has, I really hope that maybe the future of Python is that someone comes in and builds another language that becomes like the Python of its time. I do hope that's largely the future that Python finds itself in, that the community or someone else is going to build another language that brings forth a new generation what Python brought to the world. \n\nAs far as working in Python and things happening out there, what's something that you're excited about in the world of Python? I'm not seeing that much of what's happening in Python unfortunately, so it's kind of hard for me to say. I think I have pretty high hopes that what happens around poetry and packaging will move towards a place that's a little bit more dependable, pardon the pun. I think this is the biggest area where I'm excited that something is happening. Also, it feels like typing is moving in a more stable and useful direction, so I think it's pretty good. \n\nIn terms of where Python users are, it's pretty obvious. In the data science world, there's a lot of stuff. I just don't necessarily know how much it excites me personally, but I find it always interesting to see what people build with Python. It has become so commonplace in certain areas that it's just exciting in itself. I associate less with those things than with effective development. \n\nWhat's something that you're interested in learning next for yourself? Programming? No, I don't know. It doesn't have to be. I feel like I'm moving a little bit away from specific programming problems to more interesting technical challenges that come through work or just generally learning more about the world. Economics is a thing that interests me, but there's a lot about psychology and how humans work that interests me. Politics interests me, too. Just having kids grow up has become a significant part of my life, and figuring out how to handle that aspect of the world interests me quite a bit. I feel like I'm spending a lot more time debugging humans than debugging code. \n\nHas debugging code helped you with debugging humans? I don't know if the reverse would be true, either. Very different problems, very little overlap. One interesting thing about programming for me is that it has some real-world impact through debugging humans. My understanding of the world is largely based on my experience in programming, growing up in the open-source community, and specifically the Python community. \n\nMy ideas of how the world works have been shaped by people I've interacted with through my work. Especially in the open-source community, you have an idea about how the world ideally works, and maybe it does, maybe it doesn't. You have political ideas shaped by people you interact with, a much broader sense of what's out there. If I wouldn't have started programming in Python in the open-source community, I probably wouldn't have interacted with so many people from different countries, different cultures, different ideas about things. Programming has shaped my ability to understand humans. \n\nMaybe if I would have been an assembly programmer, that would have been different because it seems less of a community kind of experience. But the Python community is a very diverse one. It had and still has the desire to do things right, maybe it doesn't always achieve it.But the idea is there. That's quite interesting. I think it's definitely character shaping. You've done a lot of talks in the Python community, going out to events and things like that. I know right now it's not really happening. Do you have plans to do any of that sort of stuff online? I want to be honest. I don't have a good excuse for not doing it. For me, the big problem is that people invite me to podcasts and I wonder how much relevance I still have in the Python community. There are way more capable people to talk about certain topics. It's quite funny.\n\nA couple of years ago, there was a good reason to speak at conferences. I feel like maybe I'm not the right person to be there anymore. I feel a little bit misplaced sometimes about conferences now, especially if you look at the last couple of talks I gave.\n\nI feel like discussions about the trajectory of languages and ideas for that are important. As programmers, our goal is to solve problems. That's where Flask started, solving your own problems. One thing I've learned is that I'm less attached to communities now than I used to be.\n\nThere was a guy, his handle was Why the Lucky Stiff, he was very active in every community. From one day to another, he disappeared, and I found that fascinating. I feel like I could disappear from the Python community and it wouldn't change much because I don't feel such an emotional attachment to it. Now that I'm doing a lot of Rust, it's an awesome community, but I keep more distance now.\n\nI don't know if I'll be interested in Rust in five years. I don't want to become a luminary or lose interest in programming. I feel awkward when asked for advice on how to become a good programmer because I'm not sure myself. That's a limiting factor for me in doing talks. I appreciate you coming on the podcast and talking to me about stuff. I've learned a lot and appreciate all that you've added. You've built a cool community with your projects. Thank you for coming on the show. Thanks for having me.We're talking to me on the show this week and I want to thank you for listening to the Real Python Podcast. Make sure you subscribe to the podcast in your favorite player. If you liked the show, leave us a 5-star rating and a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you could leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "wmnbogzfBws": "Welcome to the Real Python Podcast. This is Episode 22. Do you want to distribute your Python applications to other users who don't have or even use Python? Maybe you're interested in seeing your Python application run on iOS or Android mobile devices. This week on the show, we have Russell Keith-McGee, the founder and maintainer of the Beware project. Russell talks about Briefcase, a tool that converts a Python application into native installers on Mac OS, Windows, Linux, and mobile devices. We spent some time digging into Beware's cross-platform widget toolkit named Toga. Russell talks about some of the intricacies of converting graphical user interface components from across multiple computing platforms. If you're interested in contributing to an open-source project, he also talks about how you could get involved in the project, and we also talk about the struggle of getting funding for open-source projects.\n\nAlright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with the community of experts at realpython.com.\n\nHey Russell, it's nice to have you on the podcast. Hi, thanks for having me. I was wondering if we could just go ahead and start with a little bit of a history of the project of Beware itself. \n\nYeah, okay. So there's sort of an interesting two channels that sort of converged about five or six years ago. I was just kind of tinkering in my spare time and I had this vague theory that I wanted, basically, I wanted to build a debugger. I learned to program back in the 80s on Turbo Pascal, which had a really good debugger. And then I moved into the Linux Unix world and you ended up with GDB and PDB, which are very good debuggers but don't have a user interface on them at all. That sort of entry mode user interfaces or a text mode user interface is really hard to use. And so I had this theory that, okay, we've got this wonderful 4k laptop with high resolution everything, I should be able to use modern graphical tools and build a thing that is just a debugger that I can use to debug Python and be able to get a good debugging experience but without having to swallow the entire IDE experience. You know, buying or getting into a full PyCharm or VS Code or something like that. It sounds cool. So this would run as a separate kind of tool next to what you'd be coding exactly. So you have your editor for editing code, the debugger for debugging code, the test coverage tools for looking at your test coverage. You know, standalone tools do one thing, do it well. It's sort of a classic Unix philosophy kind of idea. But not Unix philosophy in the sense that everything has to be done in the terminal. Let's use the fact that I've got this incredibly powerful graphical workstation to visualize things, you know, see lines of code as I step through them. But do it at the but it only does debugging. It just is a debugger. Cool. And then step one of that is I need a graphical toolkit to do that. I tried doing it with Tkinter and it just sort of started hitting so many barriers with it. Basically, the time I could never find a graphical toolkit that I could just pip install and have it be native and have it work everywhere. At the same time, I was actually had a startup at the time. It was a Django web startup thing and we got to the point where we needed to have a mobile app to support it. We needed people in the field to gather data in the field, take photographs, go through checklists, kick lists, that sort of thing. Okay. And you know, I've got this incredible Django Python code base. How do I use that on a mobile platform? And I basically, there wasn't an answer that was viable. I had a poke around, eventually ended up using PhoneGap, which is a JavaScript framework and basically regretted it from day one. I just hated everything about working with it. And so there has to be a better way if only just because I want to reuse all this Python logic that I've got on the server on mobile. And so the two sort of came together. Like on the one hand, I need a graphical toolkit that works cross-platform and there's a gap here that there's no Python GUI toolkit that works on mobile. Okay. Maybe this is the reason why another GUI toolkit is the way forward. Maybe this is the thing. And a bunch of tinkering and whatnot that came around. I was playing around with how hard is it to write to native APIs directly from Python. Turns out it's actually a lot simpler than I thought it was. So, you know, how hard could it be? The classic first new project mistake. Sure started building a widget toolkit and that kind of expanded and expanded into this sort of, let's see where Python can be, can we use Python for front-end tools, which is essentially what the Beware is. One of the confusions we have is that Beware is an umbrella project. You don't install Beware. \n\n[End of Transcript]You install Koga, Briefcase, and all these other little pieces beware is this big project. Umbrella project of little tools that all do one thing really well, much like the idea of debugging. It's just for debugging and a coverage tool that is just for coverage. \n\nYeah, I just had a conversation with Armin Roanoker for about Flask and all his pallets projects and how they all kind of fit together in a similar way, which I think is a really good approach for this kind of thing. To be able to have, you can tell me this but as far as development if that's helpful. To have it sort of separated somewhat.\n\nYeah, I mean there are definitely complications. I won't lie that there are complications. Even just from the perspective of people turning up in our chat room and say I've just installed beware and I'm getting a bug. It's like, well no, you didn't install beware, you installed Briefcase or Toga or one of these other things. So can you narrow that down? \n\nAnd someone reports a bug and they record the bug against Briefcase and no, it's not actually a Briefcase problem, it's a Toga problem. So you've got to migrate the issue over and there's that sort of complication definitely exists. But it does also mean that you can bring someone in and they can become an expert on packaging or like how am I going to put this application and wrap it up so that I can distribute it and they know nothing about how GUI frameworks work, they only know how the packaging tool works. So it does focus attention on what is this tool, what is this piece of the puzzle trying to do and solving that problem really well. \n\nAnd if possible, what we've been trying to do with the beware tools is not just solve it for beware's purposes but solve it for everyone's purposes. For example, Briefcase, our packaging tool, can package other apps. It can package QT apps, it can package Tkinter apps, it can package, I think we've seen an example someone packaging a Kivy app with it. So it is not a beware specific tool for packaging, it is a Python packaging tool that happens to be under the beware umbrella. It does work really well with Toga, which is beware's GUI toolkit, right, but it's not specific to beware. \n\nOkay, one of the things that you were mentioning on the site also is the idea of hopefully getting maybe gaming going. And I noticed the pursued PyBear as one of the platforms that maybe you've been talking with on some of that. Yeah, I've been speaking with Piper and the team there and they've contributed a patch recently to support essentially add pursued PyBear as part of this as one of the initial templates. Interestingly though, that actually required absolutely no changes to Briefcase itself. Oh wow, Briefcase has a packaging tool just says okay, tell me what your dependencies are, what are your Python dependencies, and I'll wrap them up into a package that runs. The only sort of manifestation of pursued PyBear in Briefcase is the wizard starting off in the first place. Pursued PyBear is there as an option and if there's some stub code to say this is what a stub pursued PyBear project would look like. \n\nAnd then you install pursued PyBear and your application is packaged. So yeah, we're hoping to be able to support any, you know, asterisk any framework and game frameworks for most of that because Piper again just recently submitted a game to, I think it was Ludum Dare, a little whatever the game jam competition is, and like this is one of the first times that I'm aware of that or that they were aware of where a Python game is in one of these competitions with a Windows installer that just runs right. You don't have to go and tell people how to build a virtual environment so they can install your game and run it, you just give them an MSI file and they run it, which is I think is the real benefit of something like that. Here is it is one of these big unsolved problems with Python is how do I give my code to someone else so that they can use it when they don't care about the fact that it's written in Python.I think that's one of the things that is most interesting to me about it. When I went through the tutorial this week trying to get familiar with tools, I've done a little bit of iOS development and a little bit of Mac development just playing around. A lot of the commands at the very end felt very much like the kind of commands of building and creating the actual installer, which is really neat. It feels different from some other Python packaging tools that try to put all the resources together.\n\nWhat is your experience with this, and what are you trying to do that's maybe a little unique? The sort of throwaway line that I like to use is that Briefcase is the dumbest thing that could possibly work. We are very deliberately not trying to be clever in anything that we do. A macOS app is not anything particularly special, it is just a directory structure with subdirectories, a metadata file, and an entry point that is executable.\n\nBriefcase is just templating that directory, it is a cookie-cutter of a directory structure. It is very deliberately not trying to be clever and wrap things up into a single archive; it is just being as dumb as it can. The easiest way to get a working Python interpreter running is to give someone else a directory with site packages, lib, and bin directories, so it will just work for them.\n\nOn other platforms, like Windows, we ship a directory with the official CPython embedded installer with entry scripts and an MSI wrapper that sticks it in your start menu. On Linux, we use a format called AppImage, which is a mountable image that knows how to execute itself inside that disk image. The whole Briefcase packaging story is just to get a Python interpreter onto this person's machine without them having to download Python.\n\nAfter you've created this build, you have a distributable. In the case of the Mac version, it's a DMG disk image that mounts to your desktop. In Windows, it ends up being a single folder in your applications directory that contains your application's Python code, dependencies, and interpreter. There is a metadata file that gets loaded into your registry for the start menu entry.That's it. If we are not trying to do anything clever about packaging an executable or wrapping it up, not to say that we don't necessarily want to. One of the big wish list items we've got is to be able to do a genuine single exe installer. However, a lot of the other packaging tools out there are taking that approach and my experience has been that they never quite work. They involve playing silly games with the Python importer, for example, because you don't have 15 files or 100 files in a site packages folder that you can just open. It goes in packages all of that into a single archive and then tricks the Python interpreter into how it thinks it's opening a file, but it's actually just going to an offset inside that bundle, which can work except when it doesn't.\n\nYeah, and like that's the whole game that was being played. If you've ever built a Python package, there's an option in distutils for zip safe, and that's essentially that. Can this thing run inside a zip? Do I actually rely upon this Python file being a Python file? A disturbing amount of code out there in the ecosystem actually does. They need to be files on disk in a folder the way that it normally runs, or else it just doesn't work. And that's getting aside from when you've got binary modules and how you wrap those binary modules up in such a way.\n\nOne of the things I was thinking about that caused problems for what I was trying to do in an office environment was trying to share. I was working on a Windows platform and I was trying to use, I think it was PyInstaller. One of the other tools that's out there, we don't particularly call out names, but it was very picky as far as the environment. This was a 64-bit machine that I was working on, but if I wanted to distribute it to a machine that was 32-bit, it wouldn't work. I had to have a virtual machine or some machine that was in that same exact architecture to go. Is that a similar problem that you would have in creating something with a briefcase?\n\nThat absolutely, yes, yes, that problem would still exist. I mean, the briefcase doesn't magically solve any architecture problems. If you go to the CPython page to download your installer, there are at least two installers, one for 32-bit and one for 64-bit. And I think the 32-bit one will run on 64-bit, but I won't stand by that one.\n\nSo, you know, it doesn't resolve architecture differences. It won't make an executable work on a different architecture, but it will make it really easy to say, \"Okay, now here's my 32-bit installer and here's my 64-bit installer because they are two different installers. There are two different sources you can use.\" So yeah, and PyInstaller, again, I don't want to pick on PyInstaller specifically, but they are going to have the same problem, right? Because you actually do have to worry about those architecture things. And I think it probably gets even worse because all the games about trying to open up files in specific locations are going to be even more critical because you're trying to do offsets into a 64-bit binary versus a 32-bit binary. But you know, the executable is the first step, and if that doesn't work, then it's a moot point anyway.\n\nThat would be one of the things you've got to think about in general. What's your target, right? Yeah, what are you setting up for? It's somewhat mellowing out on the Mac platform, though. I guess with it about to get a whole lot more interesting.\n\nI was going to ask you to take a divergence into ARM stuff. The interesting thing is that back, this is like the fourth time Mac has changed its hardware architecture. There is a well-established path for how this works. Interestingly, the CPython source code still has hangovers from the last architecture change, moving from PowerPC to Intel. Mac's toolchain is already very much multiple architecture aware, and you actually see this on iOS because every time you build an iOS binary, if you're doing a fully compliant binary today, you're actually compiling it four times, for x86 32-bit, x86 64-bit, v7 and ARM 64. And all four binaries coexist in what's called a fat binary. So, you know, you look into it as an architecture, like in this single binary, there are four different sets of offsets depending upon what architecture you need. The Mac compiler toolchain knows how to deal with that and knows how to compile something twice and stick it into an executable.\n\nSo, it's not a solved problem, but it is something that the Mac ecosystem is well aware of how to make this work. The legwork is being done, partially done, certainly not a solved problem from the perspective of briefcase. However, I have a reasonable degree of confidence that it won't be too difficult when we get there. Did you try to get yourself a development kit?I did, but I'm not quite that important. Also, they're not cheap. So, yeah, no. Yeah, and I mean, I guess it depends on who's the priority of chains and so forth. One of the things you're using as a tool throughout this process is this .toml file. I haven't done a lot with them. I've done a little bit with Docker, and I keep seeing more of these tumble files. I just wanted to have you explain a little bit about them, if you don't mind, to make people familiar with what they are and how they're helping with the development.\n\nOkay, the toml is relatively, in the grand scheme of things, it is ironic that having developed YAML, yet another markup language, it has since been superseded by yet another markup language, which is toml, which is Tom's own markup language, Tom Preston-Warner from GitHub fame. It is designed to be effectively the issue that exists is that there are CFG files which are very easy to read, but there isn't a formal specification for them that is universally agreed upon and is rich when it comes to things like dictionaries and lists and all those kind of rich data structures. When you get to moderately complex configuration, you need those rich data structures. You need to have the ability to do key-value mapping and lists of items and a clear understanding of what is a string and what is the escape character to get you into a string and how to put that character inside a string and all those little details.\n\nPython specifically has gone to toml for PEP 517 and PEP 518, which is around the packaging metadata. Cast your mind back 20 odd years, Python introduced distutils, which was how you build a Python package, but it was assumed that you would always be using setuptools and distutils to build your Python package. Since then, there have been new tools that have come out that are alternate ways of building those packages, but you still have to have setuptools and distutils installed to tell the installer which packaging tool you're using. So, there's kind of this issue of the setup.py file is executable code, which means it has a library dependency, which means that you need to run something to find out that you're not going to use setuptools to install your package.\n\nPEP 517 and PEP 518 are about defining the metadata of how do I build this package, what tool do I need to have to build this package, and that needs to be not executable, so it needs to be in a markup format. At which point the question is then, well, what markup format are we going to use? They did a survey, and toml is probably the best option out of those set because JSON doesn't have comments, you can't use comments in a JSON file, and comments are really useful in configuration items. YAML is eclectic and has some very interesting failure modes and all sorts of weird executable exploits. Raw configuration files, no one can agree on the format of a CMG file actually is, so you're left with toml, which is very easy to read, very easy to parse, and also gives you the full richness of key-value stores and lists and clear string definitions. It is yet another format, but it is quite clear and very rich in terms of what you can do with it, and yet the parser is not that complicated.\n\nBeware didn't specifically say we're going to use toml, but they said there is this new packaging format, we're going to use pip project toml, which is the PEP 517 format, and we're just going to integrate with that ecosystem. Brett Cannon has a blog post about it. What the heck is pip project toml? I'll include links to PEP 517, PEP 518, and that blog post, along with your PyCon talk. It just kind of intrigued me as you said there's been lots of ways to think about packaging, so it kind of sounds nice that from a top-down sense, there are some decisions being thought about, especially for projects like yours.The pushback that is existing, or at least that I'm seeing anyway, is mostly around misunderstanding what it is trying to do. We have had setup.pi forever, we set up.cfg is just starting to emerge, and all of a sudden we've got pi project.toml. Are we supposed to be putting our configurations in our setup.cfg or our pi project.toml? It's a little bit more churn than would be nice to have from a community perspective. But this time, it is actually being thought about from first principles, and we've got a format that is rich enough to allow metadata to be specified in a format that is rich enough and serves all the other needs. I don't want to use setup tools at all, but I know that this project.toml exists and I can say what I'm using instead of setup. \nUsing the tools for briefcase and kind of doing that initial setup, it does a lot of it for you. It helps you construct a lot of that toml file. Well, it does from the perspective of briefcase. We're not actually putting anything in that metadata file that isn't briefcase-specific. The packaging story for something like briefcase is fundamentally different from the packaging story for something like setup tools. Setup tools is primarily for defining a package that you're going to upload onto pypi that someone else is going to install into their project as a dependency. \nBriefcase is about packaging applications and it's a lot more about the deployment story. It's a lot closer to deploying a website than deploying a package to pypi. Briefcase does generate a pi project.toml in order to be part of that ecosystem and agree that this is where your metadata for how your project is being built sits, but it is not trying to build the project that is going to go to pypi because your app won't ever be uploaded to pypi. It will be uploaded to an app store or to an s3 bucket so it can be downloaded by someone. \nAs far as the different platforms go, I was able to create a mac app that isn't installable, a DMG. I didn't go through the extra steps of the signing process, which is important if you're going to put it in a store. The idea of the project is also to be able to be on mobile devices, correct? \nWe were very lucky to be the recipient of a grant from the Python Software Foundation a little under a year ago. We got that grant to fund us to rebuild our Android backend. We had Android support about three years ago in an experimental form using a particularly eccentric approach that worked well but was not sufficient. We used to do a compilation process of taking python bytecode and turning it into java bytecode directly. That approach is still worth looking into, but it's a big job to reproduce the whole of the python standard library and all of the cpython module.What we've done is gone back to first principles, back to scratch. We now approach iOS in a similar way to Android. We take the C Python source code, compile it with a C compiler for the platform (iOS or Android), and treat it as an embedded Python installation with an embedded library where you can throw your application code and it runs. There is a bridging process from Python to system native libraries, bridging from Python to Objective-C and from Python to Java to interact with buttons or widgets on the screen.\n\nAs of two or three weeks ago, we formally said that we support Android. Ashish Laroya has been working on this for the last six months. We have rolled that out into Briefcase so you can now run the tutorial on macOS, Linux, Windows, iOS, and Android. You can take a \"Hello, World\" application with input and a dialog box that does some math, drop the code in, run it five different times, and get five different binaries. It goes beyond simulation and runs on the hardware, even in the app store.\n\nTo run it on iOS, you need to be in Xcode. Open the project, plug your phone in, and press the play button. You need to set up your developer profile with Apple's developer program for all the signing stuff. For Android, you can almost completely automate the process by plugging your phone in, starting to run, and simulating devices that look the same from the perspective of Briefcase.\n\nFor development purposes, I have a base-level Android device that I use for testing. Tablets and phones are common choices, but it's up to personal preference.The thing that's interesting, and this is one of the reasons why the Android support lagged for so long is that I did the iOS support first. iOS is my daily driver, so I did that support first. But way back in four or five years ago, I got that going and I've had the app running on my phone forever. That was using that embedded C Python approach, and I tried to do that on Android. The problem is that Android devices really don't have only very recently been even remotely comparable to iOS devices in terms of raw CPU speed. I don't want to hate on Android people who like Android or whatever, but I'm sorry, Android devices are slow compared to iPhones. It's only very recent devices that are even remotely comparable to iOS. So, five years ago, it was unusably bad. The speed of starting up a C Python interpreter on an Android device was just not plausible. And on top of that, the way that you talk from Python to the Java Virtual Machine is through this layer called JNI, the Java Native Interface. Four or five years ago, the Android kernel actually had a hard-coded restriction on the number of JNI references that an application could hold open at any given time. That basically meant that it wasn't plausible to use JNI. That's why I went down this other rabbit hole of trying to compile bytecode.\n\nWind the clock forward four or five years, the situation has gotten a lot better. Android devices are a lot faster, and the JNI restriction has been lifted. So, jump onto Amazon and find a hundred to two hundred dollar cheap Android phone, it's a perfectly workable Android phone for testing and development purposes. However, they are still slow, really slow compared to an iPhone. The latest generation Nexus, later generation Samsung phones, they are broadly comparable, they're still a lot slower, but they are broadly comparable with an iPhone. But the cheap phones are a lot slower. The real acid test here is that if I load the Treble Tips app onto my iPhone, it starts up in one second, there it's running. If I load it on a really recent Samsung S20 or whatever, or S10, it's the same thing, loads in a second or two. On my test phone, my 100 test phone, it's about a 10-second startup the first time, about a 5-second startup the second time, which is not great. When it's running, it's okay, a little laggy, but it's okay. They are slow, but they are definitely good enough for test purposes. The golden rule is that a developer should never have a new machine because they should know how bad it is for everybody with a bad machine. It's probably not a bad idea for you to have a cheap device because it does point out exactly how bad the experience is for everyone else. They're perfectly usable for test purposes.\n\nOne of the things I was wondering about is this idea of Toga and the graphical user interface library that you have there. What's involved in that being cross-platform and having widgets that can be on Windows or on an Android device and so forth? It's mostly an issue of trying to find the common ground in terms of what it is you're not trying to describe. Internally, Toga has essentially three layers: a public interface layer, an implementation layer, and a native layer. In the case of something like a button, it's pretty straightforward. You have a Toga interface that is a button that can be pressed and we're going to call the callback when a button is pressed. There is an implementation layer that is a button, and there's just one widget that needs to be able to talk to the native layer, where on iOS it's a UIButton, on Mac it's an NSButton, on Windows it's a Windows.Forms.Button, on Android it's an Android.Widget.Button, on GTK it's a GTK.Button. You just need to connect the dots between what you call it publicly, what the platform calls it. And on top of that, one of the things Toga is trying to do is be a Python-first framework.So, the metaphors in the UI are not just C wrapped in Python. We use attributes the way Python does, try to use context managers in a Pythonic way, and present APIs that are Pythonic in their approach. This sometimes requires tweaking around on more complex widgets. For example, a scroll pane on GTK is just one widget, but on Mac, it's actually two widgets - a container and a scroll bar that need to be munged together. \n\nThe challenge lies in bridging the gap between the implementation layer where we know we need two widgets, and the system's native platform. On Linux, this is easier due to GTK's native Python binding. On iOS and macOS, we use Rubicon to bridge Python calls to Objective-C. Similarly, on Android, we use a Rubicon for Java. On Windows, we use Python.NET, which is more complicated due to the absence of a C types analog.\n\nThe calling convention is crucial, as C types enable us to invoke any C function. Swift uses a C-like calling convention, making it predictable and potentially compatible with C types. If Objective-C were to be dropped, we'd need to find a way to bridge the gap with a new language. \n\nIn Toga, we have all the basic primitives like windows, buttons, sliders, checkboxes, text inputs, scroll boxes, tabs, trees, and lists. The widgets are most mature on macOS, with progress on GTK, Windows, iOS, and Android. A good analogy is if you can build it in Tkinter, you can likely build it in Toga. One widget we're proud of is the canvas widget, which allows drawing vectors on a page.Yes, great. You can draw pretty lines on a screen. The real kicker is that we've actually got it to the point of maturity where it can be used as a Matplotlib back-end. So you can use Matplotlib to draw charts natively on a Toga page. You could literally build a Matplotlib charting widget for an app that draws charts in real time by rendering them through Matplotlib directly into Toga. The charting widget is not available on Android at this point, but it works on all desktop platforms.\n\nThat's great! In terms of building data gathering and data display apps, it's not a problem. One of the reasons I got into Toga in the first place was that we have a web widget. You can build a web browser into Toga in about 30 lines of code. It's not Firefox or Chrome, but it is able to display a URL. You can connect up a web browser, which tkinter doesn't have, for example.\n\nIt's by no means mature, it's version 0.3 in development. There are things missing, bugs, sharp edges, and things that aren't going to work quite right. But if you're willing to be adventurous, you could build an app that gathers data in the field and posts it to a web API without difficulty.\n\nThis week, I want to shine a spotlight on another Real Python video course about Python decorators. The course covers how functions are first-class objects in Python, creating simple decorators, using syntactic sugar, decorating functions with arguments, and creating real-world examples of decorators. It's a worthy investment of your time to learn how to use decorators and recognize their use in code.\n\nI was wondering about distributing to the web as another platform. At one point, we had a demo running for web as well. I come from a Django background and would like to see Toga targeting the web as an application platform. The hiccup at the moment is getting Python running in the browser. The emergence of asm has opened doors for what we could potentially do in the browser, but we need focused attention to get it working legitimately.\n\nToga has scoped out the idea of a Toga web backend that can take a definition of a modern single-page app and render a user interface via HTML, CSS, and JavaScript.That's exactly the same story as with a native widget toolkit on a desktop platform or on a mobile phone. It's just that instead of talking about rendering it in single pixels with an API that draws a box on the screen, it's a render div with style border one pixel solid. So yeah, there is a story for building GUIs using the same API that we see on desktop platforms but rendered in the browser as the delivery mechanism. \n\nYeah, it's like another layer of translation, which is interesting. I suppose that's kind of a bugbear that I've had about the web for a while. No one builds apps for desktop that involve rendering individual pixels on the screen anymore. You can get to raw draw pixel on screen, but nobody does that ever because we have worked out that it's better to put an abstraction layer over the top that is draw button. Draw button gives you a button that has accessibility controls, renders nicely when you click on it, and if you really want to go fancy, has little audio controls and is keyboard navigable, and all the other stuff that goes around the outside of that. \n\nBut on the web, we're still very much hitting rocks with hammers. We are drawing individual lines on the screen, and everyone is reinventing the wheel when it comes to what a button looks like and what a pull-down looks like. We haven't taken that step back and really said, \"I want to build a user interface on the web. I don't care about the mechanics of how you draw those pixels on the screen. I want to tell you what I want my interface to look like and then have the back-end platform worry about that.\" \n\nSo that's kind of, you know, definitely longer-term pictures in terms of what type where Toga is looking at where we'd like to go and the fact that we can now legitimately say, with WebAssembly (WASM) and whatnot, that there is a path for getting Python running in the browser. It could be a renaissance for Python on the web that we can legitimately say you can build your app in Python, deploy it on the web as an application, and never actually have to learn a second language in terms of CSS and JavaScript and HTML. Always just keep it at the Python level and put things on the web. \n\nYou used a term there that I'm not familiar with, I think it was WASM. Oh yeah, sorry, WASM is Web Assembly. \n\nOkay, what happened a couple of years ago because we've had multiple generations of JavaScript interpreters, people like Microsoft, Apple, Firefox, Chrome, and Google all fighting with each other to say they've got the fastest JavaScript interpreter. We now have really fast JavaScript interpreters, and someone sat down and worked out what is the minimum subset of things that compiles really fast and go like JITs and compiles internally in the JavaScript interpreter really fast. They came up with this subset of ways you can trick the JavaScript interpreter to run things at almost native machine speed, and they call that ASM.js because it's essentially assembly language for the web. \n\nThey took a step back from that and said, \"Okay, instead of trying to write this JavaScript in this incredibly convoluted way that we could occasionally stuff up and not end up with stuff that's ASM.js compliant, let's see if we can work out a way to define in an assembly language form, like in a literal assembly language, the instructions that I want to run, and then let's get a C compiler to target that language.\" \n\nNow we have the ability to compile C code that will run in the browser that isn't running natively; it's running as JavaScript, but the JavaScript runs really fast because the interpreter is jittered or is just in time compiled. If you can run Quake in your browser, you can run a Python interpreter in your browser. \n\nThere's a project called Iodide, which is essentially a duplicate of a Jupyter notebook but without the server component. It is Python, NumPy, Matplotlib, and SciPy running in your browser. When you type a new Python command, it runs in the browser natively. WebAssembly is how you get code to run in your browser without writing JavaScript because it's using the JavaScript interpreter.But you never write a line of JavaScript to make that happen. You're writing things in a binary format that the JavaScript interpreter understands effectively and that then gives us this runtime common environment because every browser's got JavaScript and JavaScript is incredibly portable. If I compile that, going back to our original question, don't care whether it's 64-bit or 32-bit or an ARM machine, it's JavaScript and it runs as JavaScript and it'll run everywhere and it'll run fast everywhere because JavaScript jitting compilers are hideously optimized to do this ASM.js subset. It's like the thing they keep bragging about with every revision of iOS or Android or what have you is like, you know what is that our JavaScript interpreter is five percent faster on whatever monkey a benchmark exactly.\n\nThe other question I have is, and this is kind of goes back to my conversation with Armin, and I was trying to get an idea about version numbers and Flask sort of famously had a non-1.0 type of version number for many years, and then there was suddenly a decision - well, okay, we're gonna be 1.0 now. So I'm wondering if there's some of that zero versioning, what's your thought process there with not only beware but also Toga and stuff? \n\nI am a believer that major version numbers are communicating something significant. I am not a believer in everything being 0.something forever. In terms of Toga and the beware tools specifically, they're all broadly about version 0.3 at the moment. For me, that's saying it's not a complete toy, but it's also, you know, wear gloves, you're going to get caught on sharp edges mentally. My model is when I say Toga is version 1.0, that is something you can rely on, that is a stable API that I'm not going to go and change, or the project is not going to change arbitrarily. If it does change, it's going to be for very good reasons and we'll provide backwards compatibility parts and all the rest of it. So like I think version one communicates something significant about the maturity of the project, and that is like we are targeting a version one. No, I haven't got like it's going to be out next week, but we normally there is a version one in our future. And if I had to stick a wet finger in the air and say what that is, it's essentially you could use this as a replacement for TK Enter. Here is a not incredibly sophisticated but sophisticated enough toolkit that we are an adequate replacement for. And then you know version two is when you start making significant changes beyond that or you know, the sort of gets more into the difference between version one and version two for me is not as significant as the difference between version zero and version one. \n\nAnd so you were saying that for Toga then, well Toga but more broadly across the rest of the tools as well, like they're all getting close. Briefcase at the moment is version 0.3 because I'm kind of semi-reserving the right to change things if I have to because we just don't know. Like a lot of this stuff, you build a design, you build an API, and then you discover that, oh crap, that didn't quite work like that does it. That actually gives us friction in places we don't need it. I am willing to break things at the moment in the interest of maintaining a stable API or maintaining a good API. Versus a stable API. When it gets to version one, I won't call it version one until I know we've got this bedded in and we know that the basic structure we've got here is good. I would estimate the Briefcase is a lot closer to being version one than Toga is at the moment. Not that they're both that far off, but Briefcase is a lot closer to being genuinely usable right now as a version one product.\n\nWhat is your day-to-day involvement in the project? I started the project, good lord, was it six years ago now? This has been one hell of a year. So it's been about six years since I originally started working on all this. I'm the founder and sort of the principal maintainer. If there's a question, it's a 50/50 chance it's probably me who answers it on the mailing list or on the chat rooms or whatever. There is a team of people around it who swing in and out variously, contributing when they've got time and when they've got interests. Ashish, in particular, for the last six months, has been doing a lot of work, but because he's been paid to work on it. That is not, however, my paid day job. This is not what I do when I do have a small number of financial sponsors. We do get grants from the PSF and things like that occasionally. But this is what I do in my spare time. It's not my paid day job. I would like it to be my paid day job, but just try to find a way to actually fund this, sure without like, oh, just go get VC. Okay, but then the VC is going to want something.So, what are we going to have to sell? Like, what part of our soul are we going to have to sell to make this? I would rather this be good and maintainable long term without having to work out how we're going to monetize the community. Not that I'm opposed to making money, I just don't like making money as my prime incentive here. It's building a thing that is useful. \n\nAnd how do you monetize that in a way that doesn't introduce perverse incentives into the community, where you're desperate, like having to do things like Reddit, where they have things and then lock down parts of the community? I don't want to get into those games. I want this to be a community project that just happens to be financially sustainable.\n\nMy day-to-day is like reviewing the stuff that comes in and patches, trying to respond to questions and feedback as they come in, finding time on weekends to fix those problems when I can, but my time is limited. Every little bit of contribution from the community is fantastic, well-welcome, and gratefully accepted.\n\nIt's going to ask you, like how would somebody get involved and help with the project? Roll up your sleeves and start helping. If you've got a big.org, there is a contributions page that can walk you through, gives you a broad direction you could go depending upon your skill set. The thing that seems to scare people off is that, \"Oh, but I'm only a beginner, I've only been programming for a couple of years, I couldn't possibly contribute to a project like this.\" \n\nThat's where nobody is an expert. Having the interest to genuinely learn how the Windows API works when putting Windows widgets on the screen, if you use Windows on a day-to-day basis and you would like a really good Windows widget toolkit, guess what, we need your help. \n\nI want to support Windows a whole lot better, but I need someone to take hold of the Windows platform, make sure it absolutely sings, do things that build widgets that feel native, build APIs that look native. There is a small leap that you need to get over in terms of how do I translate this Python API into this documentation written for C# programmers, but it's not as big as you might think. The bridging APIs that exist are fairly straightforward, method names are exactly the same, there is occasionally some type manipulation, but it's not seventh level Dan black belt level stuff. \n\nYou've got to pay attention, and if you learned to program last week, it's probably a little bit beyond you, but if you've got a year or two under your belt, I guess you could probably do it. You've just got to be willing to do a bit of research in the background and read up about what's going on. \n\nThese are the Rubicon kind of things you're talking about, not even necessarily Rubicon, just at the level of Windows. The biggest issue with Windows at the moment is making the tree widget fast, making the tree bridge work. Someone needs to go and look on the Microsoft page for the API for displaying a tree widget on the screen and convert that into a wrapper API that is compliant with Toga. \n\nAll the documentation is there, a wealth of documentation out there for how you build a Windows tree in your .NET application. There isn't literal documentation for how to do it in Python, but the API is there and documented, and I can tell you how to map from Python to that API. \n\nWe just need someone to do the research, work out how to build that widget, and then translate that into some actual Python code. Structurally, there's going to be a lot of similarity there, a lot of very similar stuff, and it's literally trying to work out, \"Okay, so we need to display an icon on the tree.\"How do I display an icon in a tree using the Windows.NET API? Let's go off and research and find that, and then translate that into the actual API calls that need to happen in Python. It sounds a lot more complicated than it actually is. The implementation of the take button, as a simple example, is like 30 lines of code. It is not difficult code to understand. Now, a button is a relatively straightforward widget, but if you can wrap your head around those 30 lines of code (which are not complicated), it is more complicated, sure, but not hideously more complicated to make the same thing work for any other widget.\n\nBut there is just a lot of stuff that needs to be done, and it all needs to be done before version 1.0. Right, okay. So, if anybody wants to get involved, the biggest thing is to basically show up and keep showing up. The most frustrating thing for me, as a project maintainer, is when someone turns up, says they're enthused, spends an hour explaining how something works, submits one small patch, and then never comes back again. If it's me scaring people off, I'm terribly sorry and would like to know what I'm doing wrong because it isn't my intention to scare you off. Having people who show up regularly means it's worthwhile spending the time and investment to make them better and help them over time.\n\nWe have Olga Bilat, a woman based in Turkey, who has been one of the big contributors to the Windows back end. She, by her own admission, is not an expert programmer, but she turns up regularly and makes some patches that are amazing. The Windows back end has gotten incredibly better as a result of her contributions. If this is an endpoint where you would like to see Python be able to do these things, get involved. Now is the perfect time. I got involved with Django before version one, and every contribution was a huge contribution back then. It's a lot harder to get involved with Django today, but if you can find something easy to be done in Toga, now is the time to get involved. This is where it's easy to get involved, and you could find yourself in a similar situation to mine in the future.\n\nRegarding Briefcase and the whole Beware project, are there things you wanted to talk about specifically on top of what we've already covered? The only thing really is the eternal open source funding issue. I've been around open source for a long time, and finding financially viable models for open source is something I'm passionate about. Even Django has difficulty finding funding to maintain the Django fellows. Toga does not have someone using it in production for a huge app, so how do we get from here to there? Developing it on weekends is exhausting work.\n\nThat's all I have regarding Briefcase and the whole Beware project. The open source funding issue is something I'm very passionate about, and finding financially viable models for open source is challenging. It's important to have money to pay for someone's development time, especially if we agree that having Python on mobile and being able to develop front-end web stuff is valuable. Developing on weekends is exhausting work.And it doesn't happen quickly if it's being done on weekends. We've seen multiple versions of this in the Python community. Beware has seen it. We got a grant from the PSF six months later, we have a fully functioning Android implementation that would not have happened without a grant from the PSF. Pipeyi lived in this development hell for years, and they got a grant from the Mozilla grants wing. Six months later, there was a finished version of Pipeyi that is there and is robust. Money makes things happen. We need to work out how to get that money into our community, into the things. And I, okay, if it's not Tiger, that's fine. But we need the injection of money into the tools that we are using, into our ecosystem so that we are not always playing catch up for the things that are changing, the developments in the ecosystem that we're seeing. So that we are doing our research and development to make sure that Python maintains and continues to be a useful platform into the future.\n\nAt the simplest level, it's no open your wallet and donate to the PSF because they are in a position to judge that sort of stuff. Or if you've got particular prejudices like Beware where you do believe in their message, give them money even though you're not using them because it does make a huge difference. Like the day that I can give up my day job and actually go and work on Beware full-time, and ideally not just work on full-time by myself but with one or two other people so that I'm not just echoing around in my own head. That's going to be the point at which the project is going to start, not just be, \"Hey, look, I put out a little minor bug fix on the weekend.\" It's, \"Hey, this week we delivered a new feature.\" Yeah, because I was in 40 hours on this project, not two hours on the weekend while making sure my kids were fed.\n\nI wonder about that model that a lot of authors have. I know this is probably smaller scale, like Kickstarter kind of things and so forth. I don't know how well that works for open-source projects also. Kickstarter is a model that always gets suggested, but it misses two important factors. The first off is that it is once-off income. It's like, \"Okay, yeah, let's do a Kickstarter to get together version 1.0, you know, whatever amount of money that is that happens to be. I'll go estimate it, put up a Kickstarter. It is once-off money, and you know it funds six months of development or you know three months, six months, 12 months of development, how much time it is. And then what, right? Then it's not being maintained. That's not a good situation to be in.\n\nThe other thing is that because of that, the contracting, like if you are a contractor, contractors charge more than week-to-week employees because a contractor needs to hedge for the fact that next month they're not employed, right? So they will charge you know twice, three times what their normal actual employed hourly rate is, just so that they've got that safety margin. If you are in an environment where there is already not enough money, you don't want the person that you're paying to be charging you three times the rate, because you're going to get one-third the amount of work done for the amount that's actually being done, right? \n\nI totally get the appeal of Kickstarter and like it's yes, let's bring the community together, but what we really need is Kickstarter for ongoing funding, right? Like Kickstarter Patreon, yeah, Patreon is closer to that model, but not just Patreon. I do have people who pay month by month subscriptions, and I'm incredibly grateful for it. But like, what do they, like they get everything they're getting now, what do I withhold that you don't get, right, until I've got enough for a living wage for me or enough for a living wage for one other person?\n\nSo, yeah, so it's that when I don't have something to hold over you, when I can't withhold something, there is a model, yeah, like Kickstarter, you don't get it unless everyone pitches in, yeah. What do you withhold if it's ongoing maintenance or it's an ongoing subscription, and that's like there is something here that we haven't gotten? I have a book written by a woman named Delano Ostrom that gets cited a lot. Her work, she actually won the Nobel prize for economics for this work she did about sustainable ecosystems in the commons or sustainable economic commons. One of the things that is a key factor she identifies is that you need to be able to exclude access to the resource. If you've got a fish out fishing ground or forest or grazing lands or something like that, the way you maintain it is that you basically have to have a set of rules for how you can use it, and if you don't adhere to the rules, you can't use it.\n\nOne of the rules is that you need to be contributing back either with money or with resources or with something, but you need to be giving back to be able to use it in the first place.And that is sort of an anathema to the open source ecosystem because the open ecosystem is very much either out there and everyone can use it with no restrictions, or the nuclear option of it being GPL'd and you can't use it unless you are also giving away all of your stuff, which is not a viable option for the vast majority of projects. Anyway, the real takeaway is that I am open to anyone who wants to have that discussion or anyone who has ideas about how to restructure or re-work, reframe the problem to enable R&D work and long-term maintenance work in open source ecosystems. So if anyone has any ideas, please get in touch because I'd love to hear them.\n\nYeah, it's definitely something I've wanted to think about, not only the idea of people coming in and helping contribute time, but also all the things we spoke about before with building up your resume and getting that experience. It's important to not be afraid to show up and contribute as a developer.\n\nI am also very aware that as a white Anglo male, I have the privilege of being able to do this stuff in my spare time, which is not available to everybody. Building out your resume is great, but you need to have the spare time in the first place. When volunteered resources are the only resource we have available, we need to make the most of it.\n\nI don't want to waste anybody's time if they're trying to contribute to a project. The best way to ensure it's not a waste of time is to know that there is a two-way commitment. I am willing to give the other end of that commitment, but we need people to show up and commit long-term.\n\nOne other thing you mentioned early on was the idea of tuning the Python package to potentially be smaller. It gets very weird and political quickly because there are so many people using Python in different ways. Python has always talked about itself being \"batteries included,\" but some of those batteries are leaking. There are libraries in the standard library that may need to be reconsidered.\n\nThere is a bigger discussion that needs to happen because in education, one benefit of Python being \"batteries included\" is that users don't need to install additional code. Whereas in the Node ecosystem, you need to install a lot before anything works, which kind of works because it's in the browser.The Python ecosystem has a value proposition that everything is there to start with, making it politically complicated to strip things out. In a mobile development ecosystem, the goal is to have things as small as possible. For example, in building a calculator app, there's no need for email parsing libraries if the task is simply adding numbers and converting Fahrenheit to Celsius.\n\nThere isn't an active project addressing this issue, but many have discussed the need for it. One potential solution is tree shaking, which involves removing unconnected code from the code that is actually running. This approach may be a viable solution to make Python more efficient.\n\nTree shaking involves deleting unnecessary code, even on a smaller scale within libraries. While challenging, it is a solvable problem that can optimize code performance.\n\nWASM (WebAssembly) is an exciting topic in the world of Python, reminiscent of the era when Java was considered the universal solution for cross-platform compatibility. However, Java's tight coupling with its virtual machine hindered its widespread adoption. In contrast, JavaScript's versatility and presence in web browsers have made it ubiquitous across platforms.\n\nJavaScript's success lies in its integration with web browsers, making it a crucial language for modern applications. Despite Java's decline, JavaScript remains a dominant force in software development.And they've optimized that JavaScript interpreter and they've optimized everything about it and they've developed WebAssembly (Wasm). Wasm actually looks like it might be a better way of delivering on that \"write once, run everywhere\" platform than Java ever was because Wasm standardizes the thing that is complicated, the binary interchange format. If you can compile and target Wasm, my C code, your Python code, someone else's Erlang code can all interchange because we have established a common binary format in Wasm. That is really powerful, a really interesting idea, and one that has a whole lot of potential if we can finesse the details.\n\nI definitely want to make sure that Python is on that train, is able to play in that world because that is genuinely what makes things cross-platform. The great irony of it all is that we get there not by paying attention to JavaScript the language, but by completely ignoring JavaScript and just using its runtime, exploiting the fact that it has a common runtime everywhere. So we are going to get \"write once, run everywhere\" by using a language that borrowed the name for marketing purposes in a runtime where we're going to ignore the language that actually borrowed the runtime for marketing purposes. That sounds like a normal operation of things.\n\nIf you were going to suggest one resource or one place somebody could start to learn a little bit about WebAssembly, do you have a good place that you send somebody? Not really, that is kind of the biggest issue that we've got at the moment. Getting it is very much about reading assembly code manuals. It hasn't been documented well yet from a user's perspective. Scriptin, which is hard enough to say let alone use, is the C compiler, the compiler toolchain part that targets it, and their tutorials aren't too bad as long as you understand C to start with. For a completely green person just learning to program, it's probably not that accessible, but that is kind of the big gap at the moment, how do you make Wasm actually usable for people? I don't know that we've kind of got there yet.\n\nThe potential of it sounds really cool, especially for how abstracted Python is from it, allowing you to still be able to do all these other things in the distribution. Potentially, you know, here is this great JavaScript library I'm just going to invoke it from my Python code, which I can now do because we both agree on the runtime interchange. We are in a position to better do that kind of thing now.\n\nSomething that has come across my desk a couple of times now and I really do need to sit down and spend some time on it is a project called Pylance, which is an extension to VS Code that looks incredible. It's one of those code completion extension pieces that looks incredibly interesting. I need to find some time to actually sit down and play with it in anger, me too. That's high on my list of stuff I want to look at and learn more about.\n\nThank you so much for coming on the podcast and talking to me. Thank you for having me. I want to thank Russell Keith McGee for being my guest this week and I want to thank you for listening to the Real Python Podcast. Make sure you subscribe to the podcast in your favorite player and if you like the show, leave us a five-star rating and a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "tsJ5ZYGBfgg": "Welcome to the Real Python Podcast. This is episode 24.\n\nHave you wondered how you should package your Python code? You've written the application, but now you need to distribute it to the machines it's intended to run on. It depends on what the code is, the libraries it depends on, and with whom you want to share it. This week on the show, we have Itamar Turner-Trauring, creator of the website pythonspeed.com. We discussed his article options for packaging your Python code, including wheels, conda, docker, and more, which covers the vital question of how to share your code. Itamar also briefly discusses his Python memory profiler named Phil. We talk about his recent PyCon 2020 presentation \"Small Big Data: What to do when your data doesn't fit in memory.\" We also cover several other resources available on his website for data scientists who want to get deeper into docker. So let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Itamar, welcome to the podcast.\n\nHi, thanks for having me.\n\nI was wanting to start off talking about your website in general and talk about the name Python Speed and maybe your thoughts about why you came up with that. So naming websites is hard. So yeah, probably as what can I find... I wanted to have another site, code without rules.com, which focuses on more generic programmer productivity content. And I wanted some place to talk very much about Python-related technologies and tools. One of the things that Python gives you is that it lets you develop software quickly. It's also inherently a slow language, so there's a lot of work you have to do to make things go faster. There are all these libraries built upon it. So that's one part of it, making people more productive both in terms of the way they write software and in terms of computer efficiency. A long-term personal goal of mine is to do stuff related to climate change. Computing is a big resource in terms of carbon emissions. More efficient software is good, and one of the things that excites me about Python these days is that it's being used by a lot of scientists and people outside the web development world. There's a whole bunch of science and non-software engineering happening with Python. Helping people who are doing research, scientific research with Python is also something I'm excited about because it's a good thing in general. Also, there are a lot of people doing stuff related to climate science and energy efficiency.\n\nWhat are you doing day to day, like what's your regular gig outside of creating articles on your website and such?\n\nI do some training. I've had some classes teaching on Docker packaging for Python, intro to Docker packaging, production-ready details to get there. I've created some related products that I sell, and I also do some software development and consulting.\n\nCool. You were recently on Michael Kennedy's podcast, Talk Python to Me, talking about your latest software development project, Phil, your memory profiler.\n\nAt one point, I had a job where I was doing an algorithm pipeline for processing images for gene sequencing at a startup. Memory usage was a massive bottleneck in terms of hardware costs. Running stuff in the cloud, RAM is really expensive, and images are huge. This is spatial gene sequencing, so there's a lot of data. But more broadly, memory is more of a bottleneck in software processing data than you think. It tends to be running closer to capacity. When things go wrong, it's not that the program is slow, it's that the program crashed, and I have no results, or my computer is utterly wedged. So, I've been writing a lot about how to reduce memory usage, but in order to reduce it, you need to measure it. The tools that existed for Python were not sufficient because they were more focused on memory leaks. If you're doing data processing, the main issue is that you loaded a lot of data, and your memory usage spiked. The existing tools didn't capture that peak moment, so I wrote a memory profiler to capture that. The initial version would run a full program, an end-to-end process. This week, I've been working on adding Jupyter support.So I just kind of started my first day at work yesterday. I got to work for the first time in Jupiter and Albert. You're writing some code and you say, \"Oh, how much memory is it going to use?\" You can use a Jupiter magic to profile just that function. Within your notebook, you get a profiling report saying this line of code called by this line of code was responsible for fifty percent of the memory. Wow, cool! I'm hoping to release that sometime soon once I document it and clean it up.\n\nYeah, I was thinking you probably recorded that podcast a month or two months ago, right?\n\nYeah, it's about a month ago probably. Okay, so you've been working on it quite a bit. That sounds cool. I know that's a really common environment to be working in inside of notebooks as far as developing huge amounts of data science. Community feels comfortable in it because it's interactive in a lot of ways. So that sounds like your tool will add to that interactivity and look at these huge datasets that people are looking at and where they could make things more efficient.\n\nThat kind of leads to a little bit about talking about your Python 2020 talk, which is a little bit about how to reduce the footprint of your project somewhat in memory. I had a guest recently on, Hannah, talking about her book \"Thinking in Pandas\" and that led into some similar areas where you guys are talking about efficiency and how to make things run a little bit better, which your site dives really deep into. Your Python 2020 talk \u2013 tell me a little bit about that.\n\nSo I guess the thing I'm trying to do in the articles I'm writing and talks I give in training is like software is an immensely useful tool but there's a lot of rough edges. The infrastructure underneath the nice high-level bits that we like to think about. At some point, you have to understand how the operating system is doing things or how the hardware works. Unfortunately, you can't just say, \"This is the idea I'm trying to express, just do it.\" You have to go lower down and hit that lower-level detail. So, that's what I'm trying to teach \u2013 here's how to solve the problem and here's just enough so you have a better mental model of what's underneath so that next time you encounter it, you know how to approach it. For reducing your memory usage or in order to process large amounts of data in limited memory, there are standard techniques that if you're a programmer, you probably know how to think about it.\n\nI think about databases in that way. If you have any background in that, you would structurally want to make things efficient and work cleaner. But a lot of people don't have that background. So, my goal was to say here are these concepts which apply also for things like using pandas or numpy. Compression is one technique where you can represent the same information in memory with less. It's just getting rid of redundancy. You can do that in a variety of ways. Batching is another technique where you load data in chunks, process those chunks, and then maybe you're done or maybe you combine the processed data. Indexing is the final technique, where you have an index in a relational database to load only the data you need. Those three techniques can be applied in pandas and numpy using built-in facilities they provide or sometimes external libraries.\n\nIt sounds like a lot of what you're doing is similar to some of the training that I would do. I've worked in training for musicians.I did some retail training with Apple. I've done training for phones, computers, and general digital stuff. A lot of it is sanding off the sharp edges, making sure people aren't hurting themselves as they go through the process, and avoiding painful mistakes. The goal is to get them to a point where they can use stuff. It sounds like a huge part of what you're trying to do in the data science world.\n\nIn an ideal world, people wouldn't have to think about this. There are tools starting to work on it, but there's always some level of expertise needed when processing data. Even if you're not an expert in the field, spending time on algorithms gives you a good intuitive model of the data structure. You end up with a good understanding of how to compress the data, which is specific to the data you're working with.\n\nUnderstanding the techniques and being an expert in your own data is useful. It allows you to apply your expertise using those techniques. One thing I wanted to talk to you about was an article you wrote called \"Options for Packaging Your Python Code: Wheels, Conda, Docker, and More.\" I wanted to discuss the intent behind this article.\n\nThe original idea for writing the article came from someone looking into distribution within their organization. They were using one tool that wasn't working well and were exploring other options. The answer to any software question is always \"it depends.\" Having a wide array of solutions can be overwhelming, but it's good to know why these tools exist and what motivates people to use them.\n\nThe article covers different options for packaging Python code and explains the differences between them. By understanding the big picture and the extremes of including everything from just source code to other assets, you can make better decisions on which tool to use in specific situations.\n\nThe scenarios for using these tools can vary depending on the tool and the situation. One big dividing point is libraries versus applications, with the article focusing on applications that can be distributed with wheels.\n\nLast week, I talked about an article on Real Python about wheels and their relationship with pip. We discussed the scenarios for using wheels and the reasons for choosing that option. The article focused on distributing applications using wheels.One starting point is distributing a library, especially if it's open source. You'll want it on the Python warehouse so people can just do \"pip install.\" You might have libraries within your organization that different developers are using for different applications. You might have a local server that serves things that \"pip\" can talk to or even other things. You can give it a URL, have you set up that kind of thing before?\n\nThere's \"devpi,\" a common server people use for internal deploys. You can also just give \"pip\" a URL or even a kit. You just point it at that and it'll look at that repository first before it goes to the outer world, or you can say just use this particular repository.\n\nYou can do things like mirror PyPI's down to record your deploy. You can have your own packages added. Libraries, you'll want to package in that way. Probably what wheels give you is, traditionally, you would distribute this to source code. For a pure Python library, maybe that's fine. But if you have to compile something, that means whenever you install a package, you have to compile it, which can require work in terms like setting up all the compilers and development headers.\n\nIf you're deploying to multiple machines, it's a waste of resources to compile the same thing multiple times. A wheel lets you pre-do that. You would be compiling something outside of Python, like c libraries. If you're working with c or Python or fortran or c plus, your tool would be compiled, and that's where wheels get interesting because you need to target the environment and machine you're going to put it toward.\n\nWhen you install Python packages, it used to be a lot more work because you had to compile everything. These days, much of the time, you don't have to use a compiler at all because the maintainers of the packages have pre-compiled them for you.\n\nYou can also use wheels and then \"pip\" to distribute small applications. Python development tools are distributed that way. For development purposes, that's great because Python developers already have \"pip.\" Beyond a certain point, you start hitting limitations of wheels if they depend on other packages.\n\nPipx lets you wrap around \"pip\" to create a little virtual end for each of your different tools. It ensures they can still call each program and do it differently. Wheels are fundamentally designed for libraries, so if your package depends on other packages, you have to install all of those.\n\nYou can include shared libraries in wheels, but it's extra work. If you're distributing a Windows GUI application, you could distribute with \"pip,\" but the user interface consequences may be confusing. You can shove a lot into a wheel, but beyond a certain point, maybe you don't want to.\n\nWheels, in theory, allow you to shove multiple libraries into a single wheel, occasionally called vendoring. Requests is an example of a wheel that includes multiple libraries to make it easier to install.But it's not like it's extra work and it's not like the tooling isn't really designed for that. So the next step is to say I would like to distribute a thing that has all of the source code necessary to run my application and maybe even some shared C extensions in one file. There's a bunch of these tools that build on zip app, which is sort of built into the Python standard library. But zip app doesn't do like C extensions, so it's of limited use.\n\nThese tools typically come out of large companies like Google, Facebook, and LinkedIn have all built their variants of this. I found a Twitter lightning talk when I started researching it to talk about it in the last episode. He had a longer talk, but then this was like a 15-minute talk on the particular tool pex, and it kind of showed me it was a useful tool even though it was probably seven years ago or something like that.\n\nEven at that point, it seemed like that was a useful tool as they were talking about passing code around utilities or applications inside of an organization. They would say, \"Okay, well, this is where you know the repository where you've put all these packs kind of things.\" So Chris, just to go through the progression, wheels typically include only the code for a library application and don't include the dependencies. Pex and other things like that include both the application code and the dependencies, a sort of little instruction about how, like what tool to run by default. So it's closer to being an executable than a wheel. A wheel is like you install it and drop some files everywhere, but a pex file is a thing you can run.\n\nSo it acts a lot more like a command line tool. And if you are distributing a little program, it's a nice self-contained single file you distribute, and it does not include Python; it's just the code. So it presumes Python's pre-installed. This is where the internal distribution thing comes in. If you're in a large company, you can probably assume that all the machines have Python in a particular version, and they've all been provisioned in the same way.\n\nIt's like saving disk space; you don't have to have an extra copy of Python. So you're not wasting disk space if you have 10 scripts. Think of these as command line types of things that would be run from a terminal or shell. You can use it for a server too, but there's this implied infrastructure, like there's a presumption that you have servers and you're thinking about how much disk space you have and have a way to distribute files. My impression is these tend to be used by people that have managed server farms, virtual or otherwise.\n\nAs an individual developer, it's not clear to me where I would use it, for example. Does that take us to the next level of the system packages? If you're doing a pex, it's typically the Python code and maybe the Python extensions, but sometimes you need system packages. Like you might need to have some system package installed, and the pex doesn't have any way to express the dependency.\n\nIn theory, you can do a bunch of work to shove it into the pex, but more probably, if you're using pex, you're in an environment where you can assume that you've pre-provisioned these servers. Thinking of tools like in audio and video, like tools that on my Mac I've had to use brew to install probably to add like MPEG compression or something for videos or photos. In a scientific environment, they may need to work with compression, decompression, or outside tools. I'm trying to think of other system tools that would need to be distributed like that. Sometimes it's libraries, sometimes command line tools.Like video encoders, maybe you need a command line tool to talk to a server. Without pip or the pecs and friends, you don't have any way to express that dependency. You just have to document that you need it or find something to shoehorn into your package, which can sometimes be difficult or not worth the effort.\n\nAnother approach, which I think is the oldest approach, predates wheels and pecs, are system packages like Linux distributions. For example, brew on Mac OS, and Choco on Windows. Basically, you have the ability to package some software like an rpm or debian package and have dependencies on other packages. This traditional sysadmin approach lets you express dependencies on system packages that you require.\n\nStill giving you the unit of installation where you can install or uninstall your whole piece of software or upgrade it as a unit, instead of just blocking files in the file system.\n\nSorry to take a step back, but what does rpm stand for? I think it's a Red Hat Package Manager. Okay, that's a guess. The deb is the package format for Debian and Ubuntu.\n\nYou mentioned app, like using app to add things to your Linux installation in the same way. In Debian and Ubuntu, you install Debian packages typically, and in Red Hat systems like Fedora or CentOS, you use tools like dnf or yum to install those packages.\n\nThis traditional system administration approach often has the Linux distribution packaging some Python packages already, but you typically want to package them yourself to avoid getting stuck with outdated versions.\n\nConda takes a different approach by packaging everything into one packaging system, separate from system packages. Conda Forge is the biggest and most popular package channel, providing all packages in one place regardless of the Linux distribution.\n\nIt's like the experience of brew, but with Python packages all in one place. Conda Forge is closer to a Linux distribution where the people doing the packaging aren't always the authors of the software.And so, it's kind of like a Linux distribution or Brew in that sense. With Conda, you can have dependencies that are sort of like, which in the other approach. You think of it as your video encoder is a thing installed with pip. In Conda, you would install it with Conda and you install the Matplotlib with Conda as well. They're both just Conda packages.\n\nWow, okay. I'm not familiar with that part of Conda. I had played with it a bit, and it always kind of became this divide between the particular I worked at a bank and we would use an Anaconda initial distribution. I am familiar with adding Python packages through it, but I had never used it as a tool to add those other kinds of tools with it. So I guess that kind of leads to two questions. One is, are all of those things available from Conda directly? Can you search their directory and find those sorts of resources?\n\nAnd then I guess the second one is, how do you create the things? Are you using this Forge as a tool to build the distributions of C shared libraries and other things for yourself to get to?\n\nConda Forge is not a tool so much as a source of packages. You can think of it as a giant package repository with a heavy Python focus, but it also has other programming languages and a lot of packages that are in PyPI that you can install with pip are also on Conda Forge, but not all of them. It can include things like libjpeg, libmemcached, libogg, which is an audio encoding library, and many more.\n\nFor making Hog files, it has these things and also has a lot of the most popular Python libraries typically. For simple Python packages, contributing to Conda Forge is actually really easy, and there's nice automation. Adding stuff is pretty easy, but you can fall back to pip packages if needed.\n\nWhen distributing applications, for an actual application, you might create an environment.yaml file, which is a description of your dependencies. You can also specify additional packages you need.\n\nFor applications, you can't do that, but for your actual application, you do have the ability to fall back to pip if necessary. Especially for data science or scientific computing, there are many packages focusing on that world. Conda Forge packages many of the dependencies you care about, providing cross-operating system packaging.\n\nInstead of having to deal with system packages as dependencies, Conda Forge simplifies the process. It allows for consistent installation across different operating systems. In most of the bank, we were using Windows installations of Anaconda and then using Conda from there.\n\nI could see that's why maybe sometimes it didn't have every single tool because maybe they weren't prepared in that environment.The official conda provided packages are a smaller subset, while conda forge is much bigger but also more freewheeling. It's a community project, which has some downsides sometimes.\n\nImagine if I was a bank, I might be a little bit more wary. That's sort of the next step, a different approach. We don't want system packages; we want this to be integrated, our Python and system packages to be integrated into one package system.\n\nThis week, I want to shine a spotlight on another Real Python video course. It covers the type of Python skills to practice so you'll stand out from the competition. It's titled \"Python Coding Interviews: Tips and Best Practices\". The course is based on a Real Python article by James Timmons, and in the course, James Ooey Geo takes you through how to use enumerate to iterate over both indices and values, how to debug problematic code with breakpoints, formatting strings with f-strings, sorting lists with custom arguments, using generators instead of list comprehensions to conserve memory, defining default values when you look up dictionary keys, how to count hashable objects with a collections.counter class, and how to use the standard library to get lists of permutations and combinations. I think it's a worthy investment of your time to learn the types of skills that will show your knowledge of Python. Like most of the video courses on Real Python, the course is broken into easily consumable sections, and you get code examples for the techniques shown. Check out the video course; you can find a link in the show notes or you can find it using the newly enhanced search tool on realpython.com.\n\nThe next step is to say I don't want my users to even think of this as a Python program at all or a thing like they have a packaging system. I just want to give them a program they run. This might be where you're distributing to people who aren't necessarily programmers, or even if they are programmers, they don't care what language it's written in; they just want an executable. There are tools that let you do that, and they will take all your Python code and your Python interpreter and create a single executable. Pi installer is one of them, I think the most cross-platform one that's the one I used. I created some tools for some other users and I talked about that a little bit, but it seemed like it kind of out of the box really just sort of worked for me. I didn't really spend a lot of time with it and didn't require a lot of additional tools. I definitely needed the environment to match between the two; I couldn't move to somebody else who didn't have a 64-bit machine like if I was compiling it on there or by installing it on there. It needed to be the same distribution across both. I guess the biggest problem with it is that you are making kind of a large file in the sense that it has all of Python with it. Yeah, it has a little Python, and also you end up with this file and you have to distribute it somehow. Maybe then you want an installer like for a Windows installer or maybe a broken organization that has ways to distribute files. So, it just gives you this executable that can run, but then you have to maybe you can distribute it to people like they can download and then how do you update it. So, it just solves the packaging Python and your code and dependencies into one file. If you're using Kakanda, you can use like if you do a conda package some console pip give someone pip install for exe, you're going to have to like on Windows you'll have to create it wrap it with an installer and an update mechanism of some sort, which you can do but it's more work. It doesn't it's harder to scale it out and have variations of things.\n\nI had Russell Keith-Magee of Beware and Briefcase, which is another really kind of a similar tool in that sense. One nice thing is it does add the installer part, which is kind of nice. It'll create an actual MSI for Windows and in the case of Mac, it'll have a DMG, you know where it literally shows like the picture of you dragging into the application folder and kind of handles some of that overhead. The one unique thing is of course the idea of being on mobile devices, which is pretty cool, which they're still working on and kind of geared toward GUI stuff in some ways because he's developing these other Beware tools of toga, which is like this whole GUI environment and trying to replicate all of that stuff. It's a really neat project.\n\nI had a little thing last week where I was talking about these things, talking about your article but also talking about Pi Oxidizer as a project, and I got kind of stuck using it. It's a little harder in the sense that you do need to have an installation of Rust, and I had not used Rust at all. So, I got Rust installed and then I worked with the crates and things inside of Rust, but I only had a couple of hours to play in this environment.I was able to make the example of creating a rebel file and working with that, but once I tried to go beyond that and include additional packages, the documentation started to break down. I was spending a lot more time on it, as I didn't understand the bzl file very well. It didn't make as much sense. Maybe you had a similar experience, I don't know. I hope that's a bazel file. My encounters with bazel have not been fun. It just seemed like the documentation fell apart. Have you used either of those in your own experience of trying to distribute things to other people?\n\nI believe I may have used pi and store. I worked on a project that was using pi installer in the past. I think pi oxidizer exists because it has optimizations for much faster startup that pi installer can't do. These optimizations make it more complex as it has to compile stuff, whereas pi installer is mostly just smooshing some files.\n\nPi installer seems fairly straightforward and like a good starting point. Briefcase is similar in that way. I was up and running quickly. I used to make tools for small businesses to go paperless, and I ended up using FileMaker. Now that I'm doing more in python, I want to do more processing and crunching of things.\n\nI'm looking at some of these tools like pi installer and briefcase as a way of developing things to give to a client. They may not want to open up python or be in a terminal, depending on their employees and team. It depends on what you can distribute to them.\n\nI should add briefcase to the webpage. It's neat. I've been impressed with it. It's still not 1.0, but we talked about that. It's intriguing how creators wait for the right time to release a version.\n\nContainer images go a step further than distributing packages with pi installer or briefcase. They package all the files you need to run an application into one package. It includes everything you need to run the app, even if you need specific shared libraries installed.\n\nContainers make no assumptions about the external runtime environment other than being able to run a container image. This allows for a reproducible runtime environment regardless of the base operating system. You can run the same image on different platforms with the same file system. It's the next step in reproducible runtime environments.I've played with them and used two or three cloud services in my experiments and learning about them. Everything from Amazon to Heroku which was actually a very pleasant experience setting up a Django kind of thing. I haven't used them as much for data science though. I did have Tanya Allard on episode 8 and she was talking about this topic quite a bit about containers and it kind of goes through some parallel things that you've talked about on your site. Creating images through stages and testing for security in the world of data science, which is her focus, also of reproducibility. In that case, you are controlling through this container the operating system, the version of Python, the file system, the database type, and all those kinds of things along with all the other things you were talking about of your code. It's very reproducible and I thought that's kind of neat.\n\nIt's another layer of being a developer to understand Docker. The thing about Docker is heavily you can run when there's a Windows variant of Docker. Have you ever tried to make a Windows OS container though? I'm told it's difficult. I've never actually tried. It's not fun and they're huge too, right? I mean, that's the big problem with the whole idea with a container, hopefully, is to use something a bit smaller for the operating system in the file system, hence the popularity of Linux distributions.\n\nLinux is typically what you'll be running Linux containers on. Linux is based on Unix, which was created in the beginning of the 1970s. Docker builds on Unix and features added by Linux. If you're using Python, there's Python packaging, so basically there's literally like 50 years of technology decisions that all intersect in Docker packaging. Unix signals are sort of this when you hit control C and your program exits on Linux or MacOS. That was designed in the '70s, and it's problematic in a whole bunch of ways. If you don't quite package your Docker application correctly, when you hit control C or otherwise try to shut down your container, that signal gets swallowed and it will wait 10 seconds and say, \"Oh, I guess clean shutdown failed,\" and then it'll kill it with extreme prejudice, the equivalent of doing kill minus nine.\n\nMaybe slow shutdown is a mere annoyance, maybe slow shutdown might have some impact on your upgrade times and your service level agreement. Depending on what you're working on, maybe you don't care, maybe you don't care about security if you're running in production, you kind of have to worry about it. It might be quite important that it runs really well and securely in fast and small images. I have my current list of best practices, like 60 long, and I keep adding to it.\n\nSome people don't have to think about this, but some people do, and it's just a lot of details to get right. Depending on how important it is for you, it might be quite important that it runs really well and securely in fast and small images. Once you've gone through a lot of that, say for your own personal Docker container that you're going to use as a base to develop upon, how many of those 60 things will have been checked off so that you can move forward? Obviously, you're going to have to keep things up to date and pay attention to new developments, but is there a flattening out of the learning curve at a certain point where you've developed a base container?Definitely like it's and some of it. You start doing automatically and some of it, like you create one. Like, you copy paste some stuff. For the really sophisticated use cases, I've created a template people can get. But for most people, you do it once and then you have your own internal thing you copy, and that's fine. So it's not like you're committing to this never-ending new career path. Yeah, it's, but you need to understand how it works and depending on your what you're building, you might need to make sure you have this understanding like security. Or maybe it'll turn out that it just takes a really long time to build the images and so it's worth spending some time there to speed it up. But once you're over the hump, if that weren't the case, I don't think people would be using it as much as they do. It's just this hump you have to get over, so this is why I spend a lot of time writing about it because it is such a useful tool.\n\nYeah, it's just not obvious. And yeah, if you were, I haven't gone through all the resources on your site because it definitely has a huge amount of great resources for Docker. One question I have, though, is if you are, let's say you're way earlier on that curve and you haven't even set up Docker for the first time on, say, your own workstation, and you want to start investing time into this idea because you've seen other people using it and you think it'll be one of the best tools for what you want to do. Do you have real starter resources or are a lot of your resources more in the intermediate kind of area? So far, I get, you know, complete and utter like first-time ever, I don't at the moment have anything for that. Or that's not quite true. I've written a book based on my training material, but you'd have, okay, yeah, called \"Just Enough Docker Packaging,\" which is sort of focused on the packaging aspect but also starts you off with just like I've never done this before, run your first container like, and then package your first thing and then understand what's working. And this is a paid product, and I have a few articles that are about the basics if you want, you're sort of like, you know, first-ever you interact with Docker. The Docker website has some intro tutorials. They're pretty good. Yeah, and they'll get you to a certain point, but then when you hit the point of like, what is Docker packaging actually doing? Like, why, like, just pull up, what do they do next, that's what they sort of hit. That's where you hit this wall, and so that's why I have a few articles and then the book, which are more about these, you've done Docker for the first time and you kind of got a sense of why this is useful and cool, but like you need to understand how it actually works to actually move beyond that, yeah.\n\nI guess kind of related to that, you talk a little bit about, you have an article talking about sort of best images to work with, and one of the popular ones that was out there is something called Alpine because of its size. And I feel like in some way relates to a lot of the things we've talked about so far, in the sense that how it's prepared and not prepared for what you want to be able to do. Can you talk a little bit about that, like what's a good best image to start with? Yeah, and so they're saying like a Docker image is sort of a self-contained Linux file system. Basically, when you're making your own Docker image, you typically start with some pre-existing image and then you add more files to it. It's basically a little bit like a Git repository version control where you have the sort of initial stuff and then you add some commit to some more stuff and commit some more stuff and it all gets like, you're downloading this whole sort of thing with history like it has layers, that's what they call it. And that can be relevant when you think about this image size because the layers, it's like git history like you don't ever, the first approximation, like things don't ever get removed, they just get added, just like you can get history, you can go back and see old versions. So you start with a base image which is like so you don't have to figure out how to shovel a Linux distribution to a Docker image and it provides them for you. People provide them for you, you can build on other people's work. And so you want a Linux distribution because you need or you need at some basic level like you need like the standard C library and you like a few files that Python expects, need Python to be installed, the Python depends on like OpenSSL.So, you can do secure connections to HTTPS and there are a bunch of libraries you need in Python. Docker has the official Python Docker image, which I recommend as a good base image for your own Docker files. It is a good starting point to build on because it is based on the stable version of Debian Linux distribution. The stable version of Debian Linux guarantees security updates for packages for a number of years and ensures stability without changing things unexpectedly.\n\nIf you rely on a C library or something like that, it provides a stable base to build on. The official Docker images for Python take a Linux distribution, usually Debian, and install their own Python on top of it. This allows you to get the latest Python version even if Debian itself does not have it. This combination provides access to thousands of packages, stability, security updates, and the latest Python version.\n\nThere is also an official Python image based on Alpine Linux, which is smaller and faster for package installations. However, Alpine Linux uses a different standard C library than Debian, Fedora, or CentOS. This difference can cause compatibility issues when compiling binary wheels, leading to longer compile times and additional steps to manage image size.\n\nOverall, the choice between Debian-based and Alpine-based images depends on the specific requirements of your project. Debian images offer convenience and compatibility with most packages, while Alpine images provide faster installations but may require additional effort to manage compatibility issues and longer compile times.If you're a Python programmer or data scientist using Alpine Linux for Docker images can result in longer build times. It's one of those things people shouldn't have to think about. These weird gotchas shouldn't take up your time. You just want to run your software and write code, but these issues can cause long builds without explanation.\n\nYou also have to figure out how to compile packages like Matplotlib, which can be a pain. Avoiding Alpine Linux is typically a good idea for Docker packaging in Python. It's popular in other languages like Go, JavaScript, and PHP, but for Python with C-based libraries, it's best to avoid the hiccups.\n\nUsing Alpine Linux can help make Python more efficient and avoid installation issues that can go from 30 seconds to 15 minutes. It's challenging to install packages that aren't binary wheels, especially for scientific computing with compiled code like TensorFlow.\n\nThere are tools like Pi Installer, Pi2Exe, and Pi2App for specific platforms, as well as Singularity for data processing applications. Singularity is less popular but designed for data science and scientific computing, allowing access to local directories and running as the current user.\n\nIn addition to briefcase, there are other tools like Pi2Exe, Pi2App, and Singularity, each with its own use cases and advantages. Singularity is more niche but can be useful for certain applications like data processing. Docker focuses on isolation, while Singularity emphasizes accessing local directories and running as the current user.\n\nA follow-up article could explore how packaging works with Singularity's own packaging system and the ability to convert Docker images. This comparison could provide more insights into the advantages and disadvantages of each tool for data processing.Yeah, do you have time to answer a couple of weekly questions that I ask everybody? \n\nThe first one is, what is something that you're excited about in the world of Python? It could be anything from a package to an event or an editor. Something going on in the world of Python that you're excited about right now.\n\nSort of the silver lining of being in a global pandemic is that a lot of conferences are now online. It's interesting being able to give a talk in a European conference. I wouldn't be able to do that before. It was really impressive how they expanded it hugely from being in person to online. They added more time zones and talks from all over the world. It's amazing to see how they ran it, and I'm happy to see people finding ways to continue building community even in the face of the pandemic.\n\nI'm still sad about missing PyCon, which I've been going to for years. It's a chance to meet people I don't see more than once a year. But I'm happy to see the ways in which people have managed to continue these conferences and build community.\n\nMy talk at EuroPython was about Docker packaging and specifically best practices for running in production. I talked about a process for organizing packaging, starting with critical things and then moving on to less important things so you can leave it in a good place even if you get interrupted.\n\nI think they were posting the raw, unedited versions of the talks on YouTube. They might also be doing video editing and posting the edited versions publicly.\n\nThe other question is, what are you interested in learning next? It could be Python or beyond. I have a book called \"Statistical Rethinking\" on my desk that I've been trying to learn about Bayesian probabilistic programming. It's written for the R programming language but has been ported to Python.\n\nI want to do some data analysis for the local candidate for the municipal elections and see if I can build a statistical model for the next election.\n\nThe book is called \"Statistical Rethinking.\" I did some research to find a starting point for learning Bayesian modeling since I took a statistics course a long time ago and didn't quite understand it.\n\nDavid Amos, my co-host, brings articles from PyCoders, and that's how I found out more about what you're doing. He mentioned a resource on YouTube called Three Blue One Brown.He had one video that I watched because he was talking about a library for how he does his graphics in Python. He was explaining these concepts in his video on Bayesian theory, and it was very interesting. He's very good at distilling information and using graphics to reinforce it, which I think is useful. That sounds like a cool book.\n\nIt's aimed at scientists and sort of guides you on how to analyze data in the context of statistics. It also touches on the modeling process. I've read half of it a couple of times just to grasp the concepts, but to really learn it, I'll have to do the exercises. I haven't quite gotten to that yet.\n\nYou mentioned there's a repository with stuff in PIMC that goes with it. I think I possibly found it through the PIMC website because they have books you can learn from, and this one seemed like the most aligned with what I wanted.\n\nThank you for coming on the show and sharing your knowledge with me. Thank you for inviting me.\n\nI want to thank Edamar Turner Trowing for coming on the show, and I want to thank you for listening to the Real Python Podcast. Make sure you subscribe to the podcast in your favorite player, and if you like the show, leave us a five-star rating and a review. You can find show notes with links to all the topics we discussed inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey and look forward to talking to you soon.",
    "c6KzObF__TU": "Welcome to the Real Python Podcast. This is episode 26. Why is Python pulling in so many new programmers? Maybe some of that growth is from Python being a full spectrum language. This week on the show, we have Michael Kennedy, the host of the podcast Talk Python to Me. Michael reflects on five years of podcasting about Python and many of the changes that he's seen in the Python landscape.\n\nWe discussed several stories about the different ways that Python is currently being used and how that is drawing in many new programmers. Michael covers some potential Python stumbling blocks of async, the Python Global Interpreter Lock or GIL, building desktop apps, and type checking. We also talk about how podcasts can act as a form of language immersion, so let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at RealPython.com. After the podcast, join us and learn real-world Python skills with a community of experts at RealPython.com.\n\nWell, welcome to the podcast, Michael. It's great to have you on. It's fantastic to be here. Thank you. I'm excited.\n\nSo I partly wanted to have you come on to talk a little bit about the landscape of Python. I'm newer in the world of Python programming. Specifically, I was programming in a lot of other languages and sort of landed in Python two and a half years ago and started to really dig in. I wanted to have you on to talk a little bit about your history with Python over the last five years and being this podcast host with your show and some of the changes that have happened over the last five years. We can kind of dive into there.\n\nWell, yeah, that seems like a good place to start, right? Where have we been and where are we going? I think when I got into Python at least six or seven years ago, I was getting into the language and then the podcast I did that a little bit after, not much after actually. I was pretty new to Python when I started podcasting and I started Talk Python. I did not start that podcast because I thought I was this expert in Python. I wanted to hear stories like the one that we're going to share today, and there were no podcasts. My journey started pretty close to around then, and it's kind of amazing to see it. But that was the heated debate of whether Python 3 is just wrecking the community or is actually a great thing, right? It was still a debate of whether you should even bother about Python 3 and if it makes sense to migrate your program over to Python 3. Looking back from 2020, that's a ridiculous statement, and I was always on the side of, I don't understand why you wouldn't want the new library features and all the core developers were working on Python 3. They were not working on Python 2. So all the energy at the foundation was being put into Python 3, so it was confusing to me. But I think we've actually figured that out. I think we can say we're beyond the 2-to-3 debate and we're just in modern Python land.\n\nI always thought it was funny. You guys on the Python Bytes podcast of the death clock, yes, kind of fake attention. That's about when I started was when you guys started to ramp that up, and I was like, \"Oh, wow, okay, it sees it.\" But I thought it's not PythonClock.org, it's Oregon maybe. Let's see, is this still there? Yes, it's still there, PythonClock.org, but it just took down to zero. So yeah, it's still there. Yeah, I think we're past it. You know, the one thing that I wish we could have seen was supposed to have PyCon back in April, right? That was the first PyCon after the official retirement of Python 2, and I was hoping for like a big celebration with Guido, other core developers, and whatnot, and like a big community acknowledgement of like, \"Wow, it took eight years, but here we are on the other side of this, how amazing.\" And you know, we just didn't get that opportunity, but I think people don't hear people talking about it very much these days, so it seems like we're in a really good place.\n\nSo that's one of the big things from that whole ecosystem. I think that's the biggest, is the beyond the 2-to-3. Well, yeah, I can imagine that those are a lot of the conversations maybe early on were still struggling between both things or that whole transition of, \"Okay, we gotta get this code base moved forward.\" I know I had Longa on to talk about his recent Python talk, but I know you've talked to him before about some of the stuff too of what was happening at Facebook and then moving their code base over.\n\nYeah, absolutely. He's a big proponent of the type hints, which also come in Python 3, right? Yeah, not even early Python 3, but later Python 3.But yeah, over at Facebook, and specifically Instagram, I think was his area. They did a lot of work to add type hints and mypy type checking, and they found that they've discovered and removed a bunch of bugs and cool stuff like that. All that stuff for being a dynamic language is a really great way to help with testing and moving everything forward. I'm a big proponent of it even though I'm kind of new. It's one of the first things that I wanted to learn, and that kind of leads me to us talking about the whole idea that you have a similar starting point as I did. That's how I found your podcast, as I'm one of those people that really like to immerse myself into this kind of element. I feel like, \"Okay, what are all the Python books?\" That's how I found Dan and what are other resources. So I found your podcasts, and then kind of going from there, is that a similar experience that you had?\n\nIt is, yeah. I think there are just so many resources out there now. There were a lot of resources then, of course, there was Stack Overflow and YouTube and stuff. But it seems like there are a lot more people who are taking this idea of content creation for Python developers and people who need to learn and get better at Python, and they've taken it to the next level like Dan and Real Python and all you guys definitely are in there. I ended up making that my full-time job thinking of some of the folks on YouTube, Syntax, Corey, those guys, they're really focused on it. Even if you look at the more traditional training companies, some of the big online catalog places and whatnot, they've all started to embrace Python much more.\n\nI also think one of the big stories kind of in parallel with that is the embrace on the enterprise corporate side of embracing Python. Python used to feel much more like the rebels, like these are the independents and they're using this funky open-source language. But when you put on the tie and the suit and you go down to the main company, it was Java, it was .NET, it was these more traditional languages with support contracts from Oracle or from Microsoft or something like that. Now you look at Microsoft and they're all about Python and things like that. It's a different world, but it's such a good world though.\n\nOne of the questions I used to ask as a weekly question that I thought was really clever, but then I kept getting the same answer was, \"What is something that you thought you knew about Python but you were wrong about it?\" The answer that I would get most commonly was, \"Oh, I thought it was a scripting language.\" After about five or six of those, I was like, \"Okay, maybe this isn't the best. Maybe I need to rephrase the question or figure out some other way around it.\" But I think from, I guess, I don't want to call them old-timers, the people that have been doing Python, like somebody like Brett Zlatkin who's working at Google, and some of the people from Microsoft and so forth, I think you're right, that whole rebel alliance kind of idea that they're coming in and using Python in these new ways, but initially, Python was thought of as just a scripting tool that I can use to write these simple programs. But the evolution is pretty large.\n\nThat's a really interesting way of framing it as a scripting language. People ask, \"What's your favorite scripting language, bash or Python?\" To me, it's just like seeing a little tiny sliver of an iceberg or the periscope of a submariner going, \"Oh, look.\" What kind of stick do you like to drive around? It's like, \"Well, that technically is a driving stick, but if you understood more of it, there's a lot more going on there.\" So much more.\n\nThere's just so much more, and whenever I talk about Python programming or in my courses when I'm presenting a program, I don't say, \"Let's go use this script.\" I always refer to it as, \"We're going to build an application.\" And I also think that gives you a different mindset. If I'm building a script, I'm going to have one file and I'm going to cram all the stuff into it, and sure, it's 2,000 lines long in the end, but whatever, it's my script. If you're building an application, you think about the parts of it and the layers and how you break it apart. Here's this part that accesses the email API, and that's a hundred lines of code over in this section. Here's the part that handles authentication, and it's another, and it just gives you a different mindset entirely about what you build, what is possible, what expectations there are of you as a developer to build it correctly with tests and patterns and factoring correctly and whatnot. It's really interesting because it starts you down this little path that sort of diverges, but in the end, it's massively diverged where you end up.Yeah, I think it leads to something that we were discussing earlier, the idea of Python being this full spectrum language. Do you want to dive into that? Yes, I would love to dive into that.\n\nSo I just talked about how Python is great and you can do all these real CS things. Right, it has generators, classes, all the high-end lambda functions, functional programming, all the high-end CS ideas. But I don't think that's why Python is so popular. I think it's popular because it's this thing I call a full spectrum language.\n\nIf you think of programming languages on a spectrum of beginner-friendly, expert developer-friendly, or pro application-friendly, maybe also put on that spectrum somewhere like productivity or something. Okay, there are a lot of languages that live on the left hand of that spectrum where beginners are happy. That could be sort of funky compute environments like MATLAB, it could be VB like Visual Basic VB, where it's really incredibly easy to get started and get something up and going. The problem is you can't take those things to the other end of the spectrum, right? Nobody would say let's go build YouTube in VB or let's build, let's take our MATLAB program and turn that into a true analytics API. Right, you just, you're like okay, we're done with this language, we have to drop it and switch to a \"grown-up\" language, right, where we do professional stuff. And that's a challenge, right? Like if you learn the one thing, it's hard to make that transition in the same way or be happy making that transition.\n\nBut Python is special because more than almost any other language I know, you can be very effective with Python with a partial understanding, a very partial understanding of what the language is, what it does, or even the concepts in it. So for example, imagine I'm a biologist and I have a research lab. I've got a bunch of data I need to transform it, and then group it, and then I want to do a little analysis on it and then graph it, and maybe there's a library that understands the file format. I know I could use Altair to graph it and that would be great. I could go and write a Python script and probably just what they would think of it as that has like five or six lines like load data file, make transformation, do grouping, show graph. They don't even really know about like the dunder name equals done domain, they don't know about functions or classes, and yet they've built something. If they showed it to somebody, they'd be like \"Wow, that looks pretty awesome. I didn't know you programmed. How did you do that?\" And they never think of themselves as a programmer, so that's like the way left beginner side of that thing. But then over time, it grows and you need more to do a little bit more like \"Well, what if I want to pass different information and reuse the same computation?\" Well now you need a function, let's learn about functions. And then, \"Oh, I want to share this, let me learn about packages.\" And it just slowly grows until a couple years later, that biologist is like \"I'm kind of a programmer, how did this happen?\"\n\nYeah, but there's no point where it goes \"Oh, I have to be a programmer, let me go learn C++ so I can do this for real.\" Like you just keep going with Python. I was just reading an article today that the folks in a UK university took the data from the Kepler space telescope that looks for exoplanets and they used machine learning and AI to find like 50 additional planets in the data that nobody discovered. Wow, that's still Python, right? That's not like, \"Well, they switched to a real language.\" It goes all the way to the state of the art scientific computing or like YouTube is written in Python, which is processing a million requests a second. Million requests a second in Python, right? And Instagram, we already spoke about them, like there's just so many high-end things. So when I say it's a full spectrum language, it's like really beginner-friendly as much as any language you can imagine, and yet you don't have to abandon it to get to the professional apps that you might want. You can go use Flask or FastAPI or TensorFlow, whatever, you just keep going.\n\nYeah, it just keeps on growing. That's kind of where I started with it, was trying to be a problem solver within the programming space and working with these small businesses. The thing that excited me very quickly with it was as I did my immersion and trying to find books and so forth, I ended up seeing all of those paths. I was working in sort of a data science sort of shop inside of the bank, but I was the one being requested to build tools, to build things that I could stand up, and everything was there. I wasn't needing to necessarily leverage all these additional other languages to stand things up. I could do almost all of it within Python, which was very exciting to me. Yeah, I think the opportunities just keep revealing themselves as you get farther and further in.Right, you solve one problem with a little bit of automation and then you're like, \"But this other thing, now that's not the thing that I do all the time. There's this other thing that's constantly bugging me. So how do I automate that?\" It's just these little steps. If you keep taking those steps, you end up in a place where you're just so different from your colleagues who are not doing that kind of stuff. Even if you're not a programmer, if you're a programmer, it's a different story. But if you're not a programmer, but you adopt these little things like you're describing here, it's night and day what you can accomplish.\n\nIt'd be great if we could get that data off that website, but it's just in the web page and then it's all in HTML. And then if we could process it and graph it, but Excel doesn't like I can't Excel that, not easily. Well, a little web scraping, a little Beautiful Soup, a little bit of Pandas, and we're done, you know what I mean? It's just so different. So, yeah, one of the things that I think that has led to another thing that we were kind of discussing initially was talking about the growth of Python. That's something that I don't have as much history with, but I think you've probably seen, you know, just even with the growth of your podcast and the growth of the audience that you've been seeing. You want to talk a little bit about what are the areas of growth that you've seen with Python in the last five years?\n\nSure. So, the way I think about the Python space, I don't know how accurate this is, but this is my mental model: there are three equal-sized slices of the Python ecosystem. We've got the web developers, these are the most old school of us and I count myself amongst them. This is one of the first main areas that Python really was shining. Then we have the data scientists who are doing all variety of stuff, and then we have \"other,\" and I think that \"other\" is also a third, is probably about a third of the size, and that's just everything. It's those people that are automating Excel, those people that are doing a little bit of web scraping, it's the DevOps, it's the, there's just so many things.\n\nIf you look at the growth of Python, I think it's grown a little bit for the web folks. It's definitely gotten better for the web folks like FastAPI, Flask is really coming on strong. There's just so many cool things happening on the website. There's so many web frameworks that are people are creating and iterating and coming up with something beyond that. They're so much more mature too, yeah, you know, as we kind of look at them, like just things with like what Django, just in my time of jumping into it went from 1.11 to 2 to now 3, you know, and that's like in a year and a half or two years at most, and it's just amazing all the things that they've added and the maturity level of what those tools offer.\n\nAbsolutely. I think a lot of the recent innovation has to do with the dropping of Python 2, by the way. Like as soon as you say we're going to embrace the Python 3 features, well, all the older frameworks, they didn't. Right, they weren't built around the assumptions that you had those things there. They weren't built around the assumption like of course you could do async and await, why wouldn't you? Or of course you could have type information and that type information means something like tools like pedantic or FastAPI and so on, all super interesting stuff there. So in terms of the growth, like that's a vibrant area and I think it is growing.\n\nBut if you look at where the real growth came from, I believe it's from that scenario that biologist I described. It's people who don't even consider themselves Python developers, but they realize I can probably solve this problem with like 10 lines of Python. Yeah, and then they iterate, they make a little bit better, they have some success, and they just keep growing and they kind of get sucked into the gravity well of Python. And I mean that in a good way, right? Like they're like, \"Oh, I could also use this other library.\" Oh, and now I've learned a little bit more about the language, I can write a slightly better program, and they just slow, it pulls them into the whole world of programming altogether. So I think there's many, many people out there who don't or at least initially did not consider themselves to be developers, but then they did a little bit of computational programming and over time, they sort of mastered it. They become very powerful on their tool set, and now they're doing daily Jupiter stuff.\n\nYeah, and if you look at some of the data computation conferences, it used to be like, \"Oh, we're using Julia and R in around 2012.\" A lot of that stuff switched to Python and Jupiter, and if you look at the stack overflow trends, guess what, there's a strong inflection point right around the maturing of all the Python data science tool sets. It's just like there's a strong curve that goes up right there, and it's like those are the same people coming over. Yeah, that stuff is so exciting to me.I really love the data visualization area and all the different packages there. At the same time, I was starting to learn Python and also learning some of R. I could definitely see partly what you were talking about before. R is really great at a handful of different things and is definitely a useful tool in data science, but it's not really a full spectrum thing.\n\nYeah, it's super specialized and when you're doing that specialized thing, it makes a lot of sense. But if you move beyond it, then it gets really hard. Absolutely. So over the five years of your podcast, what were some of the stories that you could think of that kind of show off these trends of the development of Python and the community over this time period?\n\nI'll highlight a couple for you. One of the ones that I thought was really interesting in the early days was talking to Mahmoud Hashemi, who's been on the show a couple of times. He's done all sorts of interesting stuff. When I looked at the Python space, all the conversations, especially five or six years ago, were about small websites or Silicon Valley tech startups choosing Python. But traditional corporate S&P 500 type companies were still using Java and .NET. It was really interesting to talk to Mahmoud about how Python is being used in the enterprise.\n\nThere are so many cool success stories that break a lot of misconceptions. For example, over at PayPal, they have some APIs, microservices, and a Python API that gets called billions of times a day. It has a couple of millisecond response times and uses a tight little binary format. These stories are important to show the success of Python, which can drive adoption.\n\nIt's a double-edged sword in the sense that you need people familiar with the language, but you also need shining beacons that show what's possible. For example, in the school I was working at, I introduced a tool called Mainstage from Apple to recording engineers. Adoption was low until I showed an article about Nine Inch Nails using the software for a live show. This example helped people see the potential of the tool and drove adoption.And it's like, you really should understand computers because that's really the wave of where this stuff was at. Years ago, when I was trying to be this person evangelizing that kind of stuff, I can imagine that's an experience that people have with Python very often. You have to have that thing to show someone to say, \"Hey, this is amazing.\" Like you've been saying, Instagram and Facebook, and even these like that PayPal thing is, again, like, \"Hey, APIs can be written in Python, and it's actually really powerful.\"\n\nWhat we can be doing with it is nice. It's also approachable and readable at the same time. Another aspect of all that is if you look at the Stack Overflow developer surveys, which is a great source of general developer community trends and interests, if you go to the section on most loved and most wanted programming languages, Python is either number one or it is right there. There you go. So, if these big companies think about, \"Oh, all of our employees keep leaving, we've got to hire new ones,\" I don't know why they don't like to work in this restricted environment where it's like half cobol, half Java. Surprise, they're finding more interesting stuff to do.\n\nIf you can work in languages that developers really want to work in, you can get the best people to come work for you. Because you can say, \"You don't have to do Python on the side and C++ during the day. No, you can just work in what you want to work in.\" For me personally, I will not work in another place if I had to go get a job using a technology that is not one that I really care about, unless I have to. But if there is another option, even if it pays less, there's a good chance that I would still go do that because all day long, I would be happy writing code in what I want.\n\nYeah, no, and that's what's kind of fun about it too. You know, kind of going a little bit into the community, I think too of the people that I've met that are programmers in it. When I was doing my immersion and trying to learn all the stuff that's there, the community in general was sort of positive-leaning and willing to engage. I was trying to, at the same time, maybe just a little bit before I started in Python, I kind of dove a little bit into JavaScript and I had a real hard time ever clicking with any of the things that were happening.\n\nIt felt very exclusionary in certain ways of like, \"Oh, well, you should be using this tool. Why are you even bothering with that tool that was last week?\" That's exactly my feeling about JavaScript as well. I feel like there's just no sustained thing, right? It's always, \"Okay, this is fine. Our very next goal will be to try to replace this with something better.\" Yeah, I admire that, but on the other hand, it's kind of frustrating to say, \"Every six months, the thing that you thought was awesome and important is not just slightly less interesting, it's looked down upon.\"\n\nIt's like, \"You're still using that? Vue is so 2019, what are you doing?\" I'm like, \"I'm still writing a video, I don't care.\" I also get that feeling that there's impatience or something in that community, where Python is also changing quickly, but I don't feel like it has that same aspect. It's a little more appreciation of where we come from.\n\nThere are some growing pains, obviously. You've been through that with the whole 2 to 3 transition and even with the newer revisions coming out, there's grumbling about, \"Why is there this focus on this? Why is this focus on that?\" But across the board, partly why I was super excited to get into this community was the wanting to share, grow, and see success in everyone else. It felt less competitive and more cooperative.\n\nI really agree. I think it's also interesting to talk about the rebels in a positive way. I think you talk to some of the folks like the guys over at Anaconda Inc., and it's interesting that all these corporate folks are coming in who have had a different relationship with technology.So if you're an open source, you kind of know like we're all in this together. We're all rowing, let's go. You can't just go to a project and say you have to do this for me because it's their project. They love it and if possibly, if you can convince them it's a good idea, then it'll be there. But if you come from working with Java and Oracle and you've had a service level agreement that if anything is not right, these are the people you call and you tell them how it's not right and you get them to fix it. If you're an enterprise developer who's not super passionate and it's just your job, nine to five, you do your job and you go home. You don't really love the technology of it, but that's what you do. And somebody comes and says now you've got to learn this new language, you've got to learn this new technology and make it work over here. And when it doesn't, you get frustrated. You're like well there's no one here to help me. How do I go and file a frustrated issue on a GitHub repository and have them fix it when really it's their spare time contribution to the world. It's not their responsibility necessarily to fix that problem.\n\nOh yeah, so I think there's going to be an interesting tension as Python becomes more popular and more adopted in the world where those deadlines matter. People are used to having a company there to support them. What's going to happen when it's not? Do you feel that this growth in enterprise, do you think there's a reciprocal aspect of the enterprise giving back to Python? I mean not only with users and people adopting it, but financially and other ways of support. Have you seen that? I've seen it somewhat. I would like to see it a lot more.\n\nYeah, I find it nearly unacceptable that a bank can have their core trading engine and their fundamental internals running on Python and they don't contribute 100 million a year back to Python or something like that. And there's like two of the probably top five largest banks in the United States are running on Python in major ways. Like one of them has 35 million lines of Python code, another one has I don't know how many lines of code but 5,000 Python developers. That's a lot of Python, wow. Just from a personal well-being, you think like we got to make sure that this technology is stable and on point because we're so built upon it, right?\n\nAnd I just think we in the Python community define the right way for those organizations to see the value in supporting the community directly. There's things that are really expensive in the Python space like the bandwidth bill for PyPI as in pip install is something like 40,000 a month. There's so many things we could do if those companies stepped up. Not to just single out banks, but those banks clearly have a lot of money and a lot of reason to support it. But if those companies just said you know what, this is really important to us, we're going to contribute one million dollars a year to support this organization. You don't need many organizations like that to support the Python space before it transforms how stable and how much it can accomplish. For example, the PyCon conferences are the primary way in which the PSF is funded.\n\nYeah, that seems crazy to me. It seems like if all of they get so broadly used and consumed, it seems like that there could be more. But yeah, so I do see them doing it. I do see the tech companies doing a little bit more. But I think that these more mainstream companies, there's just not a mechanism like a donate or a sponsor with no return value is just not the world that they live in. So I don't know what the right answer is, but I hope that we can find something to capture that value.\n\nOne of the things that, having worked in the bank, there's these acts, if you will, that are designed inside of the companies that the bank has to give back to the community. You know, that they're based in, yeah. That's part of a financial thing and it's somewhat regulated and I don't know, I mean that's really maybe overstepping the bounds of this, but something like that where it can be seen as affecting a community or this larger community of developers and so forth. So that these people that are sometimes it's literally their weekends, what have you, to continue to building on the support there. I don't know how to change the focus but it's something I'm very interested in and would definitely want to bring in some people from the Python organization and talk a little more about like okay, well what are ideas and plans and things like that. I'm having a group of people from pip, yeah. Hopefully talk to them soon about, I know they were talked on Brian's podcast recently and so I know they're trying to talk about enhancements there. But I want to also maybe talk to them a little bit like you said, the hosting bill sounds crazy.So I believe fastly the CDN is donating so all the stuff is donated, right? Like the hosting bill for pipeyi.org is covered, the bandwidth bill for fastly is covered. But imagine what happens if they decide that they no longer want to donate that much bandwidth, right? Everything's in a bad place all of a sudden. And if you can't pip install anything, your automated deploy to Kubernetes at your bank is going to stop working. And all of a sudden, someone's going to pay attention when the bank site, the trading systems go down or whatever, right?\n\nThis week I want to shine a spotlight on another Real Python video course that covers a topic we touch on during this week's episode about how to wrangle Microsoft Excel files using Python. It's titled \"Editing Excel Spreadsheets in Python with OpenPyXL.\" The course is based on a Real Python article by Pedro Pregrero. In the course, instructor Joe Tatusco takes you through how to read Excel spreadsheets and iterate through the data, manipulate spreadsheet data using Python data structures, create simple and more complex spreadsheets, format workbooks using styles, filters, and conditional formatting, enhance spreadsheets by adding images and charts. I think it's a worthy investment of your time to learn how to use Python to manage and automate processes with these extremely common spreadsheet files and workbooks. I think it could save you and your office tons of time and frustration. And like most of the video courses on Real Python, the course is broken into easily consumable sections, and you get code examples for the techniques shown. As one of the newest courses on the site, it already has transcripts with closed captions ready to go. Check out the video course, you can find a link in the show notes or you can find it using the newly enhanced search tool on realpython.com.\n\nSo what are some other stories you've seen of changes in growth in the Python space? Let me tell you one that kind of highlights this full spectrum thing. I've seen that a lot of folks who come on and they're not, you know, they're just doing some kind of science, but it turns out that Python is really good for them. This guy, this is a show that I mentioned a lot because it really breaks a lot of paradigms, and it's one of these things that like you can look at and say, if that guy can do that, I'm fully underperforming and I should be able to just do so much more. Why? I just need to think bigger. I got this message from a guy named Cornelius Van Lit. Cornelius is a PhD researcher who's also a monk, a very interesting guy in the Netherlands. He works at a university doing research on medieval philosophy in the Islamic world, so like 980 type of timeframe, right? Yeah, so he studies humanities, works with a lot of folks that are kind of in the library science side of things. That doesn't sound like a high-end programming sort of role, and how are you going to apply programming to this? So he said, \"Hey, I want to talk about Python,\" and I got this cool story to share. I'm like, \"Okay, you gotta convince me somehow that this is gonna work, right?\" But I'm so glad I had him on because he is using Python and OpenCV and computer vision to understand these calligraphy manuscripts from a thousand years ago. And there's certain things you can learn, like if you look at the shape in which the scrolls are folded, there were patterns at different time frames. So if it was an 800 AD scroll, it might have this type of folding, and if it was a 1200 timeframe scroll, it would have a different way of being folded. If you were writing on it, it would have this ornate stamp that's like your signature, but it's a picture in a really complicated way that's not just your name and whatnot. And he's using OpenCV to identify those stamps, create a graph database to look at the collaboration relationships across different philosophers, to look at that folding pattern, to automatically classify what timeframe the work was performed in. All of those kinds of things. And he's just taken something that seems like it's not super understandable by computers, there's not like really, it's not like, \"Well, we're doing finance, so Excel, and then a little bit more.\" It's really far away from something that looks like easily understandable. It's not even written in computer form, it's like calligraphy. And he's applying these cool technologies to it and just being able to answer questions, you know, like a thousand times bigger than the other people who studied this stuff. That's pretty cool. I mean, that's something I've, I don't have the CS background, again, I've kind of bounced around lots of different languages, and that idea of graph theory, it would be interesting that he would sort of land into it in the sense that he has this subject domain of knowing these particular philosophers, and I'm guessing the people that are doing the writings, they may be somewhat separate, you know? Somebody's actually taking the dictation and writing it down or translating it and so forth, but to see the relationships across the time using all those different markings and the images that he's able to gather, that's pretty cool. Yeah, it's really cool.And now he's a big proponent going around giving talks saying all of you people who think you should run away from computers and they're wrecking books and they're wrecking all this long-form reading and like you need to embrace this now because those of you do are going to just leave everyone else in the dust.\n\nYeah, just the amount of time that it would potentially speed up for him. When did you talk to him?\n\nThat was in 2019, almost exactly a year ago. That was episode 230.\n\nOkay, so I was just such an interesting guy, and I think it really tells the story of here's somebody who has a question they can take a little bit of Python and they can be much more effective and not in little steps but in big steps, right? Like, per here's the thing, like I wouldn't think, \"Oh, I can solve that problem with computer vision,\" you know what I mean? Like, I just don't usually think, \"Oh, I can apply this crazy thing, or I could create an artificial intelligence that's going to go do that,\" like I'm more like I can probably create an API or something, you know? Right, so even for me, I don't know that I would have thought that big to do it, but the fact that there's like this grand vision plus a little bit of code knowledge. Right, because it sounds like it would take a, you know, computer science PhD and like image recognition sort of work, but it doesn't. And so that's why I really like the story because it reminds people that they can think bigger and do these amazing things and they probably can be successful doing it, yeah.\n\nIt's totally sort of inspiring in a lot of ways, you know, the idea of using these tools to do the problem solving, which is always things that I kind of come back to is that that's really what we all are as is you know this person might have had a form of frustration and wanted to stand off some of these hard edges and definitely speed up what he's doing but also potentially uncovering you know there's stuff that the computer vision can see that you know somebody's not going to see themselves and be able to have the computer remember things for you and be able to spot the relationship.\n\nYeah, there's a lot of interesting stories around that kind of stuff with like machine learning and oftentimes that means Python. One other thing that we did is we had folks on about how machine learning is being used at I think it was CERN but also at Stanford.\n\nOkay, yeah, they were using machine learning to look at the particle traces out of the Large Hadron Collider and trying to understand when they're discovering like Higgs boson type things or they're discovering a new quark that they didn't know about or things like that. Really, really interesting stuff that people are applying these amazing ideas to. It seems like there's just no end of these stories, they just keep coming, you know.\n\nThat's cool. How are you finding these types of guests? Are a lot of them reaching out to you, or are you like kind of reaching out to the community and asking for the voices? How's that changed for you over the last five years?\n\nIn the very early stage, it was, \"Here are five things that I know about Python that are interesting to me, and I know who's behind it so I'm going to reach out to them. I'm going to reach out to Mike Bayer from SQLAlchemy and we'll talk about SQLAlchemy because that sounds fun and reach out to Chris from Pyramid web framework and talk to him about that,\" and so on. And pretty soon I ran out of ideas that I knew about or who to reach. In the early days, it was a lot of, \"Okay, well what else is out there that I don't know about looks interesting.\" It was a lot of like seeking out stuff. And now it's just a never-ending inbound supply of like, \"Hey Michael, that was cool, did you know about these other three things that are amazing?\" And so, yeah, that's cool. Yeah, that Large Hadron Collider article is episode 144 over at Talk Python, where I had Michaela Paganini, Michael Kagan, and Matthew Feigert and they're all talking about the amount of data that the Large Hadron Collider generates. It's one of those things that just boggles the mind, like you can't write it to disk fast enough. There's not enough disks to put it in, right? So there's all these layers of you have to process it here and filter it down to only the interesting stuff, and then you take the interesting stuff and you feed it to like a C++ layer that can condense it and pull some stuff out, then you feed it off to a Python layer to analyze it. There's just.\n\nYeah, there's some cool videos about how much data flows through those systems also some of another interesting thing I don't know if I've done a dedicated show on it I would like to. I've tried to, I don't know, I don't think I was successful not definitely not as a main topic.\n\nYeah, is the use of Python in astronomy, okay, and controlling telescopes in terms of processing the data that comes out of the telescopes like I said they, you know there's folks who are using machine learning to find the exoplanets. That's just awesome, you know.One of the notes that I saw on our document was about async. I know that was a conversation that kept going back and forth for a while. You even created your own teaching resources on async. I feel like it's one of those topics that is very interesting in the Python space. There are a couple of things in the Python space that haven't been supported or are so hard to do that people don't see them as part of the spectrum of tools.\n\nLet me give you a side example before we talk directly about that. When was the last time somebody gave you an application that you could download from an app store or an installer that you could put onto your computer, into your dock or taskbar, and double click it, and it had a window that was written with Python? Basically never, right? There are a couple of examples, but almost never.\n\nThe reason is it's hard to do. When I talk to people and say Python is really missing out on this desktop application thing, a lot of us sit down and work at computers. The CLI is great, but GUI apps are still really important to a lot of people, especially outside the developer space. They're like, \"I never really build desktop apps so I don't know why I need this feature in Python.\" The reason you don't build desktop apps is because it's nearly impossible. It's this chicken and egg thing. There's not much energy being put into making it super easy.\n\nI wonder if there is some of that where, in we spoke about JavaScript briefly, but the whole idea that when I was getting back into programming and delving into this world, there was this whole idea of front end and back end being considered different skill sets. As a problem solver, you kind of do need different skills. I know it requires different skills, but there needs to be a framework with a visual drag-and-drop thing like traditional visual basic from the 90s for Python. That would be insane. People would build all sorts of apps. Maybe not traditional web developers, but you could bet that some data science folks or whatever would like to share their projects with people.\n\nAs a proof of concept, I created this little menu bar app recently. You can download a zip file and drop it into your applications on your Mac and run it. You wouldn't know it's Python. It could just as well have been Objective-C or Swift. It's possible but not common. Anyway, I feel like async is like that. Python has been separated from having great parallel computation capabilities because of the GIL and things like that. The desire to say yes, I need async in this place, or the experience of having success with it previously is not as common in the Python space as it is in C++ or C#.\n\nIf we could take a digression just for a second because I feel like it gets mentioned a lot and I always get a little confused sometimes by these topics. How is the Python GIL, the global interpreter lock, stopping or the problem? When I first learned Python and tried to understand this async stuff, I thought the GIL was a parallel, multi-threaded thing. Technically it is, but the point of the GIL is to make non-parallel Python code run better.The way the Python memory is managed in Python is every object is a pi object instance, a pointer to a pi object thing, and part of every pi object is a field that says how many variables refer to this, right? The reference count. So, as soon as things stop referring to that object, it's deleted in memory sense.\n\nSo, you have two choices. If you have true parallelism in Python, every time a variable is assigned or unassigned from one of these pi object pointers, which could be simple things like numbers even, then you are at risk of a race condition around that object. Like things wanting to get to it or update it.\n\nIf, like in one thread, one is unassigning right as another is assigning, even like variable plus equals one is not thread safe because it's like read value, okay? And then change value. And if they both go read read and two threads go read read and then increment increment, you're going to end up with a plus one instead of a plus two situation.\n\nThat reference counting section, without the GIL, would have to be thread locked. And if it's thread locked, then all of a sudden incrementing a number goes to take a thread lock, block out all the other threads, increment the number, unblock all the threads. It's much more expensive to do non-parallel regular Python. Its core memory management system becomes expensive because of that thread locking. So, what they said is, \"Let's just let only one line of Python run at a time. That way only one variable assignment or unassignment could be happening and we don't need threads dreadlocks. So the GIL is really there to optimize the serial version of reference counting.\"\n\nYeah, but because it's so baked in, it's really tricky. Eric Snow is actually working on something called sub interpreters, which is very exciting. This has been mentioned a couple of times. Brett Cannon and Anthony Shaw from Real Python are super excited about it too. It's come up multiple times on the podcast.\n\nThose are very exciting. The reason that it will work is you'll still have the GIL and you'll still have reference counting and you'll still have this race condition, but what they're going to do is say if you want to have two threads, each thread can have its own interpreter and its own set of objects it manages, cares about, and has access to. And one thread will not have direct access in a reference pointer style to the other object. Within any given sub-interpreter, there's only one thread so the GIL doesn't have any issues. And if you want to exchange data, share data, there's a data passing mechanism that is separate from the overall object reference counting. That'll allow them to basically run eight sub interpreters on an eight-core machine if that's what you want. It's still ways out, a lot of the cleanup work is already done, but it hasn't manifested itself in the full end product yet. They're making these architectural steps towards making that possible. \n\nThat kind of took us away from talking about async...well, I mean that's also definitely very much about async. Async is the idea. It's one of these things that has been really challenging and so people like, \"I don't really need to do that.\" But if it was super easy and you could all of a sudden make your program run eight times faster, 16 times faster by basically doing no extra work. And what I mean is if I have my MacBook here with 12 cores if you count hyper threading, if I take up a Python program and I put it in a while true, incremental number type of loop as hard as it can hit the CPU as it wants, my CPU usage on my computer goes to nine percent. That's the max, like that is the upper bound of how much I can take advantage of it. You're like, \"Oh, that seems not so awesome.\" My gaming computer has got like 16 cores that are hyper-threaded, or something ridiculous, right? How much of that can I take advantage of? Like five percent, if I don't take async into account. So, that's one side.I think that matters to the data science side, the computational side. As a web developer, I don't care about that, it doesn't matter. If I was doing web development, I'm using microwhiskey or something like that, and it has multiple threads. It's doing a lot of parallelizing underneath, it's helping you not have to think. Yeah, exactly. It's already cr... like, so for example, on top, on training, we have that hosted on microwhiskey and we have eight. So when it starts up, microwhiskey starts eight worker processes.\n\nOkay, and those eight worker processors are running eight copies of the Python website. Those are eight different gills, right? A gill is per process, not per machine type of thing. So they're effectively doing what the sub interpreter thing is doing, just in a really hard way, right, by doing multiple processes, okay?\n\nSo it's on that level, it's in a pretty good spot. But what I do care about is, somebody makes a request to me, I want to talk to the database and figure out who that is, and I want to talk to the database again and figure out the stuff that they've got. And then I want to talk to an API to figure out where they're physically located. And then I want to talk to this other thing, maybe to place an order, I don't know, some random thing like that. The amount of time that my Python code is running might be less than a millisecond. The amount of time that whole process takes might be 100 milliseconds, right? If I could somehow say there's a whole lot of time I'm doing nothing, process go do other things, you could handle so many more requests. I mean, this is the foundation of the magic of Node.js, like this single-threaded thing that can handle a hundred thousand current connections. It's that idea that let it go do other stuff while it's waiting for a callback instead of a blocking call. And with async and await and async io, like that's what you get in Python.\n\nAnd it's so easy to scale the waiting time. And a lot of the benchmarks or performance comparisons that come out, they try to scale stuff that's not the right thing, or they try to emphasize scenarios where, \"Oh, we're going to hit this database super hard, so we're going to try to take this bunch of worker processes and where instead of just doing one request, we're going to do a hundred requests, and we're going to send that all against the same database.\" Well, the database is going to go like, \"I can only take like 10 at a time,\" and now I'm done, right? You're just pushing where the block is. But if you're talking to external things, right, external APIs, other things that you know have a limit beyond what you do, right, then all of a sudden you can basically completely replace that weight with doing other work.\n\nSo I don't know, I think there's really interesting things. And one of the stories that I think this was great is from one of the Python Bytes listeners. We were talking about some of these libraries and some of these things and even some of these debates about whether you really get better performance with async or not. And he said, you know, I adopted one of these things you're doing. I really wish I remember the guy's name, but you know, if he hears this, thanks for sharing the story. And he said, I was doing this web scraping or pulling a bunch of stuff down, and it was taking like hours to run, and it was really slow. So I tried, I switched it over to async io and aiohttp client and stuff like that, and then kicked it all off, and then my computer crashed.\n\nOkay, why did your computer crash? It crashed because it got so much data back from the internet, it ran out of memory and crashed the program, right? It had sent this like, \"Hey everybody, give me like all five thousand of you web servers, send me all of your data now,\" broke the dam, right?\n\nYeah, exactly. And I know there's a lot of debate about whether or not it's like really an advantage or not, but if it goes from hours to I got so much of a response that it crashed my computer and like 16 gigs wasn't enough RAM, like that's making a difference, right? Yeah, totally.\n\nSo anyway, I love that story because it's just kind of like, it's so in your face. Like, well, it was barely sipping on the straw and now it just ran out of memory because it got it so quick. That's a huge difference. And with since Python 3.5 and above, like the amount of difference you write in code is incredibly small to make those changes. Instead of variable equals blocking call, it's variable equals await blocking call, and that's about it. So it's really a straightforward thing you can adopt in the right situation. I just think a lot of people, like the GUI story I told, I think a lot of people don't, it's not quite on their radar because it's been too far out or it's been kind of impractical or something for so long. And even though now it is practical, it's still just not something that in the community, people are really doing as often as they could.\n\nYeah.It's a need of not only educating people on what's possible with it and having those resources out there, showing examples of it. I keep seeing more talks and I had Lucas on the show to talk about his async talk with music. The sequence he built was a great example of how to use async in live music, and it was super cool. That's a really cool example that matches well with your background. It was fun.\n\nSo, what have you been teaching lately? What are some of your new courses? I've been thinking a little bit more about internals and data science lately. The last course I released is \"Python Memory Management and Techniques,\" which has been really fun. Diving into reference counting, garbage collectors, and answering questions like why Python has both reference counting and a garbage collector. Exploring simple design patterns that can make your code use less memory and run faster has been fascinating.\n\nWe're also doing a course to bring people from the business side to Python called \"Excel to Python,\" showing folks how to use pandas and Jupiter for data science tasks that they might have done in Excel. Bringing it full circle has been really fun.\n\nBuilding the community on that level, like the prevalence of Excel, even in banking, is essential. My wife is an Excel queen, and she can do anything with it. It's a great way to get people excited about what they could be doing with Python and making things easier.\n\nThere are some really interesting examples of spreadsheet fails in history. Copy and paste errors in Excel causing million-dollar losses or wrong phone numbers being bugged due to formatting errors. Understanding data, tables, and cleaning data prepared me for conversations in the Python space, like using the right container for objects to ensure efficiency.\n\nNumbers in Python are not like numbers in other programming languages, which I discuss in the memory course.So, a number in C++ might be a four-byte integer that goes up to four billion or whatever, and it would be four bytes. Right in Python, it has the number, but it also has all the Pi object stuff and the pointers and the variable to point at it and whatnot. It's 28 bytes for like one number. One number in the letter 'a' is 50 bytes. In C, that would be one byte. It's literally a character like pointer, so understanding if you store it this way or that, it's not just a little bit different; it could be 10 or 20 times different. \n\nOne example is if you have a list of numbers and you put them into a list, you know, bracket, bracket, thing, append, that's awesome and it grows and it's super handy. But if you were to take the same numbers and put them into an array, like Python has a class called array which stores homogeneous types instead of a bunch of different types like it'll store all integers or all shorts or all floats, that's eight times less memory. \n\nIf you had a bunch of numbers you got to load up, just changing the type of array thing could be eight times difference in how much memory is used. Talking about an object like the letter 'a,' it's because it's truly a string and it has all of the different methods that it can apply to it and all the other stuff. All the things to handle the most complex string that it potentially possibly could, and it's just a letter 'a.' There's no character class right in Python, versus like string, there's not like a C string versus a char type of thing; they're all the same, which is also the magic of Python, right? It's so easy because you don't have to go, \"Is that integer too small?\" like it doesn't matter, integers can be as big as they want to be. Or is that string how do I like encode the characters? Generally, you don't worry about that stuff.\n\nDo you feel like we hit the majority of the things that you wanted to touch on in the big ideas section? I do feel like we've hit a lot of them. I guess one more, let me just throw this out to your listeners and folks. One of the things that surprised me when I started the podcast was I thought who's going to listen to this show the most? The most dedicated Python developers out there, the ones that are probably maintaining the libraries that I'm talking about and working on the language. Not beginners, no, no, not beginners because why do they care about the internals of how Flask handles this or whatever it is we're talking about? \n\nWhat I learned over time is like half, at least half the people who are listening are really new to programming and Python. I found it amazing that they would say things like, \"Oh, I listened to the show and for a month I didn't understand what you're saying,\" and I'm thinking like, \"Wow, that's dedication.\" I would think you would not want to listen anymore, but they're really committed to learning Python and programming, and they treat the podcast as like language immersion. Like, yeah, if I want to learn French, I'm going to move to Lyon, I'm going to live there for a year until I know French, right? And it's going to be super uncomfortable in the beginning, but at the end, you know, I'll be having this great conversation somewhat at least. \n\nI just think that it's interesting to consider podcasting as the language equivalent of tech, like the tech equivalent of language immersion. Yeah, I'm that guy. I didn't write to you, but it's awesome. But that was me like, you know, two and a half years ago, and of course, at that point, there was this back catalog, and I was like, \"All right, how far back do I want to go?\" And so, you know, what's kind of neat is a lot of them, you know, episode-wise, can be evergreen in the sense that this is a topic that is going to be repeated and so forth, and I'm hoping to try to create that evergreen content myself in the sense that yeah, it sounds like that you are, and I think that's really valuable because it's one thing to have timely stuff, but it's another to capture these big moments and stories and just keep them around. \n\nTotally. Yeah, well, thanks for helping with my immersion. You're welcome, and I really just wanted to bring that up because I know there's a lot of people out there, way more than it would seem initially, who are doing that, and I just want to like kind of say, you know, hey listeners, this works, it seems like, and you're welcome here. And that's, you know, the other thing that was exciting about it too is just like, you know, finding people that are out there and kind of going back to the idea of finding guests. I haven't really had anybody flatly say no to like a request at this point. It's been me trying to find what fits in the topics and find stuff that is interesting, so that's been the fun part of it. You know, it's again kind of going back to the community thing which has been really cool.Yeah, it's a real honor to just spend 10 hours on something you're inspired about and learn about it. I always consider myself the first guest or the first listener. Especially when you're editing it and so forth, that's a different level.\n\nI have a couple of weekly questions that I ask everybody. The first one is, what are you excited about in the world of Python? You're so immersed in this world, is there something that truly excites you? Yeah, there's so much stuff out there. It's really inspiring to see now that we've stepped beyond the two to three boundary. All these different things going well. This new language and these new features like type annotations or async or whatever are what we can count on being there. Well, now we can reimagine how things are working. It's really hard for me to just pick one thing, but the thing that I'm inspired about right now, I guess I'll give you two because I can't narrow it down. One is FastAPI.\n\nI think FastAPI is the business. I think there's so much interesting stuff around the way FastAPI takes type annotations and model binding through Pydantic. You can have a class with type annotations from Pydantic and say, here's an API method and it takes a user registration object. It will look at the inbound form post and fill out all the parts of the class, even with validation. It makes writing professional code super smooth and wraps it up in a nice async and await enabled framework to just fly.\n\nThe next API project that I'm working on is definitely using FastAPI. It's based on Starlette and some other things, including uvicorn, which is one of the async ASGI servers based on uvloop, which is a faster async IO event loop implementation.\n\nThat was something that right at the end when I was talking to Lucas, who was mentioning those two things, he wasn't using the built-in async, which is interesting to me, the idea that the language is built so you could drop in these replacements. It's pretty amazing.\n\nThe other one is unsync. As much as I've had positive things to say about async and await in Python, there are a couple of clumsy things that I don't understand why there wasn't one final layer put in place to make them easy and awesome. Unsyc lets you take threads, multiprocessing, and async and await and turns them all into the same API that uses the async and await keywords. It's a beautiful unification across all existing parallel frameworks in Python.So, the other question is: what's something that you want to learn next?\n\nI'm going to go with FastAPI. I really want to get deeper into that. I also would like to do a little bit more with type annotations. So far, I've used them as editor support, like PyCharm. I want to make sure that PyCharm or VS Code knows exactly what is returned from this method. It'll give me auto-complete, type checking, and stuff. And that's fantastic.\n\nWith tools like MyPy and MyPyC, you can get CI-level verification that your program is still sticking together and whatnot.\n\nWhere have you used your type annotations up to now?\n\nThe way I try to think about where type annotations go is on the boundaries of application layers. Maybe I've got a data access layer that talks to databases and all that kind of stuff. You don't have to overwhelm every single part of your code with type annotations, but if every top-level function in the data access layer talks about what it takes and what it returns, editors can infer as you start using the data access layer.\n\nIt's still one of those things that you described at one point where you got started, what it is, and so if you just put it on the boundary of an API, it's usually enough to completely cover what you're doing in terms of getting help from the editors.\n\nOne of the things when I did a course based on Gerg Iron's article from Real Python about type checking, his article is huge, but I called it \"101 Sort of Type Checking.\" Nice. I did a video version of it, and as I dove into it, that was one of the things that I had a hard time with because I was like, this is something I want to learn. The first thing I did was decorators, and then I did that one.\n\nThese are things that I would look at in code and go, what is that? What is it doing? So one of the fundamental problems I had with type checking was, why would these things be here? What is it doing and so forth? And then as I did the research, it's all about intent, right? Like, what is this thing doing, especially if it's going to talk to something else, like if your code's going to be part of an API, and so forth. That seems to be the vital thing where type checking is really going to help cover yourself in so many ways, and also documentation.\n\nIf you imagine that you're creating a package that other people are going to use, assuming it's Python 3 only, you're welcome to use type annotations as much as you want. Maybe that only has five function calls, but if you put type annotations on what goes in and what comes out, it's going to be so much easier for people to use your library.\n\nOne of the things that just makes me want to pull my hair out is when I get to some API, and it says you create one of these classes and then you go do the thing, which is fine. But then the constructor, the initializer, is *args, **kwargs, and like anything. I have no idea what goes in here, what type goes in here, how many things. Then you go look at the documentation, and it'll probably say there's some, maybe it'll tell you the type, maybe not. Like Boto3 from AWS is like this. And then you go look at some example on Stack Overflow talking about how they're accomplishing a thing you can't quite pull off, and they're using a different keyword that's not even in the documentation. You're like, this is killing me. I just want to go play in traffic for a while because I can't take this library anymore. And if you just had default values, named parameters, and type arguments just on the constructors or just a few places, life would be so much better. So anyway, that's my philosophy on them.\n\nI think that's been kind of a little bit of a trend that I've been noticing, and I don't know how you feel about it. When I started, I started seeing args and kwargs everywhere, and I was like, oh my gosh, this is a super confusing thing too. It seemed like that was way more common three or four years ago.\n\nI think you're right. I think we're seeing less of it, and I'm thankful for it.I mean I think everybody should be. Tell me what you were thinking here, what was supposed to go in. Let me throw one more wild idea out there for you while we're on this topic. \n\nReally quick, sure, I talked about pedantic and fast API and how that's cool. One of the new beta features that pedantic, which is the validation layer of those classes that are being used inside a fast API, they came up with a decorator that will, at runtime, do checking on your type annotations. So in C++ or Java, if you compile your code and you pass an integer where a string goes, the compiler would fail and say no, no, you can't put an integer here, it's a string. In Python, that's a suggestion, right? Like, well, it looks like a string, but whatever, we're just going to let it go through at runtime. The pedantic validator will enforce that you pass the right types that match the type annotations at runtime, so almost like compilation. \n\nI don't know if I'm necessarily recommending people use it, but it's a pretty interesting idea to say that you can opt into making these runtime requirements not just editor helpers, right? That makes sense, I guess. \n\nIf you're willing to answer the old question that I had, that I kind of retired, is there something that you felt like, as you got into Python, that you thought you knew but in the end you were wrong about it? I like this question, it's a good one. I don't, that doesn't necessarily mean I have a good answer or an answer, but that's okay. \n\nLet me tell you, when I first got into Python, I thought I understood maybe even a little tiny bit before I got into Python, and then I didn't understand, but now I think I do. I came from learning C and C++, doing C++ as a professional developer for a while, doing like 10 years of C# development, mixing in some JavaScript development. Every one of those languages is about curly braces, semicolons, parentheses, type stuff, except for JavaScript, right? When I looked at that code, it was fine. I thought, okay, well, you've got to have all the types everywhere, you've got to have curly braces around your conditionals and your if statements, as well as the print parentheses around the actual condition. And I went to Python and I thought, this is just a weird language, like the white space mattering, it's kind of weird. Why don't I like the fact that I don't have to type if parentheses test close parenthesis, I can just type the test, that's a little bit weird, but I kind of like it. It took me a couple of weeks to get really comfortable with it, but I still conceptually thought, oh yeah, but like the C-style languages, like that's the real programming language, and this is an interesting one, but it's not as legit as that style. And then I had to go back and work on this C project for a while, and what really surprised me was I looked and I'm like, I can't read that. Why can't I read all this? There's crap everywhere on the screen, I can't read what it's doing, even though for like 15 years I looked at code like that, I'm just like, it's so overwhelmed with generic types and parentheses around this and curly braces and semi and the thing that really shocked me and surprised me was I thought that those things were required, I thought just to properly structure stuff, you really had to have parentheses around like your test in your if statement, and you really needed semicolons to say here's the end. And then I went back to Python, I was like, ah, much better, and just a week ago, I was freaked out by it, right, and now I'm pretty sure as I go back and try to read those languages, it's just harder, and so what I thought I understood about Python was that it was like this sort of cut down wimpy version of true programming languages, and I just realized what now I understand is like this is a much better way, and that if you look at these real programming languages, C++ or whatever, they've got this baggage that is unnecessary, like there's no reason for parentheses around an if statement, you know, you can just go without it and it's easier to read and so on and so on, and that really surprised me but it continues to make me happy. \n\nThe visual noise of it makes it kind of unapproachable in a lot of ways, all the symbols or whatever you want to call it. I got okay with it because I thought this is the real way and okay, so it's fine, and I was totally, you know, you hear a lot of people complain about those kinds of things that are coming from a place of not having experience with either, and you're like, oh well, that's just because you're not used to the symbols. Like I did that for like 15 years, I was right, I wanted used to it, I still had that feeling, and I just think it's so interesting. So I was wrong that those symbols were one better or two needed, that they required to level it up, yeah. \n\nThat's great, exactly. Hey, thanks so much for coming on the show and thanks for doing Talk Python for so long, you definitely inspired me to do this podcast. Awesome.Well, it's been a real honor. I had a great time talking with you. Thanks for inviting me and congratulations on your show. I know it's off to a good start, and you're doing a great job, so keep it up. Thanks, thanks so much. All right, talk to you soon. Yeah, bye-bye.\n\n[Music]\n\nI want to thank Michael Kennedy for coming on the show, and I want to thank you for listening to the Real Python Podcast. Make sure you subscribe to the podcast in your favorite player. And if you like the show, leave us a 5-star rating and a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "2maIctjQARQ": "Welcome to the Real Python Podcast. This is episode 30. Python 39 is here this week on the show. Former guest and Real Python author, Guerra Arnajella, returns to talk about his recent article \"Python 39 Cool New Features\" for you to try. Also joining the conversation is Real Python video course instructor and author, Christopher Trudeau. Christopher has created a video course that was released this week also based on Guerra's article. We talk about time zones, merging dictionaries, the new parser type hints, and more. Guerra and Christopher not only cover the new features but they also offer advice about ways you might incorporate them into your code. We also discuss what you should think about before updating your code.\n\nOkay, let's get started. [Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Hey, I want to welcome both of you to the show. Guerra, hi, how's it going? Good, good, good. And Christopher Trudeau, I want to welcome you too. Hey there. All right, we're here to talk about the release of Python 39 that came out on Monday, and we're recording this a little bit in advance. There's an article that's up on Real Python which is by Guerra, that's the cool new features in Python 39, and so we're going to kind of go through that. But the reason I invited Christopher Trudeau on also is to talk about his video course which came out on Tuesday, again recording in the future past, and you guys have some experience working with it, but also kind of diving into what are these new features. The big feature, the first one that kind of comes through that I find is a big feature is the proper time zone support or the zone info library. So who wants to start off? Yeah, I could probably jump in. This one is one I'm, for some reason, like... well, I don't like time zones. Yeah, I like good libraries for working with them. That's something that hasn't been in the standard library, so you kind of had to go to some external library. I've been using the dateutil library for a while to work with this. That's a library that's been at least maintained now for the last couple of years by Paul Ganssle, and he has been the one that has brought this into the standard library. Okay, so it's his interpretation in some ways. I believe so, and my still somewhat limited experience with the zone info library is that it seems to be essentially very similar to how dateutil is doing it, but there are some of the more advanced features in dateutil that have not been ported. So the zone info is a slightly simpler library, but it still handles time zones fairly properly and it's quite easy to work with. So it's been quite pleasant to just be able to access time zones with Python. So, what were the types of things that were missing? In the datetime library some while back, I don't remember exactly when this became available, they did introduce essentially functionality for handling time zones. So there is functionality for converting between time zones, there's functionality for dealing with the weird things that typically happen at daylight savings when you have hours that disappear or other hours that you kind of repeat twice. But there was no implementation of concrete time zones except for UTC time. So if you wanted to have a time zone for Central Europe where I'm at or another one from, say, East Coast or Central time zones, you would have to actually implement your own time zone object and then spell out the rules for when does the daylight savings thing actually happen and so on, which of course is not practical at all to keep track of. Right. My understanding for why they didn't introduce that back when they kind of introduced functionality is just that they didn't want to have the burden of maintaining the time zones inside the standard library because the standard library changes very slowly. It's only released once a year going forward, I guess. Yeah, we could talk a little bit about that too as we go forward too. Yes, exactly, that's another new feature, I guess. So that's kind of been the concern mainly that it's better to keep it outside of the standard library so that you can actually maintain it whenever there are changes to the time zone databases. The solution that is in the zone info is that zone info doesn't actually come with the time zone database itself, it just brings functionality for actually reading the standard format of timezone databases and then at least on Mac and Linux, you'll typically have a zone database installed on a computer that kind of handles updates with the update mechanism on your computer and so on, so it's kind of more or less kept up to date. But then they also added another library that they call a first-party library, which I don't think I've actually heard that term before, so it's not the third-party library which they usually talk about, right.Apparently, a first-party library is something that's not part of the standard library but is still maintained by the core Python team. So, if you were to install Python 3.9, is there an extra step that needs to be done to take advantage of it?\n\nExactly, so it's not part of the standard library. If you just installed Python, you will not have the timezone database package called tzdata timezone data. But, you can install it on your computer if it doesn't find a system timezone database, which will typically be on Windows unless you have installed something there.\n\nThat's something you would do from the Python Package Index, right? Using pip? So, it's a pip package you can install with pip. On Windows, you'll have this extra requirement to install the tzdata if you want to be sure you have it.\n\nAnd that would then be a package that is, since it's not part of the standard library, something that can be updated whenever necessary. Essentially, my understanding is that it's just a compiled version of the timezone database from the IANA.\n\nYes, exactly. So, it's a new module called zoneinfo, and there is a zoneinfo class inside of that module that you just initialize using a text string describing your time zones. For instance, for me, it would be something like \"Europe/Oslo,\" and there are many recognized keys from the IANA database.\n\nThis database listing includes historic information as well, right? On the Mac, it had over 590 entries, and on Linux, it's just over 600. It goes far deeper than just the 2526 around the world that we have. It includes information that could be calculated from the past and centralizes it across different countries, even if they might be in the same time zone.\n\nAnd that's a historic thing as well, right? For example, I'm out of Toronto, Canada, and there is an America/Toronto, technically in the same time zone as America/New York. But if you go back far enough in time, we weren't adjusted at the same time they did.\n\nBecause there are dates where there's a difference, and if you're doing today's date, there's no difference. But there are times in the past where that's changed. I can think of a couple of states that are even like that, Arizona and Hawaii, where they don't change for daylight saving time.\n\nI could see that maybe there was a point in time where that got modified. In the article, you kind of go into a particular one of Christmas Island in 1994, where they skipped a whole day on New Year's Eve, which is one of the craziest things with time zones.\n\nThere are some fun videos pointing out these weird things with time zones, which is why you don't want to implement them yourself. This is probably one of the craziest ones where they decided to skip December 31st, 1994, to move across the international date line.\n\nYou don't even have to go that far back, George W. Bush changed it in North America, shifting the date that daylight saving time changed by three weeks. This means Canada and the United States are now out of sync with the rest of the world when switching over.It's important to not have all that in your head. You don't want to have to think about it.\n\nYeah, okay, well that's nice. That's a nice addition. So, kind of diving into the next one, updating dictionaries. What's the change with the syntax for updating dictionaries?\n\nSo, there are two new operators that have been introduced: pipe and pipe equals for merging and updating dictionaries. These are just shorthands, not actually doing anything new with a dictionary that you couldn't do before. Now you can do it fairly succinctly. You can merge two dictionaries by putting a pipe or operator between them. In the article, Garan mentions that there's a dictionary with PyCon and another dictionary with EuroPython information in it. You do PyCon pipe EuroPython and you get the two dictionaries merged. Or equals is just a short form for the update function that already existed.\n\nNice, so it's just kind of reusing some operators in this new context to make the syntax look a little more streamlined, for the most part.\n\nYes, the big advantage of it, at least with the pipe operator, is that this has been implemented in all the dictionary-like classes. Some of the short forms that you used to merge dictionaries would accidentally turn a defaultdict into a dict, which you don't want to do. But because defaultdict is also pipe aware, it's smart enough to know that if I'm merging two defaultdicts, I get a defaultdict out of it. Whereas if you'd used a couple of the shorthand mechanisms for doing that before, you could accidentally convert it into a different dictionary type. There's a chance that you might prevent a weird edge case bug that you might not have noticed before by doing it this way.\n\nYeah, you're actually changing the functionality of that type, which is really going to create a bug that you might not have been able to catch. Type stuff, yeah. Okay, you'd have to do a lot of type checking on top of it to, you know, like, is this still a thing? Yeah.\n\nIt's the kind of thing that tends to pop up months later. Why isn't this dictionary ordered anymore? Oh, right, okay, because it's changed. Why doesn't it have a default key? Well, you might not find out until you go to use the default key later on in the code and not realize why it's disappeared. So yeah, it's the kind of thing that tends to be hard to hunt down. Do you have an example of code where you've needed to merge dictionary stuff that you can think of off the top of your head where this would become more useful?\n\nI've got the update side, like you do the updates very frequently. Merge isn't as common, I don't find, unless Karana, you've got something.\n\nNo, I'm trying to think of it. I know there's places where I would kind of have stuff in two dictionaries and need to look it up, but I don't have a good example.\n\nI think that's okay. If I'm dealing with multiple JSON packets coming in off of the web and then I'm needing to store those or change what's in the database, if I'm storing the JSON in the database, you're always converting the JSON into dictionaries and dictionaries back into JSON. So anytime you're trying to store those things in the database or update those things from the database, you're always playing with dictionaries.\n\nYeah, and you're adding or modifying the keys that are there. The old surefire way is to create yourself a little loop and make sure you've got all the keys. Well, this is a nice little one-liner that means you don't have to do that. You don't have to do like, for key, value, you know.\n\nYeah, exactly. That whole deal. Okay, cool. In that case, you'd still have to be careful of the type if you're doing even the loop style comparatively to the shorthand. Another example I think you guys gave was the shorthand using unpacking, is that right? Using the two stars to unpack the two dictionaries and then combine them.\n\nOkay, I think there's some other kind of underlying stuff that's there. There's a change to, I don't know if these were there before, but there are the dunder methods for these operators, the dunder or and the dunder is it I or is that right?\n\nYes, yeah.So, like most operators in Python, they are actually implemented as functions on the class because everything in Python is a class.\n\nThere's an underlying dictionary class that implements double underscore or the word or, and double underscore for the pipe and pipe equals operators. This allows you to override those and change the behaviors in the classes. Some other examples where that would be useful is typically seen when implementing your own dictionary class or updating a class to have dictionary-like behavior. By implementing these functions, you can have them behave the same way. Alternatively, if you were trying to add custom features to a default dictionary, you would want to ensure that the underlying operators behave properly as well. Unlike other programming languages where these operator overloaders are done naturally, in Python, they are mapped to functions, giving you control over their behavior.\n\nMoving on to the next topic, there was a change in decorator syntax which takes us back to episode one and the subject at hand. The response to the tutorial went online, and although feedback was limited, the positive responses were appreciated. The tutorial was split into sections and aimed to provide practical solutions to different use cases for decorators.\n\nThe change in decorator syntax might not be significant for most Python users, but it is worth noting for those who enjoy working with decorators. Essentially, the only thing allowed to be used as a decorator is a name, possibly dotted. This limitation was put in place to ensure consistency and ease of use when defining decorators.\n\nOverall, despite the limitations in decorator syntax, Python continues to offer a powerful and flexible way to implement decorators in your code.So it's not usually something that would come to mind. I want to run this dictionary as a decorator, stuff like that. Over time, there have been cases pointing out why I can't do this. I think for this one, essentially, it was more of not necessarily being super useful or necessary, but more like it might be useful for the few people who actually need it. There's no reason not to do it because it's an easy fix. It's essentially just removing a limitation, not really implementing anything new. So it's not going to change the way other people have been using it.\n\nRight, so if your decorators work now, they will still work after this change. It kind of just gives you a few more ways that you can directly write decorators. And again, it's not that you're able to do anything that you weren't able to do before. Even if you had a dictionary full of decorator functions, what you would typically need to do to actually use the decorator would be to just add a temporary variable that refers to your function. Then you can use that variable to decorate with. It was kind of just one extra line of code that was somewhat inelegant, but it would still work. Now you can just type it out directly as you need it.\n\nThe motivating example in the PEP that describes this change is based on a GUI someone built with many different buttons. You need to connect each button to a different callback function. One way to keep track of your buttons would be to collect them in a list or a dictionary. But before Python 3.9, you would need to go through a temporary function or do some other weird hacks to be able to use it from the list. Now you can just use the list or the dictionary directly. Nice, okay.\n\nIt's going to save some code writing in that type of example. It will make the code slightly clearer, meaning that you don't have to go through that temporary variable that seems somewhat unmotivated. Do you have a use that you have been thinking about that you might use for it? Actually, Christopher and I were talking about this. What essentially, I guess my examples in the article feel a bit far-fetched, which is somewhat illustrative of the use of this. I don't have any personal things where I think I really want to use this. In the article, there's an example where you could start with a dictionary of decorators and then ask the user using an input which decorator they want to use. You could even pick it out from the dictionary dynamically like that. How that would actually translate to something useful in the real world, I'm less sure of.\n\nThis comes across as something called the signals and slots pattern, common in GUI and web frameworks. It might help people in that exact corner. But I don't think anyone else is ever going to notice it. If you look at a web framework like Flask, they use decorators to map your URL to the function that responds with the content when that URL is hit. I could see them doing fancier things with generating those URLs, like maybe having a dictionary of URLs somewhere. You could access those dictionaries by name instead of hardcoding things. It gives you a bit more flexibility, but to his original point, it's a bit of an edge condition.\n\nFor those people who it affects, they think it's great, and everyone else can ignore it. The next conversation I had was with my wife, who doesn't use Python a lot but helps me with the podcast. We were talking about type hints and the new annotations, which were intriguing to me. The example you guys use in both the article and the course, where you need to annotate the units of something, is a good one. Typical type hints would simply display the type, but in cases like using miles per hour or kilometers per hour, or potentially other units, it's important to annotate the units as well. All those types are floats in the end.So there's not that much information, and it's a subtle historical change in how annotations have been used. I think it's a callback to capture some of those uses and provide both, but maybe I'm diving in too prematurely to talk about it.\n\nAnnotations have come full circle from their original purpose of meta information on variables, like units, to being used for type hints. Now, type hints are the most common use of annotations because compiler tools and IDEs can use this information to provide additional tools for coding.\n\nThe change has introduced a new class that allows you to annotate with both kinds of information. By codifying this, IDE tools can continue to look for type hints while still accessing meta information.\n\nIt's a hybrid approach to the original purpose and the purpose that emerged over time. IDEs like PyLance can take advantage of type hints to show both aspects, enhancing coding efficiency.\n\nType hints have gained popularity due to Python being dynamically typed, requiring vigilance in unit testing. Type hinting aims to bring some compile-time warnings to dynamically typed languages, catching errors earlier in development.\n\nThis compromise aims to make Python safer like static languages without restricting the flexibility of dynamic languages. It allows Python programmers to leverage features of static languages while maintaining the flexibility of Python.\n\nThere are two ways to access annotations: using double underscore annotate as meta information or using the get type hints method from the typing library. This method can provide both type hint information and associated meta information.\n\nUsing tools like MyPy for type checking can enhance the coding experience. This change in annotations allows for tracking units and typing in code simultaneously, providing flexibility and efficiency in coding.\n\nOverall, the shift in annotations allows for multiple purposes without sacrificing functionality. It streamlines the coding process by integrating unit tracking and typing seamlessly.Yeah, we've been talking about units here the whole time. Actually, the annotated it just gives you access to add metadata. It's up to you to define whatever metadata you want to have there and interpret them. So, it doesn't put any limitations or really help you interpret these things. It's up to you to put whatever information you want there and use it later. \n\nIf it's something more complex like a dictionary, you could have some other kind of annotations in there to indicate things that you were expecting to be built inside of here. For example, this is supposed to be a last name or this is supposed to be something different. Another example that will probably be used would be things like saying that okay, this number should be a float with typing information, but it should also be in the range 0 to 100, for instance. \n\nYou could have some tools or your own code that would enforce that or use that for testing. These kinds of annotations are intended for people who will use your code, more likely programmers, versus just end users. \n\nIn the code, you end up writing something like \"distance: feet, time: seconds.\" It can be done very easily for people using a library later to figure out what numbers they should pass in. \n\nFor this week's video spotlight, I want to remind you that Christopher Trudeau has created a video course all about this week's topic of cool new features of Python 3.9. In the video course, you learn about accessing and making calculations with time zones, merging and updating dictionaries, using decorators based on expressions, combining type hints and other annotations, and much more. \n\nLike most of the video courses on Real Python, the course is broken into easily consumable sections and you get code samples for the examples shown. It also includes a shiny new transcript and closed captions. Check out the video course, you can find the link in the show notes or you can find it using the newly enhanced search tool on realpython.com. \n\nThis kind of moves us into categorically something you guys kind of said okay more changes, and this one to me feels like a fairly large change even though it's under the hood and a lot of people may not notice it. We've spoke about this before, myself and David Amos, we were talking about the introduction of the peg parser. \n\nI don't have the full overview of myself yet either, but I claim that it's both in a sense one of the coolest features and you'll hopefully never notice that it's there. What's kind of happening is that in the background when you're running a Python program, the source code is parsed into tokens and these things that are then interpreted further down. \n\nFrom the start, it has been done by something called an ll1 parser, which is a very explicitly simple parser. It's not able to do very advanced stuff, and that has been one of the reasons they used it when they first started Python. They wanted the language to be easy to parse because that would hopefully make the actual interpreter easy and keep the language easy. \n\nThe ll1 parser essentially means that it reads one character at a time without backtracking, so it needs to be able to read your code and always understand what's happening without ever getting into an ambiguity, which would mean that it would guess wrong.What this means and kind of go back again. That just worked fairly well for Python. But over time, they realized that it is also a limitation to some of the things that can be implemented in Python. There are some things that are not strictly part of what's called an LL1 grammar, so something that can be parsed by an LL1 parser. They have done some hacks essentially in the parser to get around those things.\n\nAfter Guido stepped down as a BDFL two years ago, he started investigating what's called PEG parsers. PEG, short for Parsing Expression Grammar, is a more powerful parser than the LL1, so you can avoid some of the hacks that have been made. It also opens the door for doing more advanced things later, something that has been implemented now in Python 3.9. But they are not taking advantage of it at all, so there are no features in Python 3.9 taking advantage of this new parser.\n\nUnder the hood in Python 3.9, both the LL1 parser and the PEG parser are available by default. The PEG parser is used, but you can add a command-line flag (-x old parser) to run on the old parser. If you see some weird behavior, you can use this command-line flag to test if it's an actual problem with the parser. They have done extensive testing of this new parser by running it on the whole standard library and most of the biggest packages on PyPI.\n\nThis is an important time for anybody to test their code to make sure it works because the ability to use the original parser is going to be deprecated. This is only available in Python 3.9, and for Python 3.10, they will remove the LL1 parser, leaving only the PEG parser.\n\nOne thing that has gotten the most buzz is something they call structural pattern matching, which is like a more powerful version of the switch case statement. It can do a lot of cool stuff like assigning variables based on patterns, similar to pattern matching capabilities in functional languages. It looks really exciting and may show up in Python 3.10.\n\nThe foundational difference between an LL1 and a PEG parser is that a PEG parser actually has infinite lookahead, allowing it to characterize things and look at groupings.So when you start seeing the difference between the equals and the double equals, it'll know and it'll be able to handle that kind of thing quite succinctly without making the grammar for the language overly complicated. So again, this isn't one of those things that as a programmer, I do my best not to think about. I don't want to have to think about it, that's why you run the compiler, that's what it's for.\n\nDiving into those, as mentioned earlier, features like pep622, you couldn't do them with an ll1 without getting very hackish in the underlying code. This will allow the compiler to be more elegant down the road and will allow us to introduce new features into the language that otherwise we might not have gotten.\n\nAlong with the complexity that it potentially could allow for, these additional statements where it's looking ahead and having a better grasp of what's going on, this whole kind of context is there potentially a speed difference at all, do you think? Yeah, I'm not sure, I think they are comparable. So they've kind of done some tests on this and in some cases, the peg parser is faster. Probably slightly more than, well, in some cases it's a bit slower, but it's within 10-20 for most of the time. But I think Python 3.9 is the first kind of release for quite a while which is not significantly faster than the previous release, and I think overall Python 3.9 is actually slightly slower than Python 3.8.\n\nBut it's essentially comparable to 3.8. And I would expect that, so it's generally easier to optimize code when the code is general. So the more exception cases you have in the parser, the more little hackish things you do, the more little edge cases, the harder it is to optimize the general state because there's always an exception. By making the compiler easier to maintain, if they decide they want to tackle a speed problem, this should make it easier for them to do that in the underlying compiler.\n\nSo it's gonna be a nice sort of step toward the future of Python if you will. The next few are kind of small, the first one is the sort of string prefix and suffix, which you know, I did a whole course on strings and the idea of okay, if you want to remove things from the beginning of a string or the end of the string, you can kind of get odd results sometimes. So prior to Python 3.9, to remove something from the beginning and the end of the string, you really had to do it manually. A common misuse of the strip function was thinking that it was actually pulling a suffix off the end of the string, and that's not actually how strip works.\n\nWhen you give a string to strip, it will peel any of the characters in that string off of the target string rather than the word that you're trying to peel. So if you were going to remove the suffix, you would actually have to find the position of the suffix and then chop the string using slicing or something like that in order to get rid of a suffix at the end of your target string. Python 3.9 has introduced two new methods in the string library, remove prefix and remove suffix, that will look for the string given in the function in the beginning or end of the target respectively, and if they're there, peel them off, and if they're not there, don't peel them off. So it's a nice clean little thing without having to think about the structure of the string too much.\n\nIt's not going to dive into the rest of the body of the string and potentially remove additional characters from the end. To be able to do this previously, you would have to have found the substring, checked whether or not the substring was there, and then sliced the substring. So essentially, it's replacing three or four lines of code with a single line, which is usually a good thing. Do you want to take this one, the type generics?This one is just cleaning up a little bit on how to work with types. One of the weird things when you get started with types is that if you want to type in things like lists or dictionaries, or what's in general called generics, which is usually a container that can be parameterized like a list of numbers or a dictionary of strings mapping to other lists and things like this, to do that you need to import, for instance, list with a capital L from typing and use that to type into it. The reason for this was mainly that the syntax of using lowercase list square brackets didn't really exist, and it was a bit complicated to introduce it. Therefore, instead of adding that complication, especially early on when they were using type hints before they knew if type hints would be popular or not, they created a separate type which they could experiment with without messing with some of the important things in Python. Now, they are confident that type hints are here to stay, so let's go back and fix the generics so that you can use the natural syntax of just using lists and dictionaries with the actual built-ins instead of having to import them from typing.\n\nThis will save a lot of extra imports and confusion about lowercase and uppercase list usage. However, we still need to wait for Python 3.9 to use it, as not everyone can switch immediately. Python 3.9 will deprecate the typing capital L list versions, and they will remove the list from the typing module in 2025. This gives a five-year window for the transition. The double underscore future also allows you to use this in Python 3.7 or 3.8 by importing it. It's a way to get ahead of the deprecation and take advantage of it in earlier releases.\n\nThe topological sort is a way to sort dependencies in a graph, such as in a package installation scenario. It helps find the order to install things so that dependencies are met. This algorithm problem is now available in the standard library in a new module called graphlib, which currently only contains the topological sorting mechanism. It may include more in the future.\n\nThe topological sort applies to directed acyclic graphs (DAGs), which means there are no loops and only one direction inside it. It's a useful tool for organizing dependencies effectively.To have a well-defined topological order or topological sort, you need to have no cycles and direction. It's really only for DAGs, and I think if you have some cycles, I don't remember the error if it actually raises an error that tells you there's a cycle if it's that specific. But it does raise an error if your dependencies are not in a cyclical dependency graph. One thing that we just don't cover in detail in the article is that it has a fairly simple API where you define your dependencies as a nested dictionary essentially, listing the nodes and then the edges to it. But it's also possible to use it in a more interactive way where you start a topological sorter instance and then add the dependencies as you move along. Once you have built up your graph, you can then start to chop off the nodes in a correct order.\n\nThe reason they've added this API is that it has some very nice applications in parallel processing. For instance, this can tell you if you have several processes running and can deal with things in parallel. You can ask to give everything that's ready to do now, yielding out two or three different nodes with no dependencies to start off. Then you can start working on those. Once the work is done, you can let the topological sorter know you're done with the node and ask what the next one will be. It has a nice API for dealing with the more complicated application of topological sorting, which might be interesting in the data science community and the algorithms used for learning and using trees.\n\nYes, I believe most of them already have implemented something like this, but now there's something available out of the box in the Descent library, which would be nice. When you were in your video course talking about these next two, Christopher, you said you had a background in explaining the greatest common divisor before. The GCD is a function that takes two numbers and returns the largest number that divides into both. For example, the GCD of 49 and 14 is 7. 7 is the largest number that will go into both 49 and 14.\n\nPython 3.9 adds the ability to do this across more than two numbers at a time. Prior to Python 3.9, you had to write extra code or use functools to chain these things together. Now you can do it on multiple numbers. LCM was not part of the math library before. LCM is the least common multiple, the smallest number that both 14 and 49 will go into is 98. LCM was not part of the math library before, but it's been added in Python 3.9, along with GCD.\n\nTalking about these new HTTP status codes is another kind of nerdy thing. I'm wondering how often these are going to be used. These status codes are available in the HTTP module in the standard library, where there is an HTTP status class. There have been a couple of new status codes defined in the last couple of years, such as 103 Early Hints and 425 Too Early. I don't really know what they would signify, but it's something when you have some asynchronous things happening.And kind of haven't really gotten an answer back yet. Or something like this is what it's kind of. The newer versions of HTTP allow the browser to ask for header information ahead of the body rather than getting them together. So Early Hints allows you to request to do this, and this will make it look like the web page is loading faster because the browser can start showing things as soon as it gets it. The problem with this is you end up with the possible challenge of what's called a replay attack, which is the browser asking for the same information over and over again as part of the TLS handshake. So they introduced 103 to get this information, and then they introduced 425 for the server to be able to say no, I'm not going to give it to you yet because you're asking too early. But that being said, this is what I do for a living and I had to look these up, right? This is an edge case, so these are just communications between potentially your own Python app in this case and the browser. I would expect the biggest change is going to be you're going to find this using this inside of things like the request library when you're writing code to take advantage of the server providing these headers sooner rather than later. \n\nAnd there was kind of a silly one in there too, right? What is that one? Yeah, so there's also the third error code that's added, which is 418. I'm a teapot. And this is kind of an old joke that has somehow festered. So back in 1998, I believe it was, there was an April Fool's joke where the Hypertext Coffee Pot Control Protocol (HTCPCP) was introduced. And this was then written up as a proper RFC, I guess they call it a Request for Comments, so sort of like an official document describing this new protocol that would then help you control, monitor, and diagnose coffee pots. It kind of is made to look more or less like HTTP and it kind of uses methods like HTTP does, codes similar status codes, but then it also introduced this new status code, 418 I'm a teapot, which would then make sure that people didn't start brewing coffee inside of a good teapot. And this is of course just a big joke, so it's never been a part of the HTTP status codes, but it has somehow been lingering around, it has been implemented done by several libraries. There was an initiative from, I believe this would then be IANA, to remove this 418 before it kind of ended up everywhere, but then it was of course a big debate about this and somebody started a \"Save 418\" webpage so you could kind of, which then ended up with them, I think it's not, 418 is still not an official HTTP status code, but the number has kind of been proposed to be a reserved status code that will not be taken by other things so that it's more okay to now implement 418 in different libraries. So it's been in requests for many years but now it's then also included in the HTTP standard library. \n\nI guess that kind of takes us to a bit of a wrap-up section where we can talk about what are the use cases you have for upgrading or time frames. Christopher, do you, what's your plan as far as Python 3.9? I tend to upgrade the compiler itself as quickly as I can as soon as it's out for any of the projects that I'm working on personally that I don't have any dependencies on. I tend to move to the latest and greatest immediately, but that's more of a habit than anything else. Okay, that being said, due to backward compatibility issues, for example in the open-source libraries that I maintain, I'm not going to be introducing any of the features here that aren't future-proof for quite some time because 3.6 is still supported and still out in the wild. If I start adding pipe operators in for my dictionaries everywhere that's going to break code for people. I've had folks on the internet give me a hard time for using f-strings in some of my libraries because they're not there in all versions and so you have to sort of understand how this is going to impact the people that you're working with and the people who are using your code before you can make a decision about how to make those changes. But for my own projects or things where I'm in control of the server, I tend to upgrade early. For things like libraries and stuff like that, I'll upgrade my test suites, but I won't make the language changes until things are a little more established. So for example, the annotated hints, you can get that at a future so you can use pipe and pipe equals for dictionaries if other people are using your code, you might want to wait a little bit. And Guarana, much the same story, I tend to update my kind of the interpreter I'm running as soon as I can just because it's I guess fun and easy to upgrade early instead of getting stuff stuck behind. But for the libraries, I do as Christopher does, essentially make sure it works at least back to 3.6, which seems to be what has kind of been the.I guess the lowest version that's been supported for a couple of years now because the f-strings got so popular that a lot of libraries moved on to them quite early. Yeah, I think for Python 3.5 was just the latest version that was released, so it's now unsupported. Python 3.5 and now Python 3.6 is the oldest Python version that is officially supported. So I think for libraries, it makes sense to still write 3.6 compatible code. It's kind of nice that most of the things like dictionaries and the remove prefix are probably some of the features that will not be easy to use in older code. While the time zone support that we talked about, which I think is probably the one that I personally will have the most use for, is available as a so-called backport. So while it's not installed with my Python 3.7 or 3.8, I can pip install a package called backport.zoneinfo so I can use it from there, and that's completely compatible with the zone info module in 3.9, so that kind of allows me to start using the time zones already now, wherever I want to, essentially.\n\nI think essentially the question of upgrading is a little bit just which context are we upgrading in, right? So if it's for stuff you're running on your own, then it's usually okay to start upgrading fairly early, well if it's libraries other people depend on, it's nice to just stay backwards compatible for a while longer at least.\n\nYeah, that makes sense. I know we talked about it briefly, but if you were going to compare this release with previous releases, how would you compare it say with the changes that came in because you've been writing articles on this? This is like your third year of doing this, yes?\n\nI guess maybe it's longer because the cadence changed too, right? Yeah, I guess we haven't talked too much about that, but this is my third new features in Python article, which kind of started somewhat randomly. So that would be more two and a half years ago, then I guess for Python 3.7 and at that point I was a fairly new author with Real Python. Dan just posted a question, does anybody just want to write an article for the new upcoming Python 3.7, which will be released in three weeks, I believe if I remember correctly. Here you go. At that point, I had investigated a little bit into the data classes that were, I guess, the headline change in Python 3.7. I had written an article about it, so I was kind of in the mood for it already. So I kind of jumped on that one and fairly quickly was able to write the article, and we were able to publish that on the same day as the release of Python 3.7.\n\nThen last year, when Python 3.8 was released, I was kind of thinking it would be fun to try to do the same for Python 3.8, and we managed to do it again there. I kind of ended up having to harass some of my co-authors and reviewers because again, it was kind of done a little bit towards the end, so we kind of had gotten some experience with working with the new features in 3.8, especially the walrus operator, which I guess was the big thing there. And then they actually changed the release date of Python 3.8 fairly shortly before the actual release, a week or two or something like this, where it was moved forward, or at least I didn't notice until I think a week before that they had changed it.\n\nSo, it was released one week early. We have this big process at Real Python where we review the article in several stages, and we ended up having to, and I was kind of handing in my article to the for technical review with Jim, who I guess was on an earlier episode. Yeah, and while I was sleeping, he was awake over in the US and could kind of do the technical review. So when I woke up, I had the article and I could do the updates, and then when he woke up, he could review my updates, and we could send them over to Joanna who does the didactic review, and so on. So it kind of got everything together and somehow managed to publish this one also on the day it was published. So this year, I guess with some experience now, we managed to at least have it a few weeks early, the article ready, and then now also then coordinate with Christopher so he could do the video course together with it, which yeah, that's actually worked out really good and having a little bit of leeway and as long as everything goes smoothly here, it should have come out on the Tuesday before this.\n\nYeah, you know, it all looks good, right? But yeah, back to the actual question, I guess was how does this compare to the previous releases, and I think if we go back to also include Python 3.6, I think what ended up being probably the feature for the f-strings which kind of moved a lot of projects to only support 3.6 plus.Right, it's become very popular. It's been a long time since I wrote formatted strings the old-fashioned way. In a sense, I really enjoy those for Python 3.7. I think data classes were probably the big change there. Those were also a nice change that you could use a backport for, so it was easy to introduce to your projects. Python 3.8 definitely got the most buzz with the walrus operator or the assignment expression. I guess partly because of the fallout of the whole discussion around whether to introduce it or not, as well since that was kind of what ended up with Guido stepping down as the BDFL. But the feature itself is also changing the language a little bit. I think now that I've gotten to use it a little bit, the walrus operator is one of these things that just gives you a lot of small wins. There are small little places where it kind of improves your code a little bit without making a big change. In that sense, I guess it's somewhat similar to f-strings. It's small wins all over the place that kind of adds up over time.\n\nThis one's kind of a lot of other just smaller wins, but underneath it, the peg parser probably would be the big one. I guess the lasting legacy of 3.9 will probably be the peg parser. But for 3.9, we don't really see the effect of it right now. I think for people who need it, getting time zone support into the library is probably nice. That's probably the one that I will personally use the most, and that's an easy thing to introduce because of the backport. Then I think the updating of dictionaries and the remove prefix and suffix methods are probably the ones that will see the most use when it becomes more available. All those you kind of need to wait for having full support for 3.9 to release since it's a syntax change essentially.\n\nOne of the big changes coming up already is not moving to Python version 4 right away. It's already in process. It's something I talked about with Lukas Langa very early on in the podcast history. He's the release manager for Python 3.9, and he was telling me at the time that they were already working on Python 3.10. He thought he was going to be the release manager of that, but now there's a new person who's going to be handling that, which is probably good to take a little load off of him after 3.9. So now, version 3.10 is going to come out, and that can cause some potential issues. I had a similar problem with Apple's operating system and this installer called Brew. When the numbers went from 10.9 to 10.10 to 10.11, the simple syntax of saying greater than or less than as far as pinning the versions that this Brew install could work with sort of broke. I think that may happen in some Python code. Is that right, what you were thinking, Christopher?\n\nThat's just something you need to be aware of. There are two ways of describing a version like this inside of your code: the good way and the bad way. The bad way is with strings. So if you've been a good little boy or girl and you've been using the sys library the way you're supposed to, then you won't have this problem. But if you've got some hard-coded version strings in there, you can run into a bit of a challenge. Flake8 has been updated to check explicitly for this difficulty, so if you're using a linter like Flake8, it'll help you catch these kinds of little corner cases.\n\nSo, Christopher, I have these weekly questions that I ask everybody. What's something that you're excited about in Python right now? It doesn't have to be specifically about Python 3.9; it could be a package, an event, a book, or what have you. So what's something you're excited about?\n\nI've just started Anthony Shaw's \"CPython Internals.\" I've got a background in other programming languages, but for Python, I've always come at it from programming with Python rather than understanding how it works underneath the covers. The chance to break the spine on this and look at how the pieces fit together and maybe go back to my computer engineering roots and understand how these more complicated systems work will be a nice little refresher for me. I'm looking forward to digging into that.Yeah, nice, Garen. What are you excited about right now?\n\nI think I'll mention a library called Panel, which is a dashboarding library. It's somewhat similar to Dash that's built on top of Plotly. Panel is definitely similar and can show the same use cases. I have been using it for a project at work for a while where I'm building a somewhat complicated dashboard. It's been an interesting learning curve, but one thing that I missed when building this complicated dashboard is that it's super nice for prototyping dashboards, similar to what you can do with IPython widgets or Jupyter widgets. With a Jupyter notebook, you can give Panel some data, and it will build the dashboard from it. Then you can start playing with your data immediately. You can start from this prototype and gradually build it into a more professional-looking dashboard. It's been really fun discovering some of these features, and the community around this Panel library is really nice. It's still under very active development, and the people working on it are super responsive whenever I've had any questions. I've really enjoyed playing with that one, and it's part of a bigger set of packages called PiViz, where there are also packages called HoloViz, hvPlot, GeoViews, among others that are packaged together. It's a really nice way of working with different visualization tools.\n\nChristopher, what are you interested in learning next?\n\nThe stuff I'm working on right now is all web stuff, and the next project up is probably going to be a desktop application in the data space. I'm not 100% sure that's what's happening yet, but that's what it's looking like. As a result, I'm going to have to dig into some GUI stuff, probably PyQt, and I'm definitely going to have to be digging into pandas and likely numpy as well, and using all those things together. I've got a big to-do list in the back of my mind.\n\nAnd Garen, what are you looking at learning next?\n\nMy background for the last couple of years, I've been working with the Norwegian Mapping Authority before I changed jobs last year. I got to do a little bit of GIS tools or geographical calculations there. Now, I have a couple of projects coming up at work where we'll really be diving into even more details about this. These are things I find really fun to play with, and now I have projects where I can really go in-depth on them. That seems really exciting.\n\nOkay, cool. Hey, I really want to thank you for taking all this time to break down not only your article, Garen, and the video course, Christopher. Thanks again for coming on the show. \n\nMy pleasure. It's been a great time. Thank you very much.\n\nI want to thank Christopher and Garen for joining me this week on the Real Python Podcast. Make sure you subscribe to the podcast in your favorite player and if you like the show, leave us a five-star rating and a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "LMwIyXxcipY": "Welcome to the Real Python Podcast. This is episode 33. You probably have heard of the best-selling Python book \"Automate the Boring Stuff with Python,\" but what are the next steps after starting to dabble in Python basics? Maybe you've completed some tutorials, created a few scripts, and automated repetitive tasks in your life. Well, this week on the show, we have author Al Swaggart to talk about his new book \"Beyond the Basic Stuff with Python: Best Practices for Writing Clean Code.\" \n\nWe discussed several topics covered in his new book, including using the command line, setting environment variables, formatting code, naming, and starting with version control. We talk about learning Python by creating games and highlight a couple of Python myths. I also asked Al about his earlier books and about his idea of creating a curriculum around conference talks. \n\nAlright, let's get started. \n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Hey Al, welcome to the show. \n\nHello, thanks for having me. I wanted to have you come on because I saw the announcement about the new book coming out and that it's in this early release, and I was able to get in on the early access deal here, and I'm really enjoying it. \n\nOh, that's great. For a while now, people have asked me because I'm mostly known for writing \"Automate the Boring Stuff with Python,\" which has been a really knockout success that I was really surprised by. So people ask, like, what book should I read next? It's kind of tricky because that whole intermediate area is really hard to cater to a lot of people. You know, it's described as the tutorial desert or tutorial hell, where you know the language syntax and know enough Python that you can write some code, but you feel like you're not really writing real programs like the way that professional software developers do. All the materials out there seem to either be hello world tutorials or some advanced niche machine learning topic. \n\nAnd you really can't follow along. For the longest time, I didn't really even know what a sequel to this book would look like. In fact, looking at the git repo I set up for the book project, I actually started this about three years ago. Quite a while, and so I've been working on lots of other things in the interim. But the book as it is right now is very different from the book that I had originally conceived for it, but it's all finally done and it's coming out in November. \n\nWas \"Automate the Boring Stuff\" the first book you've ever written? \n\nI started writing programming books in about 2009. My girlfriend at the time was a nanny for this 10-year-old who wanted to learn how to program, and so he asked her to ask me to find some resources or something. I thought, okay, yeah, that should be easy. We have the internet, we can dig something up. Of course, the problem with that is we have lots of information, but it's not really curated very well at all. \n\nSo I thought, okay, I remember the programs and games written in the programming language BASIC that were written in magazine articles like Byte magazine or things like that where you would just copy it, totally type it in. All these really simple programs. I only had two books that covered programming at all. One of them was a book that a friend of mine found at the school library and it had the source code for a bunch of small little games like that. The other one was the reference manual that came with the 386 computer that my parents bought. \n\nIt was even before QBasic. I was still using line numbers as part of it. The programming book I got at the school library was great; it just had those \"Guess the Number\" type games in it. I didn't even really read the content of the book so much as just copy the code and play around with it a little bit. And then the reference manual, I had no idea; I couldn't understand any of it. It just went into lots of technical detail. So I thought, well, it was really great just having the source code for these small games, and that's how I just kind of learned from the example. \n\nSo you started in the game area. That's great.Yeah Mahmoud Hashemi in the Bay Area had a great talk where one of his talk slides was a venn diagram of how people get into programming. One circle is making video games and the other circle is getting away from Microsoft Excel.\n\nYeah, I think that one slide sort of encapsulates my entire book writing career strategy. People like making video games and they also like automating boring stuff. At the time, this was just a tutorial that I threw up on the web and put into \"chapters.\" Then somebody said, \"Hey, you should self-publish it.\" So, I did that. I created a PDF through a convoluted series of hacks and it became a poorly edited self-published book on Amazon. Once it was on Amazon, everybody thought, \"Oh, you're an actual author now.\" Yeah, I thought, \"Sure, that's a fiction that I'll let you have about me. I'll encourage that.\" And I still do that to this day. People seem to like it, so I wrote a second book about Pygame, a third book about small cryptography projects, and then approached No Starch Press for the fourth book. They agreed to publish it.\n\nI remember while writing this book, which took about a year and a half in my spare time while still working as a software engineer, I wrote in my diary that I had no idea if it would be useful for people. But it turned out to be really successful before I left my software engineering job. Seven years ago, I took a year off to finish writing the book, and it's been great.\n\nAutomate the Boring Stuff really took off, so I started creating a Udemy course and some YouTube videos. I've managed to make a career out of this, and the Udemy stuff has become a nice income stream for me.\n\nMy first Python job was only about three years ago, and they gave me your book as a reference. I got introduced to it that way and picked up a copy. No Starch is a great publisher, and I had a good experience working with them while I was in San Francisco.\n\nI've since moved to Seattle about a year ago, and it's been quite an interesting year. Yeah, interesting is my favorite euphemism to use - especially for 2020.\n\nWhen writing the book, I wanted it to be more of an advice book than a computer science or programming book. I wanted to focus on practical aspects rather than just syntax and abstract concepts. In 2012, there was a big push for everyone to learn how to code, and I wanted to provide a different perspective on programming for beginners.Do we actually all need to learn how to program? A lot of people interpret that as everybody needs to become a software engineer, and that's clearly not true. But at the same time, everybody's using computers these days. Like, 20 years ago, if you were talking with your friends in chat rooms every day, you were like this huge nerd. But today, that's just the average social media user. \n\nI started thinking, what's the minimum amount of programming that you would need to know to do useful things? And what are these useful things? I started getting ideas, like it'd be nice if you could update spreadsheets, rename a bunch of files in a certain way, send out notifications, or compile reports. I was also talking to various friends and people. There was a guy I met at a meetup who taught himself enough Python programming to automate a task where every morning he would have to go to the Yahoo financial webpage, copy and paste a bunch of things into a spreadsheet, and then email his boss. It would take him like an hour and a half to compile all of this. He finally wrote a script to do this in a few seconds and just took an extra long lunch every day without telling his boss.\n\nThere's a lot of things that, because we use computers every day, an average person who doesn't need to become a software engineer can save themselves a lot of time if they know a little bit of coding. That was the most common job I was doing inside the bank that I worked at. I was doing SQL and a bunch of other things before, and building stuff in Access and all these other kinds of tools. Then this new job I got brought me on as an automation engineer, and I didn't have as many tools as I wanted because of the secure environment. So, I ended up creating small tools, and Python was the best tool for me to rapidly develop these things and solve problems.\n\nPython's popularity has exploded in the last 10 years, even though it's a 30-year-old language. It has origins in the ABC language, designed to be easy to learn and use. Everyone likes tools that are easy to use, whether amateurs or experienced software developers. I first got started with Python in the mid-2000s, and I stopped learning new programming languages because Python was great for everything I needed.\n\nIt's easier to list the things that Python hasn't dominated in the software space, like embedded computing. But there's MicroPython and CircuitPython for that. Gaming is another area where Python isn't used much, but there's Pygame and a few commercial games made with Python. I adapted my book on games multiple times, with technically the fourth edition being produced by No Starch Press. Each update improved the book, cutting out extraneous detail. The types of games in the book remained the same through each edition.But I would also just sort of make that simplify the source code and simplify the explanations. So, I would actually end up with fewer pages than what I had started out with, which is always great because I remember learning this fairly early on. Every time I find some programming book that's like 600 pages, I realized that about half the stuff would be things that I already know. So, I would just start skimming the book and then realize at the end of the chapter that I haven't actually been paying attention to anything.\n\nOkay, but it's, yeah. \"Automate the Boring Stuff\" is also getting to, I think, like 500 pages, and I know the second edition had about 100 pages added on to it. I'm just very keenly aware that for a lot of people, programming is seen as this really intimidating thing, especially because all of these books are 600 or 1000 pages long. It seems like such a huge investment and people are worried about, \"Am I even smart enough to program?\" Once you actually start programming, you realize that actually nobody knows how to write software. We're all constantly making bugs, right?\n\nDo you find that to be a goal then, to make it less intimidating by maybe keeping the book a little smaller?\n\nYeah, definitely. In fact, I think with the follow-up book that's coming out soon, \"Beyond the Basic Stuff with Python,\" I think it comes out to be about 325 pages, which is sort of what I want to aim for in a textbook. It's not even really a textbook per se, but just like a technical book that you would sit down and read through. Not just like a reference book that you have on your shelf that you only consult every once in a while, but something that you actually read cover to cover.\n\nI started to do that. I started kind of diving into it, and I have this real mixed past of different languages and different books. For a little while, I was going to learn Swift because I was interested in the mobile thing. I kind of bounced around and kind of landed on Python and really fell in love with it. Ended up working with Real Python, which I've covered multiple times on the show. But there are things that are missing. I went to college in the 80s and dropped out. I got into music, was in a band, toured, and just kind of left all that behind. I came back to computers and all that stuff much later, so my CS background is limited. I found it really great to learn by teaching. That combination has been a great way to learn.\n\nYeah, for sure. I kind of get that from a lot of your writings, the way that you're explaining things. It feels like you've found a lot of these stumbling blocks in \"Beyond the Basic Stuff\" and you're trying to share that advice and say, \"These are the things that I always call sharp edges that you have to sand off and try to help people not get cut off as they're working through things.\"\n\nI try to compile a list of the random things that you just learn with experience that everybody who is an experienced software engineer seems to know but nobody really remembers when they learned it. There are already a lot of great books out there if you want to learn more about the Python language itself. So, I wanted to touch on some of that stuff but also go into general software engineering best practices. I talk about code style, code formatting, and conventions. This is why we do things this way. At the end, these are all just my opinions on things that I've learned in my career and what other people say. They're not necessarily the one true way to write software. That whole idea is very nebulous, and most of the time, getting into arguments about it is not as productive as you think it is.\n\nI've been that way about technology my whole life. I've been around all these different people who really want to turn everything into some form of technological religious battle. I'm so agnostic about all of it. I have what I like to use, what's my favorite, and maybe it's just because I've been surrounded by the Python community so much. The Python community is really great, but I think I've noticed that it's sort of tended to die down in the last 10 years. Certainly, in the 2000s, I had lots of friends in computer science who were like, \"You use Windows, that's for losers.\"And just a lot of like, here's what the real programmers use. The webcomic xkcd has a whole joke about that where it's like, well actually, real programmers use butterflies to flap their wings in such a way that it alters the magnetic particles on a hard disk. That's how you should really write code.\n\nYeah, I've been part of that whole religious thing for Macs and PCs. It could be like a video game platform or even the music stuff. People were so anti-digital stuff. As you get older, you realize none of that stuff is important at all. Everything is sort of terrible. You should work on creating things, shipping, getting things done. Even right now, I still think programming is fun and really cool. But at the same time, I'm more focused on creating software that people actually use. If I could create software that people actually use by wiggling my ears instead of typing on a computer, that's what I would be practicing every day.\n\nThe actual process or the languages of the platforms that you use, I don't think that they have any inherent betterness. Especially after several years working in the tech industry, you realize you've seen how the sausage is made and any illusions you have about the sacredness of something is long evaporated.\n\nOne of the things I liked you covered was an area about environment variables and setting them up. It's an area that I don't have a lot of background with, like bash and terminal scripts. But it's something you need to know to get past some of those basics.\n\nIt's nice because you cover all the languages, all the platforms - Windows, Mac, Linux. That's actually the first part of the book. The first chapter is getting help and how to ask questions properly. There is a whole etiquette behind asking programming questions. You learn things in school where you have a person to ask questions to, but on the internet, it's very much asynchronous communication. You post something, then wait for a reply. It helps to have all the information up front.\n\nI still get emails from readers saying my program doesn't work, and that's the entire email. I finally wrote up a blog post that I send them a link to. Here's how you can ask for help. That's a foundational skill that people don't necessarily have instinctively.\n\nPeople don't seem to really know or formally sit down and learn the command line. It's something you pick up over time. The command line is a great way to unambiguously run certain programs and perform certain actions. It lends itself to automation better than a graphical user interface.\n\nThe command line is intimidating because it's just a blank window with a blinking cursor. It doesn't offer help like a graphical user interface. People put off learning the command line for a while, along with things like the file system and environment variables.\n\nPython and programming instructors have picked up on the fact that setting up Python on different systems can take up a lot of time in workshops. I quickly cover basic command line commands to help with this process. You don't have to become an expert, but understanding the basics can be helpful.And like, oh, you can have an asterisk that represents a wild card to mean all files in this current folder. Here's what current working directory means and all these other random bits of knowledge that you pick up over time. But it can be hard to find a place where all of that is collected and gathered into one spot.\n\nYeah, I liked it. I learned a couple commands inside of there that I hadn't been using and practicing. There are other ones that I am more familiar with, but I didn't know the idea of just printing out the entire environment, which was great in the history. These should be common commands that I should know, but I just, you know, that's one of those things where if you gathered all your information in all these random places, there are going to be gaps.\n\nIt's also really easy to go deep into the command line and have all these convoluted commands where you pipe the input of one program to the output of another. It does some really sophisticated things, which is cool but also intimidating for beginners who just want the program to do the thing they are concerned with.\n\nI like that you had a chapter about naming things. There's an old joke that the two hardest problems in computer science are cash invalidation, naming things, and off by one errors. Naming things is really hard. I stream on Twitch irregularly, and I realize it's hard to come up with good names for variables, functions, and things like that.\n\nYou come up with names for all these things, but there are drawbacks to some ways. We don't need to write function names like in the 1980s with C where functions were written as abbreviated versions. Readability is important when writing software, and coming up with descriptive names is crucial.\n\nI have a chapter full of advice that I've picked up, and I have a low-level anxiety all the time about this book. I can already see one-star reviews coming in, but this is what works now. Ten years from now, we might be doing something completely different. Naming by emojis might be the way to go.\n\nA lot of people use variable names that are just single letters, especially in computer science classes in college. This comes from the fact that computer science grew out of mathematics, where math notation is all individual letters or Greek letters. It can be confusing to see algorithms presented in pseudocode compared to real code that you can run under a debugger.\n\nI don't like pseudocode.But it's this thing that we continue to do because that's the way it's always been done. I'm in the same boat when I've taken some several real Python articles written by people who are probably much more in a CS background than myself. Everything is foo bar baths and all these kinds of weird things, or the variable names are just individual letters or letter and number. It's like my eyes end up crossing, and I go out of focus, and it means nothing to me. I quickly converted it to... \n\nI see you do kind of a similar thing, the Pythonic style of Monty Python names. It's like spam, bacon, eggs from the Monty Python spam sketch, yeah exactly, and lobster. I totally agree, it's fun in that way, it's kind of silly, but at least it's more of an object than foo, you know? But it's still a bad habit that I have even when writing these books, and I need to go back and probably in a future edition, I'll try to get rid of it entirely.\n\nThere's a chapter in \"Beyond the Basic Stuff with Python\" where I just covered jargon and these variable names are called meta-syntactic variables, things like foo and bar and spam, and they're just stand-ins for generic variable names. It doesn't matter what the name is, we're just showing some bit of syntax. But at the same time, a lot of people do get turned off by that. It seems to completely lack context and it's completely abstract, and that can be really hard to follow. It's sort of... I never really appreciated how hard it is to come up with good examples that don't seem entirely contrived. And because of that, I end up just falling back on, \"Oh, we just have a list in a variable spam,\" because I want to talk about lists more than variable names and it doesn't matter what the name is, right? Sort of like if you're teaching a business class and you just talk about widgets and things like that, well, you know the actual details in the real world do matter.\n\nSo the chapter on names sort of talks about how it really is important to sit down and come up with names if you're writing software that you intend on actually updating and using continuously, right? So it'll make sense to you in the... oh, sure, yeah, it's such a huge part of it, right? The whole documentation and naming are like a good percentage of documentation, yeah. I mean that's really important when writing software on a team that everybody can understand the code that everybody else is working on. But also, you know, every programmer has had the experience where they're looking through some code and they're like, \"Who wrote all this stuff? It makes no sense,\" and you find out the answer is, \"Well, you did three weeks ago.\"\n\nTalking on the theme of working with teams, I see you have a chapter about code formatting and using black, yeah, black is a tool that will go through, it doesn't change the behavior of your code, it's a code formatter, it just adds spaces or removes spaces or makes your code look cleaner without changing what it does. It's a really great tool for formatting Python code. But I think the most useful thing about it is that it prevents you from getting into arguments that are kind of pointless with your team members about spacing or changing or making little check-ins to the repo with better style changes and then having a co-worker change them back because they prefer it the other way. There are things about the way that black formats code that I don't quite like, but on the other hand, I can live with them, so it's just so much easier to say, \"Hey, this is something that software can do, we don't have to sit down and do all these tedious little edits, we don't have to have arguments, let's just do what black does to our code and that's that, that's what we'll just do.\" It's so much easier to make that decision than to make the thousands of little decisions forever and ever about how you should format code or anything like that.\n\nWe use it at Real Python for a variety of reasons, to again avoid any kind of arguments on that stuff is still, I don't know, it's a form of efficiency, yeah. And you know it's been said before that programmer time is so much more expensive than CPU time. Going back to some of the ideas on naming and explaining concepts, why do you enjoy teaching Python using games? It's probably because that's how I got into it. I remember my parents got my sister and me the 8-bit Nintendo when we were pretty young, so I was really into video games as a kid and really into Lego building blocks.When I first found my friend introduced me to this book that taught programming and basic, I thought, \"Whoa, that's really cool,\" even though the games that I made weren't nearly as good as anything that I played on the Nintendo. Most of them were based and most of them didn't work. I had a lot of projects that were just half-finished and never did anything. I don't like talking about the fact that I was one of those kids that early on learned programming because it reinforces the idea that you have to have started really young and had tons of experience. Everything that I learned between the third grade when I was first introduced and graduating high school could probably be learned in a dozen weekends. \n\nIt really wasn't easy because we didn't have Wikipedia or YouTube tutorials, or even all the books that are available now. You just found the O'Reilly book on a certain topic and that was pretty much the definitive guide you used for whatever programming language. We didn't even have Stack Overflow, so if you had questions, you had to figure it out on your own.\n\nIt's so much easier to learn programming these days. Video games were the gateway drug into programming, and I think it still is for a lot of kids today and people in general. I have another Python book project in the works that should be out in April of 2021. It's like the old Byte magazine code listings, with about 80 Python projects, most of which are games. They are all text-based, which is nice because the output of the program is the same text medium as the source code, making it easier to understand. \n\nThese programs are generally under 250 lines of code and are simple things like guess the number or blackjack. It's a neat little project that you can create yourself and is mildly amusing for a short time, but it only takes a short amount of time to type out. \n\nGames are a great way to get into programming, and I'm glad that computing has video games as this thing. If you want to get into car engines, there's a huge investment required, unlike in programming where you can create something fun in a short amount of time. It's a very exciting time for electronics now, with prices coming down and programmability increasing. \n\nI never got into hardware mostly because of the investment required. My parents got a desktop computer in the 90s, which was not common at the time, but having it at home was a huge advantage for me. I want to make programming books available for free because even a small cost can be a barrier for some people.I'm trying to. It seems really absurd now in the 21st century when I pay about 15 bucks a month for web hosting, but I can send out tens of thousands of copies of my book to people. It's just so incredibly cheap to distribute information. \n\nI kind of want to get rid of as many of these barriers as possible. This week, I want to shine a spotlight on another Real Python video course. It's about a topic we touched on briefly in this week's episode. It's one of those areas where a good foundation goes a long way towards your programming future. It's titled \"Unicode in Python: Working with Character Encodings.\" \n\nThe course is based on a Real Python article by Brad Solomon and is presented by previous podcast guest Christopher Trudeau. Python's Unicode support is strong and robust, but it takes some time to master. By the end of the course, you'll know what an encoding is, what ASCII is, how binary displays as octal and hex values, how UTF-8 encodes a code point, how to combine code points into a single glyph, and which built-in functions can help you. \n\nI think it's a worthy investment of your time to learn the intricacies of Unicode, UTF-8, ASCII, and how to use them when programming in Python. Like most video courses on Real Python, the course is broken into easily consumable sections and has code samples for the techniques shown. It also has a shiny new transcript in closed captions. \n\nCheck out the video course; you can find a link in the show notes or you can find it using the enhanced search tool on realpython.com. \n\nShifting topic a little bit in the \"Beyond the Basic Stuff\" chapter about Git, why did you include a chapter about that in this book? \n\nGit is a version control tool, which for folks who don't know, is basically if you could just save every time you saved a file, you could go back to previous saves. Version control tools are especially useful in software development because then you can see all the previous versions of the code that you've been writing. Git is one of those things that all professional software engineers use but isn't something that amateurs, hobbyists, or people who are just getting into programming are aware of. \n\nIt can be intimidating and technically challenging, but the basic ideas are fairly simple. I only have one chapter on Git where I talk about how you can save snapshots and then roll back to previous snapshots of your code. \n\nWith this book, I try to figure out all the things that you aren't really aware of as a beginner, like code formatting tools, the concept of code style, and Git. I have another chapter on jargon and technical terms, explaining the difference between an interpreter and a compiler, a module and a framework, and engine and an SDK. \n\nI try to break down any acronyms and technical terms in the podcast because I feel like not everyone listening may understand. In fact, especially with technology, even professionals can use technical terms inconsistently or interchangeably when they're not the same thing. \n\nWhen I was writing my first programming book and teaching, I realized that writing a book and teaching something is the best way to learn it because you have to stop after every sentence and question if it's actually true. You have to stand behind it, and it's a weird process.Yeah, every sentence is a possible nitpicker review on Amazon or something like that. When I was writing my first programming book, \"Invent Your Own Computer Games with Python,\" I realized that I actually didn't know the difference between an expression and a statement. I just thought, \"Oh, those are just code instructions, they mean the same thing.\" Then I realized, \"Oh, actually no, expressions are the instructions that can evaluate down to a single value, like 2 + 2 evaluates to 4. Statements are every other expression, like the for statement, while loop statement, or if else. I was like, \"Oh yeah, that makes a lot of sense.\" I had been several years out of college at this point, employed as a professional software engineer, and I didn't know this basic fact.\n\nI would occasionally get into discussions about the interchangeability of the terms \"parameter\" and \"argument.\" Technically, they're very similar and often interchanged, but if you want to get super technical, it's funny how the term \"keyword argument\" should actually be \"keyword parameter,\" but nobody seems to use that terminology. Everyone is just used to saying \"keyword arguments.\"\n\nVariable names like \"kwargs\" threw me off initially, seemed jargony. I talked to Michael Kennedy about it, and it seems to be moving in a different direction, becoming less common in some packages. It depends on where you look, but it's nice to have things named and defined.\n\n\"Automate the Boring Stuff with Python\" doesn't cover object-oriented programming because it's an extra layer of complexity that you don't always need. It's easy to over-engineer code, especially when learning new features.\n\nThe first book where I talk about object-oriented programming is \"Beyond the Basic Stuff with Python.\" OOP is a feature you don't always need, like all the args and kwargs stuff. You can write code without it, but sometimes you can make use of it. It's easy to over-engineer code when you learn about new features.\n\nThe last three chapters of the book cover classes and why we use them. Classes bundle code and data into objects, creating units from classes. I came up with the metaphor of forms that you fill out, like at a doctor's office. Classes are like blank form templates filled with information about objects. Objects created are instances of those forms, like actual doctor's patients. You don't have to translate real-world objects literally into classes; it's how you use it in your software, like a car class in a racing video game or a traffic simulator.And so, there is no canonical car class or animal class. Another common metaphor used is that things like animals or cars are used because they lend themselves to explaining inheritance, which is covered in the second of the three OOP chapters. I want to emphasize upfront that you really don't need to use inheritance. It tends to make things overcomplicated. Luciano Ramalho, the author of Fluent Python, wrote in his book that programmers tend to love creating hierarchies and taxonomies of classes, thinking they are adding organization when they are really just adding bureaucracy to their code.\n\nSix months later, we often realize that what we created is too complicated with submodules and grand visions that were not practical. With years of experience, I've realized that most of the code I write today will either be changed, deleted, or forgotten about in a few years. Code needs to be maintainable and readable, but like the poem about Ozymandias, the great works we create will likely be forgotten or changed soon after.\n\nThe third chapter briefly covers multiple inheritance, which I took a long time to understand and explain. I added a warning that you should avoid using inheritance and especially multiple inheritance. However, if you encounter it, you need to understand how it works to avoid problems. The chapter then delves into Python properties, overloading operators, and how objects can interact with operators like the plus sign or the length function through dunder methods.\n\nOperators like equal and not equal can be customized using dunder methods, which is a neat feature. These operators are shorthand for function calls, simplifying common operations like addition or string concatenation. It's easy to go overboard with using punctuation marks for operations, like in Perl where it can seem like random keyboard mashing. Regular expressions, stemming from Perl, are powerful but can also be easily misused if not careful.Knowing regular expressions is a useful thing. It is pretty good that we have shorthand notation for text pattern matching with regular expressions. It's always a balance between readability and reusability. I have done a few things with regular expressions while working in a marketing department, dealing with addresses and names. It's the tool for that kind of task.\n\nAutomate the Boring Stuff took off because there are many tasks we do on a computer where there is commercial software available. Departments and organizations fit their workflow to the tools they have. For example, many companies are tied to the way Microsoft Outlook works. With programming, you can create custom tools for personal or organizational workflows. There may not be commercial software available for every task, but with a bit of programming knowledge, you can automate things and make your life easier.\n\nThere is a myth that Python is slow, but it's misleading and irrelevant for most cases. The slowest part of any software is often the human user, not the code itself. People tend to focus on writing fast code rather than user interface design, which is also important. Some myths in programming, such as global variables being bad, were relevant at one point but are no longer as critical. It's important not to over-rely on global variables to maintain code isolation and easier debugging within functions.At the same time, it's okay to use them. Sometimes, you shouldn't just blindly point to a global variable and say we need to get rid of this because global variables are bad. There are a bunch of myths like this where they require more context. Another one that I talk about in the book is functions should do just one and only one thing. Functions should never be longer than 30 lines of code or 20 lines of code or some arbitrary number like that. While that is true, you don't want to have your entire program in one function. It's easy to go too far in the opposite direction where now you have a thousand functions that are all really small and tiny. Individually, they're easy to understand, but now you have these thousand functions all calling each other, and so the relationship between them has now become much more complicated than the program that you had before.\n\nThere are a lot of these code myths, and I had to be very careful when I was writing this section. Some people might say, well actually that's how I write programs, and what's wrong with that. So again, I have to say this is just my opinion and in my own experience, and from what I hear other people talking about as well. I can already see the blog post reactions, the hot takes, all swagger, it's code myths. But yeah, I mean that's the nature of the world. Things that I write down, I'm probably gonna look back at \"Automate the Boring Stuff,\" which I first wrote in 2015, I think when it was published. There are still things I was like, I really want to change that, I have no idea why this book is popular. Oh god, people think that this is the right way to do things.\n\nThose sort of problems, but it's still like having just being aware of the rules will help you out because then you'll have a better understanding of when you can break these rules or when these rules don't apply. Totally, so I think that's what I'm trying to convey to people who have already learned the syntax of a programming language like Python, but they don't necessarily know how things are usually done in professional software or organizations. That's cool, I feel like that kind of is like an overarching theme for the whole book, right?\n\nYeah, the gotchas, the oddities, the advice-based throughout the whole thing, especially because the second half of \"Automate the Boring Stuff\" just covers all these third-party modules for doing things like updating Excel spreadsheets or reading PDF files and things like that. The problem with that is those modules can get out of date, where newer versions come out, and then people start complaining that this book is out of date, even though you can always run the old versions and it's fine. Python 3.9 has just come out, but that doesn't mean that every organization needs to instantly update to Python 3.9, although you should update to Python 3. Everyone should do that at this point.\n\nWith \"Beyond the Basic Stuff with Python,\" I wanted to try to get something that was a little bit more timeless, so it would stay more relevant longer than an entire book because it takes a year or longer to create these books. So you want to get as much out of them as possible. I hear that's a big problem from people who have written books on Django or something like that, like a new version comes out every year. So you have this limited window of when a specific edition of your book is relevant, and then you have to update it, and it's a lot of continuous work. They've been moving fast, going from 1.11 to 2 to now 3.\n\nYeah, I've bought some Django books from William Vincent, and he's been trying to update them as he goes. I can re-download an updated version, but it's definitely challenging for him. Audrey and Danny's \"Two Scoops of Django\" is another one. I've heard from them that this is a big problem for them of keeping the book up to date. But at the same time, I'm glad that all of these folks do this work because the Django tutorial online is really great, and you have Stack Overflow and other things like that.But there is, I still think that books have a place in the tech industry, even though we have things like YouTube tutorials and Stack Overflow. A book is like a cohesive unit of knowledge, where you won't have the anxiety of randomly googling things for five hours and not being sure if you have the correct information. With a book, you can just read through things and there is an overall vision behind why all this information is compiled together.\n\nI'm a book author, so of course I would say that everybody should buy three copies of my book to read it faster. When it comes down to it, the time frame involved in planning and writing a book, having an editor, and releasing an early copy for feedback make it a different animal. Books definitely have their place.\n\nI have these weekly questions that I like to ask everybody. The first one is about something you thought you understood in Python but turned out you were wrong about it.\n\nThere's a talk by a Python talk by Ned Batchelder called \"Facts and Myths about Python Names and Variables.\" He mentions a gotcha with mutable objects like lists and dictionaries. When you change one variable that refers to a mutable object, you end up changing all variables that refer to it. Python assignment only copies the reference, not the value itself.\n\nLearning that everything in Python is an object and variables only contain references to these objects was eye-opening for me. It made so many things make sense that I hadn't known before. Programming languages are social conventions, invented by humans. There is no one true way, but you can argue that the language you like is the best objective language possible.Yeah, totally. What is something you're excited about in the world of Python? It could be a book, an event, or a project. Well, there's this book coming out next month called \"Beyond the Basic Stuff with Python.\" So, a serious answer that we talked about earlier. Python is relevant to many domains like data science, web applications, sysadmin, but not so much in gaming, embedded, or mobile. The Beware project is seeking to address this. It's a way to write Python programs that can run on Windows, Mac, Linux, Android, and iPhone. For the last few years, I've been telling myself I need to make time to get involved with the Beware project and help out because it would be fantastic to write Python code and create Android and mobile applications. It's like the next frontier that Python should conquer, in my opinion. They are making steady progress, despite not having a major corporation backing them, like Python. Once they can start getting that off the ground, it would be fantastic.\n\nI posted some stuff about Beware on Twitter, and Russell reached out to me. I ended up having him on the show to talk about Beware. We discussed the whole thing with Android, which they were able to get funding for. Russell talked about the struggle to get funding to keep going. He said he'd rather work on Beware than have a day job, which makes sense. It would be cool to take games and projects and put them into those projects in a simplified way. Russell Keith McGee is one of the core reasons Beware continues to exist. The major challenges in tech are not technical but organizational.\n\nSome games have been programmed in Python. I was hoping to get Piper on from Pursued Pipe. She worked with Russell on some stuff and did a talk recently. I missed it due to life. She did a PyGotham talk that intrigued me. There's a game called \"Code Mallow\" on Reddit, a four-player fighting game written in Pygame. It's one of the more impressive Pygame games I've seen. There's also a strategic World War II game called \"Unity of Command\" written in Python. Pygame seems to be the main framework for these games. Unfortunately, Python programs can't fully take advantage of multi-core CPUs due to the GIL. Games are CPU-heavy and require calculations to draw the screen multiple times a second.So that's something where you really need to have multiple multi-threading to run all these calculations, but also have the ability to rely on automated memory management because you can't just have garbage collecting happening at random points that would slow down the frame rate of the game. So Python, I think, hasn't really taken off in gaming for that reason. That's an area where Python is slow and is somewhat of a valid criticism to have when it comes to making video games. But at the same time, not every video game has to be a blockbuster $100 million production, right? You can still make a lot of really fun games with simple graphics. I think things like Minecraft or Stardew Valley have really shown that. Or strategy games and stuff like that. Yeah, you can make these games that don't rely on intense 3D graphics, but they're still engaging and fun. So I think Python and Pygame can have a real edge in that area.\n\nWhat do you want to learn next? Obviously, you can't see this, but I'm now staring at the whiteboard that has dozens of post-it notes and random scrawlings written on it. I would like to learn C# and Unity because I have some little 3D game projects that I'd like to make. But I'm still sort of stuck in the 16-bit Super Nintendo era as far as all the games I make. Where it's like, \"Ah, 2D graphics are fine.\" But there are some 3D things that I want to work on. Kotlin is a language that I think has a lot of promise and I want to learn that so I can write Android applications, which is something I picked up years ago but then I didn't keep up with it. But that could be amazing. And then a lot of people just sort of assume because I wrote this popular programming book that I know everything about coding. Again, that's a fiction that I will encourage in everybody. But the truth is, there's still a lot of things I don't know. I haven't really touched on many machine learning or deep learning or data science topics at all. Like I still haven't gone past the hello world examples in pandas and a lot of things like that. So that's on the list as well. Most of my ideas are usually software-related, even the ones that aren't. I want to learn video editing and the basic filmmaking techniques, but mostly just so that I can create programming tutorials on YouTube and online classes and things like that.\n\nWhat tools do you have in mind for that? I have no idea at all. Adobe Premiere seems to be the main thing that people use, but that is also expensive. So I'd like to learn the free software stuff for that, like Blender for 3D modeling and 3D printing. There's a great tool from DaVinci that I've heard of that's free as long as you're not doing 4K. And I think for most tutorials, 1080p is probably okay. For assembling stuff and putting things together, it's totally like one of those teaser kind of things. For 4K, that's making TV shows and movies at that point. Probably it's a whole other level. So they're trying to follow the strategy that Adobe used, which is like, \"Hey, let's make Photoshop the industry standard.\" They never gave away Photoshop for free, but it was really easy to pirate. So everybody learned Photoshop as opposed to the Linux freestyle software alternative. Video editing, 3D modeling, and 3D printing. I've yet to actually sit down with Circuit Python or anything and make a blinking LED thing. Getting involved in hardware seems like it would be fun too. But at the same time, I have tons of book projects, software projects, and other things that I'm also working on.\n\nYou mentioned this other project when you were talking to Nina on Python T, and again, this is just one of those one-off things. You're like, \"Oh, this would be a fun idea.\" But it was about there being so many virtual conferences this year, right? Everything that's going on, and I thought it was a neat idea. I found a lot of guests by looking through the PyCon listings and watching a lot of the videos, and it's been really useful. A way to gather that. But you're kind of talking about creating a pseudo curriculum, and I thought that was a really great idea.Yeah, sort of goes back to when I was working on an earlier version of Beyond the Basic Stuff with Python. I wanted to have a chapter on packaging, pip, and all of that. Python has had a varied history when it comes to packaging. The main way that I learned everything was going through all these old PyCon talks and learning from them. I later wrote up a blog post that's like a Python packaging curriculum, listing all the PyCon talks I watched in a specific order with brief summaries of what you've learned. PyCon has been putting up the videos of their talks on the internet for free, which is awesome.\n\nPyCon and the Python community are different from other tech conferences. PyCon was one of the first tech conferences I went to, and I realized that other conferences are mostly ways for vendors to sell you things or require expensive tickets. PyCon is centered on actual people, meeting folks, exchanging ideas, and making information freely available.\n\nI call it Picon University, but I won't use that name in the final product. The idea is to create a mini curriculum for beginners and intermediates based on free online PyCon talks. I would come up with questions and answers for each talk so that people can learn about different topics like Python packaging. The goal is to get people to watch these old PyCon talks and truly learn from them. It's a cool idea, but creating a structured curriculum is a lot of work.\n\nOne of my early guests was Brett Slatkin, and his talk about refactoring and early code stuff was well-structured. His book \"Effective Python\" is fantastic and offers great advice. Thanks for coming on the show, Alice Weigard. I appreciate it. Thanks for listening to the Real Python Podcast. Subscribe, leave a 5-star rating and a review. Show notes are available on realpython.com/podcast. Leave us a question or topic idea. I've been your host, Christopher Bailey. Looking forward to talking to you soon.",
    "CZc4F46ezTs": "Welcome to the Real Python Podcast. This is episode 39.\n\nHave you started to use generators in Python? Are you unsure why you would even use one over a regular function? How do you use the special send method and the yield from syntax?\n\nThis week on the show, we have Reuven Lerner to talk about his PyCon Africa 2020 talk titled \"Generators, Coroutine, and Nanoservices.\" Reuven helps developers around the world become more fluent in Python. We talk about some of his teaching techniques and also how he continues to learn.\n\nReuven is a believer in the continued practice of Python through exercises. We discussed his book \"Python Workout\" and his weekly Python exercise courses.\n\nThis episode is brought to you in part by Scout APM. Scout APM is application performance monitoring designed to help developers quickly find and fix performance issues without having to deal with the overhead of enterprise platform feature bloat.\n\nAlright, let's get started. [Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHi Reuven, nice to talk to you. Super happy to be here. I wanted to start off talking a little bit about your website in general. I thought the title is kind of interesting of teaching Python and data science around the world, and how that might have changed over the last year. Why is something going on? [Laughter]\n\nSo, I've been doing consulting. I opened my consulting firm in '95, and I was originally doing a combination of programming consulting. Very early on, I think it was like early '96, I had someone ask me to do some training, and it was always part of what I did. It was probably about 10-15 years ago that I decided, \"Hey, this is something that I really enjoy doing, and there's demand for it. Why not?\" So, I basically went whole hog into just doing training. Pretty soon, I then just started doing only Python and Python-related training. I mean, I still do Git and I'm starting to ramp up again and doing some Postgres stuff, but really, it's almost all Python. I was thinking about how can I describe what I do to people. Or how can I describe to people what I do to people is torture them. And I realize, well, I have like what I think is a super fun job where I typically travel around. Last year, I was in the US, UK, Europe, India, and China, in addition to being in Israel. I go and sort of come in and talk to them and teach them how to improve their Python skills and increasingly their data science skills as well. So that's all fun and well, but yeah, the pandemic has changed things. On the one hand, it's changed everything. On the other hand, it has changed nothing. So let's change nothing in that my clients are all high-tech companies where their people are maybe working from home, but they're still working and they still have a demand for training. Even before the pandemic, I was doing one or two weeks a month of training on either WebEx or Zoom. So now, instead of being say 25% of my time, it's 100% of my time. The big difference is that companies have started to realize, you know what, maybe people are not interested in spending all of their time in front of a screen for family, social, entertainment, and work. And oh yeah, by the way, we're going to throw you into training. So I've started to mix it up a bit where instead of doing a full day of training, we'll do a half day. So instead of like four full-day sessions, we'll do eight half-day sessions, or we'll just do like a two-hour session on a specific topic, almost like an extended conference talk specifically for that company. So they'll watch my video course, then we'll have a Q&A session. So I've had to sort of mix it up more and be more creative and experimental. But I figure they're experimenting, I'm experimenting, and somehow we'll get through this with all sorts of new models for doing training.\n\nYeah, I think that's great that you're able to change it up and see the demands that are on everybody. I keep hearing about these reports of people just sort of the exhaustion of trying to communicate over these means, you know, via video communication, and using all these different parts of your brain. So I think that idea of having part of your course be offline, let the person study at their own pace or whatever, and then following it up, I think are you finding that is working well?\n\nIt works well, but people then need to find time/motivation to actually watch the video courses, and that's actually been a problem. So one of the clients where I've been doing that, they actually pulled back from doing that. They said we're just going to do live in-person courses online, but in person because people felt like, yeah, we want to watch the videos, yeah, we want to get through the course, yeah, we want to get to the Q&A.But they felt so much pressure from work that they couldn't really get to that. So we sort of had to backtrack a bit on that front, at least with one company where it's doing it a lot. But in others, they've enjoyed it quite a bit where I come in and they've actually watched the videos. So I think it has a lot to do with company culture and how much their managers are willing to say, \"Yeah, it's worth it as an investment for our people to be encouraged to watch these courses and take them,\" as opposed to, \"Well, in your own free time after you're done doing everything for work and your family, sure, go watch it. You're lucky we're paying for it for you, right?\"\n\nCompany culture has had a lot to do with it. In fact, company culture has a lot to do with how comfortable they are even taking online courses. Well, the companies that have been doing it for years, they're just continuing to do it, and for them, it's not a big deal to do a full day online. Whereas some of the others, they're shell-shocked by the idea. Like, I see the engineers don't know how to handle themselves online in terms of online learning. They've just never done it before. So I always say, like, I have to sort of fill the room. Like, if I'm in a country where the culture is not one of engaging with the teacher very much, specifically China, this happens a lot.\n\nWhere the culture there is one of you listen to the instructor, you say, and if you don't understand it, it's your fault for not understanding. You don't say to the teacher, \"Hey, I think you got something wrong.\" Oh my gosh, this is, of course, diametrically opposite from Israel, where they will delight in telling the teacher that they're wrong all the time.\n\nSo, in China, I've developed sort of techniques for, as I call, filling the room. Like, I have to be more lively, be more entertaining, dial it up to 11 on all fronts. And so I've tried to do that online a little more. So even if people are a little hesitant to engage, they'll do it more, and that seems to be working okay. It's still not the same as being in a classroom, but it could be a lot worse. I used to teach in a classroom and do like eight-hour classes, and some of that involved what I would joke calling it \"infotainment.\" You know, like that you have to really figure out an act, almost make it engaging, make it funny.\n\nBut then also the whole trick of engaging with them, so I would constantly be peppering them with questions as I went. Is that a technique that you use in a case like that where you're trying to pull engagement out of them?\n\nI do ask some questions. I try to constantly say, \"What do you think? What do you think?\" Well, you know what, who has questions about this. It very much depends on the group. Sometimes they're really active. If it feels like I'm pulling teeth, then I'll try to pull a little harder. And if I don't get anything for that, then fine, I'll just keep going. Usually, there are at least a handful of people who really respond, and they're like, \"Oh, I always want to know about X, Y, and Z.\" And even just having a handful of people like that can really make all the difference.\n\nYeah, but by the way, like what you mentioned about entertainment and so forth, I constantly am looking to stand-up comedians for not necessarily for jokes but for their techniques in keeping an audience engaged because they are masters at it. They get up on a stage, they're able to speak, and everyone just follows them for an hour. Now, they're not just trying to get any technical information out of it.\n\nBut I watched a class that Steve Martin gave with MasterClass about how to be a good stand-up comedian, and I definitely got some ideas from there about how to refine it, how to present it. Not necessarily to be funnier - my family will assure you that that's not possible - but basically to try to engage, right?\n\nNo, that sounds good. That sounds like a good resource. I have a subscription to that too and I've watched a variety of things and been meaning to dive into that because I really liked his book, \"Born Standing Up.\" It was a really interesting book. But I think it's cool that he went back and did a course on stand-up. I follow the same kind of ideas. There are all these different styles that you can get into, and I feel like it's almost a shtick after a while. Like, I'm guessing you end up repeating a lot of the same subjects and teaching a lot of the same things, and so you have kind of a pattern and you can almost do it in your sleep.\n\nFor sure, for sure. I mean, there's certain stories and even sometimes what joke I'm going to tell at which point. Especially in a case where you're trying to pull engagement out of them, I do ask some questions. I try to constantly say, \"What do you think? What do you think?\" Well, you know what, who has questions about this. It very much depends on the group. Sometimes they're really active. If it feels like I'm pulling teeth, then I'll try to pull a little harder. And if I don't get anything for that, then fine, I'll just keep going. Usually, there are at least a handful of people who really respond, and they're like, \"Oh, I always want to know about X, Y, and Z.\" And even just having a handful of people like that can really make all the difference.\n\nYeah, but by the way, like what you mentioned about entertainment and so forth, I constantly am looking to stand-up comedians for not necessarily for jokes but for their techniques in keeping an audience engaged because they are masters at it. They get up on a stage, they're able to speak, and everyone just follows them for an hour. Now, they're not just trying to get any technical information out of it.I'm a strong believer in not just giving the answer. It's very easy to say, \"Here's the program, here's the exercise, here's the solution.\" But that's not really going to help because seeing the solution is not as good as seeing the process of getting to the solution. Whenever I give them an exercise and they have time to work on it, I go through the process of solving it. I always try to do things that might lead to mistakes, so they can see the thought process. I've repeated this hundreds of times in certain cases.\n\nEach class is a little different because I'm constantly trying to refine and improve. If something doesn't work, I learn from it and try to do better next time. I like the idea of dropping things in that lead to unexpected results. It engages the smart people who are staying quiet, making them wonder if I'll spot it.\n\nTeaching troubleshooting is hard unless you have trouble. I like to have them work with that. I wanted to talk about conferences and why I wanted to have you on. I liked your PyCon 2020 Africa talk where you talked about generators and generator functions acting like co-routines and nano services. I thought your teaching techniques were cool.\n\nI found out about the disassembler for Python bytecode a few years ago. I think it's amazing to interpret the bytecodes. It helps understand how things work behind the scenes. I've had mixed results showing it to students, but in an advanced Python course, understanding how the language works is crucial.\n\nI'm not a low-level guy, but I appreciate the elegant simplicity of Python's implementation. Python uses Python to implement Python, which is amazing. Understanding the basic rules and ideas of Python helps everything else fall into place.\n\nThe example you showed with multiple return statements and using dis to disassemble the function and show the bytecode was impressive. It proved the point that Python stops at the first return statement. Understanding how Python works under the hood explains many weird error messages.Okay, well, this is all that's going to run. This is all I need to compile. Am I right in explaining it that way?\n\nYeah, and I must say, I was actually surprised by that, right? Because I've always heard and understood, and again I'm not like a deep compiler interest kind of guy, but I always understood that the byte compiler in Python is pretty dumb overall. That it's more or less a one-to-one correspondence between your Python code and the byte codes. Here's a clear case in which they said, \"You know what, why write these bytecodes if we're never going to be able to get there? Let's just dump that.\" So, I thought that was kind of interesting.\n\nI always feel like if I have an aha moment, probably someone else out there will have that similar sort of aha moment. So, hey, why not share it with them? I definitely did. I like that idea too, like Python is not trying to be clever about this. It's like, \"Oh well, let's save all this and compile all this extra stuff even though we're not going to use it.\" And, you know, I know what they mean, and it's like I don't know what you mean. This is what you wrote, man. This is all I'm gonna do.\n\nThe other thing that you kind of focused on that I thought was really cool in the talk is you talked a little bit more about exceptions and the idea of exceptions inside of Python. You know, a lot of people immediately do this sort of equal equal error, you know, kind of comparison. That's right. No, actually exceptions can be used for a variety of things. The example that you're using in this case is that it can be used for signaling. Do you want to dive into that a little bit, like how you kind of came across that?\n\nSo, yeah, well here's the idea that I often try to get across, which is your program typically runs for one line, then another line, the other line, you know, one after the other. And that's all fine and well. Exceptions are basically our way of breaking into that. They say, \"Wait, wait, there's something unusual going on here.\" The analogy I should make is you're having a conversation with your friend and their cell phone rings, and they're like, \"Hold on a second, I gotta take this.\" Maybe this doesn't happen as much in the US as it does in Israel, but like in Israel, \"Oh, clearly the person calling me is more important than the person speaking to me face to face.\" Python is like, \"Oh, I better answer this call. Something urgent has come up.\" It's often going to be an error, right? It's often going to be, \"Hey, I don't know what to do in this situation,\" or like, you know, worst case, you're out of memory or something. But it can also just be, \"Hey, there's something weird going on here that you should know about and you should take care of right away.\" It's like this alternative, I would normally say, like an alternative return structure, like a parallel communication channel. Right? So you've got the regular communication channel, you've got this parallel one, and I just don't think people make use of it as much as they could or should. Now, that doesn't mean we should start replacing everything in our programs with exception handling. That could be a little hard to understand and maintain. But especially when it comes to generator functions, when they're being used as co-routines, the cool thing is you can say, \"Hey, I want to basically raise an exception inside of this other code.\" Because normally raise allows you to say, \"I am experiencing an issue. I want someone else to notice me and do something.\" But in the case of generators, you can say, \"I'm going to tell that co-routine that it should raise an exception.\" And if it then handles that exception, you can basically be sending it into a new state. You can almost think of it as like a state machine that you're moving from one state to another.\n\nYeah, that's cool. I guess we could dive back a little bit further and talk about the general idea of generator functions and how they're different from a regular function. And I know it's hard in the podcast form, I always thought about that where it's like, I don't want to make it a tutorial, but what is this idea of a generator and how is that kind of a unique thing comparatively to what's happening with a function? And then we can maybe go a little further into where you're talking about this idea of the co-routine idea. Sure, sure, and by the way, yeah, I mean we're recording.But I'm still waving my hands as I usually do. Alright, we'll send stills for people to watch on the show. So, look, a regular function when you run it, it runs as I was describing before. Linearly, like it goes starts at the top, ends at the bottom typically, and it returns something. It returns a value. So, the idea of having a function return multiple values is just laughable. Like, you can call it multiple times, you get multiple values, but each time you call it, you're getting one thing. And a generator function is a bit different. A generator function basically returns multiple times, but we don't use the return statement there because we use return while it's gone and done. So instead, we use the yield keyword. And yields basically say, \"Here is a value, but I'm not giving up yet. I'm just gonna go to sleep and I'll be around when you next need me.\" And so here's the value. I'm going to sleep. Oh, I'm up. Okay, here's another value. And this is used through the iterator protocol, the communications between us and a generator function or the result of running a generate function which is a generator. Every time we say next to it, \"Give me your next thing, give your next thing, your next thing,\" it's going to wake up, go through the next yield, and return something. So you could do something as simple as some sort of iteration, but you can also sort of spoon-feed information from a file or from the network or even infinitely large data. But obviously, we can't fit infinitely large data into our computers unless you get a really serious upgrade. And so in that case, you want to get it little by little by little, perhaps add infinitum. So generator function allows us to do that. The thing is, generator functions are great, but this whole idea of, \"Well, let's keep it around and have what's known as a coroutine,\" that's been around for a while, but I haven't seen people say what we can and should do with it other than some esoteric sorts of descriptions. I think it was David Beasley who gave a few talks in the past about cool things you can do with it, but those got kind of complex even by my standards, although David Beasley is really smart, so like when he does something, if it's complex, he's the right guy to be addressing it. I think he was also the guy who gave me the idea of describing the function going to sleep, which I thought was a fantastic metaphor. People have talked about coroutines, meaning let's keep this subroutine, let's keep this function around and fired up and ready to give us an answer. And whenever we need something new, we're not going to exactly stay next to it. We don't want just the next thing, but we're going to feed it data. It's two-directional communication, so it's not just \"Give me your next thing, give me your next thing.\" It's \"Give me your next thing based on this, give me your next thing based on that.\" So it can be like, \"Okay, you have infinite like you can give me information from the stock market, which is obviously an infinite supply of data. Give me your next stock trade of ABCD company or EFGH company or whatever.\" And the coroutine then has already connected to the service for the stock market, it's already all fired up, all it needs to do is get your input, do something, and then yield it back to you, get next input, and he'll just be waiting there. It's like a butler or something waiting there, right? And so I often thought of coroutines as a solution looking for a problem. Like, okay, we can do this, now what? Now that we've got this great technology, now most people in the Python world were like, \"Oh, this is a great solution for concurrency.\" So asyncio is based on a slightly mutant version of this. But I was like, \"Well, I wonder if there are some examples how we can at least think about coroutines and perhaps use them in our system outside of the asyncio context.\" And I'm not sure if I made a compelling case for where they can be used in production, but I'd like to think at least, you know, I convinced myself that it's an interesting idea and that it helps to explain that whole ecosystem of generator functions and coroutines better to at least evaluate whether and where we'd want to use them.I like how, through that explanation, you're kind of explaining the idea of a little historical context of async I/O and the idea of things running in the background. Like you said, kind of sleeping or napping and being ready to go in memory. This is efficient in the sense that you don't have to repeat the whole code to get everything set up. It's sort of staged and ready to receive it. You're using the generator keyword \"send\" to send new values into the generator and trigger new things. Typically, when you work with a generator or anything with the iterator protocol, you're just saying \"next, next, next, give me your next thing.\" Send basically says, \"Hold on a second, we can provide some input.\"\n\nYou can affect this as little as a nano-service, which is different from a micro-service architecture. It doesn't require a separate computer or process. You can save money by having it in-process. The overhead is tiny, and it can be a way to conceptualize and compartmentalize in a different way than with an object-oriented system.\n\nOne of the things we touched on briefly is setting up the service and getting it ready to go. Eventually, you may want to stop the service, especially if connected to a database or online service. Using exceptions to stop the service can be useful. You can throw an exception to say, \"Time to go,\" and have the service shut down gracefully.\n\nGenerators are like private storage with local variables, so connecting to databases or web services is streamlined. Each instance of a generator can be connected to a separate service. This allows for multiple instances to run and iterate over them, essentially re-implementing async.\n\nI've seen lots of inappropriate code, but not so much inappropriate generator usage. People are often mystified by generators in general.They've heard about them, they might kind of sort of understand them. A cool example of where I never would expect to see generators used is in pytest. If you have set up a pytest fixture, a fixture basically, if you're testing with pytest, a fixture is like I expect to get such and such data back all the time. It can pretend to be a file, pretend to be a service, something like that. In a lot of other testing frameworks, you have like startup, setup, and tear down. The way they did that in pytest is, if your fixture is not a regular function but if it's a generator function, then the stuff before the yield is the setup and the stuff after the yields is the tear down. I don't know who thought of this and it's genius, right? Because it allows you to basically split this function into two parts, and the yield part is almost like a clear marker between the first part and the second part. If someone in my class were to suggest that, I'd say that's inappropriate, but because it comes from the people of pytest, I'll just call it genius. There you go, that's cool.\n\nI've definitely seen it used for reading in files, like reading in lines from a text file or book and processing them as they go. It can be used for really large data files, loading in a massive CSV that maybe wouldn't fit in memory. This is a nice way that it can process as it goes, as opposed to having to ingest a huge file and wait for all that to come in to move to the next step, being able to yield partially. Normally when you read from a file, you get it one line at a time, and that's not technically a generator, but it is implementing the iterator protocol and not using much memory. The trick is, if you're reading in from a file with a certain format, you don't want to get one line at a time, you want to get three lines at a time or between two markers for each record. That's where a generator can be fantastic, where you know you're getting in a record each time but don't have to worry about how much memory it's going to be.\n\nYou can shape how you want to process things at a time, say this is the chunk size that is needed to do this process. Even in my courses and book, I have an exercise called read n, a generator function that takes a file name and n, the number of lines you want. I can say I want my files three lines at a time or four lines at a time, and each chunk is that many lines long. It wouldn't be too much of a stretch to say I want it between these markers, so I only want to get the dates or timestamps from this log file, and the generator will skip over everything else, giving timestamps.\n\nTell me a little bit about your book. It's from Manning, is that right? Yes, it's from Manning, \"Python Workout,\" a collection of 50 exercises to improve your Python fluency, realistically more like 200 exercises with three bonuses beyond the exercise. Every exercise has been through the ringer with my courses. People ask me how they can improve their fluency, and I say keep practicing. I collected exercises I've used in my courses and added additional ones. Each exercise should take about 10 minutes and has been through the ringer with my courses.So I could, like they often have some tricks in them. Someone just emailed me for one of my online courses, saying, \"You always make the questions seem so simple, and then I discover they're not that simple.\" So evil, right? But the idea is that if you work through the exercises in the book, you're going to be more fluent. You're going to be able to reason at a higher level and not always be saying, \"Wait a second, what are the arguments that I passed to this? And when I use enumerate, what am I getting back?\" You want to have a general fluidity to your use of Python so that you can get more things done. I often joke that I want to put Stack Overflow out of business - fat chance, right? Because people shouldn't have to look up these simple things on a regular basis. They should have a sense of fluency so that they can attack things at a higher level of abstraction.\n\nHow long did it take you to make the book? Well, basically, I originally self-published the book on my website when my mailing list was really tiny. A bunch of people bought it, and then Manning came to me and said, \"We like your book, we'd like to republish it.\" I was like, \"That's ridiculous, I am an entrepreneur.\" A few years of humbling sales later, I went back to them and asked if they would still be interested in republishing it. They required a lot of edits and improvements, but they were great to work with. I'm now working on a proposal for a new book about pandas.\n\nIn the original book, what was something that you were super excited about including that you felt would make it special? The unique thing was the approach of the book itself. It's not a book to teach you Python, it's the second Python book you buy after taking a course. There are many sidebars in the book now that explain things, but the original goal was to help you hammer through additional exercises to get fluency.\n\nIt's neat that you're able to take something from your teaching experience and combine it in a new way. It's also neat that the book allows you to practice techniques and build on top of them. That's something that's been missing. I always found that using a single tool never quite worked for me in learning languages. I had to mix them up.\n\nWith Chinese, I have daily lessons with a teacher in China, but just talking to her isn't enough. I also need to practice reading, so I use an app for that. I try to look through the Chinese version of the New York Times when I'm feeling ambitious.Oh wow, this is real. That's like, this is really hard. My teacher is like, \"Why are you reading that? That is not interesting.\" I'm like, \"I think it's interesting.\" But you're trying to get it from all different sorts of sides in all sorts of different ways. And of course, when I was going to China three to five times a year teaching there, that was, as I described it, like my end of semester final exam. Where I'd go and every time, what do you know, I could read more signs, I can communicate with people more. Yeah, and that was just an incredibly satisfying experience.\n\nDo you end up watching any\u2014I mean, you mentioned reading the New York Times or what have you\u2014do you try watching media and see if you can pull it off without the subtitles or what have you? I've tried. So there's this great podcast, basically it's called \"Listen to a Story, Learn Chinese,\" and they're still a little fast for me, but I've tried. I take early morning walks now, especially with a pandemic, like you gotta, like that's before sunrise and try to walk for a long time before coming into teaching. Yeah, and so I've tried to start listening to them more and more.\n\nAnd I know that if I just give it like half an hour a day for four or five months and I know, like, you need that sort of time perspective, then it'll not seem fast anymore. So I just need to convince myself, don't do it once every week or two, do it once a day, because you just need that exposure, you need to sort of get your brain thinking in that way. That's kind of what we were talking about in the same parallel subject of talking about learning Python. And it's definitely a thing that I did, is, you know, I started listening to podcasts and I was listening to Michael Kennedy's podcast, and he was on, and we were talking about this idea of, you know, it's a form of language immersion. You know, you're sort of surrounding yourself with these concepts, and you can kind of then have these aha moments, even if something isn't completely making sense, where you're like, \"Oh, that's what they were talking about, you know,\" and it starts to make sense again. And I think that's really kind of cool. You know, it depends on what level you're at and so forth, but are you having that experience?\n\nYeah, oh, there are definitely times like, I mean, when I'm there, it happens a lot where someone will say something to me, I'll be like, \"Oh, I learned this in class, I can't believe it's really useful.\" What do you know? And I mean, people were super nice to me in China because here I am, an American/Israeli guy, clearly not Chinese, speaking to them. And first, they sort of fall over, and second of all, then they fall over themselves to be nice to me. And so, you know, even if I didn't quite understand them, they would really make efforts to try to make it more understandable or speak more slowly. And I just had dozens, hundreds of these aha moments each time, whether it was with the structure of the language or pronunciation, and it was thanks to people being kind about it, yeah.\n\nSo, to bring it back to programming a bit, when people ask you a question because they don't understand, like, it's so easy to say, but it's so obvious. Guess what? It's not obvious to people when they're starting, right? And so I think one of the really learning Chinese has been a great thing for my teaching of programming because it reminds me what it's like to be in the position of being a student, not understanding, being curious, wanting to learn, and just not quite having all the pieces together yet to be able to make sense of it all, yeah.\n\nNo, I completely agree. I was learning French back in high school and then in college, and then I finally did a trip to France, and it was with my parents. As a long time ago, you know, when I was around the hotel, I would try to speak French to them, and they would just not\u2014they would not have it. They would just speak English to me. It was like they were just sick of tourists trying to do that. So then eventually, I went off the beaten path and I went to like stores in a mall and kind of went out into the city of Paris, and people there were like way more interested in me trying to speak French to them and working with me and kind of coming up with ideas. That was really kind of neat. And so, I was at the time, I had an Atari ST. I don't remember those computers, of course, sure. And they were more popular in Europe, in my opinion, than in the US, and there were pieces of software that were only available there. So I was literally searching for this graphics program that was only sold in the European market, and I found it there, which was really cool.Wow, it was like an art program to do. It was called ZZ Rough back in the day, but it could do multiple pens and then the pen strokes as you went over them. It would know that it was being. It wouldn't just occlude, it would combine the colors and do all this cool stuff. It was unique at the time, and it was fun to search it out, speak, and practice the language.\n\nI feel like that's something that is kind of hard right now for a lot of people learning at home. Finding that combination of reading books, watching online tutorials, or listening to a podcast is good, but having that other person to ask questions to and interact with is something else that they may need to build on top of. It's neat that you have that kind of combination.\n\nYou have online courses where it's like a weekly course, right? I have a bunch of online courses, some are video courses with exercises in them. I also have a bunch of courses called Weekly Python Exercise, shockingly enough a weekly Python exercise. There are six different cohorts, each 15 weeks long. On Tuesday, you get the problem, the following Monday you get the solution, and in between, there's a forum where people can ask questions and interact.\n\nIt's a combination of everything together, like getting the problem, testing, and having a forum about that problem. Seeing other people's solutions is so useful. People then modify their solutions based on what others wrote. It's a learning experience that has been fun and exciting for me.\n\nI've met people from around the world who are learning Python or trying to improve their Python skills. This week, I want to shine a spotlight on another Real Python video course titled \"Python Generators 101\". The course covers what generators are, how to use them, create generator functions and expressions, how the Python yield statement works, and more.\n\nWhen I was looking at your biography and information on your website, it mentioned that you have a bachelor's in computer science and a PhD in learning sciences. I found it interesting that you went back to school for learning. How has that experience helped you in teaching?\n\nThe story is basically that I had been consulting for about eight years and was beginning to feel burnt out. I was doing all these projects, and the way consulting projects end is never a hurrah, it always kind of fizzles out.So I was feeling a little down about this and I spoke to a family friend who's a professor. He said, \"Listen, what you should try to do is go to grad school, get a PhD. Your mind will be open to all sorts of new ideas, you'll meet amazing people, and you're gonna come back with all sorts of new directions and refreshed.\" \n\nI decided I'm not interested in doing a straight CS PhD. I found a few programs that combined education and technology in various ways. The learning sciences program at Northwestern is actually pretty positive. It's the first learning sciences program anywhere, although now it exists in a bunch of places. \n\nMy research group was sort of the nerdiest of the groups there. My advisor's advisor invented Logo, and my advisor invented a modeling system called NetLogo. I built a collaboration system for NetLogo models and analyzed what the collaboration looked like and how to improve the design to facilitate collaboration. \n\nEven though it was very difficult, I learned a ton about learning and teaching, and that has definitely influenced my teaching a lot. I have a Python practice workshop where different people present their solution, and we all learn from each other. I try to vary my exercises in terms of theme, length, and topic to encourage transfer of learning. \n\nPython is a great language for problem-solving, and doing exercises is a powerful tool for learning. I constantly try to understand things well enough to explain them.One of the things I was wondering about is we've talked about you learning a language, learning Chinese, and going back to school. After your PhD program, what are different techniques you have found useful to keep yourself learning, especially in the case of Python? How do you learn new concepts and dive deeper into it? What tools are you using to keep learning?\n\nFirst of all, I've always been experimenting and asking questions inspired by my students. I constantly receive questions that I don't know the answer to, which makes me wonder why things work in certain ways. Even though I teach intro data science classes and feel confident, I know that data science is a vast field that requires continuous learning to keep up. So, I read books, blogs, watch tutorials, and conference talks. I also conduct experiments to learn new things.\n\nThere are many great YouTube videos by people like Louis Serrano who explain machine learning concepts brilliantly. I agree that teaching reinforces learning, especially when you have to explain things from different angles. Good questions are when students don't know the answer, but excellent questions are when the teacher doesn't know the answer, prompting further learning.\n\nI focus on understanding algorithms better and diving into the details to articulate when to use them. I've been hand-waving with some algorithms, but now I want to understand them more deeply. I also want to explore different areas, like learning low-level languages such as Rust to write Python modules.\n\nI believe that continuous learning and exploring new areas are key to growth, and I want to be able to explain complex concepts better to my students. Teaching and learning go hand in hand, and I'm excited to continue my journey of learning and discovery in data science.But they taught us list, but if you want to see, I had to go to, I believe it was the civil engineering department where those heathens and apostates could do their sea stuff. So I used a bit of C in my first job, and I was terrible at it and I hated it. I never got pointers, never, never, so I've been burned by that and turned off to that. But Rust is supposed to be fantastic, so I've started dipping my toes in a little bit. I'm sort of excited to see where I can go with that as well.\n\nWe haven't mentioned it yet, but you do a podcast. I don't know if you're the host, but you're a regular guest on it, is that right? So, there are six of us who co-founded the podcast together, \"The Business of Freelancing,\" and we're all co-hosts, co-owners, co-everything. It's called \"The Business of Freelancing.\" I've done a freelancing podcast before for about four or five years, \"The Freelancer Show.\" All of us on the panel left to do our own thing about a year ago. It takes a little while to ramp up. The idea is that so many people are interested in freelancing and they're really good at doing something. In the case of this podcast audience, you might be a really great developer, a really great data scientist, but what do you know about running a business? By the way, when I started my business, what did I know about it? Nothing at all. It's sort of a miracle of the modern world that I've managed to survive for this long. The point of the podcast is to help people with business ideas. How do you find clients? How do you make agreements? How do you deal with taxes? How do you deal with marketing yourself? How do you use a mailing list? All these different things that those of us, I think I've been in business close to the longest one of the longest of all the panelists.\n\nBut we range in age, experience, areas of expertise, areas of like you name it, and so we're all great. We have great fun, but usually about two to four of us on a given episode, and we have guests as well. We've been interviewing some people who've written amazing books. It's great fun for me because I get to read a great book and then interview the author. And my co-hosts often give me incredible insights into my own business and how I should be doing things. That's great. I found that useful to have so many varied group of people to discuss these topics. They're all going to bring something unique to the table. It's been really fun for me just doing this podcast in general, meeting all these different people and having multiple guests at the time is kind of a fun way to spark. You didn't imagine where the conversation was going to go. So I could imagine having three or four or five people talking on a podcast as long as it doesn't get too raucous, that it could be really useful to elucidate all these additional ideas. Like you said, they all have different backgrounds, right?\n\nYeah, so we've got someone who does websites, another person who does content marketing, another person who does freelancer testimonials, and so we're sort of all over the place. We also respect each other's experience in different areas quite a bit, so it's fun to be able to sit back and say, \"Oh wow, I've learned a lot there. I should try that in my business.\"\n\nI have a couple of questions that are sort of my weekly questions, and one you've already dove into really deep, which is, what do you want to learn next? I feel like we've gone pretty deep into that one talking about you learning Chinese, the data science stuff, and your new book on pandas that you're working on. But this one is what is something you thought you knew in Python but turned out you were wrong about it?\n\nFor years, I didn't quite understand attributes. I didn't understand that there's a big difference between variables and attributes, attributes being anything after a dot. I've been on this crusade now for a few years that if I didn't get this and I was working with Python for so many years. Oh my goodness, I'm going to teach everyone I know about attributes and how they work. Because once you understand how attributes work, suddenly everything falls into place. The attribute you look up explains objects, methods, inheritance, even deeper things such as the descriptive protocol. It all comes down to the attributes.\n\nI've been speaking about it, I've tried proposing a bunch of conference talks on attributes, and I think whoever reads them is rolling their eyes, saying, \"Oh my god, why don't you just propose a talk on watching grass grow or paint dry?\"So I've had to juice it up a little bit to try to sneak it in other conference talks. But I'll get there one day. That's funny, I would watch that. That would be interesting to me. I know it seems like a simple concept, but I can completely understand that there's a lot of depth to it. It's so fundamental to Python in general. There are so many of these built-in hidden attributes that a lot of people don't even know are there. With everything being an object, it's kind of wild to think about. Like, okay, well, what are all the attributes of this thing that I just created, like a string or what have you?\n\nThat's cool. What's something that helped you in learning that? I wish I knew. It's been a few years now, but I just kept exploring it. I think people in my classes would ask me questions, and I'd be like, \"Oh, right, like how is it that a method sits on the class but we call it from the instance, and yet it works?\" I thought Python was supposed to be straightforward. I thought we weren't supposed to have any magic in this language, and suddenly it's very magical and confusing. How is the instance getting rewritten to be self? For a long time, I would just sort of accept it. \"Oh, this is the way it works. Of course, when I call a method, the instance is just rewritten to be the first argument.\" And then, I feel like, \"Wait, wait, wait, like, oh, it just gets rewritten. We're not supposed to do that in Python.\" So I think it was just a slow, gentle grinding and trying to figure out what was going on. There wasn't any one place that explained it to me, which is part of the reason why I'm on this crusade. People should understand how this works, and it makes things so much clearer.\n\nWhat's something that you're excited about in the world of Python? It could be a conference, a book, a package, or some other kind of tool that you're interested in. Well, I'm generally excited about maybe hopefully one day we will actually have conferences in person. I must say, PyCon in person was just, and especially when I had a booth. People warned me, \"Oh yeah, booth, you're gonna be so tired.\" I was so energized spending eight hours talking to people and giving out t-shirts. Oh my god, it was great. It was great. Like seeing people and seeing friends during the hallway. But in general, I think I'm just generally excited to see Python actually catching on and being considered a real language. For so many years, people would sort of look down their noses at anyone who used a high-level language. \"Oh, you're using a scripting language. Why don't you...\" I'll speak slowly so you understand. That's what we've added to. They just didn't appreciate that just because it's easy to use doesn't make it less powerful. And the fact that now all these companies around the world are not only seeing that Python is possible, but is crucial to their businesses, is just amazing to me. I've been using Python since like '92-'93, and the notion that these Fortune 100 companies are desperately looking for Python developers for their mission-critical stuff is amazing. But more concretely, I continue to be amazed by the people who do pip and pipi. Those folks are like unsung heroes, yeah, who work really hard. They're very serious. I did a tiny, tiny, tiny bit of work on that stuff at a sprint, I guess about a year and a half ago now at PyCon, and I just came away in awe of all the issues they deal with and provide to us as a community that we don't even think about. I had Sumina and a couple other people from pip talking about wanting to get feedback on all the development they've been doing. They've had this real sprint for the last year of trying to fix some of the user experience stuff with pip, and the whole change in the resolver. All that's kind of stuff that seems so behind the scenes for a lot of people that just simply, \"Oh, just pip install.\" It's like, well, there's a huge amount of work that has gone into that. A huge amount of work has gone into pipi, and it's cool. It was a neat episode, and I learned a lot in that process. I'll include links again for people if they're interested, and they're constantly asking for feedback and want help in continuing to develop these tools for everyone.\n\nThey're amazing. They're absolutely amazing. Someone totally blew me away. I mean, I saw her. I'd heard about her, and then I saw her running that sprint. I said, \"Wow, this is like a case study in how to be an effective manager and leader.\"We started by talking about your PyCon 2020 Africa talk. Have you done lots of talks this year at all, like in 2020? Is that a common thing for you to do talks?\n\nI love giving talks at conferences, but for years I didn't really travel that much for conferences because I was traveling doing other stuff. I finally decided to do that. Last year in 2019, I was at both PyCon and EuroPython. I found out about Python Africa too late, and I really wanted to go to Ghana. I was like, \"Oh, I'll go in 2020.\" Haha, jokes on us in 2020. The upside has been that I can participate in lots of conferences all over because you don't really go anywhere. So, I gave a talk at PAI Bay, a conference in Russia, and I'm going to be giving a talk actually later this week, which is in the past for when the podcast will come out, to a conference called Geekel. I've also given some talks to user groups. All these group meetings are online, so I gave a talk from my home office in Israel to the Dallas-Fort Worth Data Science group and to Chicago Python. It was really nice, and I'm totally open. I love meeting people, I love giving and having a chance to share this information. It's just super fun for me.\n\nThat's great. It's kind of a neat thing, and then you were talking about learning from them. I was talking to Al Swaggart about that idea, and he had this idea of combining developing a curriculum of, well, what order should you watch these in if you were interested in this particular topic? Like, okay, watch this one from 2016 that gets you into this concept, and then what would really build on it would be this one and this one and so forth. I thought that was really powerful. He hasn't completed it, but it's something that he's been thinking about, and I've been thinking about it too. It's been a common tool for me to find guests. Find a topic that we can discuss and then dive into the other things that they do. It's been really great. I've definitely taken advantage of all the stuff being online, though I'm totally itching for getting out there in the real world and meeting some people in person and traveling again. Let's hope 2021 starts to shape up. It looks like it is, so we could hope we can help.\n\nI love traveling so much. When I travel for teaching, for work, I often try to get in touch with Python user groups or open-source user groups. I've given talks in Beijing, Shanghai, and Hyderabad in the past, which was always great fun. I get to meet the locals. I'm really looking forward to that at some point soon, or soon-ish, on a geological time scale. It's been so great having you on here. Thanks for sharing all your knowledge with us, Christopher. It's super fun to be on with you. Thanks again to Scout APM. Don't forget the added bonus for Real Python listeners. Scout APM will donate five dollars to the open-source project of your choice when you deploy. Learn more at scoutapm.com/realpython. I want to thank again Reuven Lerner for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure you subscribe to the podcast in your favorite player, and if you like the show, leave us a five-star rating and a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "Yb1kzbsGi7g": "Welcome to the Real Python Podcast, this is episode 47.\n\nDo you feel like you understand how Python works under the hood? What is syntactic sugar and how much of it should be in Python?\n\nThis week on the show, we have Brett Cannon. Brett is a Python core developer and he's been working on a series of articles where he's unraveling the syntax of Python. This series is a fantastic resource for those wanting to learn how Python is structured and works at its core. Brett wants to see a version of Python that can run in web browsers, so he started to break Python into its syntactic elements to try to answer the question, \"What are the core elements of Python?\" This detailed series takes the reader along for the ride.\n\nBrett also works at Microsoft as the dev manager for the Python extension for VS Code. Brett is also serving his second term on the Python Steering Council, and we discuss recent Python Enhancement Proposals that the council is considering. \n\nThis episode is brought to you by DigitalOcean's App Platform. \n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at RealPython.com. After the podcast, join us and learn real-world Python skills with a community of experts at RealPython.com.\n\nHi Brett, welcome to the show.\n\nThanks, Chris. I wonder if we could start out talking a little bit about the work that you're doing at Microsoft on the Python extension for VS Code.\n\nSure. So, I'm the dev manager for the Python extension for VS Code. My work is mainly in two parts. I'm what's called a people manager at Microsoft, which means I have people who report to me, and I'm in charge of the whole process. I also manage the development team to ensure that the extension meets the product manager's needs. \n\nOkay, cool. I had Savannah on a little while ago to talk about some of the upgrades with Pylance. Is that team connected to what you're doing?\n\nYes, my team is in charge of the core extensions, including finding your environment, running code, linting, formatters, testing, and debugging. Pylance plugs into our extension as the language server, providing type checking, linting, auto-completions, and syntax error detection. They are a sibling team to me within the same workgroup at Microsoft.\n\nIt's been interesting to see the shift at Microsoft towards open source and giving back to the community. There's a focus on promoting Python and making connections with the community to benefit both the company and the users.Hey, we're trying to make, I'm not picking on anyone specific, but like, hey, we're trying to get auto completions working with pandas. Okay, so let's go talk to the pandas team. But we don't want to just come in and be strangers, we also try to help them out so that there's benefit to the community because a lot of us care about Python as a community overall. Not just how do we best get value to Microsoft by plugging into the Python community. I very much view myself as a member of the Python community who happens to work at Microsoft to try to make sure that things from Microsoft work as well as possible for Python. The whole team generally has that view, so it's led to a very nice perspective.\n\nYeah, we're obviously working for a company that's trying to make money long term by using and implementing Python, but we also don't want to screw anything up. We want to give back and show our support to this community as best we can because this is very much a symbiotic relationship. So, yeah, it's led to a reasonable staffing of people contributing to try to make Python development as good as possible, not only for Azure, but in general. It's been really great talking to all these different players in that space and a lot of the developer relations people. I feel like it's helping to show that shift of wanting to give back to the community.\n\nTo be perfectly frank, if the company wasn't willing to give back to the community, I wouldn't be there. So, how long have you been part of the core Python team? There are two parts to that. When did Brett subscribe to Python Dev? That was mid-June 2002. And then, when did Brett get his commit bit? That actually happened on April 18, 2003. I actually memorized the date and pulled up the commit a couple of times, so I am past 17 years at this point. Wow.\n\nWe were talking a little bit before we started about your background in C. Has that been crucial for you to be able to contribute in those ways? It helped, I wouldn't say it's crucial. My actual first contribution to Python stemmed from my contribution to the Python Cookbook first edition. I actually implemented `strptime` in pure Python because I needed it on Windows. At the time, `strptime` function was only available on Unix machines because it just came with glibc. I re-implemented it, although you had to manually type in the format. It irked me so much that as a graduation gift to myself after I graduated with my philosophy degree, I spent the week after implementing an algorithm that used `strptime` to reverse engineer the locale information for dates and times. I emailed Python Dev afterwards and they walked me through the process and I got committed. My actual first commit was pure Python, and it's still in there if you go and look at the `strptime` code.\n\nThat's not to say the C knowledge didn't help. I started to do the Python Dev summaries, which back then was a semi-monthly summary of everything that happened on the Python Dev mailing list. I took a gap year between my bachelor's in philosophy and doing a master's in computer science, and I had the time and wanted to learn. Any time a bug came in, I could raise my hand and say I'll take a look. I was able to dive into the C code, and luckily, the CPython codebase is very clean and well-organized. It's one of the cleanest I've ever worked on in terms of C.There are definitely some perks, noise, and C already. Is that by design? Are there people who groom that codebase to make sure it stays that way and doesn't get spaghetti-like? I wouldn't say we go through and groom it specifically, but it is a very specific goal in any PR review that the code stays readable. For instance, for the longest time, we actually had a general rule in the team that the interpreter could not get complicated to make sure that it was easily understandable for external contributors and anyone else who wanted to come forward and help out. That's not quite held up because, as I'm sure everyone listening knows, Python's popularity has gotten kind of big at this point. And so, telling everyone, \"No, we don't want this because while it might speed up Python, it's going to make the code harder to read,\" the pushback from the journal committee started to kind of be a little hard on that. So, we've let that one go a bit, but we've persistently gone along the idea that it is important to keep it readable just because we have a lot of external contributors who try to help out, and the core team is only so big with so much time on their hands. Because, to be perfectly honest, the vast majority of core devs do not get any paid time. I get 20% of my time thanks to Microsoft, and I steal a bit more when I can. Okay, but the vast majority of people get zero paid time. It's all volunteers. And because of that, we have to make sure that it's easy for people to jump in and out of the codebase as appropriate. So, we continuously make sure that as we accept pull requests, the code does not get worse in any way, tries to stay nice and clean and readable. And doing things like you were doing initially with kind of managing all of the information and creating these summary reports, that's still kind of a role that somebody who's interested in getting started and wanting to contribute could potentially do. I'm sure someone could definitely do it if they chose to. Although, ironically, the volume on Python dev has dropped significantly. Back then, all traffic went through Python dev, but subsequently, the volume got so high we actually have created multiple mailing lists to kind of manage that. For instance, we now have Python ideas where people are encouraged to go if they have just a random idea about how to improve the language. And then there are people there who can help show previous discussions as to whether that idea has actually already been discussed and decided on, or that is a new idea but here are some issues, or okay, let's discuss this. There's a kernel of idea, or that's great, we should definitely discuss it as a group and then take it forward to Python dev. We also have Python committers, which is publicly archived but only open to core devs for discussions that really just don't need public commentary, to put it nicely. Sure, that makes sense, yeah. Someone definitely, I'm sure, could write summaries of all this stuff. I don't know if the volume, honestly, has gotten so big that it'd be possible for one person, one person taking a gap year, to keep up with it all on top of it being spread across three different mailing lists. I mean, when I started back in 2002, I still constantly ran into people who either never heard of Python or just went, \"That's the language where whitespace matters, isn't it?\" Like, the volume was completely orders of magnitude different. So, I don't want to discourage anyone who wants to give this a shot, but I just don't know if the volume would necessarily lend itself towards one person covering all of this. But if someone wants to do a blog post summary once a month or every two weeks and publish that out somewhere, I'm sure people would read it. Yeah, I'm just thinking there's other ways to help with the core project in additional ways. Oh yeah, there's so many. I mean, we have people helping with translations, people helping with documentation. It's not just about the code. There's an entire ecosystem and a project and community around all this that have needs that run the gamut. So, you're right, there's definitely, it's not just about the code, it's about all of it. It's a whole package, and there's always room for help. What are, if you can talk about them, what are features that you're excited that Python is looking at adding in the next revision? That's an interesting question. So, we actually just started a new steering council, so we currently have two PEPs in front of us. I want to talk about things that we haven't made official decisions about. I understand because that's a bit more interesting. Because Python 3.9 just came out and I honestly, every version is kind of a blur to me. It's just, I know this got in, I just don't know where the cutoff landed for me. So, it's just kind of in Python now. It's, and I run the newest version so I know I have it, I just don't remember when it went in. But in terms of potential future features, one is actually deprecating distutils, getting that out of the standard library because it's so brittle that people are constantly not willing to touch the code because we're too worried we're going to break someone's build.So, we're trying to actually just rip it out, just take rip the band-aid and just like, we are not the center. Library does not move at the speed of Python's packaging ecosystem. So, we should just not pretend that we know how to manage that kind of thing. And so, there's a path before us to actually take that out and just dedicate it. Okay, and just go use setuptools or flit or poetry or any of the other build tools. And just basically let them own the experience. \n\nThe other one that's in front of us that's actually kind of there's actually an idea that is split across three PEPs with one competing path, if you can keep that straight on pattern matching. So, if you have any experience with functional programming language, you've probably come across this where basically you're able to have something like a match statement that doesn't, it's not quite like an if-elif chain or switch statement that you might be familiar with from other languages. \n\nWhere it's all based on like some kind of like is this number greater than that, it's typically used more in terms of matching against structure. So like how long, how many items are in this tuple, is this an object with this structure, that sort of thing. It makes a lot more sense when you actually look at it. But Guido Brandt Butcher and I believe there's two other co-authors that wrote PEP 634 which tries to add pattern matching to Python. \n\nThen there's 635 and 636 also by them that give kind of more background information on this whole thing because it's been a massive undertaking for them to write this path and a lot of discussion back and forth. Like there was a previous PEP, I think it was 622 or 620 that they did that got a lot of feedback and just to manage the volume, they actually wrote those three PEPs. \n\nThe Nick Coughlin has written a PEP called 642 that takes a different syntactic approach to try to implement pattern matching. So that's currently in front of the new steering council as well. We have not made an official call yet. The 2020 steering council made an initial recommendation that PEP 634 be accepted but we didn't have enough time in the 2020 term to feel like we could come to a full decision on it. \n\nSo we basically made a tentative recommendation to the next steering council and we're letting the steering council make the final decision. I have no date on when that's going to happen specifically, but it's being actively discussed. \n\nThis episode is brought to you by DigitalOcean's App Platform. DigitalOcean's App Platform is a new platform as a service solution to build modern cloud-native apps. With App Platform, you can build, deploy, and scale apps and static websites quickly and easily. Simply point your GitHub repository and let App Platform do all the heavy lifting related to infrastructure. Get started on DigitalOcean's App Platform for free at do.co/realpython.\n\nI guess that kind of brings up the idea of being a member of the steering council. \n\nWell, so I've actually been on the steering council since its founding in 2019. We hold, so Guido retired July 2018 and then the inaugural council started February of 2019. Just due to timing of when we figured out what kind of governance model we wanted, how to do the voting for that, and then actually holding the election. \n\nAnd then what we did was we decided to basically, it's tied to a release cadence so basically you're steering council for a release. And at that time, that was roughly 18 months but that release that Python was actually ending around October or November, I think technically it was December because that was 3.8. \n\nBut then subsequently, we switched to an annual cadence which basically meant that we now have one-year steering councils and we basically ask for nominees during the first two weeks of November. We then lock down the nominees and just allow them to answer any questions, whatever for the latter half of November. And then we vote for the first half of December and then that leads to the new steering council that technically starts December 16th but what really doesn't start till January 1st. \n\nAnd so we actually just had our first meeting of the year this past Monday and yeah we meet once a week and talk for an hour about whatever is shot our way on top of time permitting where we think we need to kind of either help direct things or help make things happen. \n\nThe way I view it is we're kind of the backstop for the CPython project and the Python language. So basically if the entire development team quit tomorrow, the five of us would be kind of in charge to make sure the wheels don't completely go off and we can get the project back up and going. \n\nTo me, that means what do we need to do to make sure that doesn't happen right? So like how do we prevent burnout, how can we make contributing easier, how can we make the core dev experience easier, dealing with any disagreements, helping reach consensus on things if a consensus can't be reached, being the final decider on things. Basically what Guido's former role was and that's it. It's just basically just kind of keeping the project going. \n\nYeah, that's cool.So you've been retained as part of the steering council. Sounds like I have not voted off the island. All right, great. Partly why I wanted to have you come on the show is we had talked about on a previous episode, David and I, about your syntactic sugar unraveling series. And I wanted to kind of just get a little bit of background on it and discuss some of the concepts that you're covering in it.\n\nI think the first thing I wanted to talk about is just the idea of. I'm a little confused at the usage of the term syntactic sugar, and that might be my own personal not having a lot of background in computer science. When I think of syntactic sugar and the way I've heard it used in other places, tutorials, and articles, is things like decorators or other kinds of unique looking structures inside of the language that maybe simplify the way something's written to make it quicker. But as I go further and deeper into the series, I'm like maybe I don't completely understand what this term means. So I think we can start there.\n\nWell, I actually say your definition's spot on. Okay, yes, you have to be willing to let go of what you define as simple. To me, syntactic sugar is anything that is syntactically added to a language like Python that you typically don't have to have. It's just a sprinkle of syntactic sugar, a nicety. It doesn't provide any magical semantics that you can derive from the language in some other way, but it makes life simpler. Decorators are literally nothing but an at sign that implies a function call that gets passed in a function object. It's really simple. It doesn't do a whole heck of a lot. You can easily just define your function and then take the decorator, ditch the at, and just go. Name a function equals decorator and then pass it in the function, and you basically have replicated exactly what decorators do. That's literally what it does underneath the hood. I think a lot of people don't realize that Python syntactic sugar, from that perspective of just giving you syntax that really underneath the hood, you could do another way without any issue, goes really deep.\n\nThat's actually a lot of where its flexibility comes from. Like I don't think a lot of people realize that plus is nothing special, it's literally a method call. And as you said, you can read the blog post, but it's just kind of mind-boggling and eye-opening to realize that so much of Python really isn't inherent in its design to the point of \"oh, I couldn't make that work in Python if I didn't have it.\" Python just gives you a lot of niceties to make your life more productive as a software developer. But in actuality, we could take it away, and you could still end up with roughly the same result. You might not have the nice plus symbol to mean addition, but you could fake it with method calls. You really don't have to have us give you the plus symbol to make it work. To me, that's what syntactic sugar is - if I took the syntax away, could you get the equivalent semantics some other way? And if the answer is yes, then it's a nicety, but technically we could take it away from you, and you can still get the same end result.\n\nIn this case, a large number of the way that Python's created as a language is basically almost everything is an object. Everything inside of the language is an object. So when you're thinking of something like an integer, as it's defined, it has methods. So to call something like addition on that, it actually is calling to these methods underneath it. You use the term magic methods, and I heard a lot of people use that also. I just want to kind of break things down because I want to make sure I got this clear. Whereas I hear a lot of other people say, \"Oh, they actually should always be called dunder methods with a double underscore in the name of it.\" I don't really care. There's always a lot of people that get religious on one side of these battles. One way or the other, but I'm kind of intrigued in what the preference is between those two, and which way do you kind of lean in that way?\n\nWell, funny enough, the language reference calls them special methods. So there's three ways. The way I call it is, I historically called them magic methods, or maybe special methods. I probably mentally might start calling them special methods because I keep reading the word special when I read through the language reference for these blog posts. It's good to know, but I still say dunder when I talk about them, like the dunder add method. I don't say the magic add method or the special add method. So when I refer to them, I use the term dunder for double underscore.I usually technically separate them just because. For instance, you might see some projects use a dunder version attribute to specify what the version is, which by the way you don't have to do anymore thanks to import lib.metadata. It will let you actually query a package for the version, just a total sign, good to know.\n\nI view it as a difference between the naming of something and whether or not it has special meaning to the language and interpreter. That's where I draw the distinction between a dunder method as in that's just names under add versus it's a magic or special method because the plus operator in Python actually will do something special based on the existence of a dunder add method. So that's where I draw the distinction, the terminology, okay.\n\nIn general, the idea of syntactic sugar is a good thing, I hope so. Are there places that it can be kind of overused potentially? I mean, it's a balance, right? Like to me, Python's goal is to make people productive, sure, right? And one way you make people productive is you make code readable and easy to understand. Sometimes there is a certain pattern that is so common it makes sense to add new syntax to the language to simplify that pattern to be easier to identify and understand and easier to type and everything else that leads you to be more productive.\n\nAs you mentioned, decorators are a perfect example. There is nothing special about them. You could totally do them now without them, and we did for decades literally. But I don't think anyone would argue that decorators aren't handy. The reason they are handy is they are a little bit of syntax that took something that was a common practice and made them much easier to comprehend and visually see, right? Because before we had decorators, you'd write your function or method or whatever, and then at the bottom, you'd reassign the name, calling it through some function that would do something funky to the function object to make it do something different. But with decorators, what we were able to do is syntactically say, \"Hey, these things should be attached to the top to visibly see that the function you're about to read is not going to exactly do the thing you expect. It's going to do some other things because it's going to go through these decorators that might change its semantics.\" So you should be well aware when you start reading from the def line that the thing that this name is going to be attached to won't be exactly what you're about to read potentially.\n\nVisually, it kind of gives you the heads up very quickly, exactly. To me, that is the definition of good syntax, something that is useful both for reading and writing and leads to an improvement in cognitive understanding of what's going on in the program, right? You never want to see syntax be added that makes things harder to understand. If syntax doesn't open up either isn't a great generalization of a concept that we were already doing as a community that makes things easier or did not significantly lower the cognitive overhead or the ability to ease the writing of certain algorithms or problems, then that's not a good use of the syntax.\n\nIt just becomes overhead of having to learn new syntax that you just honestly won't use very much, and it doesn't simplify any understanding, right? Assignment expressions, the walrus operator, are a good example. A lot of people argued against that because they said it's going to be a new piece of syntax that I don't think would be used enough to warrant the cognitive overhead of having to learn yet another piece of syntax in Python yeah.\n\nNow I personally didn't think that, and I'm still on the side of yeah. I can see the usefulness of this, let's go with it because I saw it as a way to simplify certain patterns of like, \"Alright, you always have to set this variable to none and then you check it and then you do an assignment and all this other stuff, and I can now simplify that to a single line.\" I fully understand that the concept that this variable is either going to have a default value potentially or not based on what the return is. If it doesn't have it, I'm going to assign something, and I've used it multiple times now, and I'm very happy with it. I think that led to a cognitive lightning as it were of the load on my brain of certain patterns, yeah.\n\nThat is basically where I see the benefits of this syntactic strawberries just opening the door to possibilities that are easier to comprehend. You're using it in a couple of the examples already in the unraveling sort of series, those made sense to me kind of right away. I've kind of embraced it again I'm kind of newer to the language so it's easier for me to maybe embrace certain changes, yeah.It was like, \"Oh, that makes sense. Let's save the step.\" In this process of the assignment, as you go, is actually a useful thing. Funny enough, actually, the assignment, like some expressions, actually close the door to unraveling a lot of the Python syntax as syntactic sugar because it allows different semantics of what a variable will be bound to at different times. The best way to think about it is if you use a walrus operator as an argument to a function call, that means subsequently, the arguments later on in that function call and that whole list of arguments that you're passing in can use that assignment expression. So, that variable you just created has to be available later on, which means you can't lift things out of a function call that you're passing in. You really have to work a lot harder to kind of lift stuff out because the order of execution becomes much more sensitive due to potential new variables that only just appeared because of time expressions.\n\nI've been able to use it for a couple tricks to get the point across that this isn't magic stuff happening in Python when you use the syntax. It really simplifies things but also closes the door on my face in a couple of other ways in which I can't easily explain things. The expression is completely breaking, so I can't go that route. It's kind of like the double-edged sword of lots of these things.\n\nWhen I went to your site and started looking through the list of articles you've created, you had a post just before this whole series which was talking about the idea of web assembly. Maybe we should talk a little bit about that. I've had a couple of people on talking about web assembly - Armin Ronacher, who's a big fan and created Flask, and Russell from Beware, who's very interested for similar reasons to why you're interested. The idea of Python being able to be used in other places, like in mobile, is appealing since the web is portable across computer systems, desktops, etc. Having something that can work inside there and getting Python involved would require some changes.\n\nMy interest in WebAssembly stems from the fact that Python isn't as available in the browser as I would like. I personally appreciate the Python community enough that I would like others to benefit from what our community offers. I think we're a great place for people to come together and be inclusive, helping people out. I want to bring as many people as I can into the community while keeping its feel of inclusiveness, diversity, and welcoming. One place we don't have people coming in is the web browser stuff and mobile. Every phone has a browser, so having a WebAssembly version of Python could potentially open that door to a larger audience.\n\nFancy phones are more powerful than the first computers a lot of us grew up with, and not being on them means a huge part of the programming community isn't experiencing the wonderfulness of the Python community. Getting a WebAssembly version of Python could potentially open that door to mobile and browsers, reaching a wider audience. Mukash Linga, a core dev, has also talked multiple times about it. Many people have expressed interest in seeing this happen. So, I brainstormed what it would take to make it happen and how I could empower to do it. If I ever tackle that project, I would have to make it as small as possible due to limited time and commitments.I'm busy right now, I'm making Python Web Assembly happen. They ask, \"Why can't you come out right now?\" There's a balance in life of how much of my finite time on this planet do I give into Python and personal projects versus having an actual life outside of Python and work.\n\nI just went like, \"Okay, what's going to take? So how do I find this? Basically, how do I find the minimum viable Python that would need to be implemented to make things work?\" Mentally, I just went like, \"Okay, what is actually the bare minimum semantics that an interpreter or compiler needs to implement that couldn't be implemented via Python itself?\"\n\nThat's what kicked off this blog post series. I'm trying to distill down the exact syntax and thus the exact semantics that you can't implement in Python itself. Because once you have that, that's your implementation goal. If you know that everything else can be built on top of Python syntax.\n\nA lot of these problems start to distill down to, \"Alright, I can translate syntax pretty easily potentially and just kind of transpile it.\" From a lot of these languages that transpile down to JavaScript to be able to run in the browser. You can also do that from one language to another. Like I can just take today's Python and transpile it into no syntactic sugar anywhere Python. I just have to be able to run that no syntactic sugar Python some way.\n\nFor me, this is step one in terms of trying to figure out where that boundary is. \"Alright Brad, if you're going to try to make Python happen in WebAssembly, what is the absolute bare minimum you have to make work so that you can say with this building block, I can make the rest of Python work because I can just fake the syntax into other syntax.\"\n\nPart of that also of getting down to this core of things that are needed, you had questioned in that very first article, \"Okay, would it need a REPL, this sort of interactive version of Python which I can imagine would be rather difficult to implement in something like WebAssembly because the idea of compiling it on the fly and stuff like that.\" I'm not positive on that, but it seems like that would be something that certain people would miss obviously. But it's something that I think you're right in the sense that if you're distributing applications and trying to get bypassed these other areas, it could be a quick idea of like, \"Okay, this is something we might be able to get rid of.\"\n\nI actually got surprising flack on Twitter over that whole suggestion of teaching. Like, \"How could you do that? Python's popularity, it's all because of how flexible it is in the REPL, etc.\" But the point of that was just, \"What is the core of Python? What really has to be there? Is Python's success really because of the REPL? Like if Python didn't have the REPL, would we really never use it? Is that really it or not?\"\n\nA good example of where I'm coming from this thinking is, I hear a lot of people these days go, \"Oh, Python's so popular because of all the packages it has on PyPI.\" Well, I predate PyPI. People come in thinking, \"Oh my god, this is so amazing.\" Like, I come back when I looked with a jealous eye at CPAN for Perl and no one knows what that is. Because back in my day when I first started with Python, Perl was the language with all the crazy packages out there that helped you do so much. Where's Perl now? Not to belittle Perl, but obviously Perl's popularity has slipped even though they had a massive amount of packages to help you get things done.\n\nTo me, the number of packages we have on PyPI is a trailing indicator of Python's popularity, not a leading indicator. The leading indicator is the number of people who have snuck Python into their companies because they really wanted to use it and management wasn't willing to say yes or was just unaware of the fact that they wanted it. So they just brought it in anyway. That really shows the magic and popularity of what Python is. The fact that people bring it in anyway, whether or not management says yes or is oblivious to the fact, shows that it is so great of a language and community that people are willing to put in the time and effort to create these packages.\n\nFor me, saying, \"Do we need a REPL?\" is very much one of these things that, \"Okay, would Python function without it? Is it really that critical to Python?\"I'm not trying to disparage the idea that the Ripple isn't useful as a development tool and is definitely helpful. However, there's also the possibility that I could just run this code in Python and have a REPL there to play with. Does it have to be live in the browser to function the way you want? This is a totally open question.\n\nThe basic outline of my grand plan to get Python into WebAssembly is as follows: the first step is to determine the core of Python, the minimum viable Python that needs to exist to implement the rest of Python potentially. This may involve writing a compliance test suite to ensure that Python is implemented appropriately.\n\nAfter this blog post series is done, I plan to work with the Python development team. This is very much in my head plan and has not been discussed with others yet. The plan involves coming up with a compliance test suite to determine if Python 3.9 semantics are fully implemented.\n\nOnce I know what the core of Python is, I want to have a test suite to track progress in getting Python into WebAssembly. This will be beneficial for the community beyond just CPython, as CPython is the reference implementation of the Python programming language.\n\nThe next step after the compliance test is to actually make Python work in WebAssembly. I'm not sure if the answer is a compiler or an interpreter from scratch. CircuitPython and MicroPython have provided some guidance in terms of memory usage for IoT devices.\n\nPhones in the browser present a different challenge compared to IoT devices in terms of memory usage and download size. While phones may have more RAM, download size is crucial for browser performance. The goal is to have an execution-efficient dictionary for phones and browsers.\n\nIn conclusion, the plan to get Python into WebAssembly involves determining the core of Python, creating a compliance test suite, and developing an efficient implementation for phones and browsers. This is still a work in progress.Yeah, it's going to be an evaluation of all, right? Does it make sense to actually compile straight down or would an interpreter make more sense? And if you do an interpreter or even a compiler, does it probably, and my gut feeling says yes, is it best to target a small download but best execution performance? Historically, we don't have that, right? Like Pipeline C Python's at one end of the spectrum where download size is not a concern, right? Python itself is already, I think, like 13 megs on my machine when I last looked, which is totally fine on my Mac. That's fine, it's not a big deal. Same on my Lenovo, it's not a big deal. That's 13 megs to download and run, right? Same with Pipeline.\n\nBut like IoT, they have really crazy constraints where they really have to care about every single kilobyte of use. But the browser is kind of in the middle. I want to download fast, but if you have to use five megs versus five kilobytes to run the same thing but I get like, I can run it like two to three times faster with that more memory usage, I would argue on the browser you should totally go for it, right? Like, I don't think this is going to be the worst performing cost in a web browser if Python's performance goes that way. \n\nSo to me, I would say yes, MicroPython and CircuitPython could very much be an inspiration in terms of if we have to look at what the core semantics of Python that need to be implemented are, they could be used as inspiration definitely. Like, I still don't know where is that line where if I don't implement something for Python it's no longer Python, like where is that floor, right? And we don't have that defined anywhere. We have a definition of what the full language is, but if you look at CircuitPython or MicroPython, they have a page that says like we don't implement these semantics for various reasons, either they haven't gotten to it, it's too costly, the performance would hurt too much, what have you. And I'm not questioning their justification, but the point is, is that CircuitPython and MicroPython are still very serviceable implementations of Python, but they do not fully implement the semantics as laid out in the language specification. \n\nSo they are definitely an inspiration in terms of realizing that you don't necessarily need to implement all of CPython to have a useful version of Python. Now, those people who go Python is useful because of all the packages are definitely going to go no, you need to implement the whole language because I want to use this package that's there, it needs to have pandas, it needs to have everything exactly right. But if you view this as a green field new area, much like IoT was a new area to Python so you didn't just blindly carry Django over, but that doesn't mean all Python code is thrown out but you are willing to go like okay, the packaging ecosystem is not going to start here, we might have to build it from scratch but at least Python the language is here because as I said earlier to me the leading indicator is people want to bring Python to an area, not whether or not we have the most packages in the world, yeah.\n\nSo to me, MicroPython and CircuitPython show that you don't have to bring CPython with you to still be useful and successful and actually have an impact. So I am purposely not looking at this as oh, look at all these people who have taken CPython and compiled it down into WebAssembly already, I view this as more just okay, that showed that there's definitely a taste for this but obviously at like a 13-meg download it's just too big to ask people to download, so it just all these are showing me I don't think it's nuts to do a from-scratch Python WebAssembly that doesn't necessarily do as much as CPython does but also isn't necessarily a microprocessor Python based on performance requirements and there's a potential option for this third middle ground between the two that implements some but who knows how much and now my brain's just going I don't know, sure. \n\nSo that's where this whole kind of grand plan goes. I do want to say though, thanks to my wife, I do have spousal approval to work on this idea. Okay, she's been learning Python and the first course she took was the data science one and they were using kind of a custom Jupiter experience and running Jupiter Hub behind the scenes when why does this keep disconnecting? Why do I have to keep refreshing my browser every time if she left the class and came back to work on the assignments? It's like, oh, well, they're using this thing called Jupiter Hub, they're running a big server over it. It was from the University of British Columbia over at UBC. When you come back in, they probably closed it, you gotta reconnect. Like, well, why isn't it just in the browser? It's like, well, no one's implemented Python in the browser, it's a whole thing. It's like you should get on that. Like, I said, just so you know, that's a multi-year project, this is not a small thing. That's okay, just go make it happen. So that's too funny, thank you very much. Thank you to my wife, Andrea, for saying like I'm allowed to put time into this and this is how I convinced her like, no, sweetie, I have to write this blog post to get you Python in the browser, yeah.And there you go, kind of rolls our eyes. Now I don't think she's regretted telling me this yet, but at least it makes you go okay, I'm willing to let you finish it. And she, by the way, a shout out to my wife, she proofreads all my blog posts. So if there's a minimal amount of spelling and grammatical mistakes in them, it's very much thanks to her. So okay, kudos to her and thanks for her for doing that.\n\nYeah, but yeah. So yeah, this week I want to shine a spotlight on another Real Python video course. We've been discussing a lot about the structure of core Python this week. I thought this course would be an appropriate one to spotlight. It's titled \"Cool New Features in Python 3.9\". The course is based on a Real Python article by previous guests Guerra Arna Hiela, and in the course, another previous guest Christopher Trudeau is your instructor. He takes you through accessing and calculating with time zones, merging and updating dictionaries effectively, using decorators based on expressions, combining type hints and other annotations, and much more. I think it's a worthy investment of your time to not only learn what the features of Python 3.9 are but also how to implement them in your code. And like most of the courses on Real Python, the course is broken into easily consumable sections and you get code samples for all the examples shown. All the video courses on Real Python have transcripts and closed captions. Check out the video course, you can find a link in the show notes or you can find it using the search tool on realpython.com.\n\n[Music]\n\nI wanted to dive into the article, just the kind of like the you've kind of created a, I don't know, a template sort of structure where you sort of start up okay, well, this is the topic we're gonna talk about. I love that you have the amount of time that it would take to read on your blog post, that's fantastic. And then you say okay, we're going to talk about, let's say, binary arithmetic operations. And so then you'd start out and he said well, one of the ones that's hardest to implement or to think about would be probably minus because of the way, you know, you can't do, you have to do it in a specific order and all that kind of made sense to me. And then you use disassemble after kind of creating this simple function to show or dis, which I talked about with Reuven because I hadn't really seen that used again. That kind of speaks to my background and use of Python.\n\nBut I think that's a fantastic teaching tool, yeah, just to kind of show what's going on. So that shows kind of what's happening. I don't know, I don't want to say the right words but at the sort of the C layer of stuff and then you kind of implementation layer, yeah, okay, implementation layer. And then you have another layer there where you're kind of showing okay, what is that and then you actually have a call to the CPython source code to show where that's actually being implemented. And then the last part or third portion of your sort of template is to recreate it in Python. Did I get the structure right?\n\nYeah, you nailed it, okay. So initially when I, you know, like looking at the very first one, I'm like I don't understand, I don't know where we're going but by, you know, two or three of these, I'm like oh, I get it. And so that's kind of where I'm like oh, he's really doing a lot of work here, a lot of thought into how would you, you know recreate these things and build these things. And it's not only useful if somebody wants to learn more about the implementation of Python but also like structurally to me, like one of the things I keep seeing is like okay, the types underneath there and kind of like explaining the importance of well, at this implementation level you're going to need to think about, you know, the types coming in and out and kind of showing the type checking happening inside your code there. Anyway, it's just explaining a lot. I mean, it's taken me a while because I don't have the computer science background to sort of let it sink in, but as I read more and more of them kind of starting in reverse, it was like oh, this is really illuminating and I kind of, you know, each further want to explain more of the earlier ones. So well thanks for noticing that and saying that, I do appreciate it because I that was very purposeful okay when I set out on this. Basically, I mean obviously I know the language well enough that I, I kind of mentally just have as an exercise are able to just kind of do this like okay I can totally do it this way and just, I could just be done with it.\n\nBut that's a phrase I've started to use recently, I work to pay for my open source habit, sure. And so part of that open source habit is kind of just sharing knowledge and helping others out and just teaching and just kind of just like, I have this knowledge but there's no reason it needs to stay in my head and I have a bachelor's in philosophy which means I enjoy writing so I'm happy to blog like I actually derive enjoyment from doing it, yeah. So it just made sense to me like okay so I'm gonna do this.I can totally blog about this. I could just go, \"Hey, you can undo as you said like subtraction into this and be done.\" But that's fine for those people who are just gonna go, \"Oh, okay, cool.\" People are gonna wonder how did I figure that out, like how did I really make sure I was not making bad assumptions based on outdated knowledge? Because, as I said, I've been doing this for 17 years. Even I, I mean, and I will fully admit, I do not fully know how everything works in Python. I know how a decent chunk works, sure, but that doesn't mean things have not changed underneath me. There are corners that I never just dove into, et cetera, et cetera. But it does mean I happen to be lucky enough to build up the skill set to know how to figure the stuff out if I need to.\n\nOne of my goals with this blog post series was to use that structure, as you so loosely explained, to show people how they can do this on their own. Right, this is not a unique skill, this is not a magical skill, and I wanted to demystify all this to go like, \"Look, anyone can do this.\" Here's Python code. We use an interpreter, which means we have a big eval loop that is just literally a big for loop with a switch statement in C that just goes, \"Okay, I want to do an add. How do we do an add?\"\n\nSo, let's go look at the code. Okay, the code's here. Alright, let's figure out where to look in the code because honestly, the trickier points with C code that I find is just traversing the code base, and especially Python, just because it's physically so large. So, I just happen to memorize where everything is, right, like I partially, and especially this stuff because way back when in 2007, around there, that's when PyCon was in Austin, Texas, I helped finish the compiler because that's when Python switched over to having an AST and doing this compilation that way.\n\n\"What does AST stand for?\" \"Sorry, abstract syntax.\" \"Okay, so the way I have a talk from PyCon Canada if you ever want to dive into how Python's compiler works, it actually goes from syntax down all the way down to execution. It goes step by step where all the processes go. But the way Python currently works is it takes your syntax, it goes through what's called tokenizer and basically breaks it up into the words that it is like, 'Okay, that's an if, that's an expression with the number four, a greater than sign, and two,' all that stuff. And just breaks it up into a stream of words and then that goes through the parser which creates what's called the concrete syntax tree, that is the general structure from a syntactic perspective of what the code is. That then goes through the compiler, goes through, it gets converted into an AST which is more the semantic meaning, right? Okay, this is an if node and this has this kind of expression, it just structures it in a more programmatic way, less of a person way. And then the AST is what goes into the compiler and then the compiler spits out Python's bytecode, which is what you see when you call the dis module on it. And then the eval loop is just what executes that bytecode, and that's basically how Python works. And before this, we literally just went straight from concrete syntax tree to bytecode, like there was no this middle AST, let's make it more kind of semantic specific and we just worked straight from the syntax, and doing it from the AST allows us to do some optimizations the people optimizer to make some things run a little faster. It's easier to reason about when you're doing the compilation and all that kind of stuff, so it just led to a lot of extra perks, plus it allowed us to expose the AST as the module which various tools are able to use to kind of understand things versus having to deal with the raw syntax which is a bit more cumbersome anyway.\n\nThe point is I have all that in my brain because I helped write it, and I actually wrote the dev guide of how Python's compiler works. So because of that, I figured alright, I might as well help guide people with how and where to find all this stuff because I know where it is and it'll take you a while to find it all on your own. So I might as well just link to the code and just show like, 'Hey, I'm not pulling tricks here, this is how I figured this out on myself right now. You don't have to go diving into all the files to figure it out, I'll just link straight to it in the repo and you just read along and see how I did it. Now obviously, I don't expect everyone to read this part of the blog post, not everyone knows C and that's totally fine, and I don't think it's critical to understanding, it's just if you want to come along the journey with me of how I figured this out on this blog post for this piece of syntax, you can follow along. Admittedly, I do cheat sometimes, for instance in my import blog post I totally leave out all the code.Partially because it's implemented re-implemented the import system in Python back in Portland back in the early days. But also because it's just so ingrained in my brain that I just kind of knew exactly what I wanted to say. I just wanted to get it done and I just did. It was going to be treading so much old ground for me since I have the entire import system memorized and I've given that talk twice. Yeah, I was going to say we can link to those talks if you want to dive a little more into what's going on with import. I think that'd be good.\n\nYeah, sources for them, but it was one of those things where I had to go like, \"Okay, personally, it is going to be a slog and boring as hell and I'm not going to learn squat.\" So I took a shortcut and just left that all out. And that's when I just said, \"Hey, if you want to look at the code, go look at it. It's all in Python. It's in the standard library. Go for it. But I'm not going to link to it because I'm going to get zero out of it. And I know I'm just totally going to punt on writing this blog post if I do that.\"\n\nSo I called an audible on myself and just like, \"Damn, you know what? I know I'm not going to want to do this post if I do that. So I'm going to take a shortcut and just not put in the effort and just forget it. I'm just going to write it and just be done with it.\" So I did. Yeah, so some of the topics that you're covering so far, you start out with attribute access. You then go into binary arithmetic, which we kind of discussed already a little bit. And then the one that you were kind of alluding to earlier is this augmented arithmetic assignment, which if people aren't familiar with the words because sometimes those words just seem like I still had a problem with like the idea of like unary versus binary operations. I was like, \"Huh, oh yeah.\" And so I'm like, \"Oh, okay, well that's like if you put a minus sign in front of a variable, that's unary because it's working on a single thing versus binary would be there'd be like two operands that you're sort of applying the operation to. Like, okay, like terminology is always one of these things that's like the big stumbling block, especially coming out of the language reference, right, where they're like it's very purposely very specific and has to be overly formal English. Like, \"Oh, piece of code, right?\" Or it's just very formal and it's like, \"All right, I'm going to try to use the formal names just to kind of get the point across. If you ever read the language reference, this is what I'm talking about. But I try to avoid it in the post just because it's not defined yet. Because otherwise, yeah, you do not need to have a CS degree to understand how this works and the terminology is funky and edge-casey enough in like kind of like the language corner of computer science that it's very understandable if people don't know what the heck most of these terms are.\n\nYeah, so for that augmented arithmetic or arithmetic, I think that's the first one that I can go, \"Okay, yeah, that actually that's not always implemented in languages.\" I feel like the idea of like a plus equals is like something that, you know, I'm thinking of Swift as a language that they were trying to figure out ways to, you know, how are we going to implement these things? You know, and this is like more recent history. And so they were like trying to figure out like, is that a good idea? Is that a bad idea? Yeah, actually there's a story behind that. Yeah, go ahead.\n\nI can tell. So when I was learning Python, I learned it while I was doing my philosophy degree and I was trying to do a minor. Anyway, I volunteered at the open computing facility at Berkeley and a lot of us who were there, most of us were either like cog-size students because at that time it was really hard to get into the CS department or CS majors. And we just talked computers and programming and stuff. And I mentioned that I was learning Python and one of the members of the staff went, \"Oh yeah, I don't like Python. It doesn't even have augmented assignment.\" Because he was a big Perl fan and Perl had it. Okay. So I was like, \"Is it that big of a deal really?\" And then, subsequently, a couple of years later, we got it. Thomas Wouters, who's also in the Python Software Foundation board member, actually is the person who implemented it. But, yeah, you definitely don't need it. That's a very, I mean, that's a perfect example of syntactic sugar, right? X plus equals one as a way to just up a variable by one as an increment. You totally do not need syntax for that. X equals x plus one is not that complicated, but it does lower the chance of a typo. Conceptually, it's easy to understand once you see it. \"Oh, okay, yeah.\"I get that and then once you understand generally what the rule is, anytime you see any other operator, you'll get what it means. But I hadn't seen the one for power. I'm like, you would do that. I'm like that seems like a little abstract because I think people could be confused as to what side each thing's on. Maybe, yeah. The way I always remember is basically just with augmented assignment, it's whatever is on the left-hand side of that statement, just assume it's immediately put on the other side of the equal sign. Yeah, okay. And that's how I always remember. But yeah, power was definitely one of those.\n\nAlright, we're gonna do. I'm willing to, but it's not a oh, we should do a checklist of only the important things. This is for consistency. To understand that once you understand that the arithmetic operators can be like plus and arithmetic operators can be put on the left-hand side. See, I don't know how to talk about words on the left-hand side of equals. It probably is going to apply to all of them. And people would be shocked if they happened to be the one out of a million people who wanted to use power for this thing.\n\nYeah, but hey, apparently no one uses it considering I found a bug in it. So yeah, yeah, yeah. And for people who are not aware with, because it's an audio podcast, it's the double asterisk equal, yep. So, how did you stumble into the bug? You're just going through each of them as you work through it? Yeah. So, I'm doing a couple. With the blog post, I actually have a project I'm keeping called \"dsugar\" on GitHub. It's all open source, once again open source habit.\n\nThe way I actually do these blog posts is what I did was I went through and I looked through the grammar keyword module, and I think another nuts token module, I think as well. And I basically looked for all the bits of syntax that Python has and I stuck them all in a readme on this project. And basically, I just decided like okay, which one of these do I think I can or syntax syntactic sugar that I can actually devolve into other Python syntax. And then based on that, I went okay, how do I prove that? Right. It's nice for me to just write a blog saying oh, you know what, this just converts to this, isn't that lovely? But that doesn't necessarily prove that the semantics hold up, especially for the bigger initial expressions that are much easier to kind of test. You're like, well alright, if a plus b translates to a dot under add b, I should be able to prove that. Okay, so I basically just started to actually implement all this stuff to verify that I got it right.\n\nWhen it came to augmented assignment, I did what I did when I did binary arithmetic. I wrote out a test suite for verifying that this stuff translated to this thing in the end. And luckily for all these things that are in the operator module, it was very easy to test against see Python. It's like okay, here's my version of the operator module that does the thing, and then here's the standard lib version of the operator module that actually just uses the syntax behind a function call. So if you go to the operator module and look at the docs for the add function, it just literally says adds two objects. Well, if you look at the implementation, it literally is return a plus b. Mine, on the other hand, literally re-implements what plus does. So to make sure I was getting the semantics appropriate, I used the wonderful PyTest project to basically use parameterized arguments where I write the test and then have the test run passing in my version of the operator module and then passing in the standard lib version of the operator module and just run the same test and assume they both pass. And when there's a discrepancy, typically if the standard lib one fails and mine passes, that means my test is wrong. And I wrote for my test and didn't actually write for what works. And then if mine fails and the standard lib one passes, that just means my re-implementation is wrong. And then when they both pass, they're like okay, I got it.\n\nSo this is how I was double-checking myself until I started to get the fancier syntax where I just happened to know it just translates. But in the case of augmented assignment, I just abstracted it out so it was easy enough to just bang out like subclasses of my test class going okay, so this is for plus, this is for minus, this is for pow.Blah blah.\n\nAnd pal kept failing. I'm like, why does this keep not working? I don't get this. The standard keeps saying this tested wrong, but this follows the exact same pattern of all the other tests because luckily the general structure is so consistent for all the operators that I actually use function closures. I use functions that generate functions to implement all this stuff. I just say, \"Hey, the magic method is named this and the reverse version is named this.\" Here's the way the syntax looks to make the doc string. Give me a new function that does what you would expect to do, right? That's why it's popping out a string each time. Yeah, I mean, yeah, and it's just very cookie cutter. It's very much just a stamp out a new function that works for plus equals, for a function that works for my sequels. And my tests were passing for everything except for pal, and I was like, what the heck is going on? Why is the standard library version keep saying I'm not doing this right?\n\nAnd then I dove into the code because I mean I was writing a blog post and I had to dive into it to figure out how all this worked anyway. And then I looked at how pal worked, and I was like, wait, why is that different? And then I noticed that it was implemented in a slightly different way. And then I looked in the code and lo and behold, it didn't use the same pattern as the rest of the code. And I actually posted on Python dev, going like, \"Hey, start start equals doesn't work the way it's supposed to work. Anyone know what the heck's going on? Like, is this on purpose or something? Am I missing something here?\" And then Guido turned in like, \"Yeah, you know what? I think we actually said it was actually accidentally his doing.\" But basically, it went, \"Yeah, oops.\" And it just turned out that there was a cheat that someone had done because the C-level API for pow has an optional third argument. Oh, okay. And the deal is, if you pass in none, it's supposed to work as if it's not there. Well, the implementation for pow in the interpreter for the eval loop called this C function with non-set as the argument, which meant that it was acting as if it was just star star, not star star equals, because the semantics are slightly different. Because the way all of this works for binary versus augmented is like, if you do plus, right, Python tries to call dunder add on the left side of the plus. So if it's a plus b, it tries to call a dot under add. If that doesn't work for some reason, it tries to call, and I'm very much simplifying, read the blog post, it's ridiculously complicated. Yeah, it goes into it really well. It tries to do b dot r under r add as, right, and r stands for right side. So there's left and right and all this stuff. When you do augmented assignment, the way it works is it uses, for like plus equals, if you do a plus equals b, the way it works is it goes a dot under i add for in place with that i prefix, and then if that doesn't work, it then falls back as if it was just a plus b. Well, the deal was, because of the shortcut they took by reusing this part of the C API, it wasn't doing the i add bit appropriately. It was skipping it and it was just using as if it was a star star b, like a equals a star star b instead of a star star equals b as you would expect. And it was never called i pal, dunder i pow. It was always just trying to call dunder pow or dunder r pal, um, and that's it. I literally just looked through the code and like, oops, yeah, there it is. Okay, yeah, that's the trick. It's not calling the C code the same as the other ones that all had this. All right, we're going to call the i version and then the regular version and then the r version. It was going straight to the regular and r version. Like, oh yeah, that's not right. And so there's an issue open on Python itself to fix some of its own use of its own syntax. Yeah, so yeah, that was, yeah, that proved to me a lot. A lot of people implement i pow because no one ever discovered that it wasn't really being used.\n\nYeah, as you kind of go through these topics as you kind of go beyond, we talked about the augmented and then unary, and then you're going to get into comparison operators, is and is not, and then I think when we had the episode, we talked about David was talking about your article on the knot. Then you get into membership testing, kind of the in, you know, and looking into that stuff, and then boolean, and then you mentioned import statements.The last topic is assertions which leads to discussing testing again. Where else are you headed if you want to talk about it and how far? I was going to mention another thing that I noticed - the speed has changed in the release cadence of your vlogs. It started about once a month and now it seems to be at least a couple a month.\n\nYeah, well, the way I decided to tackle the order was, as I mentioned earlier, I basically went through the grammar. Then, I went through the keyword module in the token module to figure out all the syntax. I wrote them all down and decided, \"What is the most common thing everyone's probably going to do?\" It's probably going to be like attribute access, right? Like a dot.\n\nOkay, I'm going to start there and then I implemented expressions as the first thing. Unfortunately, implementing expressions was not just a simple method call. I had to implement a whole chain of methods with logic behind it to make it all work. I had to look up a lot of stuff, like you mentioned the blog post on how to implement the not keyword. I had to look up the actual definition of truthy versus falsiness, what is true and what is false, not just the boolean. Literally, what would you call truthy? I didn't know, so I had to really dig into the code.\n\nThe frequency was low to begin with because this was part of the language where I had an inkling of how all this was supposed to work, but like dunder index was added since I looked at all this code. I really wanted to not screw this up, especially attribute access at the beginning. So, it took a while to start doing the post because literally, the post took a lot longer to do. I had to dive more into the C code to see, \"Okay, this is not just a straight translation to new syntax. This is literally the semantics of a function call, like attribute lookup, and then calling a different thing based on the return value and whether you have to check on a certain type, and all this other stuff.\"\n\nIt took a lot more to actually make all these expressions work. At that point, I just followed a mental chain of, \"Okay, well if I can do dot now, everyone's going to ask how to do three plus two.\" This is kind of the traditional addition. So, I'll do binary. Once I've done binary, that falls into augmented assignment because I know that's just binary arithmetic with an assignment tossed in, so I can do that next. That's not a huge deal. The next thing people always ask if you do math is how you do comparison. Well, okay, so I'll do that next. I just basically followed the way my brain worked, like what would the next question be, and it's just persistently been expressions.\n\nI've actually now gotten most of the expressions done that actually use those kinds of tokens like plus, equals, minus, and all that stuff. I haven't touched the literals like lists and tuples, that comes later. But now that I have expressions more or less done, I'm moving on to statements. The trick with statements is there's not a lot of magical logic to them that I have to necessarily look up. Assert was very straightforward because some of the statements that Python implements are actually defined in the language reference as a translation to other statements. So, I don't have to necessarily dig as deep into the C code to see how this works like I did with plus, and not, and all these other expressions.\n\nWhen it's statement to expression or just straight statement to statement, I can just write out how it works and that's it. That's it for now. We'll see if this holds when I get to four. I know how to do this using while and but I think it's going to be pretty straightforward. But I have to double-check, like how do you get the iterator on something like I'm going to have to redefine the inner built-in, right? And how does the next built-in work and all that stuff? There's going to be some code in that, but once again, luckily the boundary is just shifting more back out to actual Python code itself and how to do the translation, unless what are the actual underlying magic semantics that I'm going to have to look up. That's basically why the frequency has come up. I will admit my wife sometimes goes, \"Didn't you just do a blog post? Why do you need me to read the other one?\" So yeah, she'll appreciate that people are noticing the frequency. Yeah.But that's basically why it's happened. So what's happened is the expressions require a deeper dive, a deeper dive into the C code. And then statements are looking like they're going to be more just straight Python to Python. So I don't have to dive as much just because I happen to know how the syntax works. But the next step is doing more statements and getting through those. So probably like four loops are going to be pretty straightforward. I think people might learn some things they don't know about how Python creates iterators for you if you don't define it under the iter method, for instance, using get item if you don't know because that can just become a while loop.\n\nAnd then like context managers, context managers are actually written in pure Python in the original PEP. So the work's kind of dumb for me and that's on that side. So because once again, nothing magical to context managers and the with statement, it's very much just a \"hey, I'm going to call this thing to get an object to do this thing and then when it's done at the end, I'm going to call this other method on the context and that's it.\" Right, it has those under methods like kind of going in and then going out, kind of like opening and closing. Yeah, it's enter and under exit, technically.\n\nExcept and then there's async versions as well because there's async with. So I think the statement versions are going to go a bit faster and then getting down to stuff like indexing on dictionaries and lists and sequences and that kind of thing might slow down a little bit because I gotta read up on technically it is always just called dunder get item. Is there something I'm missing but it shouldn't be too hard. But yeah, that's generally the sequence I'm following.\n\nI was doing expressions, now that I'm more or less done with expressions, I'm moving on to statements. And once those statements are done, I'm going to look at the syntax literals for types like sets, lists, dictionaries, that kind of thing. And then that'll be it.\n\nAll right, do you have a shining date you're like \"oh, it's going to be here or around here\" or something? I have been doing open source long enough to know to not make that mistake.\n\nAnd pretend I will always have the free time. I think I'll have pandemics especially have proven that point. Oh my gosh, yes, yeah. So no, the goal is to be done this year. Sure, I'm hoping it won't take that long as I said the posts are a bit easier to write now just because it's more straightforward on Python and less time to dive into the C code. I don't know, honestly, I'm hoping I'm going to say this year I'll be done, hopefully sooner than that just because I only have so much time to give to Python and I have other things kicking around on the steering council and the Pi packaging ecosystem and I seem to not be able to say no or to not go \"oh yeah.\"\n\nNo, that's a good idea, I should make that happen and just not do it. Yeah, so I got enough on my plate that I can't promise a date but I'm hoping this year.\n\nThat's great. So I have a couple weekly questions I like to ask everybody and the first one is: Is there something that you're excited about in the world of Python? It could be an event, it could be a package, editor, what have you? Well, I can't say editor because I work for work on one so I'm extremely biased on that one, okay, sure. I'm looking forward to Pi Cascades. I'm still yeah, I just had them on and they were mentioning you'll be part of a virtual event. Yeah, there's gonna be a panel talking about I think basically open source during the pandemic, obviously kind of focused around CPython and stuff, but yeah, I'll be on a panel I think with Marietta and Guido and Marlene and I'm sure those are the people whose names I'm just not remembering off the top of my head.\n\nYeah, so I'll be there talking. I'm looking forward to it. Pi Cascades is my regional because I'm in Vancouver, Canada. So it rotates between when there wasn't a pandemic between Vancouver, Seattle, and Portland. And unfortunately, I had to miss it in 2020 because I was in Thailand for a wedding, which I luckily got in just before lockdown happened and before things really blew up. That's right when all that stuff was happening, huh?\n\nYeah, this was back when they actually measured which countries had cases, not how many cases in each country to give you an idea like Thailand had 33, it was one of those way early people weren't panicked, some countries are really panicking but others were like yes, it hasn't gotten here yet, it's okay. And the temperature checks every day and all that but it was under control at that point so we luckily got that trip in but Pi Cascades is my regional and I love it. It's a great conference, it's very beginner-oriented and friendly, it's single track which I absolutely love as the speaker, no Q&A which I really really love as the speaker and I just I know the people who run it and I think they do an excellent job and so I just love going to that conference so that's what I'm looking forward to.\n\nYeah, it's great.And it's cheap too. For any of you listening who want to go, it's like 20 bucks for the hobbyist level and 50 if you have your work paid for. I think 10 are free if you are a student or just need some help paying for it. They priced it really reasonably and honestly, I also got a ticket because the badge smells amazing. If you haven't seen it, it's a wood badge. Like they literally burn it out of, I don't know if it's cedar or balsam or what kind, but every year when you go, I'm just standing there sniffing my badge. I need my northwest fix of just the smell of wood. Unfortunately, they're out so if you're listening to this for the first time, you missed the chance.\n\nYeah, so I'm looking forward to podcast kids. What's something that you want to learn next? Elixir, so I have used different phrasings over the years. I'm currently saying, \"I am a language polyglot.\" I used to say, \"I am a language bigot,\" basically, but unfortunately, that's not a good term these days. I think, so I'm trying to not accidentally say it anymore, even jokingly. Anyway, basically, I love learning new languages most of the time because I'm looking for things to potentially steal for Python.\n\nYeah, that's what I was thinking and borrow, steal, whatever term you want to use, get ideas that we can bring into the language, right? Because a lot of them actually come from other places. It's really weird that people are now listing Python as the inspiration for something instead of the other way around for me. Having things that show up in JavaScript and having them reference Python just blows my mind. Compared to like, like \"yields\" is the perfect example, I think. I read somewhere like JavaScript kind of got exp ideas for generation stuff from us or something. Well, we got the idea of generators from the icon programming language, which is a fairly esoteric language out of Arizona State. But Tim Peters knew the language and liked it. I actually learned the language over US Thanksgiving break for fun, right when I started my PhD of all things. Which gives you an idea of how much I need to probably not learn new languages because that's my idea of fun, sure.\n\nBut the other thing I'm always doing is just going like, \"Okay, what languages do I want to know?\" Like Python does not fit every single use case, no matter how much I want to, based on this entire podcast, I want to get it into more places, right? It doesn't necessarily fit perfectly in every scenario. So what languages do I want to have in my tool chest to be able to have available? So by default, it's Python, and if it doesn't work, what's the next language to use? For me, for systems programming, it's become Rust.\n\nI think Rust is great. I don't want to write C anymore. I don't want to write C++ anymore anyway. If I can't use Python and it calls for a systems language, I want to do it in Rust now. So I've added Rust to my toolbox as the language I'm willing to use. Just like in the browser, I'm willing to use TypeScript until I get Python there instead. So I want to look at learning Elixir because A, I think everyone should learn a functional programming language, and I know a ton. But I say this all the time, and I'm going to continue to say it until everyone's learned a functional programming language, which is never. So I'll never stop saying it. But I think people should learn multiple languages to learn different paradigms to really open their brains up to different ways of solving problems.\n\nYeah. That's what it always is, right? Everything's just about solving problems and seeing other ways to do it is great. Exactly. It's very much just how can you view the problem from a different perspective to potentially find a better solution that's going to be easier for you to maintain and understand when you're asked to read it again in six months because there's a bug and the last thing we've all been there, right? Come back six months later like, \"What the hell was I thinking? That's crazy, that's horrible, blah, blah, blah.\" So trying to have the lesson, the chance of having that happen because either you got it right the first time so you don't have to come back in six months, or if you do, they write in a clear enough fashion that you can understand it and find the problem quickly. I find broadening my mind through multiple languages has always helped a lot with that.\n\nI want to learn Elixir because the community seemed really nice and welcoming. That is a requirement for me. Yeah, the community has to be well-run and be nice and welcoming. I've submitted PRs to them for their documentation a couple of times, and they've been extremely nice about it and very quick on it and all that. But Elixir's approach to server software is really interesting to me because of the way they operate on top of Erlang and the way they try to handle fault tolerance. I think it's really clever and smart. I mean, you hear stories about Erlang systems that have like seven-nine uptimes.I mean this stuff keeps phone routers running right. This is why the phone system never goes down. There's a lot of really interesting things that they do in the Elixir and Erlang community that I want to learn more about, to either take from Python or if I discover it's just the underlying structure of the language and the runtime that you just can't replicate. I'm like okay, I want this in my tool chain.\n\nElixir is the very long-winded answer to that question. No, that's okay. Well, I want to thank you so much for coming on the show. This has been fantastic. Oh, thanks for having me. I really appreciate both being invited on and being on, and thanks for actually reading the blog post. I have no clue if people are reading it, I honestly have not looked at the metrics. As I said, I'm doing this for fun and just to potentially help out people, so if it's helped you, Christopher, it has made it all worth it. All right, fantastic. Bye now.\n\nDon't forget you can get started on DigitalOcean's App Platform for free at do.co/realpython. I want to thank Brett Cannon for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure you subscribe to the podcast in your favorite player, and if you like the show, leave us a five-star rating and a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey and look forward to talking to you soon.",
    "cvGqcZvHffY": "Welcome to the Real Python Podcast. This is episode 53. If you haven't visited the website lately, then you're missing out on all the updates to realpython.com. The site features a completely refreshed layout with multiple sections to help you take advantage of even more great educational Python content. \n\nThis week on the show, we have Dan Bader, the person behind Real Python and all these architectural changes. Among the features changed are a new bookmarking system, a section to keep track of what you've been learning lately, and much more advanced ways to search the site. A new tile system makes it easier to explore learning paths, quizzes, office hours, and other sections of the site. Dan shares details about the website technology stack and why he started using Python for the core content management system. He also talks about the struggle of being the sole maintainer and feature architect. \n\nThis episode is brought to you by PyCharm. Do you want to get your work done faster? Use PyCharm, the Python IDE for professional developers. \n\nAll right, let's get started. \n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with the community of experts at realpython.com. \n\nHey Dan, welcome to the show. \nHey Chris. \n\nThis is great. Finally, I figured I'd wait till... \nYeah, I know, totally, till number 50. \n\nYou had to wait till we had a year, you know, make sure we were doing okay. \nYeah, the bed's been made, you know, and I'm just ready to... \n\nAll right, well, I'm so glad to have you here. \nYeah, likewise. I mean, we have our recurring call every week, so this is interesting, but yeah, it's different, different vibes. \n\nAnd you know, I want to say, like, you've been doing such a fantastic job at hosting this show and building it up to where it is now. It's just been really great. \nIt's been a lot of fun. I've learned a lot through the process and kind of refined what we're doing and found tons of amazing guests. I'm excited about what the next year and further will hold for all of that. \n\nCheers to episode 100, right? \nYeah, it's only, and then I think we should go in a thousand increments and like, we'll do powers of 10. \nOkay, all right, that sounds fine with me. I'm enjoying myself, so it's been fun having David on. That's been really cool. \n\nNow I'm excited to lay out what's coming up in the near future. It's really kind of cool to have you come on and talk about Real Python, the site in general, and huge changes for the last year and a lot of them really recently. And then I don't know what time we could talk a little bit about what you see as potential areas that we can look at for the future too. I don't know if that'll be kept under wraps in secret or not. \nNo, for sure. I try to be pretty open with that stuff, but yeah, you're absolutely right. There are so many changes that at least like public changes that have happened just recently over the last couple of weeks. And there was a lot of work kind of behind the scenes on the back end that allowed us to do these things with the learning platform. I'm super excited to finally talk about it because it's been such a big part of my life for the last couple of months. This is great. \n\nIt's like you're the primary architect behind all of it, which is pretty amazing. \nPretty much, yeah. Do you run the ideas by other people? \nYeah, I mean, always trying to do stuff that's based on real feedback and listeners. I've probably seen this like on the site, we usually have feedback buttons sprinkled all over the place. There's some automated service and stuff that we run. And then what I found is that the important stuff will always keep on bubbling up, right? Like somebody will raise it over and over again, and that's like the critical data point. \n\nOne thing, for example, was it was really hard for people to find to be able to resume what they were doing, kind of continue where they left off when they were using Real Python to learn something and they were coming back like a day later. It was really hard for them to just continue what they were doing and pick up where they left. That was one of the things that just naturally kind of bubbled up higher on the site and also based on feedback that we had within the team, where David would hear it in office hours, we would hear it from our author team. It would just be something that would come up all the time. So that was like a natural thing that was pretty high up on the list. And I think usually that's how it happens.I think that's the best way to also do product direction, not always maybe because it's easy to get reactive to things. A lot of times when somebody suggests a solution, I try not to just go for the solution or implement that directly. It's more like the signal is, \"Hey, this is painful, and here's how I think this should be done.\" But you kind of want to disregard the \"how this should be done\" part and focus on this being a signal for, \"This sucks, this is not good, this is painful, there's a sharp edge here we should send it off.\"\n\nExactly. So I was noticing that, and of course, I spend a ton of time on the site not only reading articles but setting up courses and doing stuff with the podcast. It looks like it goes pretty far back. I don't know if there are any limits to the continued learning, but how does that work exactly?\n\nFirst of all, I want to say since you're working behind the scenes as well with me and the rest of the team, you've seen all the rough edges essentially, right? Because I think it's a lot more polished on the public-facing parts than some of our internal tooling is. Your question was about this continued learning. It's the first thing right below the newest article.\n\nPreviously, when you would go to realpython.com, which is what we call the front page, if somebody goes and types in realpython.com into their browser, previously it was just a long list, like an infinite scrolling list or not infinite, but you could scroll for a while and it would keep on loading stuff. A list of learning resources by publishing date, very blog-like. It's kind of the history of the site. It started out as a programming blog, and now we've got different types of content. There's the podcast integrated into the site as well, for example. There are video courses, quizzes, and all these other types of things. It was just getting harder and harder for learners to understand what's available. We have over 200 pieces of Python learning content on the site. At some point, a flat list is just not going to cut it.\n\nUntil about a year and a half ago, we didn't really have any concept of progress on the site. Learning progress was just like maybe you're reading this article, maybe starting to watch courses, consuming content, but the site didn't really know that about you. You'd have to use your browser to bookmark stuff or use Google to find content on the site. I've been on this quest to change that, to really improve the learning platform or improve Real Python as a learning platform. We needed to do a number of things on the backend side to have a data model or a representation of that learning progress.\n\nWith this most recent update, when you're logged into your Real Python account and you go to realpython.com, you'll see as a headliner the latest tutorial that's been published, whether that's a course or whatever. Underneath, it'll have a headline sort of Netflix style that tells you, \"Here are the last things you looked at that are unfinished. Why not continue reading this tutorial or finishing that course?\" It may look like a straightforward thing, but it took a while to make this happen, and there's been a lot on the backend side that needed to change for that. For example, we didn't even have a concept of what it means to complete a tutorial or to read it. The site wasn't aware of it.\n\nThe video courses have always had a bit of a completion tool pretty early on. We had that from the get-go, and I think that was a good model. It was a great way to learn about what was working or not working from a UI perspective. It started out as a completely separate universe compared to the articles. We only have that for courses. When you look at Real Python, it's like a great multimedia platform. It's got a lot of baggage.But really, that's what it is, I think. And that's purely a good definition for it. My definition of it is, okay, you want to learn Python, you want to get better at your Python skills, you want to stay up to date with what's happening in the Python world. If we just give you courses or written tutorials, I don't think that's really going to cut it. I think what helps people the most is when they can really immerse themselves in a topic with various different forms of media. In our case, for Real Python, that could be a deeply researched written tutorial on a particular topic that is almost like a book-length sometimes. We've had some articles where we had to implement infrastructure improvements to serve them to people because it would affect their browsers and whatnot. You want to be able to access that and maybe watch a video course on the same topic that's broken down. You want to engage with other learners in the comments. Maybe Chris had a great guest talking about that topic on the podcast, so we want to surface that for you as well. And on top of it, we want to have an interactive quiz that learners can take to see where they stand on that particular topic. If it's a broader topic, not just a thin slice into a certain topic, then we also want to give them a sequenced learning path so someone can start at point A and we'll guide them from A to B to C to help them broadly cover that topic. That's the direction we were going, we are still going, and a lot of this just didn't really exist or you had to put in a lot of effort to make this kind of learning experience happen for you. Now, if you have a journal or a notebook to keep track of everything, that's a game-changer. I hated it every time I had to tell someone in our community Slack channel that they had to use their browser bookmark because we didn't have article bookmarks. We want to change that. The continued learning for me is looking at a handful of articles, courses I've been working on, and so forth. It only takes written tutorials and video courses into account right now, but I think in the future, there's room to experiment with quizzes and learning paths. I think it might make sense as well, although it's still a bit fluid in how to best surface it. I kind of like the idea of the continued learning section having some intelligence to do the right thing, nudging you in the right direction based on what you've recently completed and enjoyed. From a user perspective, that's probably nicer than just recommendations. It should be magical, where you go to the site and the first thing you see makes you feel motivated to learn and improve. If you get to the end of an article, it won't drop out of the list unless you mark it as completed. It's not the best experience because readers will often do that themselves.I'll jump to the end of the article to look check out the conclusion, right? Yeah, skim it. You're skimming it and so we set it up so that completing a written tutorial is always a manual action. Whereas in courses, if you watched all the videos, the progress maps really well to the video watch time. Once you've seen everything, that means you've completed the course, you get your completion certificate, and we celebrate with you.\n\nBut on the article, I think it's more linear. A lot of times, although our articles are written with that in mind where you could start at the top, sit down, kind of work through the whole thing, and it will take you by the hand and guide you through everything. But what we noticed is that a lot of times people want to survey the content. So if we automatically mark stuff as completed, that's a bit tricky. So we leave that up to the user, but the system will know that you started reading this thing. It also has an estimate of how far we think you've read, which is kind of dumb. It's just looking at whatever section is visible right now and calculates a percentage score based on that, or a percentage like reading depth. But for you to say \"I'm done with this,\" it's a manual action. You have to signal that to us, and you can do so in various ways on the article. There are a couple of buttons where you can mark an article as completed or bookmark it if you want to surface it later and review it.\n\nMoving beyond that, what do you want to dive into next that you've updated? Good question. Like I said, this is part of a broader theme, and one of the other interesting things that has happened here is our search has seen a ton of improvements over the last month and a couple of weeks. It was continuously getting better since 2017, but this most recent iteration is a big leap forward. Now it is personalized to a degree. When you're logged in, it will take into account the content that you've completed. You can now run search queries directly on realpython.com, where you can say, \"Hi, I'm Chris, I want to learn about Django views at an intermediate or advanced level, and the resource type I want for this is video courses or articles.\" Then, for all of those except podcasts, only show me stuff that I haven't completed yet. It's something you can click together with various filters and stuff, so you can go in there and type in, \"Show me all the resources on Django views,\" then filter it down to intermediate to advanced level, and then filter down to only video courses. It will highlight to you exactly that. There's other types of sorting you can apply, so you can say, \"Give me all the Django stuff that I've completed and order it by when I last viewed it.\" That would be a great way for you to review things, for example. We're basically making all that data available to users and learners to be able to improve their information and for them to know, \"Here's probably the next thing that I should check out,\" and also make it really easy for someone to find something they've seen in the past. That really felt like a huge change, just being able to support that type of search query.\n\nI'm liking the status thing, that's really cool, where you have bookmarked things that you've completed based on the user, and then in progress or not started at all, and then the skill levels. Those are kind of unique filters you don't usually see in a search engine that's very specific to the platform. Like it's really tailor-made for learners and for the type of content that we have too. I think a great strength of Real Python is this multimedia aspect, the diversity of types of media and learning resources where on certain topics like decorators, you could probably spend days just doing a deep dive into this type of content. It takes a special type of person to really do that and take all of that in, but it is available and it's all connected in a way that makes sense, which in my experience, that didn't really happen when I was searching for a topic on Google and found a blog post.And I find a YouTube video. These are all disjointed things. On Real Python, I can tie all of that together. I can really immerse myself into that topic and have it all in one place with one quality control team in place that will make sure this is accurate and good stuff. It's vetted. I think you've covered this on another podcast where you're talking to Michael Kennedy, but I don't know if you wanted to describe a little bit of the Python that is behind Real Python.\n\nYeah, sure. What frameworks and stuff are you using? Sure, yeah. I mean, I love talking about this stuff because it's such a big part of my day. Real Python actually used to be hosted on PHP for a while, and then it sort of became a static site, just static HTML, but there were some bits and pieces that were powered by PHP. This is way back when, before I took over the site. One of the first things I did when we relaunched it at the end of 2017/start of 2018 was I want this thing to actually be running on Python. We can't make the best Python learning resource and host it on PHP.\n\nSo yeah, there were a couple of months of me basically working, having Netflix open with Star Trek TNG on an endless loop and then hacking away Django code and relaunching the site as a Django app built on Python 3 with PostgreSQL and Redis as the backend services. PostgreSQL as the database and Redis for caching and ephemeral data storage. But back then, the search didn't really exist in the first iteration. But if we're talking specifically about the search feature, that's built on PostgreSQL full-text search, which is really cool. PostgreSQL is just a fantastic database. I'm grateful for all the open-source folks who make this project work and continue to improve it.\n\nMoving beyond search, what were some of the things you had to do to implement bookmarks within articles themselves? Yeah, I mean, for this stuff, it was one of the easier parts. It's basically a bit of UI. You need a button for it, and we wanted to have that button in several places. The tricky bits are not really tricky, but one of the things is we have quite a bit of traffic, and a big part of our infrastructure is the content management system behind RealPython.com. I want to make sure it's fast and a good experience for people. It is quite maintainable with a small team. It's not using the latest and greatest technology on the front end. It's still primarily built around static pages, standard Django views, which has SEO benefits too. One tricky bit there was figuring out how to do this in a way that wouldn't require us to fundamentally rewrite how the site renders content. I view all the JavaScript bits as incremental improvements. You should have a great experience even with JavaScript disabled on the site, and I think you can get that today.I view things like the bookmarks and that stuff more as an add-on instead of it being a part where the whole site is built around that concept. I'm talking about single page applications, for example, where basically your browser, your backend only provides an API. The front end is purely done in JavaScript, fetches all the content, renders it, displays it. If your browser can't execute that JavaScript, there's nothing that you see, just an empty page.\n\nThis approach makes some things easier and other things harder. For us, I always leaned more towards the classic Django approach with incremental improvements on top. We've strayed away from that a little bit. The search interface, for example, is a Vue.js application that is rendered entirely client-side. But for the bookmarks, it gets rendered in Django in a template, then activated with JavaScript. There's a bit of JavaScript that hooks up all the events and keeps it synchronized.\n\nThere's an API on the backend that will store that state change. If you click the bookmark button, we'll save that bookmark for you and surface it in other places. The trickiness comes from exposing that information in other places on the site. For example, in the search, you want to be able to filter on bookmarked items, making search results personalized.\n\nWe use a content delivery network (CDN) to serve static assets like images. Cloudflare is used for this purpose. The search results were cached on the CDN edge, making them super fast. Now, with personalized results, the caching needs to be adjusted. I wanted to do this without massively complicating our infrastructure, given our small dev team size.\n\nWe are still able to cache most of that stuff and augment it with personal progress data. It's a multi-layered process where we fetch all the results, merge personal data, and serve it back to the user. It's all these little things that should be straightforward but have many moving parts, especially in ensuring fast performance.So then the other thing you were able to do in the redesign is surface this whole area that says explore real python. Some of this is new this year, which is super cool. I mean, the podcast being a tile that's on there and then David Amos taking on the office hours thing, which we've talked about briefly on the podcast but haven't really delved too deep into. That's been a whole big upgrade and it'll be, I guess, in the summer, it'll be a year for that. So it's coming up pretty quick too. Yeah, that's been a wonderful thing. The office hours, for those listeners who don't know, are like weekly Q&A calls with David from the Real Python team where people can bring their questions or just watch it as a sort of like a lecture. I think that's been a wonderful add-on. I'm super excited about the community features that we've added to Real Python, and I would count the podcast in that as well. I love listening to the show, and usually, I get a sneak peek and we talk about titles and stuff, right?\n\nI think it fits right into that area where it's not just the learning content but also getting a different perspective on how real people use this stuff and being able to ask questions in our community chat and whatnot. One piece of feedback going back to when we started talking about this, how do we decide what to change, what to improve, what to work on? That was another big item on that list. I might have even been on office hours where David was showing an interactive quiz or something, and somebody was like, \"Oh my god, this is amazing.\" I didn't realize this was on the site. It is in the navigation menu, but it's in a dropdown, and that immediately made me think, \"Man, this is just not visible enough.\" I get it if you're browsing the site on mobile on your phone or something, maybe it's not the biggest screen or something like that. This stuff is one or two clicks away, and we have an onboarding course, a welcoming course where I walk you through the whole site as a new learner and explain this to you, but I get it. People skip that, not everybody watches it, and I want to make sure it's easier for people to see what's in store when they want to use RealPython.com.\n\nSo again, sticking to this Netflix-like theme, which, hey, I'm watching a lot of Netflix right now because it's still the pandemic and we're just at home a lot. One of the things I think they do really well is when you go to the site or pull up the app, they show you exactly like, \"Hey, you can continue watching this thing you're probably going to like it.\" In our case, I think it's a bit more complicated because it's not just all video content, but we really wanted to just directly show you there's learning paths, quizzes, a podcast, office hours, and other things. This new front page design now has these sections, and it will be very easy for us to add more sections in the future. One of those sections is the Explore Real Python section where it highlights all the different areas in these tiles and points out why the podcast, quizzes, and other features are helpful. I think that's been a really positive change, especially for new learners and new people using the site.\n\nI think it's huge. It's the discovery part of it.I feel like the drop down menu thing is just such a barrier, especially in mobile. Having the stuff in front of you is really going to make it easier. I mean, you think about the example of a streaming service. How are people going to go to a drop down menu when there are all these other things on tiles right in front of them? They've kind of been indoctrinated into that methodology of infinite scrolling through stuff or having potentially a menu.\n\nI like that, you know. I think that's really helpful. Having these things pop up on the surface and being well combined into the search area. It's a whole section about exploration. Yeah, 100%. Like, you're absolutely right about what users want to see and use. It doesn't make sense to fight against that. Somebody listening to this might think none of this is rocket science, but it's really quite interesting where a lot of plans or things we've tried in the past. It's just so interesting how when things go live, the rubber hits the road, and we get real user feedback.\n\nWe have a real Python community Slack where people can have early access to new features and provide feedback. It can sometimes be half-finished stuff or not super performant, but the performance part is taking the most time. We have three million readers a month, and we want to run this on a small team without huge infrastructure costs. Optimizing for good and quick experience is key.\n\nInitially, I was thinking about hosting real Python on WordPress with a bunch of plugins, but now it's a Django app, my bread and butter. We can tune it and make sure the features we want are fast and convenient. If a person is an irregular user of real Python and doesn't have an account, they just need to sign up for a free account to access features.\n\nThe new search features and article completion are currently not gated behind a paywall. You can use GitHub login or email and password to access these new features easily.I like what we're doing because we can make a lot of the learning materials available for free or have them be supported, especially in places where the cost might be prohibitive. I want to keep it like that as much as we can. There are always thoughts around whether people are going to abuse that or if someone is going to do something mischievous with the API, but for now, I want to keep this open.\n\nIf listeners want to try it, they can go to realpython.com. You won't see the news sections in the explore section yet, although that might happen pretty soon. Depending on when you're listening, you might already see it and be wondering what I'm talking about. Basically, you need to make an account, just click on the sign-in button or click on any of the bookmark buttons on articles, and it'll prompt you to make an account. Then you get access to all these features.\n\nIf you're in a search and start filtering by something that requires personalization, it will also prompt you to log in or make an account. Pretty quickly, they're already into it; that's cool. I really wanted to make it easy to use these things and have a super low barrier to entry. One of the next things we need to do is to roll out the front page to all users, even if you're not signed into an account, you're just a regular reader.\n\nIt's another conversation around what are some of the empty states for these things. For example, we can't show you any bookmarks, another section we have on there. So bookmarks are one, and another section is to review what you've learned, which will try to intelligently resurface stuff that you've recently completed. I marked as complete and it's been a while since I looked at it, and now the system says, \"Hey, you should probably refresh your memory now would be a good time.\"\n\nWe can't really do that if you're not logged in and don't have any history with Real Python. That's a bit tricky, but I think stuff like the explorer Real Python section would be great for people to see even if they're not logged in. Maybe something like what's popular right now could be interesting.\n\nThat's something we're going to build out over time and bring in other stuff as well, like other types of content. Quizzes would be wonderful for people to compare how their quiz scores improve over time. We've got a really good foundation now, and we're going to continue building on top of it.\n\nThis week, the spotlight is a bit different. I want to let you know that the Python Basics book is now available as a paperback book. The book has been written by frequent guest David Amos along with previous guest Joanna Jablonski and this week's guest Dan Bader, along with help from the Real Python tutorial team. There's an overwhelming amount of information about Python on the internet, but for many beginners studying on their own, the lack of structure for what you should learn and in what order is missing.\n\nHere are some of the highlights and features of the book. It covers each concept and language feature in a logical order, has a simple-to-follow step-by-step roadmap to develop foundational skills, and each step in this complete beginner's curriculum is explained and illustrated with short and clear code samples. It includes coding exercises within each chapter and interactive quizzes to help fast track your progress and ensure you always know what to focus on next.\n\nIf you already have some prior coding experience, even better, you'll be able to move that much quicker and get a crash course that brings you up to speed with modern Python programming. Get Real Python's practical introduction to Python 3.9 that jumps right into the meat and potatoes without sacrificing substance. Become fluent in Python and gain programming knowledge you can apply in the real world today.\n\nThe physical paperback book is available on Amazon, or you can find out more about it and how to order your copy at pythonbasicsbook.com. One of the things you have in there is the progress, and I was wondering about what it took to implement that. What are some of those changes that you had to make, I guess maybe even infrastructure-wise?\n\nWhat it took to get started on it was a lot of feedback and complaining, basically.There was one thing that stood out. I'm joking about the complaining, but I love hearing feedback like that, whether it's on Twitter, email, or in our internal communities. There was one request for a feature we have called Real Python for Teams, which is online Python training for teams tied to a single billing account. Companies can purchase seats for their team, invite them via a link, and access all the content and community features.\n\nRecently, there was a request for audit reports for training credits in some countries. Companies need proof of spending on training and employee usage. I quickly hacked together a report, but long-term integration into the team dashboard is needed. Progress allows team admins to generate audit reports showing training breakdowns.\n\nThese audit requirements around training are interesting. It's common in larger organizations and helpful for tracking user activity. It can be used to nudge users towards completing certain content or suggesting related topics of interest. We have a responsibility to help people learn, so making these features useful is crucial.\n\nI have concerns about making these features genuinely helpful without being intrusive. Our goal is to facilitate learning, not just track metrics like time spent on the site. It's more about providing value and guiding users towards valuable content.Hey, I want to hear from people if they've gotten something out of the tutorials that we create. Maybe someone can say they got a job, built something, or helped their kid with Minecraft. It's always a balance to do this without it just being fluff that doesn't add to the experience. I think we'll be able to do some cool new features based on the stuff we already have. One feature would be subscribing to a learning path, completing tasks, and moving on to the next thing. Real Python sets up learning paths curated by the team, not just based on recommendations.\n\nWe want to see where technology fits best. There have been additional changes in video courses, like Sadie working on transcripts and closed captions. The entire back catalog of video courses now has completed captions, which is a huge accessibility step forward. Everything now has subtitles for content discoverability, making navigation easier.\n\nWe also started a podcast and office hours last year, and Python Basics and CPython Internals books are making progress. Python Basics will launch soon in paperback, and CPython Internals is in the review process for the paperback version. The team has put a lot of effort into these books, with custom artwork and a color theme to differentiate levels.\n\nI'm pleased with how everything turned out, and Anthony did a fantastic job presenting the information. The team is working on QA for the paperback version of CPython Internals, and both books look wonderful with the custom artwork.I think it's a one of a kind book. It's really, the subtitle is your guide to the Python three interpreter. It breaks down how Python works at the interpreter level and helps people contribute back to the project and understand how all the different pieces fit together. It's just really great. To answer the question, we're going to need a little bit more time to review the paperback and make sure it's ready for release. But then it should also be available pretty soon, I would say on the order of weeks. Okay, yeah. So it's not going to take very long and I think that's going to be great too. I'm excited about that.\n\nAs a person who's kind of newer to Python, I've been reluctant to dive into the C portion and think about the internals of Python. But on the podcast, it has been my chance to explore that more and more. Talking to not only data science people and them talking about different ways of implementing different C structures and things like that to speed up certain things that they're working on. But that conversation I had with Brett Cannon about his sort of deep dive and trying to unravel it started to make it feel like, oh okay, I should be able to dive into this and navigate through what's happening as far as the different structures and so forth. I feel a lot less nervous about it. I mean, it's definitely more of an intermediate to advanced topic, but I'm feeling more and more confident all the time with my time in it. And definitely having talked to Anthony before, I can definitely see where he's coming from as a teacher. I hope to have him on the show again about it. I think that we should work toward that soon with the podcast with the release. That would be great.\n\nThat's a great way to celebrate the release. I would agree, this stuff is so fascinating because you can kind of push it all away for a really long time. When I usually don't think about these things when I'm working in Python code and you're kind of in that universe, but then every once in a while it's like, well, it's really kind of good to know how the garbage collection stuff works or how somebody's parsing things work. Anthony's really done a stellar job on this and really broken it down into actionable little things. He basically shows you as part of the book how to make changes to the Python syntax and add new operators and stuff. So things you can't do from within Python code directly but you have to go through modifying the actual interpreter C code. It's super cool because it gets you to do stuff right away and you're actually making practical changes.\n\nI think this is super nice, it's pretty good. Here's my chance to finally ask Dan Bader himself my weekly questions. So, what are you excited about in the world of Python? I am really excited about the forward progress. There have been many changes recently, not so recently in leadership and a lot of change around when Guido stepped down from BDFL. He's still the dictator for life but a benevolent dictator. There's been quite a change there and with these things, you're never sure how they're going to work out. It's been great to see just how strong the language is, how strong the core dev team is, and that they've been able to release new stuff non-stop. Seeing a lot of changes and improvements to the language that we can argue about whether or not everybody likes them, such as the walrus operator stuff or most recently the match case construct. But I'm generally really excited about that and I think it shows that there's so much strength behind Python and the community and so much interest in improving the language and experimenting with it to a certain degree. I think that's huge news and it's going to mean that more and more people are going to use Python for various things, which I think is great too. It's obviously great for Real Python as well, but just from a perspective of more people being in touch with this wonderful language and hopefully developing a passion for programming through it. I think that's super cool and all this movement really encourages me and makes me think it's not resting.Like it's definitely moving forward. Yeah, full steam ahead. Yeah, I was watching the pie cascades talks and they had the kind of core developer team along with Guido talk about the types of progress they were able to make and what it was like to do that over the last year with the constraints of not being able to meet in person. It was a very interesting conversation. They're definitely all there and passionate to keep going. As I get closer over this last year to members and different points inside the community, I'm feeling more and more like a member myself, which has been cool.\n\nIt's just neat and very vibrant and very alive. Yes, there's lots of conversation, but in the last several months, I've seen more and more consensus. I'm starting to understand the pep process a little better. There's a lot going on, but I feel like all of it's coming from a place of good faith and wanting to expand the language in positive ways, not to break people's stuff, and to allow for newer and more interesting uses.\n\nOne of the things I'd like to talk to Guido about is his change to the peg parser and what kind of changes that allows. I think that would be interesting to talk about too. That'd be super interesting. Yeah, it would be amazing to have him on the show. It's definitely an interview that I'd be very much looking forward to. Also, being more in touch with what's happening in the language design process because I've been running Real Python for a couple of years now and just being aware of everything that's happening is my day job. It's a big passion, but it's also what I do for work.\n\nThe amount of responsibility and stuff that's resting on the dev team's shoulders or some of the more prominent folks there is incredible. With any change you make, there's always a percentage of people who are really unhappy with it. To have to absorb that to a certain degree can be tough, but it's been cool to see that it's not stopping anybody. There's still a lot of interest in improving the language and trying out things, and not all of them are going to work, but some of them will probably work out really great.\n\nI'm just really excited about the stuff that's happening there. Can't wait to play with that myself. So, what do you want to learn next? I think I want to become a better manager. It's not exactly programming related, but I look at what I do her day-to-day, and I think there's lots I have to learn in terms of building Real Python, the company, and the team around it. We're also at a point now where there's a bigger return on that investment rather than trying to maximize my time coding or squeeze out some more improvements. It's really something I'm struggling with, finding a balance.\n\nThat's the honest answer. I just feel like that's an area I want to work on in the next year or so. Have you found good resources? Yeah, there are all kinds of books out there, and it can be hard sometimes to find good resources focused on the type of remote team that we are. Many things don't purely focus on management but more on company building, teams, and making sure we have processes set up in a way that helps us achieve our goals. I'm terrified of creating processes that detract us from our goals because I've been exposed to that in other jobs.\n\nI'm sort of terrified of creating that in my own company, although I probably already have done that.Anyway, I recommend the book. We use Basecamp internally, which is like Slack, but not really Slack, more like a forum. I like it because it's less real-time focused, more on longer form writing and forum-based communication. Basecamp has a to-do list and chat feature, but it de-emphasizes chat and disables it on weekends. The company that makes it is called Basecamp, previously known as 37signals. The founders wrote books on remote work, which I highly recommend.\n\nFor Python, there's always something new to learn. People in the community chat constantly surprise me with new solutions and approaches. For Real Python, setting up an NPS score survey on the site and linking it to Basecamp has been eye-opening. The outpouring of positive comments and ratings has been amazing to see every day.\n\nOverall, I recommend looking into Jason Fried's books and exploring Basecamp for team communication. There's always something new to learn and adapt in the tech world.I don't know, it just warms my heart. It's so hard sometimes to see that because obviously the surface, the feedback that surfaces, is many times like when somebody's unhappy or something's going wrong. We had an infrastructure hiccup the other day where a vendor we were using was down for a while, so emails weren't delivered. People were waiting for stuff they had requested from the site, like a password reset or something like that. When that happens, it's immediately frustrating. I get it, it sucks. I hate it the most when that happens.\n\nHooking up this feed and waking up in the morning to check it, and just seeing the positivity that comes from that is a good thing. I encourage people to write reviews for the podcast too. I really love that feedback. We have a feed for that as well in our charitable section, where they pull stuff off iTunes and Apple Podcasts.\n\nOccasionally, I've thrown out a request for it. It's good to know, and we also have a section on the site for questions at podcast.realpython.com. You can send questions or topic ideas, things you're interested in. I'm compiling a lot of that and setting up new guests, so keep that stuff coming. Did we ever get another voicemail? We haven't gotten any voicemails in a while, so let's say from almost the summer.\n\nWe still have that on, but you can leave a voicemail. Long-time listeners might remember a few of those. Let's see if we get some voicemails. I like those. I think that's another cool idea, and I think you've done a fantastic job bringing the podcast to YouTube. Initially, we weren't sure, but there's a decent chunk of people who want to use YouTube for podcasts.\n\nIt doesn't take too much work or an incredible amount of time. I add all those links so they can search through it like chapters, which now works across YouTube. Show notes are still on the site or inside fancy players like Overcast or Pocket Casts. If you're listening on YouTube or Spotify and wondering where all these links and things are, you should check it out. There's tons of stuff in the drop-down.\n\nCool, well Dan, we shouldn't be so long before you come back. Visit soon, hopefully. If you can make time in your busy schedule for me, I'll certainly come back. Sounds good, talk to you soon. Thanks, Chris.All right, bye.\n\n[Music]\n\nThis episode was brought to you by PyCharm. Get a free three-month subscription to PyCharm Professional Edition with the promo code REALPYTHON (all caps, no spaces).\n\nI really want to thank Dan Bader for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review.\n\nYou can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea.\n\nI've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "CazMwjhedqc": "Welcome to the Real Python Podcast. This is episode 57.\n\nAre you interested in creating video games but feel limited in what you can accomplish within Python? Is there a platform where you can take advantage of your Python skills and provide the benefits of a dedicated game engine?\n\nThis week on the show, we have Pavel Vertic. Pavel is a Real Python author and has been creating games as Miskatonic Studio for several years now. He's worked inside of Pygame and we recently featured his article on creating a clone of Asteroids in a previous episode. After working with Pygame for a while, he also tried a visual novel engine named Ren'Py and a 3D engine named Panda3D. \n\nAfter struggling with these Python libraries, he started to look for an open-source game engine that could help him create the types of games he was striving to create. He found Godot and its Python-like scripting language of GDScript. We talk about his creations, the tools, and how game development is not exactly like most other types of development.\n\nThis episode is brought to you by DigitalOcean's App Platform. Alright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHi Pavel! Welcome to the show. It's so cool to talk to you. Thank you very much for inviting me. It's a pleasure to be here.\n\nHow long have you been writing for Real Python? Since last year, more or less this time, so I guess it would be one year of writing. I've only done two articles so far because of the review process for the first one took a lot of time. The review process for the second one, because it was my first project-based article, took even longer. So, by far, I've written two articles for Real Python.\n\nIt sounds like you've done a lot of talks also, going to different community meetings and things like that. Is that something you enjoy doing? I do enjoy meeting with people, with other software developers. If I have something worth sharing, I always enjoy it. I try to participate in these meetings whenever I have an opportunity and something that might actually be worth other people's time.\n\nThis second article that we talked about on the show recently about the Asteroids clone created in Pygame started out as part of a demonstration for a talk. Yes, a couple of years ago, I helped with PyLadies Bosnia, the city that I come from, and that's where the PyLadies chapter was located. I was helping as a mentor and I wanted to show the participants how they could start with games using Python. I created this very simple clone of Asteroids with graphics made by myself in Blender, which you can probably tell by looking at the examples in the screenshots. The idea was that I had three lectures where I could talk to them and show them the code, step by step, how to change this from a completely empty project to a working example of a game. I went through all the things that Pygame has to offer, such as input handling, showing images, displaying text, playing sounds, etc.\n\nAnd then, after my first article, when I was ready for the second one, I realized that Real Python wanted to have a Pygame article. So, I cleaned up the code a bit, and this could be a good topic for a project-based article about my game. The graphics were basically the same, other than the background that got updated. The code was very similar, but it got cleaned up a bit.\n\nWhat were some of the more challenging aspects of programming the game? Like, I think of some of the geometric kind of math and stuff that you have to think about. You say that it's mostly a project, but you end up having to explain some of those concepts as you're going through that too. Yes, it's true.I think geometry can be a bit complicated because something to keep in mind. For example, a game always starts drawing in a corner of a picture. For the purpose of this game, I wanted it to be drawn from the center. So, I had to apply some very simple math to move the picture a bit. Then Pygame can rotate the picture, but as a result, it returns a new picture with a transparent background. The new picture, if rotated by 45 degrees, becomes wider and higher than the original one because my game adds space to keep all the pixels from the original. It needs to add space around so the whole thing becomes bigger. You need to take that into account if you still want to draw in the center. You cannot just use the radius of the picture, but you have to use the new radius, which is calculated from the new picture. That was a bit problematic, but something that could easily be solved. The most problematic thing in this type of project, at least for me, is architecture. Like how do you have a game? Is the game a global object or an instance? Should you have asteroids? Who is responsible for creating asteroids? Is it the game? Do you start the game with asteroids or without and then create them? And if so, where are they stored? If you shoot a bullet, the bullet flies and reaches the asteroid. How do you detect that? Is it the bullet's job, the asteroid's job, or the game's job? Where do you put that code? In Python, in Pygame, you basically write a Python program with options to handle vectors, graphics, sounds, and so on. You need to figure out how to do it. The only thing Pygame requires you to do is strictly a game loop where you refresh the screen every now and then. In every iteration of the loop, you need to apply the logic, move the objects, handle collisions, and so on. How exactly you do it is all up to you. Figuring out how to do it was probably the most difficult part of this.\n\nThe architecture that goes behind everything, the idea of how to handle collisions, and so on. I know there are methods that can help with sprites that can identify collisions. But in general, there are so many different things flying around. What did you end up choosing for that decision, like for space rocks, the asteroids themselves? Are they deciding if they've been collided with, or is it the bullet? In this case, I think the game decides. The game keeps a list of asteroids and bullets, and every frame it checks and moves both according to the moving logic in asteroids and bullets. The game checks if the bullets collide with asteroids. For example, a spaceship generates bullets. In order to do that, I added a callback to the spaceship that is basically the append method of the list of bullets. Every time the spaceship shoots, it uses a callback to create a new bullet. The game provides a proper method for this callback so the spaceship can add bullets to the list in the game. The same goes for asteroids when they are hit and need to split into smaller ones. An asteroid generates asteroids, but the asteroid does not have a list of asteroids. It was either making the list of asteroids global or putting a callback in an asteroid to create smaller ones. This is how it would work in Pygame and Python. For engines like Godot Engine, you would create an instance of a new bullet and add it as a sibling or append it to the current tree in the scene.So, you kind of have access to global objects, but you don't need to create global objects because a game detects which scene you are in. Then you can just add new nodes if you add scenes or nodes if you need to. That wouldn't require an architectural perspective different than in that game. Having a normal python project required that kind of approach, I think. That's the one that I've used. I'm sure that it can be done in different ways too. Programming is always just solving problems, even if the game you're emulating exists. You still have to think about how all those things were created.\n\nOne of the things I thought was interesting when I talked to John Fincher a year ago about gaming was the idea of whether doing game programming is a good way to learn a language. I leaned towards the idea of learning in-depth object-oriented programming for Python. Do you agree with that?\n\nThis was not a question for John Fincher, it was to me this time. I'm just wondering what you think. From my perspective, game programming is completely different than any other programming. For example, a Python web application has a completely different life cycle. It starts when you get a request and stops working when the request is handled. Of course, you can have tasks running in the background or a database connection. This is one way an application can work. If you have a script on your desktop machine, then you start with \"if name equals main\" things and put all your logic there.\n\nGames are difficult because objects live their own lives. They are connected to various elements within the game. This creates challenges when working with normal programming languages like C++ or Python. Games seem to not follow all the rules I have learned about those programming languages. Trying your skills with game development is a great idea, but it may not translate well into normal applications.\n\nI think games are significantly different. Just my opinion, though. It makes sense and leads into why I wanted to talk to you further. You started dabbling in games, playing around in Python and Pygame. Maybe we could go a step backward and say, were you dabbling in other languages and trying to develop games using other tools before Pygame?\n\nYes, I actually started with Visual Basic. I had zero idea about computers and programming back then. I found a book about programming for children from nine to 99 years old. I started coding in Visual Basic and felt excited to see my code work. I quickly realized that even two-dimensional games would be difficult to make with Visual Basic. I created a Pong game using labels and shapes, but it wasn't what I wanted.\n\nI saw a representation of a snake game animated with text boxes in an iOS app, which reminded me of my early attempts at game development with Visual Basic. It was a learning experience to realize that Visual Basic was not the way to make games.So what would you move to? I moved to Visual C++ because my father's friend was a software developer back then and he had the environment, his whole environment on CDs. Also, with this came the book. I started reading that book and again, this was a UI application. Not the stuff that I wanted to do. I wanted to have 3D graphics and at some point, I got my hands on the OpenGL game programming book, which explained how OpenGL worked. But back then, I didn't even know what C++ does. So I went through the entire book. I knew what I could do after reading this book, but I still had no environment. So when I got this Visual C++ thing, at the end of the book, there was a tutorial of C++ itself, like the command-line things that you can run from a command line without any UI. That plus some OpenGL imports together created finally an environment where I could start making 3D stuff. For a very long time, I worked with C++ and OpenGL, just experimenting with different things. Back then, engines were not yet a thing, I believe. So yeah, this was kind of like they kind of explained that this was used in this game, but it wasn't yet there weren't any ready-made solutions available. So then I took a bit of a break with game dev when I was in college. But still kind of dreamed of it, and then some time later when I came back to the idea of making my own games, I was a full-time Python developer. I had this thing that I wanted to do everything in Python because Python was such a great programming language. I wanted to use it for absolutely everything - desktop script Python, web application Python, of course, so games, why not Python? And then I started looking for what are the Python options for making games, and Pygame was the first one that came up. So yeah, I gave it a try. I made a couple of smaller things, but I'm not even sure at this point if my game really supports 3D objects. I know that back then I definitely didn't get to the point where I could create anything 3D with my game. So yes, I tried for a very, very short time, quickly realized that this is not the framework made in Python that is intended to be used in visual novel games. But I realized that I don't really want to make visual novels, and this was specifically for that type of games. It wasn't really useful for anything else. You had mentioned that project to me, and I checked it out a little bit. I find it intriguing. I had seen something similar in the iOS world, this idea of creating an animated novel with sound, music, and all these other aspects of it. But it truly is an enhanced version of a comic book, in a sense, or a graphic novel or what have you, which is neat. And I think you can tell really cool stories with it. Yes, definitely. In fact, there's some interesting games that kind of almost take on that a little bit and go a little further. But I can see how it would be limiting if you're like, \"But I want to interact in an environment,\" and that kind of is a very different set of tools. So yeah, I think that the genre itself is very fixed. You have these characters and the background and the text underneath. But because of that, you could create a really good tool that does exactly this one job because the interaction is quite limited. So you don't have a lot of creative freedom. But yeah, as far as I could tell, for that one job, for making visual novels, Ren'Py seemed to be a very well-made tool, covering almost all of the aspects that you could think of. I didn't really work with it other than the quick tutorial. And also, I think Grandpa uses Pygame itself. So it's basically an extension of Pygame. But then, continuing with Python, when I finally wanted to make a serious game, I started checking other frameworks and found Panda3D. It looked promising but had its own limitations. I decided that maybe putting everything in scripts, like text files, is a good approach for any other application, but not necessarily for games where I would like to see a preview of my scene and see how materials would look like, how the lights would look like. So I started looking for options that were not necessarily strictly Python-related. That's how I found Godot Engine. Yeah, it's something that at the very end of our conversation that I had with John Fincher, he mentioned it as something that he was interested in exploring too.I kind of feel the struggle in your journey. I really want to create something in 3D without focusing too much on the tooling, like how something will live in this space, managing the game loop and objects. Some game developers find building engines interesting, while others prefer expressing their creative side without starting from scratch. Is that your experience?\n\nWhen I started, I had this idea of making games, but I focused on learning the basics first. I worked on creating an engine using OpenGL and C++ because there were no popular engines available back then. I realized I was more focused on solving technical problems than defining the type of game I wanted to make.\n\nAs engines became popular, I no longer had to solve technical problems and could focus on game development. Working on engines and optimizing low-level APIs like OpenGL was interesting, but making games involved different challenges like storyline, difficulty levels, and marketability.\n\nGoing through the struggle of learning technical aspects informed me about what's possible and how technology works underneath. In the music industry, I transitioned from being a musician to a technician, setting up sound systems and helping others with their equipment. It helped me understand the technical side while still wanting to create music.And so eventually I got to this thing like, okay, well, how much do I want to spend my creative effort in helping other people succeed and what's the balance there of doing my own kind of thing? Games have always been intriguing to me and I have enjoyed that rise of the idea of these engines like Unity or the other big ones that are out there that I've seen.\n\nThis episode is brought to you by DigitalOcean's App Platform. DigitalOcean's App Platform is a new platform as a service solution to build modern cloud-native apps. With that platform, you can build, deploy, and scale apps and static websites quickly and easily. Simply point to your GitHub repository and let App Platform do all the heavy lifting related to infrastructure. Get started on DigitalOcean's App Platform for free at do.co/python.\n\nWhen Godot kind of came along, what were some of the aspects of it that you were excited about and felt that you would be able to take advantage of?\n\nWell, when I first encountered Godot, I think it was version 2, and I was not that impressed because the tutorial was rather simple. I mean, the tutorials are supposed to be simple, but I think this one was a pong game and the collision handling was super simple. The collisions had to be handled manually, which was not what I expected an engine to do for me. So, no thank you. I don't really remember why I started with Godot back then, but my first impression was not great.\n\nWhen I started working on this first-person 3D game Intrepid, I gave Godot a try again, and Godot had already been upgraded to Godot 3. The tutorial was still simple, but the game was much more interesting, and the engine showed how many things it was taking care of on its own without having to code them, which was very nice.\n\nWhen I decided to use an engine instead of Python plus a Python module for 3D graphics and sounds, my main concern was having a nice editor where I could drag and drop models and rearrange them easily without having to code everything. Godot was very much not disappointing in that regard. It took care of a lot of logic like collision detection, showing models, materials, light sources, displaying sounds, animations, and more.\n\nI think that's even an experience you had with the asteroids game in the sense that these objects were round but when you do collisions very often, yes. In asteroids, you do not have to handle collisions in terms of moving the objects whenever they collide. The collision means that the object is destroyed, so that's the only handling you need to do. Handling collisions like if you have two cubes and you push them together, they should slide along one another, which direction they slide to, and when they reach the corner, they should stop sliding because there is nothing to stop the movement. So, that kind of stuff is much more difficult to implement.And that's what is already done.\n\nI was thinking about that, it's sort of like multiple variables x, y, and z. Then you could think about what surface they are on. Are they in space, so they just bounce versus if there is gravity and they are on a metal floor or rocks, they will behave differently for realism. It's super complex.\n\nWhen I was looking at Godot, I thought it's nice because you can visualize how things will look. You can create a scene or a level, put lights and other sources, and see your main objects, characters. It's pretty incredible.\n\nIn Godot, there is a nice editor where you can see how your game will look. There's a scene tree with nodes and properties for models like light sources. You can adjust range, attenuation, reflections, and more. You can also add scripts for customization.\n\nIt's like being an interior designer. You can easily arrange items in your game level, moving things around and making adjustments. It's fun and efficient to work with an editor like this.\n\nGDScript is a scripting language in Godot that is built into the engine. It's not the only language you can use, but it's convenient for scripting within the engine. You can also use other languages like C#, C++, depending on your configuration.You can order some visual scripts where I believe you put together blocks of logic. But being a python developer, I prefer to use a text form of a script. Sure, it's a language that is very similar to python. Basically, after going through the tutorial of Godot Engine 3 on this non-pong game, I have realized that the syntax is so much similar to python that I don't think I've ever gone through a documentation page that describes the syntax. Just when I had some smaller issues that I needed to, for example with string formatting, I need to go to the documentation and see how exactly is that done in GD script because it's done differently than in python.\n\nBut normal things like loops, arrays, dictionaries, stuff like that, it's all like the indentation that works almost exactly the same. So after you go through these small differences, you can basically most of the time write python code and it will be correct GD script code. Nice. \n\nThe types of things that are required or needed inside of the scripting part are really like the logic of the game. What are other types of things that you create in the scripting? You mentioned strings and other things like that, but I'm just trying to think of like what are the components that get scripted out inside there.\n\nFor example, in Godot, definitely input handling. In Godot Engine, you can create input actions, so that's a very nice layer of abstraction. You can say this action will be called \"jump\" and it will be triggered by a space key or a right mouse button or this button on a controller, stuff like that. And then, Godot Engine itself will later detect the same action but what you want to do after this action is detected, that's something that you need to script. So do you want to create a new bullet, do you want to turn on the engine and apply more force to your spaceship, stuff like that will have to be scripted.\n\nAlso, for example, handling collisions. If the only thing that you want to do if collisions is bounce objects one of another, then Godot will probably do it on its own. You just need to create some nodes that are responsible for physics, make sure that they are on the same layer so that they detect each other and then start the game. But if you want to, for example, destroy an asteroid when a bullet hits it, then you are going to have to react to an event that actually is called signal in Godot. So Godot will detect the collision, it will send a signal and your job is to subscribe to this signal and then to connect this signal to a method and then the method will delete in this case an asteroid that got hit.\n\nIt feels a little bit like programming in a GUI framework like PyQt or PySimpleGUI. I was actually going through a tutorial that we're going to have on the site soon about PySimpleGUI and it was interesting because it was similar that you were sort of flagging sort of things inside your Python application. You know that you're writing, but you were sort of like highlighting these signals for things to happen. It's like okay, this is named this and this is gonna behave this way and so forth. And it was able to abstract a lot of the work for you which is really nice.\n\nAnd so you were mainly just making sure logically that okay this happens, then this happens and so forth. Kind of thinking about that, you've created a handful of games now. I wanted to think of like maybe a simple one that we could break down. You created kind of a bit of an Osmos clone and I don't know if I'm pronouncing it right but you have a YouTube channel and you're showing some of the stuff that you created with that. The YouTube channel is very much neglected. Yeah, I try to. That's okay, it happens. I post stuff regularly on Twitter just to share the interesting things I managed to achieve. Also, whenever I reach a level or I figure out a project that I think could be useful for someone, I put the source code on GitHub so people can also investigate and you'd prefer them connect there.\n\nYeah, well I always think that I'm a really huge fan of open source, which is also why I like Godot as much. If I wasn't a pro, I might have actually started with Unity but Godot being 100% open source and working out of the box on Linux, which was my operating system at the time when I was working on Intrepid, this was a huge advantage of an open solution. So I try to contribute to the open source community by sharing whatever I come up with. Yeah, YouTube is unfortunate because there you can only put videos there's from time to time I try to upload something but yeah, mostly I'm trying to put on Twitter and GitHub. And the Osmos game, would you like to have any questions about this or yeah.What I was wondering about is going back to what you're talking about. What would be some of the scripting in there that people aren't familiar with in Osmos as a game? It's a two-dimensional game where there are lots of circular objects. You are this other circular object, these little bubbles almost, and you can absorb anything that is smaller than you. But if you touch something that's bigger than you, you die right away. You are absorbed by that other thing. As long as both beings touch, as soon as you move away, you stop being absorbed. If you are absorbed to zero, you lose the game. But if you absorb more than half of the mass on the screen, then you become the ultimate bubble.\n\nIt's very bitcoin-like, I'm just kidding. I think that's how corporations work, right? Totally, yeah. You get 51 percent, so in that case, it's very boolean, isn't it? Would that be part of the logic that you would write in the GD script in this game? A lot of logic went into recreating the behavior of the original Osmos game in terms of physics. The idea is that in order to move around, you need to propel yourself by throwing away pieces of your own mass, but that makes you smaller.\n\nThis algorithm could still be improved, but I started with something very simple. Your radius always decreases by this much, and you create a piece of mass that has a radius of this. You always move away with the force applied to you. I think this is actually done by the Godot engine itself. If you use a special type of physics, you just apply a force. One impulse of force applied, the value was always the same. I tried to make it more like the original game, so the larger you are, the bigger pieces of yourself you throw away, and the faster you go.\n\nWhen you press the left mouse button, you start propelling yourself. If you hold it longer, then the mass you eject is more. Getting that right took a couple of attempts, and I think at this point, it works, but it could work better. To make sure that the mass you lose is the same as the mass that is created as the new bubble, the force applied is proportional to the size of the bubble.\n\nAnother thing that got scripted is the handling of collisions. Whenever two round areas collide, I need to figure out which one is bigger and start taking away mass from one and putting more mass in the other. In this game, the color changes \u2013 if a bubble is bigger than you, it's red. If your bubble is smaller, it's blue. If it's almost the same, it's white with a tint of red. And if it gets significantly bigger, it's much redder.\n\nThis was done with signals, so every time the main bubble ejects some mass, it sends a signal that the radius or mass has changed. Every other bubble connected to the signal checks if it's bigger, smaller, or significantly bigger, and changes the color accordingly. They all have to rate themselves. It's an interesting set of problems to solve in these simple games. There's a lot going on underneath that you have to program inside it. Graphically, it may not be as complex, but there's a lot to program.But there's a lot going on inside of that. This week, I want to shine a spotlight on another real Python video course. It continues on the theme of the episode and could work as a starting point if you're interested in exploring games with Python. It's titled \"Make a 2D Side Scroller Game with Pygame.\" The course is based on an article by previous guest John Fincher, and in the course, yours truly takes you through how to draw items on your screen, play sound effects and music, handle user input, implement event loops, and describe how game programming differs from standard procedural Python programming.\n\nI think programming games is a great way to get familiar with object-oriented programming, and it's a fun way to practice your Python skills. Plus, you get a project that you can share, which can be a nice showcase of your work. Like most of the video courses on Real Python, the course is broken into easily consumable sections, and you get code examples for the techniques shown. Now, all the courses on Real Python have a transcript, including closed captions. Check out the video course - you can find a link in the show notes or you can find it using the newly enhanced search tool on realpython.com.\n\nTo think of another game that was intrepid, your first big, good old game that you did. Yes, I guess it was my first big game at all. So we have the before, before that there were experiments with OpenGL and C++, then a break, then some attempts at Python, then I think another break, and then real determination to get it right this time and make a game, trying with Panda 3D first and then moving to Godot.\n\nDid you try to build something akin to Intrepid in Panda 3D? Yeah, that was what I started with when I was working on Intrepid. I started checking how to display a model, how to check collisions, how to process input, and so on. There were some quirks with Panda 3D itself. For example, scaling a collision zone would result in collisions not being properly detected because suddenly the precision of detecting collisions also scales. There were gaps that you could go through, which was very unexpected. I started trying to follow the rule of if something is not working, okay, but if something tells me that it should be working and it's not working the way that I would expect, that's weird. If an engine would say we don't have collision zones, cool, but they had collision zones but not behaving properly, so that was a bad warning signal.\n\nI realized that something that was already mentioned, for games working purely with scripts is maybe not the best idea. Maybe it's good to have a 3D preview of a scene, maybe it's good to be able to rearrange items without having to run the program again. That was another reason as I was thinking is the loop of going back and forth and iterating on it and finding those frustrating glitches. Debugging games is a completely different topic, just as tricky as debugging normal programs but in 3D. There are also in 2D games, I believe that's also very difficult. But games have not only a lot of complexity because you have models, interactions, input, and so on, I would say at some points more complexity than normal applications, but they are completely different than normal applications in the way that I said before. The life cycle of a game is completely different than the life cycle of a Python server application or Python script on a desktop. So you kind of also have to adjust to a new way of thinking, which is good in general to think in more than one way, but it makes the packaging more complicated at times.\n\nTotally, maybe describe Intrepid for people who haven't had a chance to check it out yet. Intrepid is a game that was supposed to be a 3D escape room. In escape rooms, the idea is that you are locked inside a room, sometimes several rooms, and you have to figure out how to leave before the time given is out. You have to solve puzzles, which are usually rather abstract, not like normal adventure game puzzles where you need to talk with someone and get information, but more like you have a padlock and it uses a three-digit code.And then you need to find that three-digit code somewhere in the room so that those ideas were put into Intrepid. It was supposed to be okay, so to make it more like an actual computer game, I figured out the setup - you are on a spaceship that got damaged and you need to escape. You have like one hour to escape, oh sorry, one hour is never mentioned in the game itself, you just have this zero-meter on the screen of the computer and you can see that it's going up. When it reaches the top view, the spaceship explodes, and you have to figure out the solutions to those puzzles in that time and unlock the escape pods.\n\nYeah, so I was figuring out quite a bit of it. I didn't escape, but I was able to find the three-digit padlock. There's another one that's like, not to spoil anything, but I believe it's based on the planets. In this other screen, I was trying to enter those codes in another area and then I was finding little objects and so forth, so it was neat. As far as the 3D world goes, it has all the lighting that you're talking about. You have this pre-animated thing where you're kind of waking up out of the sleep pod. I'm very happy with this animation, it looks cool.\n\nI explained to my 3D artists how I wanted to make it look, and then they made it look exactly like I had envisioned, so I was really happy. It turned out that I can create the effect of losing focus for your eyes, just by manipulating a camera in Godot. I created random intervals where the focus point goes super close to your eyes or super far away, giving you the impression that you just woke up and you don't see clearly. It was surprisingly easy to achieve that effect, and the result was exactly what I wanted, so I was very happy with this.\n\nI'm glad that you also liked it. I was impressed with the graphics, and that kind of gets into something that I tried to talk to John a little bit about - the idea of if you are not an extremely experienced 3D artist, creating these objects in a 3D tool. I know we talked about using Blender as one of the tools that's out there, it's open source and people can play and create in it. I had somebody else talk about Blender, the author of Jupylet had mentioned it also. How did you find that person to help you create your assets, the 3D stuff?\n\nFor the 3D assets themselves, it was surprisingly easy. I was checking one of the websites with 3D models because the first thing that I wanted to do is check if Godot can handle a 3D scene. So, I bought a couple of simple models because I didn't know how to use Blender properly back then. I wanted a model with some geometry, a texture, probably multiple textures for color, reflections, normal maps, and so on. I found them on one of the websites, I think it was CGTrader. I found more than one model, but I liked one of them more than the other. Then, I contacted the person who put those models up there, asking if they would be willing to make custom models for my game. The guy was like, \"Yeah, sure, no problem.\" That part of collaboration was very easy.\n\nI knew immediately that I'm not going to make them on my own because even though I like Blender and other than game dev, I like 3D graphics too, but my skills are definitely not good enough for a full game. I needed someone with more experience. A lot of people want to show off their work and maybe they're not super interested in building an entire game themselves, so it can be a nice win-win situation for people collaborating. We'll have to include links to that CG site that you mentioned, sure, cool.\n\nSo, you went through the whole idea phase, creating this thing, building it, coming up with all the concepts and puzzles for the escape room game. Then, you were able to package this whole thing up using Godot and share it on different platforms. You mentioned Linux, but were you able to package it up for Windows? Is that something that Godot helps you with?\n\nOh yes, a lot. Godot has this thing called export templates. When you open your project, you just go to a specific option in the menu, and then you can download the templates from the Godot website. It's not like a licensed link.It's specific for a particular version of Godot. Once you download them, you can choose any of them for your project. There are templates for Linux, Windows, Mac, Android, and HTML. Possibly other platforms, although I'm not sure about iOS. Developing apps for iOS might be more challenging. I've never been interested in making games for iOS, at least not yet. There might be an option, but it could be more difficult compared to Android or desktop platforms. To work with Mac, you may need to tie to Xcode, and possibly do something specifically updated for Mac accounts. For any other platform, you just download a template, add it to your project, and then double click to export the project. You get a pck file, which is the whole game packed in one file, and an executable for the specific platform. The process is similar for other platforms. For Mac, the structure may be different due to formatting requirements. \n\nAfterwards, if you were to navigate putting it up on the Steam store, that would be a separate conversation. In the case of Godot, there are no strings attached in terms of royalties or using the tool and engine. This could be a good solution for those more interested in scripting logic rather than the technical aspects of game development. \n\nI had not heard much about it before, and it was interesting to see a finished project. You created another tool, the game called GOAT, which stands for Godot Open Adventure Template. The history of the project involves releasing to different platforms, fixing bugs, and working on another game. The goal was to create a more intuitive and enjoyable experience compared to the previous game, Intrepid. \n\nThe project was born out of exploring different ideas for a storyline and realizing the potential for a reusable framework for adventure games. The code was cleaned up, made sure it works, and a two-minute adventure game was created as an example. This game is built into GOAT and serves as a demonstration of the framework's capabilities.This is because it's super easy to export to a web version with Godot 2. Although some graphical elements might not be working, like the field of view thing when you open them in the inventory, the background is supposed to become blurred, but on the web version, it doesn't because the depth of field does not work on the web version.\n\nI'm not sure if this is a limitation of the technology they use for exporting or of the game engine itself, but the engine is growing so fast. I hope they will get it fixed soon. I'm impressed with it, and it was neat that you could play it in a browser just to check out what's going on. I was able to solve the two-minute adventure, which is neat, and you had added some additional sound with other collaborators, which was cool.\n\nThank you. I think it might be a nice addition for someone who wants to build off of Godot but doesn't want to start with zero assets. All the assets for Intrepid itself were released to the public domain after the game was done. The assets used for a two-minute adventure for CodeCom actually come from a different project, and the person responsible for the project allowed me to use those assets in my game and repository. All the people who worked on the assets are credited in the readme or in documentation.\n\nI usually come up with my own assets or pay for assets from artists who later give me the intellectual property rights. I later release those things so that people can also work on those, although it's usually difficult to use anything that wasn't custom-made for your game because even if you find two nice computer consoles, they might use completely different styles.\n\nAs long as you're prototyping, it's nice to have something that looks better than just a cube. It really helps you get into the idea that you are making a game. If it looks nice, you will feel better working on it. That's also the reason why I try to share whatever I have with other people. But if you are moving from prototyping to an actual game, the reusability of these components drops because you need to keep the style consistent and make sure everything works together nicely in 3D.\n\nThat makes sense. That's a whole part of the indie game scene, giving credit to where you found assets. I'll probably have to come back and talk some more. I thought about working in Blender and what is involved as far as features and scripting inside of there using additional programming skills.\n\nI have a couple of weekly questions that I like to ask everybody. The first one is, what's something that you're excited about in the world of Python right now?\n\nRecently, I got my hands on a small prototyping board with CircuitPython inside. Back in college, I was trying to get into electronics because that's another cool thing you can do with programming. It's not everything existing just in the computer, but actually on your desk and doing stuff. Back then, it was super difficult to get into electronic programming because you needed a chip, programmers, and other tools. With CircuitPython, I plug it into my computer with a USB, it shows as a small pen drive, and there is a code.py file. When I edit and save it, the prototyping board restarts and immediately starts executing the new source file.So cool, there's practically zero equipment needed other than the board itself. I need absolutely no other hardware to start working with, which is really interesting. I have a very simple idea that I would like to make with this, super simple but I would like to see it in action. To make something useful and then I hope I will get more ideas in the future. It just shows potential.\n\nWhich one did you get? Which circuit python device did you get?\nI got a Gamma M0 from Adafruit, nice. We just like the smallest and cheapest one with circuit python, I believe. Having the smaller than chips one that had an LED so I could actually see some colorful lights as a result of my program because that's nicer than just plugging in other things using pins.\n\nThere are so many parallels to everything that we just talked about in the sense of having to used to burn EEPROMs and the craziness of how hardware was difficult, especially if you wanted to have programmable hardware. The idea of the loop with something like circuit python that you know it's like you could get to see something very quickly and hey, my actual hardware is not broken if you are really serious about it, then yes at some point you will do it anyway.\n\nWhat I really like about this circuit python is that you can start with zero additional stuff that you need. You just need this board and you need to know basic Python. Then you can see it in action, you can change the way it is, the LED flashes, you can handle the one or two buttons that are on the board. You can just plug it in and start working instead of learning for a couple of days how to set up the whole environment.\n\nIf you want to, at some point you might get to it, that's all stuff anyway. But if you want to just start, just see if this is your cup of tea, then yeah. This is kind of I really like these kinds of things that don't force you to learn a lot before you even have to start. Godow is kind of like one of them. You don't need 1.3 gigabytes of an environment to install on your laptop and the specific operating system. You just download 80 megabytes of an executable file, double click, and then you are ready to go.\n\nYes, so I like how many tools go into this direction of hey, let's make it really easy to start with them. That's a very nice trend.\n\nThe other question is, what's something that you want to learn next? I kind of always wanted to, in terms of Python, I'm currently a bit too busy to learn new Python stuff other than trying with the circuit board because in game development, I'm trying to focus on 3D graphics and at work, I'm more caught up with infrastructure-related tasks. But in Python itself, I kind of for a long time wanted to try OCR, and I think the Python modules that make it work got improved recently. So over the time since I first heard of them, I would hope that starting with them would be just as easy as starting with this Python on the hardware thing. So I would just download something, add one or two configuration lines, and then start and see what's going on. It's something that kind of always interested me, how to make a computer detect that there is a picture and then compare it with other pictures. But I never really got time to play with this, and I hope we reached the point in Python development, being so versatile and growing language, that at this point it would be really easy to start. I hope.\n\nThere's a couple layers that you're kind of mentioning there. You're saying OCR, like optical character recognition, pulling text out of something that's scanned or a photograph. But then you almost are sort of mentioning the next layer of computer vision, detecting things that are inside of images, which sounds related and very interesting too, which is something I'm into. Photography and I had Mike Driscoll on to talk about his book, I guess he just finished it. He has a book about Pillow, the Python image library thing, which is fun to talk to him, and there's a lot of kind of interesting things in there. Obviously of manipulating images, but it's a whole separate thing from computer vision, which almost leads to video, the whole idea of one frame turning into lots. So it was really fun talking to you, thanks for coming on the show.\n\nThank you very much again for inviting me, it was a pleasure to be here. Thanks. And don't forget you can get started on DigitalOcean's App Platform for free at do.co/realpython. That's spelled d.Transcript: \n\nO dot c o slash Real Python. \n\nI really want to thank Pavel Furtick for coming on the show this week, and I want to thank you for listening to the Real Python podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. \n\nI've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "wnD30Dhy9aQ": "Welcome to the Real Python Podcast. This is episode 63. What if you could create applications and deploy them to the web with just Python? Wouldn't it be nice to skip the additional full stack development steps of learning three different languages in addition to Python? Well, that's the idea behind Anvil. This week on the show, we have Meredith Luff, co-founder of Anvil. We talk about the history of Anvil and how the founders wanted to simplify web app creation. We discussed their choice to make the project open source and how that benefited the project's development. We also cover creating a portfolio of projects and things that employers look for in the hiring process. This episode is brought to you by DigitalOcean's App Platform. Alright, let's get started. \n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Hey Meredith.\n\nHello, nice to have you coming on the show. Great to be here.\n\nAlright, we're here to talk about the project that you've been working on for several years, Anvil, and kind of some of the history of it. But also, I'm very interested in what's going on with the cross compiler that you have built too of Sculpt. I've been diving a little deeper since we started our email exchanges and wanted to learn about it. So maybe we could start there. What do you do at Anvil and maybe give a little history of the project?\n\nSure. Anvil is a framework that lets you build full stack web applications entirely in Python. So you don't need to use HTML or JavaScript or CSS. You can do it with Python. The easiest way is to go to anvil.works where you'll get an editor where you can drag and drop to create the design of your web page. You can write in Python that then runs in the web browser when someone runs your app. You can write your server-side code in Python and there's even a built-in database. The whole thing can be deployed instantly and given the URL and put onto the public internet. \n\nThat's so cool that you can kind of just go and play with it and set up a free account and just mess with it in that framework. That's very cool.\n\nAbsolutely. Well, I mean, my background, my PhD is in building usable programming systems and my long-time friend Ian was in human-computer interaction. If that's your specialty and you look at the state of the web as a programming platform today and the hurdles you have to leap over to do anything on the web, if that's your expertise, you will do an awful lot of complaining to each other about it. At a certain point, we just sat down and said, \"Okay, you know, we can build something to fix this.\" And so that's what we set out to do.\n\nYeah, that's cool. So why did you pick Python?\n\nSo, oh, this is where I'm a little bit heretical for Real Python Podcast. Python was kind of an implementation choice for this. It is the obvious language because it is the world's favorite first programming language. It is accessible, it is straightforward, and there's a huge number of people who have experience with Python because they have built something. They've been working with data in Jupyter notebooks, or they have built something locally, or they are back-end engineers. And they then run into this huge barrier where they go, \"In order to put something out on the greatest application delivery platform on earth, I now need to learn four more programming languages: HTML, JavaScript, CSS, and then React, Bootstrap, Django, plus SQL. It's just way too much.\" And so Python was the obvious sweet spot because there are so many people who are there who can write the code. It's not, \"Oh no, we're going to build something so you don't have to learn how to code.\" No, you know how to code. You've done the difficult bit. Putting it on a web page and making it accessible to the world should be the easy part.\n\nRight. Yeah, I definitely have felt that pain. I started programming a very long time ago when I got out of high school in the late '80s. And now, so I was learning Fortran and Pascal at that time. I was very tuned out because I was a musician and I was like, \"When do we do something creative with this? Where do we build something that's graphical or has something to do with sound?\" And jumping into today, it's amazing what is possible. But then there's this huge curve of like, \"Okay, yeah, that's possible, but here's a stack of ten books that you really would want to tackle before you get going.\" Or you can kind of go through the tutorial maze of, \"Okay, how many technologies do I want to tie together and, oh, yeah, preach it. What is the age of these different things?\" And, you know, so, oh, absolutely, yes. Like, \"Oh, no, that's last year's. Nobody uses last year's framework.\"\n\nThat's definitely JavaScript, unfortunately, which I find so... Is that hard for you guys as a company that is...Oh, I mean doing stuff with JavaScript. Absolutely, because obviously we are building the infrastructure that makes this possible. There is a forehead-shaped dent on my desk. We are enduring this so that other people don't have to. Yeah, that makes sense. When we speak about programming directly in Python, is that Python 3 pretty much? \n\nOh yes, absolutely. Okay, so what we have is obviously the system you're programming is different at different levels. When you are writing the code that runs in the web browser, then we use a program called Sculpt library to translate into JavaScript to run it in the web browser. Obviously, there are things that you can do with a full Python 3 on your desktop that you can't do with the web browser. \n\nRight, you can't just go ahead and open files, you can't go ahead and drive bits of GPU. So there are some limitations, but we approximate Python 3 as closely as we can. But when you're writing server-side code, then of course you are writing code for a full-fledged Python interpreter in there. That's just pick your runtime. \n\nWhat's cool about it is, I've been thinking about this a lot of how, you know, not only is it the difficulty of trying to create things, not only thinking about the graphical user elements and then the database elements, but then the server-side elements and just the idea of tying that all together. It brings me back to a tool that I've mentioned several times on the show. I was trying to help out a friend who had a small business and they wanted to build some applications. \n\nAt the time, they were pretty much a clipboard-based type of company working in environmental science. So they would go out in the field, get dirty, things would get wet, just kind of working in the dirt. They would come back, brush the mud off the clipboard, and type it into a spreadsheet. Yeah, you got it exactly, that whole thing. \n\nSo I said, well, you should be able to do this with an iPad. I had worked for Apple for a while and so I had already known logic because I worked at the school teaching logic and then I taught myself Final Cut and so forth. So I kind of knew all their different pro applications but nobody was learning this thing called FileMaker. I'm like, what is that thing? It's been kicking around forever, this database kind of thing. \n\nWith the advent of the iPad and the iPhone, they created this neat little platform that you could basically very graphically throw together an application. The thing that's missing from that platform, outside of the tools stuff that you could create, was how do I share it, how do I back it up, how do I move things around, and then probably the most difficult part is how do I put it on the web. \n\nAbsolutely. So, yeah, how could we have a shared sort of instance? They never really wanted to pay the exorbitant fees to make that happen. I taught myself how to do it, taught AWS and all that kind of stuff. But I was like, you know, this is so hard, this part of it, and it's so painful to try to just get this shared experience. Do you have small businesses approaching you looking to try to do something similar like we want to stand up our application and then share it with our clients? \n\nOh, good, just me, like all the time. That is one of the core use cases of Handle, basically. I would say people use Handle for one of three broad categories of things. And I mean, this is a programming system, you can use it for everything. So any generalization I make here is wrong. Broadly, you have three groups of people. First, you've got your data scientists, people who are mashing data around, answering questions for the business or organization they're in. \n\nBut you really don't necessarily want to be emailed a question by your manager and then work with it all in a Jupyter notebook and then email them back a report a week later and then do it all again next week. It's much nicer if you can build a tool that's self-service so they can go and answer that question themselves. The example I love to use is one of the moderators on our forums, Al Campoppiano, who works as a data scientist at a school district in Ontario. \n\nHe built a bunch of self-service applications so educators at the schools can go into their data sets and ask things like, are there any students who've suddenly started missing school? Are there people whose marks have suddenly dropped? They can find that and intervene with those students quickly, whereas previously it would have taken until the next monthly report was generated where somebody might spot the problem.That's the power of creating self-service tools. There's a whole bunch of self-service tools for baking data safe. People use Anvil for the second category, which I think involves the kind of people we've been talking about. \n\nI'm in a business organization and have some internal tools, software that we don't want our customers to see. For example, environmental engineers or scientists going out into the field with an iPad for data entry. An example is a Norwegian TV broadcast network that uses Anvil to build software for customer support. They can diagnose issues like Wi-Fi connectivity without involving external web developers.\n\nIt's important for businesses to have internal tools that can be built by domain experts rather than random web developers. The goal is to enable non-web development experts to create usable applications.\n\nThere are three categories: data self-service, internal tooling, and new consumer products. Anvil allows users to build any type of application using Python programming language. It's different from tools like FileMaker, which are more database-centric.\n\nAnvil aims to be a full-fledged web development system that is simple enough for quick application development. It's designed to be user-friendly and efficient for creating database-based applications.\n\nIn the school example, querying the database would involve using their existing Microsoft SQL Server systems. They already have a system in place, so integrating Anvil would be seamless.It's an integration challenge because they need to speak whatever their off-the-shelf thing speaks. But that's okay because they have the Swiss army knife that is Python and its library ecosystem to do it right. I said before, sure, on the browser side code, there are limits to what you can do. On the server-side code, I want to talk to a SQL Server database fine. Import pi mssql, okay, what was the problem? Likewise for accessing APIs on learning management systems. So there's a whole data aggregation thing that is again a challenge if you were doing it in anything except a really mature language with a powerful ecosystem like Python.\n\nI guess we could dive down that rabbit hole of what types of additional libraries you can access via Anvil. The list is kind of endless because I always started to look at them. But I just wanted to maybe get an example of some of them. I saw one job I had for a while was working at a bank and I was building things like dashboards. I immediately saw, oh, Plotly okay cool that's there. What are some other examples that stand out?\n\nThe really funky thing about Plotly is we have full client-side integration with Plotly. Not only can you use something like Express on the server to do a whole bunch of data mashing, but you can take it to the front end and build interactive property graphs with it. Generally speaking, you can use anything because that is the point. Anything you can pip install and even whole other environments. Going back to the data example, as that's where we seem to be right now, an awful lot of data scientists spend a lot of their time in a Jupiter notebook.\n\nAnd why not, it's a really great environment, but then you end up with this awkward situation where you've built a solution in your Jupiter notebook and you can sort of answer those emails queries by sending back a PDF report. But this is the point where you want to make it self-serve, and you can actually use a library called the uplink to connect your Python in your Jupiter notebook that's running on the machine on your desk up to your application. You get all the power of the server-side code and an Anvil application you can operate it from your Jupiter notebook. \n\nYou can actually have and we actually have an example tutorial of this on the website, you can have this machine learning model you've got in your Jupiter notebook and then suddenly say okay, and this function in my notebook you should be able to call this from the web and then we can make this a publicly accessible interactive service. So not only can you use any library you can pip install, you can use any Python environment you've got lying around as part of your application.\n\nYou mentioned briefly there, things like creating PDFs and maybe this kind of jumps to the second solution where somebody's out there doing a ticketing solution or something like that. They need to output not only a receipt but they need to report it back with some kind of report. I've seen already the tutorials on there for generating PDFs but what I was wondering about is keeping it in the web and then keeping the documents accessible. I could imagine things like PDFs or images which were something that I was dealing with with my environmental science company, those big files if you will of images and PDFs and other things like that most likely you're not going to stuff them in a database. Oh well, I've seen no reason why you shouldn't Anvil's built-in database is backed by Postgres, it's scalable.Anvil has a facility for storing blobs of binary data. It's backed by Postgres's blob store, and you can generate a PDF. I suspect you saw the tutorial, but just to be clear for listeners, generating PDFs in Python is one of those things for which the ecosystem doesn't currently have a particularly great solution. The best things out there involve generating HTML and using a library to render a PDF from it. However, we built an out-of-the-box PDF creation tool called `amble.pdf.renderpdf` that allows you to use drag and drop tooling to build PDF templates.\n\nAnvil can handle binary data, whether it's from rendering a PDF, uploading a file, downloading something from the web, or generating it with something like Matplotlib. You can turn it into a media object and store it in Anvil's data tables without any issues.\n\nOn our free account, there are capacity limits, so don't expect to store gigabytes of data. The free service allows for around a hundred megabytes. Anvil.works offers a hosted version of an open-source framework, but you can also host it yourself by installing the Anvil framework locally on your machine.\n\nThere are tutorials available for deploying applications using Anvil's online editor onto your machine or on platforms like AWS, DigitalOcean, or Linux. Anvil provides a docker file for running it in a container, making it easy to set up and deploy.\n\nUser management in Anvil is crucial but can be fiddly and prone to security issues if not done correctly. Anvil provides a solution for user management that aims to simplify and secure this aspect of web applications.Yeah, we have built an out-of-the-box user management service called the User Service. It stacks on top of data tables and manages users as rows in tables. It includes out-of-the-box features like email and password login, as well as federated login with platforms like Google, Facebook, Microsoft, or SAML for enterprise single sign-on. The User Service is built on top of existing primitives, so you can roll your own solution if desired. There's no secret source; it's just a convenient option for managing passwords securely, locking users out after multiple failed login attempts, and handling OAuth and SAML login processes.\n\nThe goal of the User Service is to simplify a common and often challenging task by providing an out-of-the-box solution that can be customized as needed. It's not about restricting users to predefined options but offering a flexible system that can be tailored to specific requirements. Ansel, the tool we've created, is designed to be a low-code tool that empowers users to customize their applications without being limited by predefined constraints. It's built on a real programming language, which allows for flexibility and creativity in application development.\n\nAnsel's opinionated approach to data representation in database tables simplifies the process of working with data objects in Python. While Ansel provides convenient tools for data handling, users are not restricted to using these tools and can opt for more manual approaches if desired. This flexibility ensures that users can work within their comfort zone and adapt the tool to their specific needs.\n\nWeb development can be complex due to the various layers and frameworks involved, but the core aspect of programming remains writing code. While some tools try to simplify this process, they often sacrifice flexibility or end up creating additional complexity. The key is to empower users to engage with code without feeling overwhelmed by the surrounding complexities. Code is the most effective way to communicate with computers, and it should be accessible and approachable to all users.\n\nOverall, the focus should be on making coding less intimidating and more user-friendly, allowing individuals to engage with programming at their own pace. By emphasizing the importance of code and providing tools that support coding skills, we can enable users to harness the full potential of technology without feeling overwhelmed by unnecessary barriers.Oh sure. The high school student I talked to, a teacher I think maybe you spoke with him a little bit also at PyCon. This guy Robert Ball, I'm going to try to have him come on the show too. He's a teacher at a technical high school in West Virginia. He said he had been using Anvil with the idea of, \"Alright, you've been learning Python this whole semester, year, whatever time period. As a technical high school, I want to see your proficiency and to do that, I want to have you create a final project.\" Most often with final projects, if it's just a set of code or what have you, it can be a little less exciting. It was something I was always kind of frustrated with a lot of educational institutions. In the end, I want to create something that I can share with other people and they would still be maybe interested in even looking at it or checking it out. In this case, for a technical high school, something I could share with a future potential employer that, \"Hey, I created this project.\" Even for an internship, it'd be nice to show that you can handle yourself with some code. So absolutely, yeah.\n\nI want to just rewind this conversation to back when we were talking about how you got started with programming because you were sort of late 80s Fortran. That was a little bit too early. I got started in this golden age of QBasic, where I could learn a little bit of programming and I could put graphics on the screen. That was back in the DOS days, that was what everything did. I could create something that was like all the other programs I was using and so I could, for example, share that with my friends. Then I moved on to Visual Basic in the Windows world and again, you could create something that was like every other application on your system. In that case, it was Windows applications with windows and pop-ups and menus and things, right?\n\nThat was within the reach of, for example, your average high schooler. And now we've got to this place where you can build web applications. Anyone can build a web application that can be used by anyone on earth. But it's not really anyone because, as you say, you need to march through this 10 book's worth of stuff before you can get that done. What we are explicitly aiming to do is to take us back to this world in which if you can program, you can build an application that's like what everybody else is using, which is to say a web app.\n\nYeah, that you can in fact share, whether you are a student showing it to a prospective employer or you are a broadcast engineer at a TV company and you are opening it up to your customer service team. It's useful, it's real. This whole thing is built because the complexity in that system is not beyond a high schooler. The essential complexity, the logic of an application of a real application, is absolutely not beyond what a high school can learn or what you can do in an internship. And it's only this messy incidental complexity around the web that stops people from building applications that are like what they use every day.\n\nWe're bringing that back, potentially financial things of like, \"Okay, who's going to help me pay for this hosting?\" And oh, all that, yes, all these other kinds of things. Absolutely. I mean something I should say is that for classroom use, Anvil is completely free, even the pay for features. So drop us a line at education@anvil.works and we will set your class up. But even if you are not in a class, if you're doing this solo, we have deliberately made the free plan with the free hosting and everything. We've made that. We basically put all the features in there. You can do everything with the free plan that you can do with the professional plans. Just can't do things like put it on a custom domain or, you know, there's a banner at the top saying, \"Made with Anvil.\" But it's not that we say.Oh no, you can only play in the kiddie pool. You can write real programs and my goodness, people do some of the stuff you see on our forums that it's really spectacular.\n\nThis week, I want to shine a spotlight on another Real Python video course. It dives into the topic of functional programming in Python. It's titled \"Python's map function: Transforming iterables.\" The course is based on an article by Leodonis Posso Ramos and in the course, Cesar Aguilar takes you through how Python's map works, how to transform different types of Python iterables using map, how to combine map with other functional tools to perform more complex transformations, and what tools you can use to replace map and make your code more Pythonic.\n\nI think it's a worthy investment of your time to learn how to apply functional programming concepts in Python and not only how to use map, filter, and reduce, but also learn some additional Pythonic tools such as list comprehensions and more.\n\nOur video courses are broken into easily consumable sections. Where needed, we include code examples for the techniques shown, and all the lessons have transcripts including closed captions. Check out the video course. You can find a link in the show notes or you can find it using the newly enhanced search tool on realpython.com.\n\nTo kind of break down some of the complexity for people that maybe haven't even cracked those 10 books, wise life choices. Yeah, to think of like, okay, what do you mean by creating a server in the sense of like the anvil code, like what is that going to do for me and where does that kind of lie in the whole stack of code stuff that I'm building?\n\nSo normally, if you are creating a traditional web application, what happens is somebody opens up a web browser, they type in the URL of the application you've built, and they see it. The web browser, which is a program running on their computer, goes out and uses the URL you've entered to identify and then connect to another computer out there on the internet, and we refer to one of these as a server. It will be running some program that is capable of receiving that connection, talking to the web browser, and serving up web pages and then dealing with the interactions. So when the web, usually actually what you do is you serve up a web page in HTML and a program in JavaScript, and when the person with the web browser clicks a button, that runs a piece of JavaScript on their computer which then sends a message back to your server and then the program you've written on your server responds to that and probably also talks to a database you're also running out on that computer out there somewhere on the internet.\n\nSo, like if we were to talk about your \"Hello World\" example that is a really common one in general that is not involving a server. It's basically a set of code that is getting loaded directly into the person's browser, their Chrome session, what have you, when they open that page up, and it's just running. But if I want to do anything additional on top of that, I want to talk to the database or I want to have say multiple different modules or things like that running that I want to be able to call, then that's kind of creating this two-way communication where I'm actually having to press a button to request something from that server to have it do something and then we're kind of going back and forth a little more. Is that absolutely and in a traditional world the way you would do that is by writing effectively two separate programs: one programming something like Python using something like Django that you then have to find a computer somewhere on the internet and run that and then another program in JavaScript that's running where the user is on their computer and talks to them and you effectively have to write two different programs that happen to talk to each other, hence the ten books. Oh yeah, oh yes, those are only two of the many, yeah, and what we did with Anvil is we tried to take that complexity away and one of the biggest ways we do that is by enabling you to write both of those things in Python. So you write the code that is running on the web browser in Python and you write the code that's running on the server on the computer out there in the internet also in Python and instead of having to make you making you have to deal with all the complexities of HTTP, which is how these two things talk to each other and how to make that sort of request from the stuff in the browser to the stuff on the server and the response, we've because that's neatly integrated we know we have Python on both ends we just say actually we're going to make some special functions on the server anything you've written in a server module that is tagged Anvil.server.callable you can just call that like a function call from the stuff in the browser so there is you know there's a piece of irreducible complexity which is that there some of the code you are writing is executing on the user's computer when they open your application.Some of the code you're writing is running out there on the internet in the central place they're all talking to. The thing you don't have to do is write those two things into two different programming languages, which is painful. Matching all the questions and answers they're asking, communicating with each other into JSON, which is painful. Setting up a new computer and installing all the software required to run a web server, which is also very painful. The idea is we've taken that down to the minimal possible. Yes, if you're using Anvil, if you're writing in a text editor with a yellow background, that code is running on Anvil servers somewhere central on the internet. If you're writing something with a white background, that code is running on the web browser when somebody opens that. You can make a function call from one to the other by tagging what the server function is. Hey, this is something it's okay to call from the web browser and making a function call from there. We've tried to make that as simple as we can.\n\nOne of the things I struggled with in the design of trying to do things, like going back to FileMaker and creating these things that were laid out on an iPad or what have you, is designing for the window. And of course, shapes change, sizes of devices change, and I have to have an iPhone version and an iPad version. In the five to six years that Anvil's been around, has that been a big challenge on the client-side, the front end side of addressing desktop computers and all these mobile devices and their look?\n\nAbsolutely, it's not quite four years we've been really out. The interview you referred to with Michael Kennedy on Talk Python was sort of our coming out party. From the very beginning, the applications created with Anvil are responsive, able to deal with different screen sizes in the drag-and-drop designer. Every time you create a container and put two things next to each other, you can change the property on that container. For example, these things will stay next to each other if you're on a desktop, but if you're on a tablet, they will switch and become full width and one on top of the other. Responsive design, being able to deal with mobile-first applications, has been in Anvil since our first release. There are a whole bunch of applications out there, like Fair Shake, a consumer rights company, that are used almost entirely from mobile.\n\nWe built our own user interface toolkit, a user interface library entirely in Python. When you're building your user interface in Anvil, when you put a piece of text on the screen, that is a Python object. There's a class called Label, you can set properties like text and alignment. Instead of generating code in a different programming language to create your user interface, we've built a user interface library entirely in Python that handles all the display stuff and supports multiple screen sizes natively. If you want to customize the look and feel of some of those things, it's easy to access.Oh yes, absolutely. This is another important part of Anvil because the web platform is huge. There's so much you can do. For example, in pixel by pixel fine-grained user interface design, you can design exactly how your page is going to look. You cannot currently do that with the Anvil editor, but you can go into the editor and then edit the CSS that styles these components. So, you can get your pixel-perfect design. Even better than that, you're not editing the HTML and CSS that comes out of the Anvil editor; you're editing the HTML and CSS that goes in. This means that once you have built the design that you want your app to look like, you can go straight back into the drag and drop designer and drag and drop buttons and text boxes, and they will follow that design. This means that you only need to tangle with CSS for a fairly short period of time. If you have a team of people, only one of you needs to get their hands dirty, and everybody else can continue designing their user interface in the style that you have created.\n\nAt a high level, the web is really complicated, and a lot of it is unnecessary incidental complexity. But complexity is there, and sooner or later, somebody's going to want to do something we haven't thought of. The important thing there is to create an escape hatch where they can do what they want. If you want to use a particular JavaScript library for which we haven't written a Python wrapper, okay, at this point, you're touching some JavaScript, you're going to get some of that on you, but we've made it possible. You can import that JavaScript library, you can copy and paste the HTML snippet. There's a place in Anvil where you can put that to load the library. Then you can go from Anvil.js.window.import, for example, Mapbox. That's a mapping library that's really quite popular these days. My colleague Brooke actually did a live Twitch stream earlier this week, as we record this, so probably like a week or two ago by the time this episode goes out, where she took the Mapbox JavaScript library, dropped it into her app, and then used it entirely from Python. The point there is that when you need to go outside the things that we've thought of, you can do it. You can always drop down. You want to do pixel-perfect design, you can drop down and write CSS. You want to use something like Mapbox, you can drop down and use the JavaScript library. We don't stop you from doing those complex things; we just make the simple stuff easy and the complicated stuff possible.\n\nOne of the things I was wondering about that's super common is accessing additional APIs across the web. Again, if you are using Python, you can be using requests and answer the question yourself. So many of the questions of that sort are just, you're using Python, do the Python thing. It's already there. We touched on it several times, also the idea of the modularity of it. Literally creating your own Python modules. You can be bringing in modules from some of these other users that someone else has built, some of this other code. Absolutely. So what you can do is have an app, a thing that's effectively a library, and you can import that library. That library can define modules you can import on the clients or on the server or in both places. You can even define custom components that appear in your toolbox. There are actually a couple of community collections of these things out there, so people who've created particular components to do something that isn't part of the Anvil standard library. You could just add that library as a dependency to your project, and suddenly all these components will appear in your toolbox, and you can drag and drop them onto the page. That was one of the most painful things in FileMaker. Can I just get a calendar picker? I don't want those stupid sliders anymore, the little scrolling wheels, you know, that kind of stuff that you see on the iPhone back in the day, which they're finally fixing some of it, but it's so painful.Well, I wanted to ask you some questions about the idea of building projects to showcase. It's been a theme that I've been discussing on the show a lot lately. The idea is that as someone who never finished college, I've been in various careers over time. It has always been important for me to showcase my work, troubleshooting skills, and communication abilities. I see this as something that can act as a showcase to employers.\n\nDo you see building projects as a common thing when employers are looking at prospective employees? \n\nAbsolutely, a portfolio is a great way to show what you can do. It's not a requirement, but it certainly helps show what a person is capable of. It makes the interviewer's life easier to see what the person can do through a portfolio.\n\nHaving a conversation about something a person has built is easier than talking about abstract ideas or solving a problem on the spot during an interview. \n\nIf you could go back in time and start the project over, what are some things you would change?\n\nAnvil was created to scratch our own itches, but there were some things we discovered later that would have been helpful. I would have focused on building a full web app system from the beginning and included server code and a database. Demonstrating the ability to produce beautiful things with the framework would have been beneficial earlier on.\n\nOne major change I would make is to make the framework open source from the beginning. We were nervous about it initially, but I now see the benefits of having an open-source product.And so I can see why we were nervous, but it's just that that was the obviously right shape for the companies. It's a web framework, it needs to be open source. We should have just got around to that in the beginning rather than waiting a couple of years before working out the obvious. When you did open source it, what were some of the benefits that you got from that? I mean, outside of potentially the love from the community?\n\nAbsolutely. I mean, the most important thing is we gave people optionality. We put the power into their hands. A meteor could strike southeast England tomorrow and wipe us all out, and your applications will be just fine because they're running on an open source framework. You can check them out, post them yourself, it'd be fine. And that, I think, is honestly the biggest benefit people get out of it.\n\nBut obviously, we also had our immediate started getting contributions from our community which is great. We've actually, so one of the developers who now works on the Anvil platform started out just as a really enthusiastic community member. He was a teacher who was using Anvil for class projects and he got really into it, got very good at using it, started doing some contracting on the side building things with Anvil, started getting interested in Sculpey Python's JavaScript compiler, started contributing to that where I'm a maintainer. And so again, we already knew that his code was good because I've been code reviewing it and then came on board and has been working on the internal guts of Anvil ever since. So like open being open source, I think throws that door even wider to your community to show you what they can do.\n\nBecause your source code is out there for them to use, we sometimes now get bug reports on our user community forum that says, \"So search and search doesn't work and I actually think the problem is on runtime.dutchline 452 here's a link to your GitHub repository.\" And I go, \"Yep, that's right. Tap, tap, tap. Patch. That's cool.\"\n\nIt's nice. It's a lovely place to be as well. It makes us feel better about ourselves, feeling like we're not compromising in favor of commercial viability. What's been your biggest challenge? Oh boy, I mean that is a very big question because okay, you want to hit some smaller ones instead?\n\nWell, because Anvil is a reimagining of what web development ought to be about, which is a huge challenge. So there were huge technical challenges. I would say probably the biggest challenge there was social. We spent a very long time in this place where every time we would go to a conference, you know, a lot of your listeners may recognize my name and voice from PyCons and various around there. I spoke at PyCon just a couple of weeks ago and we would go to these things and start doing demos and immediately get crushed by the stampede. We have brag photos on our job ad site to show that yes, we do get popular, but it was a little bit frustrating as a developer. Like I know in my internal development sense that we have built something cool and useful and our user forum is telling us that this is amazing. And every time we go to a conference, we get surrounded. And then actually getting out there into the world that this thing exists and that it is worthwhile and it's real, it's not another sort of toy-like environment has proven to be, I would say, the biggest challenge.\n\nYeah, I can see that. I look at the market for a lot of these things and I just sort of shake my head sometimes that like, you know, just going back, I know I'm kind of harping on FileMaker, but that's the one I spent the most time in. And, you know, I went to their conference and, you know, and it has a history and so there's all this kind of stuff going back. But just looking at just trying to code in it alone, it's so frustrating because it's like, just, I mean, people want to make, you know, say that Python's a scripting language and it's like, no, there truly is a scripting language that I've dealt with and that you can't do anything but just run these goofy little scripts when you hit a button or something. This is much more than that.\n\nAbsolutely. I mean, this is the important thing about Python. It embodies something that is really important about what we create, what we are setting out to create with Anvil, which is that it is accessible. It's accessible in the way that we want Anvil to be too, because it is, you know, if you went out into the street and asked somebody, hey, what does it mean for some, you know, programming environment to be accessible, they'd probably say.Oh well, it's simple for novices to pick up, and like they'd be right because it is important that this stuff is not beyond the capability of a high schooler. But if that's all it is, then you're doing them a disservice because you're sticking them in the play pen and not giving them room to grow their powers. It needs to be simple enough for the novices and powerful enough for the seasoned professionals. That is why we have these escape patches, it's why you can do all these important things with Anvil.\n\nIn the web context, people look at it funny and they raise one eyebrow and they go, \"Huh?\" But there's a conflicting goal. Nothing could possibly be simple enough for novices and powerful enough for professionals. The Python community, in particular, knows that's not true because Python is the language that you first teach an eight-year-old with their first Raspberry Pi or their first programming class in school. It's also the language that drives Instagram or that Google DeepMind used to beat the human mind at Go for the first time in recorded history. You know, scripting language my foot. It is accessible, it is a real programming language with a huge ecosystem and deadly serious usage. It should be simple enough that you can pick it up.\n\nI asked you about what you looked for in a prospective employee, and you mentioned offhandedly that you're hiring right now. Do you want to dive a little deeper into that? Absolutely. Firstly, the answer for what we are looking for depends on the roles we're currently recruiting for senior developers and junior developers. The sort of work will be the same; it's about how much experience you have coming in. The first developer we ever employed was nine months out of boot camp, and it was simply phenomenal.\n\nWe are not necessarily looking for everyone with eleven years of Django experience. What we are looking for is someone who can solve problems, who is interested in learning, and who is interested in picking up new things. Anvil itself spans everything from Python to JavaScript compilers to the implementation of this JavaScript user interface framework. There's so much to work on, and we don't need you to be experienced in all of it; we need you to be interested in learning.\n\nFor the junior developer, we are interested in someone who is able to show us that they can deal with new stuff well. For the senior developer, we are more interested in someone who has shown experience dealing with complex, difficult, or advanced systems before. But regardless of the role, we are looking for technical competence, communication, attitude, and the ability to think about the person using it.\n\nWe are based in the UK, in Cambridge, and we are semi-remote. We're looking for people who are willing to be in our office in Cambridge at least a day or two a week, but if you're around and can come full-time, please do.\n\nWhat's something that you're excited about in the world of Python? It could be a book, a conference, a package, or something else.Oh, I am filled with excitement and trepidation at how the Python language is evolving. It's like we finally got past the Python 2 to Python 3 transition, and now all these features are arriving: async await, match blocks, new ways of doing dictionaries, the walrus operator. It's all coming in thick and fast. And yeah, I do think, \"Oh, I'm type checking.\" Sorry, can't forget that. I am excited by the new possibilities, and I want to be as tempered with caution because the accessibility of Python is so important. We don't want to introduce so much complexity that we remove the ability for someone to pick this up for the first time and go, \"Oh, this is actually pretty simple. I can do this.\"\n\nRight, yeah, totally. Like we were talking offline before we started about the last PyCon just a couple of weeks ago. There were so many talks about where Python is headed. Part of it is this whole side of type checking, but also lots of development in compilers or just-in-time compilers or the general speed of Python. It's very exciting. I guess that is maybe us being able to move beyond version two and really focus on the future with three.\n\nYeah, absolutely. I'm definitely excited about new compiler technologies. I mean, obviously, like I'm a Cython maintainer, I'm a compilers guy. I absolutely love this stuff. We don't have time to talk about it now, but there's a lightning talk I gave at PyCon a couple of years ago about Pylance, about the PyPy compiler, which is just one of these really cool pieces of technology. Like write a Python interpreter in Python, mind-blowing. Some of the cool things you can do if you control the compiler. And that's actually how we do some of our sandboxing, so running code from untrusted users on our computers. Like, there is so much scope for cool things as we move the interpreting compiler space forward.\n\nI agree with you. I'm excited to see what comes next. So the next one is, what is something that you want to learn next? Oh, so am I allowed to say something outside Python? Because the Rust programming language is one of those ones I keep having my eye on. I think I keep thinking, \"I don't know whether I'm going to enjoy programming in this, but I darn well want to know it.\" Sure, that's probably up on my list. Yes, uh, just watching. I had a conversation with Brett Cannon, and I've been watching his series about unraveling Python. He's very interested in WebAssembly, but at the same time, he says, \"Yes, I'm interested in Rust, not that I'm changing, but he's always looking at other languages,\" which makes sense as a core maintainer.\n\nI think that people who get tribal about their language might be looking at things slightly the wrong way because, especially with something like Python, something like Rust, they are filling very different niches. Rust is about proving to the compiler certain properties about your code so that you can run it, which is incredibly powerful but involves you having a good long debate with the compiler before you can actually write any code. And Python is about getting from here to there in a really ergonomic and easy road. Rust is climbing the sheer cliff face, and the view at the top is going to be worth it. And Python is the smooth-paced, paved asphalt road to getting something working. These languages can and absolutely should coexist.\n\nYeah, you know, the majority of people that I've met that are very interested in Rust are people that are a little deeper into the languages and are the ones building things like frameworks and building additional tools and are kind of working at what the language is built for, right? Right, and that's what's interesting, is that it's kind of helping to build some of the machinery in some ways. Yeah, absolutely. And those of us who are obsessed with building machinery, who will devote years of their life to building the machinery behind reinventing the web as a programming platform. That's catnip to us. Yeah, that totally makes sense.\n\nWell, I want to thank you so much for coming on the show. This has been a great talk. Thank you very much for having me. I have had fun. All right, talk to you soon. Bye-bye.\n\nAnd don't forget you can get started on DigitalOcean's App Platform for free at do.co/realpython. That's d-o-dot-co/realpython. I really want to thank Meredith for coming on the show this week. Make sure you check out the show notes to learn more about the project. And I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "MYuVt85fbU4": "Welcome to the Real Python Podcast. This is Episode 67.\n\nHow well do you know your software supply chain when you Pip install a package? What steps can you take to minimize the risk of installing something malicious?\n\nThis week on the show, we have Dustin Ingram, a director of the Python Software Foundation and a maintainer of the Python Package Index. We talk about Dustin's PyCon 2021 talk titled \"Secure Software Supply Chains for Python.\" Dustin shares the types of attacks you should be aware of and how you can make your supply chain more trustworthy. We cover tools, techniques, and best practices. Dustin also discusses what it takes to keep the Python Package Index running and the players working to keep it going into the future.\n\nThis week's episode is brought to you by Scout APM. Scout APM is leading-edge application performance monitoring designed to help developers quickly find and fix performance issues before the customer ever sees them.\n\nAlright, let's get started. [Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Dustin, hey Chris. It's so cool to have you come on the show. I'm very excited by what I saw of your talk at PyCon 2021.\n\nAwesome. I'm really glad you enjoyed it.\n\nI kind of want to take a step and just talk a little bit about you wear a lot of different hats doing lots of different jobs. Part of that is working at Google. Can you talk a little bit about what you do currently at Google?\n\nYeah, so I'm a developer advocate at Google. I think developer relations takes on a lot of different meanings across different organizations. For a lot of people, they sort of perceive it as this external evangelism where I'm going and I'm talking to you about our products, I'm trying to convince you to use them. And I do do that to an extent, but the majority of my job is actually being an expert on some Python-related things and other things internally at Google so that when we build products for our customers, for developers, we build them right. So, you know, I step into the process of developing new products or deciding how we're going to add features, that kind of thing, and evaluate them on behalf of the Python community, advocate for the things the Python community needs, and then help influence the product in that way.\n\nYeah, that makes a lot of sense. That need for sort of explaining the ecosystem to this very large organization like, \"Okay, well, these are the kinds of things people are looking for and what they need.\" And I can see that need inside of an organization.\n\nYeah, I mean, it's not just that. You know, in any organization, that's probably necessary. But I think it's especially true at Google because we have so much. It's a bit like a bubble. We have so much internal tooling and we do so many things differently than the rest of the idiomatic ecosystem does things that our engineers that are developing our products, they really actually don't know. Their processes are not the same as the average cloud developer or Python developer. So, they really do need that information.\n\nI had Bret Slatkin on very early on the podcast, and he was talking about creating a lot of those tools internally and his love of Python for developing infrastructure and so forth. It's always kind of fun to talk to different individuals from these companies and see them. But how do you see customers, like the people that you're advocating for, what are the types of tools that they're using inside of Google with Python?\n\nYeah, our Python runtimes for our serverless products are hugely popular. Like, we have a Python runtime for Cloud Functions, which is like, you know, function as a service type of thing. We still have a really cool product that I love and I think it's underrated, which is Cloud Run, which is basically like run a container with an HTTP server inside it as a service. And our customers can really do anything they want inside those containers, but Python is fairly popular there.\n\nNice. You are also a director at the PSF. Maybe you can describe a little what you're doing there and maybe a little of your history too, because I just recently talked to Marlene on Gami and she was telling me a lot about the things that she's doing in her recent sort of connection to the PSF also.\n\nAbsolutely. Yeah, I'd like to reiterate that I am a director of the PSF, not the director. You're painful confused a little bit. Right, so there's actually 11 of us. Wow, yeah. So, I was elected to the board a year ago. We serve three-year terms on the board, and it's not a paid position. We're all volunteers, but we're generally responsible for overseeing the direction of the Python Software Foundation and ensuring that it's upholding its mission to ensure that Python exists, continues to exist, and remains popular and is well supported.\n\nNice. And kind of in that role, do you have a lot of duties that you need to do for big events like PyCon?\n\nNot so much.I mean, we do a monthly board meeting where we decide on making votes based on what the organization needs to do. For things like PyCon, we have member meetings, which are an important part of our outreach. We make sure people are aware that the PSF exists and that they can become members. Many people don't know that PyPI is supported and run by the Python Software Foundation. We meet with folks at events like PyCon, talk to them, and represent different parts of our communities.\n\nMarlene, for example, has done an excellent job representing the growing Python developer community in Africa. It's a lot of work, but amazing. You mentioned being my maintainer for the Python Package Index (PyPI). How long have you been in that role?\n\nProbably since around 2014 or 2015. It was my gateway into the Python community. I had done a lot of Python development before, but especially in the open-source community. I was living in Philadelphia at the time and found interesting projects on GitHub related to Python. I came across a re-implementation of PyPI by Donald, one of the early maintainers of PyPI. I started contributing to it, and eventually, it became PyPI. After working on the prototype, I became a maintainer of PyPI.\n\nAt that time, there weren't really competing indexes. PyPI was one of the older software repositories and brought all Python software under one index. It's now the canonical index for Python.\n\nReaching out to people via GitHub was a good experience for me. I stumbled upon projects and got lucky with the ones I found. I don't think finding projects in your geographic area is important, but it's about finding projects that interest you and contributing to them. My advice would be to just start and see where it takes you.Donald was incredibly knowledgeable, a great mentor, and very patient. I had this initial spark of interest in the project because it was a web application that was interestingly designed and complex. What really made me want to reach out was that I had well-defined issues that I could work on. Don was responsive and helpful when I was working on it. I would recommend it.\n\nThe well-defined issues really help to define a chunk that you can work on, as opposed to being lost in a vast landscape. As a maintainer, I file issues that are good entry points, even if it might take me the same amount of time to fix it myself. An issue is an invitation to have a discussion, not just a task to be completed in isolation.\n\nThe idea of an issue being a conversation starter is positive. Communication should happen in public to figure things out together. Reviewing shouldn't happen in a vacuum; communication is key.\n\nI was excited to talk to you after your talk at PyCon 2021 about developments in packaging and security. Ensuring the security of applications that developers create is crucial. Your talk consolidated ideas about the reliance on the package ecosystem for security. I'm excited to dive into how Python developers can ensure the security of their applications and understand the types of attacks that can occur.\n\nThis topic has been relevant for a while, but it's gaining more attention now. Many people are realizing the implicit trust in the open-source software supply chain. Understanding how the tooling and ecosystem work is important.\n\nThis talk could have been written a few years ago, but it's more interesting now with recent events in the news. It's a hot-button topic that has been snowballing in importance. The left-pad incident with a JavaScript library was a wakeup call for many about the reliability of packages on a package index.I mean that's our ultimate goal with IPI. All the software on there will be there forever, but you don't have control over individual maintainers. And that software is going to work great too, right? I mean, you're just sort of hoping and trusting. Yeah, I guess one of the ideas that I wonder about is, do I need to be a security expert to even really kind of think about this topic? Are there ways that I can approach this topic in this area of security for my own projects where I don't necessarily need to be an expert of security?\n\nYeah, that's a great question. I mean, no, I don't. There's this whole notion of shifting left on security, which just means it's not the job of the person at the end of the pipeline who's receiving or deploying the software to think about whether after everything has been done to it, it's secure. It's the job of the developer. The more that the developer can internalize a security mindset when writing software or pulling in new dependencies, the more secure their software will be. And it doesn't mean that every developer needs to be a security expert, but I think it does mean they need to have an understanding of what their supply chain is like. Where is the software I'm depending on coming from? How can I do some rudimentary verification that is actually what I think it is?\n\nYeah, so I wonder if tackling it in an order that's similar to what you did in your talk would be good. We could kind of expound upon areas that you feel like you could elaborate a little bit more in this longer format of a podcast as opposed to having to have such a tight thing for a talk at something like a conference.\n\nYeah, so maybe we could start with like, what are the types of attacks that people might be familiar with or maybe some that they're not familiar with? One that we touched on right away on the show already was typo squatting from one of the stories that was out there recently. Typo squatting is like something that was happening for a while in PyPI, and the idea of the attack is that someone could potentially create a Python package that either resembles or the name is close to something that you might manually type on the command line and you might install something that you're not intending to install. You gave an example of a potential foreign spelling of requests or something.\n\nYeah, exactly, like questions or something like that. It's not hard to find these, right? They exist. A lot of them are people trying to maybe they have typed that typo themselves and they're like, \"Oh, this is not good. I should squat on this.\" And that's fine. Occasionally, people are trying to extract your cryptocurrency wallet or something via that. I don't think it's a really, I mean, it's a valid form of attack and you should be aware of it. There are things you can do to try to avoid it, but I don't think this is really a class of attack that's compromising because at the end of the day, when you go to try and use the request library, for example, and you install request days and it doesn't actually work, you're not going to deploy that. It's not going to become part of your production software. It's not going to go out into the wild. Hopefully, it just would have been on your machine for a little bit until you, like, said, \"Whoops.\"\n\nThe way to avoid typo squatting, and we have some features in the pipeline that we're thinking about for PyPI, would either help reduce the potential for typo squats or allow people to have a little more control over what they're manually installing. But the solution is just don't be manually typing \"pip install\" whatever on your command line, especially if you're developing software. Put it in a requirements.txt file, ensure that you've typed the right thing before you go to install it, and do some verification there. There are other things to do as well, but we can talk about some other attacks as well. I think they're all going to kind of amplify toward those ideas, you know, the idea of pinning and stuff like that.Another area that was recently in the news was the idea of internal repositories. I had heard about this when I attended a local meetup for a Python user group in Colorado Springs. Shout out to Pi Springs! Many of the attendees worked for large companies, either locally or remotely, and they kept talking about maintaining internal repositories for installing packages in-house rather than fetching them from the web.\n\nThis issue of internal Python repositories is common for large organizations that have proprietary software they don't want to make open source. They host these repositories internally using tools like devpi or third-party products. These repositories contain a mix of public packages from PyPI and internal packages developed within the organization.\n\nTo configure pip to install packages from both internal and external indexes, a requirements file is used to list all dependencies. Pip then determines where to install the requested software based on the available indexes. The recent dependency confusion attack, which compromised many organizations, was due to misconfigurations in pip where it couldn't determine the source of a package if it existed in both internal and external indexes.\n\nThe attacker registered package names used internally by companies on PyPI and tricked pip into installing compromised packages instead of internal ones. This attack could have been avoided by using version pinning and file hashes for verification. By verifying hashes, pip can ensure that only trusted packages are installed, preventing such compromises.\n\nThis issue highlights the importance of security measures like version pinning and hash verification to prevent attacks on package dependencies. By implementing these measures, organizations can protect their systems from compromise and ensure the integrity of their software installations.I don't know what the steps are in the sense or maybe I'm asking more for, like, is there a resource that you know of, like, okay, these are the steps you need to do to start, you know, doing this within your organization or on your project. If you wanted to start using that, is that something that's explained well in, on, like, pipi? I'd recommend basically all, and all this boils down to best practices for, you know, declaring and installing your dependencies. I think if you're not using something that's a lock file, so like, pip-m for example uses lock files, okay. Poetry is an installer that uses log files and pip itself, like, you can configure your requirements.txt file in a way that it resembles a log file, right? It has version pins, it has hashes, and it has the full dependency tree, every single dependency and subdependency included in that file that should be installed.\n\nThere's a really nice tool that I like to use and that we use for pipi's dependencies as well because the web application that we deploy. It's called pip compile and it's part of the pip tools package. Basically, it lets you define this bare requirements file that you just list all your top-level dependencies with no versions, just the project name. And then it compiles it, it goes and figures out, you know, okay, what's the latest version of this, what are the subdependencies of this and its latest version, and then what are the hashes for all of these, and it produces this requirements.txt file that pip can just consume. But it has, like I said, the version pins, the hashes, the full dependency tree, right? Those are the important things. Yeah, so that just basically ensures that everything that when I can compile this event sees that that was available and that I intended to install, that's all that can actually be installed, nothing else can be surreptitiously installed as part of my Python defense installation.\n\nNice. So that requirements file, do you need to use, I mean can you just simply use pip install, you know, dash r and it would read that and configure it in a way that it would, you know, look at the hashes and pull the, you know, not only the pinned versions of the files but do the secure check of like, okay, this is the one I'm actually looking for?\n\nYeah, yeah, absolutely. Okay, and you sort of mentioned cryptography like this isn't like a cryptographic signature, right? It's a hash, so you have to trust that the hash that you got from pipi when you were, you know, first compiling your dependencies is right, like you weren't somehow middleman or pipi wasn't compromised. Okay, all of this is like making trying to make less and less assumptions so like you're still going to be making assumptions but now we sort of assume that we don't have to assume that what we're installing or not pinning is what we actually intended to install. We could verify.\n\nOkay, so that sounds like a nice like tool to kind of just help start to kind of look at okay ways that an individual you know working on a project can like not only get the correctly pinned versions but the hashes, so pip compile sounds like a nice tool there, you know, again trying to like avoid becoming a complete security expert. Are there additional things there like that you can think of that would help in this fight against potential like in this case the dependency squatting or typo squatting?\n\nYeah, I mean one thing that I'd recommend for folks is, you know, it's like the question of, alright, so I've been all my dependencies, I know what dependencies I'm using and like how am I supposed to know if they someday get compromised, right? And you know, it's too much to expect every developer to audit every line of code for every dependency that they introduce, right? There has to be some trust that either the community, if other folks in the community are assisting with that, helping with that, or that the maintainers themselves are doing that, right? But the question is like, well, so how do we know when if there's been a problem, there's a bug or something that could introduce a compromise? So I mean one thing you don't need to be a security researcher to do is turn on vulnerability notifications. So there's lots of third-party tools like pi up is a tool that is specifically for the Python ecosystem, dependabot is now integrated into GitHub, putting on my Google hat, like Google has vulnerability scanning as well. All these tools will basically, you know, either look at your GitHub repo, look at your container image, and determine if you're using a dependency in there that is known to be compromised, right, that there's been a vulnerability report published, and if there's a problem and you need to upgrade, I've seen that before even with projects where I'm sort of dabbling around, you know, like I was working through some Django tutorials and going through some different stuff, and so I had saved that information up on GitHub and I started to get those emails and it's like, hey, you know, Django 2.0, whatever, you know, you should look at updating this and so forth, and you know, it's kind of surprising how many emails I got just regarding that one file. Yeah.Which is cool, it's good that that's there. Well, that makes me nervous to hear you say that you got a lot of emails. One thing that we don't want to happen here is that you're just getting notification fatigue. You're being told about all these vulnerabilities that maybe as a human, you can look at and be like, \"Oh, well I'm not actually using that.\" Or like, a lot of times for IPA, we'll get vulnerability notifications for our JavaScript dependencies, but we only use JavaScript to compile our static assets. It's not a production dependency on any of those. So, I ignore those, but they still clog up our emails. I think one thing that we still haven't quite figured out is how can we ensure that there's not too much noise here and that there's a good signal? \n\nYeah, that makes sense. Kind of going back to the idea of, I don't even know what I don't know, and sort of decreasing the area of that. It's such a spanning kind of area that we can even think about. We've talked about a handful of additional things. I wonder, are there places where someone can learn about more of these potential problems and stay on top of it? Like other blogs, websites, or people that you would follow that could keep you on top of some of the stuff that's happening? I don't even know where to look for that. \n\nThat's a great question. I think this is actually one of the things that highlighted in my talk. I think we kind of aren't serving the community well enough here. We have a really nice user guide for Python packaging at packaging.python.org. It's great for publishing a package or doing certain tasks, but it doesn't really talk about supply chain security or best practices. I think we could stand to be more opinionated about this and provide a good resource for the community. But right now, it's not there. You can piece me all together, follow me on Twitter, or follow other folks in IPA or security researchers, but none of them will provide individualized guidance for your project or application. So, I think we're underserving the community a bit. \n\nOkay, well, we'll try to keep watching that space and keep alerting people to some new tools. We talked about three different types of supply chain attacks. You have one in your talk that I wasn't familiar with. Were there other compromises that we didn't touch on? I think we kind of touched on the idea of hashed versions, but not necessarily the man in the middle. The man in the middle is just the assumption that someone could compromise you. Now that we have TLS and HTTPS, it's less likely to happen. The other two that I highlighted in the talk are things I can't really give advice for fixing. One of them was about the Linux kernel developers banning folks from the University of Minnesota because they were intentionally trying to introduce vulnerabilities. The other one I highlighted was getting \"solar winded,\" which was the compromise that brought secure supply chains into the light for many organizations. Now, there's an executive order about what we need to do to have secure supply chains, at least in the US for government work.That was a nation state, like when you're listening to this podcast, there's almost nothing you can do to protect yourself from that. At the end of the day, it was not even compromised software, it was a compromised build system, like a bad password, kind of rudimentary stuff. It wasn't crazy established hacking. So yeah, just best practices everywhere and improving that generally would go a long way.\n\nOkay, so what I was wondering about then, maybe we could dive into the tools that you like to use. You mentioned some for projects that I'm deploying, maybe I'm making software for my business or applications for end-users. But then there's the side of creating things that are going to be used by others, like contributing packages to the index that are potentially going to be used by other developers and so forth. Are there things that we need to think about if you're going to be involved in the packaging side of things, like actually packaging stuff up yourself?\n\nAbsolutely, so I think if you're just a consumer of software, get yourself a lock file. I don't really care what installer you're using, just ensure that you're doing lock files with it. It could be Pipenv, Poetry, or Pip itself, but use them in a way that allows you to define the lock file and turn on hash verification and all that.\n\nThere's a lot suggested here for ways that we can make this better. One thing that folks bring up a lot is, what if we cryptographically signed every package on PyPI, and then when you're installing it, you can verify that signature and you'll know it's legit. That sounds great, but the problem is it's hard for users to use a lot of these package signing tools like PGP, and they're not super user-friendly. You're just shifting this trust around, going from trusting the right person who uploaded the package to trusting the signature that you're trying to verify.\n\nWe, as PyPI maintainers and folks working in Python packaging, are working on introducing the update framework to PyPI. This means that PyPI itself would sign the files hosted on it, and Pip would be able to cryptographically verify that signature so you would know it actually came from PyPI. But the problem always comes down to who you're trusting.\n\nAnother thing that folks bring up is, we need to start reviewing everything published on PyPI, audit it, curate it, and have a set of known secure packages. But with the vast number of projects on PyPI, it's just not feasible. PyPI is successful because it is easy for anyone to publish software there. It would be like saying we can't trust anything on GitHub and need to review everything before someone creates a new project. It just wouldn't work, so it's the same for PyPI.I'm glad you brought up that it's a community organization, like we are a volunteer project of a non-profit. Even a for-profit company like npm, owned by Microsoft, I don't think they have the resources to do this, and their ecosystem is roughly the same size. Yeah, it'd be great if you really want this, do it yourself. Start fully auditing your dependencies and tell us what you find. But yeah, it's almost just not feasible.\n\nIs that feasible or not feasible? Is that sort of what people do when they are creating their private repository? In the sense that they've done their own smoke test-style audit, that they've brought this version in and we've worked with it so far and ran our other vulnerability tools on it, and we can say that this version was safe at the time that we put it in our own repo. Is that kind of like that a little bit?\n\nI hope so. I'll give you a little insight into as I mentioned before that internally at Google, we do things a little bit differently with Python and software development in general. A lot of folks know about the Google monorepo, which is that literally all source code for everything at Google is in a single repository. If you're working on a Python project internally at Google and you want to depend on third-party code that's on PyPI, it needs to be in the monorepo. We don't actually ever reach out to PyPI to install it for our internal tools and projects. In the monorepo, we have a vendored version of that open-source code that sits in the monorepo, and every time there's a new version, someone has to go update that vendor dependency, literally copy and paste the source code into the monorepo, but then go everywhere where it's used in every tool across Google and ensure that they can now upgrade. The nice thing is we have really robust testing tools. This is not a ton of work at the end of the day. Well, actually, I don't know if I can say that with confidence because I don't ever have to do this, but it happens. It's a well-oiled machine. In that way, we essentially have a curated subset of PyPI that we have audited to the extent that we deem necessary to include it as part of our monorepo. So I hope other organizations are doing something similar, at least looking at the change log to see if it's going to break them or trying to review where the project's at if it's being maintained or not.\n\nNot that I want to get in the blame game, but I wonder if there's a name attached in that log of the person who sat through doing that if they're going to be questioned if something goes wrong. We also have a blameless postmortem culture here at Google, so that's good. I don't think that would happen.\n\nThis week, I want to shine a spotlight on another Real Python video course. I felt like it would be a good fit based on this week's topic. It's called \"A Beginner's Guide to pip,\" based on a Real Python article by Isaac Rodriguez. In the course, instructor Austin Sapalia covers the fundamentals of pip, the standard package manager for Python. Learning how to use pip starts with installing and managing additional packages that are not part of the Python standard library but also includes much more. In this video course, you'll learn about how to find packages published on the Python Package Index (PyPI), managing requirements for your scripts and applications, how to pin dependencies and work with requirements files, and uninstalling packages and their dependencies.I think it's a worthy investment of your time. This course is a great introduction to pip for those who are just getting started in Python and for those of you who want to understand more about what is happening when you install new packages into your environment. Real Python video courses are broken into easily consumable sections and where needed include code examples for the techniques shown. All lessons have a transcript including closed captions.\n\nCheck out the video course. You can find a link in the show notes or you can find it using the newly enhanced search tool on realpython.com.\n\nThere's some other ecosystem things we can do. I mentioned the update framework, and that's in progress right now. Another thing I mentioned before when we were talking about typosquatting, like we've talked for a long time about introducing namespaces on PyPI. So sort of similar to on GitHub where you have an organization and then there's repositories within that. I can't sort of flat namespace right, like anyone can publish a project that starts with anything that they want. So adding a little bit of restriction there, I think would go a long way for helping folks feel confident that software they're installing is actually coming from a given organization or group of maintainers or something like that.\n\nWhat would that look like? How would that change from the end user's perspective, or would it be more of a change on your guys' end or somebody submitting?\n\nYeah, we're still sort of thinking through it a little bit. I mean, I think it sort of implicitly happens now. For example, Google Cloud publishes a lot of client libraries for interacting with our API services from Python, and we prefix those on PyPI with google-cloud- whatever. Okay, and you know that happens similarly for a lot like PWS does those similar things. The change would be adding the restriction that, okay, you can only publish this package that starts with Google if you're part of this organization. Yeah, that owns that namespace, right? And so on, so like individuals would own their usernames as namespaces, and then we sort of go from there.\n\nSo I don't think much would change at the end for the end user. That'd just be the sort of extra little trust that like this project can only be owned by this organization. \n\nYeah, and I've noticed a few things kind of, you know, as an end user watching projects get embraced kind of brought into. One was requests over the last two years, like watching it move from a particular banner under GitHub to being psf/requests, and black being another one. I'm kind of wondering what that means in a sense. Is that like a vetting process or a support process? Like, I don't know if you can speak to that specifically.\n\nYeah, sure. So, you're mentioning a couple projects that were brought under the PSF organization, and I actually wasn't really involved in that process. But I think generally those are projects that are widely depended on by the ecosystem and the community, and we want to ensure that basically they receive a little extra support by the PSF itself. This is partially ensuring that we don't have a left-pad scenario where someone can go rogue and wipe requests off the map. I don't know if moving into the PSF organization really protects us from that, but it's a step in that direction of like, well, this is more community maintained than maintained by an individual. In the case of black, that was Lukash's project and he wanted it to be more of a community project. So it was moved in terms of the Python Packaging Authority, we have a similar organization on GitHub and now we recently introduced governance changes that allow us to ensure that we have the ability to adopt projects into that organization that we deem worthy of a little extra support and can be thought of as a community project. \n\nSo we brought in two projects recently. One was pipx, which allows you to execute any package on PyPI as an application with a nice single command. The other was this project ci-build-wheel, which allows you to, as a publisher, build lots of different distributions for your Python package before you publish it. Both of these were projects that were successful and individually maintained, but as a project at the PSF, it means or as a project of the IPA, it means that they get to use our resources, like they're in our GitHub repo, they get to use our GitHub actions and Travis CI accounts and that kind of stuff. But also that there's this implicit idea that this is a project of the IPA. If all the existing maintainers go away, we've sort of said we'll support this, like we'll ensure that it sticks around. This is important enough to continue to exist even if individuals go away. \n\nWhich is great. Yeah, we talked about pipx on the show a couple weeks ago, so and that development was in the news. So that's great.I mean the last thing I'll say was regarding security. Like I think the biggest effect I've seen over the last couple of years is organizations stepping up to provide funding for very specific projects. We have a pipeline as pipeline maintainers, we have a pretty good idea of what we need to do. We have a sense of a roadmap. What we don't have is a lot of volunteer time. One thing that helps is when organizations come along and offer to support us either by allowing us to hire contractors or project managers, or doing UI/UX studies. For example, when the new resolver rolled out, we did a UX study to understand how users are going to experience this. We've never done that before, it was fun to talk to the people involved, come on the show, and talk about it. It was really fun to talk about the whole thing and the idea of the user experience of pip is really cool that they were able to invest that time through the funding.\n\nI just, we are getting more and more support there. I'd love to see more continued support and focus on specific projects because it's really done great things. That's why we have a new pipeline now, that's why pip's resolver works a lot better than it used to, all those kinds of things. I'm actually thinking about Georgia Bullen and Sumina, and I'm thinking about having them come back on and talk about how that's all fleshed out because we were right in the middle of it where we were still asking for feedback and so forth, but I think it's been working great.\n\nI think it was a great success. I really love Futurama and there's this line when Bender is floating through space and he meets God, and God tells him when you do things right, people don't think you've done anything at all. I think that's so true. Just in software, when you do things right, it just seems like nothing's changed, but there are these small improvements happening all along the way. I think that's a good example.\n\nAs a music person who's been on the other side, being an engineer or even messing around in video, the average person never thinks about the editor or the person who's mixing the music and making all those things happen. Hopefully what they're doing does not stand out in a way that they're not getting in the way of the story. That's not to say it was a completely bump-free rollout, but I do think it was a success.\n\nThis article that you put out in April that dove into the idea of what it takes to power the Python package index, do you want to talk about that a little bit? This article was originally written about five years ago by Donald Trump, and at the time, PyPI was still pretty popular, we were getting a lot of traffic. I was inspired to update this article because some folks were trying to make an estimate for the size of the traffic that PyPI gets and what it would cost, and they were off by a lot, almost an order of magnitude. It happens all the time that folks really underestimate what it takes to power stuff like this.\n\nI think we all do. One of the first things they do when you start at Google is sit you down in an orientation, and one of the presentations they show is basically like how many computers do we have, what does it actually take, and it's absolutely mind-blowing. It's so much more than you think. When technology feels like magic, we don't think about everything that goes into it. PyPI handles a lot of requests and transfers a lot of bandwidth, and we don't actually pay for that because we have a generous sponsor, Fastly. But if we did, it would be almost a two million dollar a month bill, oh my gosh.\n\nI would imagine that's not the amount of donations that are coming in. No, not to fund it. It's a very small drop in the bucket, and we appreciate those donations. They help us do some interesting stuff, but organizations, kind of.We have great support from our sponsors, specifically from the PSF, which helps us pay some bills. If tomorrow Fastly decided to stop supporting open source, it would be an existential crisis for PyPI. We would probably try to find another sponsor, as Fastly provides the CDN for us. They were in the news recently, and the spin on their outage reaction was good.\n\nFastly has been a great partner for us, and we rely on them for technology. PyPI gets a lot of traffic, so we notice when there are issues, but they are always resolved quickly. The bandwidth is a part of powering PyPI, along with compute and file storage costs. PyPI is essentially a large bucket of files with web APIs around it, which requires hosting fees.\n\nSome projects on PyPI, like those for GPU architectures and machine learning frameworks, consume a significant amount of space. The disk size of PyPI is constantly growing due to the increasing size of projects. It's necessary to support these projects, as they are doing important work.\n\nIn the past five years, there have been significant changes in PyPI's infrastructure. More people are working on it now, with more maintainers, moderators, and contributors. Additionally, there has been an increase in funding for development, starting with a grant from the Mozilla Open Source Support project in 2017.\n\nThis funding has allowed for feature parity development, deployment, localization, and internationalization. Partnerships with Facebook, Google, and Bloomberg have also led to further development and staff hiring. Google and Bloomberg have contributed money to hire Python developers and project managers, which will greatly benefit PyPI's development and management.Okay, this is my pocket of time I have now. Coming back and just like, just as a human being, context switching in my own life is like, okay, where were we at? Yeah, that, I think, is going to be huge for you guys. Just for the whole ecosystem. So, I'm very excited by that. I don't know, I feel like there's been a rush of good news in a lot of ways. We kind of started this whole podcast on a cautious note of security, but the ecosystem, if anything, has made me really excited about these developments. It's really a nice change.\n\nAs far as the news, we've been working hard on it. Not everything is obvious at first, but we're trying to make it as reliable and secure as it could possibly be. We focus on its long-term sustainability. We want Pipeline to be around for a long time. Everything we do, every feature request, every thing that we consider when we change, modify, or update it, the biggest thing we think about is how is this going to be sustainable for the long term, not just over the next year or five years, but for a long time.\n\nIt's good Pipeline is going to be around for a long time. We want to ensure that everything is sustainable and it can continue to exist throughout that lifetime. Great, well, I have a couple of weekly questions I like to ask everybody. Cool, yeah. So, the first one is what's something that you're excited about in the world of Python? I know we've talked a lot about that across the board today, but this could be a specific event, book, package, or what have you. Let me think about that for a second. I think the thing I'm most excited to see is how widespread Python is becoming. I was introduced to Python very early in its lifetime, and I think, in some ways, I was lucky that I was introduced to it then and got exposed to it then. But I think a lot of people are seeing a lot of value in it that I had seen way back then. It's serving as this fantastic tool for people to get into technology and programming.\n\nJust seeing how much it's growing in places like Africa or in South America is like, I'm thinking about how there are millions of Python developers that haven't met Python yet, but they're about to come online. They're so close to being in our ecosystem. I kind of just want to get it ready for them because it's so exciting to me that they're out there somewhere, we haven't met them yet, but they're coming. Python is at a point in its lifetime where it's so popular that it's almost inevitable that we're going to have a blossoming of the ecosystem. It's super exciting.\n\nI'm excited to welcome them too, you know. That's been one of the fun things about doing the show, meeting other people and trying to share ways of how these are ways that you could learn this. I agree with the idea of getting the house ready for more people to join. That's cool. So, what's something that you want to learn next? It doesn't have to be specifically Python, but something that you're interested in learning next. My work as an advocate at Google has brought me into the sphere of product development. I think before I worked at Google, I was working at a software consultancy and we were doing product development there too.\n\nI'm really interested in learning how to build better tools, how to bring more empathy into the process of designing products and building software. It's something I think that there's a broader thing here about thinking about how ecosystems are built and how we define these standards that are supposed to be best practices and exist for a long time. I'm interested in just generally being more thoughtful and gaining more knowledge about how to do that well. Do you have resources that you can think of or go-to places that you would suggest if somebody else is interested in that path? I'm lucky because I'm learning from some really great folks at Google that do product and tool development there.Yeah, as far as external resources, I don't think I have one. Okay, so this last one is one that I kind of bring in and out a lot. Being that you've been working with Python for quite a while, I thought it might be an appropriate one. So, what is something that you thought you knew or understood about Python, but you were wrong about it? No, I mean, I feel like I experience this all the time. It's just so much more complex at the end of the day. Each time someone asks me some sort of question assuming I'm an expert on Python, I'm reminded that I'm not. I really don't consider myself an expert, especially core Python. I've written Python for a long time, but there are a lot of things about the ways that Python works underlying data structures and things like that that I actually don't know. So, I'm often reminded of those when I see, like, I saw recently, like I think it was David Beazley was posting something on Twitter about some kind of mind-numbing construction of Python syntax that produced this result that made no sense. I actually didn't understand what was happening, and I was like, I thought I could read Python, but this is super confusing. It was almost by design, that was the intention as a bit of a puzzle. But yeah, I mean, it's just there's not just one thing, it's all the time I'm reminded of things I don't know, and that's fine. Yeah, no, I think that's true. I think all of us, if you're willing to admit it, there are so many, just the landscape that we keep talking about of Python in general and all the different packages that are out there. But just inside the language itself, it was like a meme recently, like it's a guy and some girls like in a car or something like that and keeps asking him questions like, you know, prove to me that you know this language or whatever, and she says, \"Okay, so you think you know Python? Well, name 100 packages,\" and then the guy's like, \"The Python standard library,\" and she's like, \"Oh yeah, you got me there,\" you know? No, I set the bar too low or something like that, yeah, exactly. It's the meme or whatever, but yeah, and that's, you know, it's like who knows all of the things that are in that, you know? And I've had Brett Cannon on, and his whole project of unraveling and kind of that idea of like, what at the core are these constructs inside there, and that's been very interesting to follow. I got the book that we recently put out about the CPython internals, and I'm still just starting to crack it and get into it. I'm a little nervous because I haven't done C in a long time. Yeah. Yeah, you mentioned, right? Like Brett has been, these blog posts he does where he's unraveling different parts of Python have been so interesting and enlightening. Every single one of those is something that I was like, \"I didn't really know that's the way that worked.\" Yeah, he's doing a great job there. Yeah, it's cool. So, this is something new I'm trying to get better at doing at the end of the show. But if you'd like to, would you like to share your social info? And do you have any sort of final shout-outs that you want to share? Yeah, sure. On Twitter, I'm di_codes, and I'd love for folks to follow me there and feel free to reach out and message me. DMs are open. My shout-out is to everyone listening that is not a member of the Python Software Foundation. I think a lot of folks don't know that you can become a member for free, and you can actually become a supporting member for $99 a year. That gives you voting rights, meaning you can vote in the annual election for the board of directors. You can also become a contributing member, which means that if you, in any way, work on something in the Python ecosystem for like five hours a month, you can self-certify and become a voting member. I'd really love to see more members, especially folks throughout the diverse geographic areas of the Python community, join and become PSF members. Yeah, that's exciting. It's kind of a unique thing that I think a lot of people don't know about. It's like, \"Hey, you can become part of this and be a member.\" There are some interesting things connected to it, not only the voting but just giving back to the community in that way too. Yeah, and just showing up and showing your support. Cool. Well, Dustin, thanks so much for coming on the show. It's been really fun talking to you. Thanks.I really appreciate you having me. Real Python is great, super happy to be here. Yeah, good luck with the rest of the podcast.\n\nOkay, thanks. And don't forget, you can start your 14-day trial today with Scout APM at scoutapm.com/realpython.\n\nI want to thank Dustin Ingram for coming on the show this week. And I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review.\n\nYou can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "ijR1mqJNXX8": "Welcome to the Real Python Podcast. This is episode 73. How do you define open source software? What are the challenges an open source project and maintainers face? How do maintainers receive financial, legal security, and other types of help? This week on the show, we have Josh Simmons from Tide Lift in the Open Source Initiative to help answer these questions. Josh does open source ecosystem strategy for Tide Lift. We talk about what Tide Lift is and how they support maintainers. We also talk about the types of support maintainers need and the barriers that can block that support. Josh also serves as president of the Open Source Initiative. OSI is actively involved in open source community building and education. He talks about how collectives and foundations can be powerful tools in the open source ecosystem.\n\nThis episode is brought to you by Century, helping developers see issues that matter, solve those issues in minutes, and learn insights to keep their applications running at peak performance. Alright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Josh, welcome to the show. It's great to be here, thanks for having me. I got very excited when your team reached out to me after PyCon looking to talk a little bit about Tide Lift to me as a member of Real Python. I turned it around on you guys and said, \"Oh my gosh, I think I really want to talk to you on the show and kind of wake people up to what it is that you do.\" Maybe we could start there and talk about a little bit of background of the organization and then end that with what you do for Tide Lift. That sounds great. Tide Lift is an organization about a four-year-old startup that works to provide more assurances to downstream users of open source. By assurances, I mean making sure that licensing information is correct, that we're on top of security vulnerabilities, and that there's a responsible disclosure process. We provide these things in a fairly unique way by contracting directly with maintainers of the open source projects. We pay open source maintainers to do additional work on their open source projects to make it more reliable for their downstream users. There are lots of companies, non-profits, and organizations trying to solve the problem of making sure that open source maintainers are better supported. There's a whole global technology infrastructure built on the backs of open source maintainers, and a lot of them are not well supported. That's a problem we're trying to solve by working with maintainers directly as well as with their downstream users. So that's what Tide Lift does.\n\nI think there's a lot of details we can crack open as we continue our conversation, but I think that's a great overview. Thank you. My role in all that is Tide Lift's ecosystem strategy lead. Maybe that sounds a little highfalutin, but really it's about thinking about all the players in the open source ecosystem and aligning incentives to make sure everyone's getting what they need. We want to ensure downstream users get the assurances they need and that maintainers are well supported in that work. Incentives are not always aligned, so it's important to make sure everyone benefits from the open source ecosystem.\n\nIn a sense, it's like a hybrid of developer relations for Tide Lift. Yes, absolutely. To break open some of the questions I have, you guys have a really nice video on YouTube that goes into open source and what motivates open source maintainers. For people who are not developers themselves, it might be a big question mark for them. Why do you do this and how do we keep you doing this?So, I think that's really kind of an interesting thing that is behind a lot of what is happening there. You guys use this term \"lifters,\" and I think that might break apart into two things. Is there a difference between a maintainer and a lifter, or how does that break apart? \n\nOh, sure. A lifter is the word we use to describe folks who are maintainers and have a contractual relationship with Tide Lift. So, every lifter is a maintainer. We wish every maintainer was a lifter, but we're still working on that one. \n\nAlright, that makes sense. I guess we're going to bounce back and forth a lot, and I feel like that kind of fits what you do. \n\nTrue, in some senses. One of the questions that came up in my mind as you were introducing what Tide Lift is, is the idea of how much software that is used by businesses is open source. \n\nIt's pretty incredible the degree to which open source is really the bulk of the software inside of just about any company or organization, non-profit or for-profit. In 2011, open source was first defined in 1998 as an approach to software licensing that had been around for a while already, thanks to the software freedom movement. \n\nFrom '98, we get the open source phrase coined, and at that point, open source was treated as this radical thing. Many people in business really didn't understand how something that you don't have to pay for can be useful or of quality. Those are the days of open source being described as a cancer by a well-known company. \n\nBy 2011, Wired said open source is one, and a few years later, O'Reilly Media followed suit. We've gone from a place where open source is radical and as a hack on the copyright system. Personally, I believe it's still kind of radical, and I love that. But it's totally mainstream now. \n\nThe numbers I've seen through surveys done by the Linux Foundation show that 70 to 80 percent of the software inside any organization tends to be open source software, which is just phenomenal. \n\nYou think about how much any given company invests in paying their engineering talent to build software. If all that spend is going to only 30 percent of their stack, there's much more value that they are not having to pay people to create. They're getting the benefit of this shared asset. \n\nThe bulk of the software inside any given company is open source software, yet we still have systemic issues where there is critical software maintained on a volunteer basis by very few individuals. It's mind-boggling. \n\nStudying the language of Python and looking at a requirements file, you realize the core of Python itself and making sure it stays around. It's wild to think about building on top of the risks that a company takes by using open source software.\n\nThere's a lot to be said about the risks introduced by using open source software, but they're really no greater than the risks introduced by writing your own proprietary software. People could leave too.Absolutely, so I just want to never fall into the trap of implying that open source software is somehow riskier because it's not. One does need to adopt each piece of software with their eyes wide open. When considering adopting a given set of open source software, there are a few things I'm looking for. First and foremost, does it do the job I'm looking for it to do? Does it meet my needs?\n\nHow active is the project? Is it actively maintained? If a vulnerability is discovered, will there be someone there to address it? Are there new features being developed? Will it keep up with changing hardware architecture and evolve with the landscape? I prefer software that has maintainers and contributors, ensuring its future.\n\nI look for a diverse pool of maintainers and contributors to have a say in the project's future. I want to make sure I can trust each new release and that there's a responsible disclosure process for security issues. This ensures that when something goes wrong, there's a reliable path to resolution.\n\nI also look for a code of conduct as a signal of the community's intention to be welcoming and productive. When a company adopts software, they are betting on its reliability for today and tomorrow. They want to be part of the user and contributor community, ensuring the software's future. No one wants to adopt software they can't rely on or worry about its maintenance status. It's essential to feel confident in the software we adopt, as it becomes a crucial part of our business.That makes sense. There's so much to dive into. One thing I wanted to comment on is that open source doesn't necessarily change all of those risks. It exposes some of them and can show you things to research more than you might be able to do with some existing companies. \n\nI use software for this podcast and I'm frustrated by this company because they've had almost a year and a half to develop versions of software that will run on the new hardware that my computer can handle, but it still doesn't work. They don't provide any dates or plans of action. It's concerning because I made a significant investment, not just monetarily, but in other aspects as well. \n\nI think about the bet when using that term. That's where a service like what you guys provide can back up that bet and make sure things happen. Maybe we can discuss the types of projects that are supported and the idea of a catalog to back up that bet for a company. \n\nTo answer the question of what it looks like to back up that bet, there's something about assessing projects that I want to make more explicit. Open source has come to be overloaded with meaning. My day job is ecosystem strategy lead for Tide Lift, and I'm also president of the Open Source Initiative. The mission is primarily around stability, licensing, and clarity. \n\nThere's a legal definition of open source, but many people have their own personal definition. Open governance and open collaboration are important layers on top of the license. Projects like Android are technically open source but lack open governance and collaboration. \n\nOpen collaboration is what you tend to expect from open source projects where anyone can contribute or make feature requests.There's a sense that I can wander into your community and share information with you, and maybe even help build the project. For most people, when we say open source, we mean all three of those things - it's under an open source license, there's open governance, and there's open collaboration as well. The reason I highlight all of this is that Tidelift's work is to work with open source projects. I mean, not just open source licensed projects, but projects that are open collaboration that aren't created by a single vendor. They are just a small community of people, or sometimes a large community of people working on a project. Those are the projects that Tidelift is really trying to work with, whether it's in the JavaScript ecosystem, in the Python ecosystem, or Go. We are trying to recruit maintainers in those ecosystems to provide them with guidance, support, funding, and money so that they can have their incentives more closely aligned with the incentives of their downstream users.\n\nIf I want to use a piece of software personally as a hobbyist, I don't really need many guarantees out of that piece of software. I'm not building a business around it. But if I am building a business around it, I want to be confident about that software in the future. The way we can do that, especially when we have projects stewarded by a community of people who are largely, if not completely, volunteer, is to find a way to align our incentives by saying, \"Hey, maybe you wouldn't choose to create a security responsible security disclosure process on your own. Maybe you wouldn't choose to add signing keys or enroll in the reproducible Pele program on your own. Maybe that feels like extra work that isn't really edifying or enjoyable for you, but we all recognize it's important. So let's pay you to do that work.\"\n\nI look at what's happening in the Python ecosystem as a particularly encouraging example. In Python, of course, we have the Python Software Foundation, a non-profit that's there to steward the communities, do what the language does with the trademarks, and all of that. In Python, over the last few years, we've seen a number of events that have really shaken many downstream users awake. I think back to 2014 or 15 when the Heartbleed bug in OpenSSL was discovered and opened up SSL - a critical piece of the global infrastructure. Yet, it was maintained by someone who wasn't being paid. Everybody has realized how outrageous it is that this one person isn't seeing a dime for it, isn't getting supported to make sure that it's actively maintained and taken care of.\n\nAfter that, we had a lot of discourse around sustainability, open source sustainability. It's an important subject and also became a little bit of a buzzword where we all realized, \"Oh, this is not okay. We need to do something about this.\" Over the last few months, we've seen software supply chain attacks in the news from SolarWinds to some weird research practices to a whole range of things. Some organizations are really starting to get it. We have foundations like the Python Software Foundation, the Drupal Association, the FreeBSD Foundation, Software Freedom Conservancy. We have these non-profits that are sort of neutral stewards of some of this community infrastructure of many of these major open source projects, and they've been there for quite some time. They are not new, but the degree to which their downstream users are beginning to support them is kind of new.\n\nWhat we've seen over the last year, one of the examples that I love going back to is the way Bloomberg has stepped up for the Python Software Foundation.Yeah, Bloomberg is an organization that exists in some highly regulated markets and really cares about managing their risk and making sure that the ecosystem is healthy. This is both the right thing to do and good for business.\n\nWhat I found was that Bloomberg realized that their needs did not necessarily align with the priorities of the Python Software Foundation itself. Specifically, there was work that they wanted on the Python Package Index. While that's work that Bloomberg wanted, the PSF has its own sense of priorities, and rightly so. So what did Bloomberg do? They threw down for what I understand is the single largest sponsorship the Python Software Foundation has ever seen. They paid for engineering time to get the features they need on the Python Package Index.\n\nThis is a great example of a company realizing that their needs are not aligned with the incentives and stepping up to invest in the community infrastructure. By investing in the Python Software Foundation, not only does Bloomberg ultimately get what it needs from the Python Package Index, but the whole ecosystem benefits from it.\n\nIt seems like there's been a handful of similar sponsorships recently, and I hope it's a trend. With individuals like Wikilanga becoming the director of residence and working on backlogs of PR issues, it goes back to the idea of side projects and volunteer bases. These things don't always move fast and go in fits and starts when people have the time and effort.\n\nDefining open source, you mentioned there were ten points in the licensing. I won't go through all of them, but the aim is to ensure that we have the rights to use, study, modify, and redistribute the software.\n\nEvery one of those points is geared towards preserving those rights and freedoms in the license. Licenses also come with responsibilities, such as providing attribution or sharing modifications upstream with the project. But the bottom line is that open source software allows us to use, study, modify, and redistribute without needing explicit permission.\n\nThis growing commons of open source software allows us to move further faster and avoid reinventing the wheel. I don't need to reinvent the operating system when creating a new service because it's already there, like in the case of Linux.\n\nThis episode is brought to you by Sentry, helping developers see and solve issues quickly to keep their applications running at peak performance. With Sentry, you get actionable insights in full context to fix errors and optimize performance.Performance monitoring engineering managers and developers now have a single tool to trace Python performance issues back to poor performing API calls, as well as surface all related code errors. With Sentry's error monitoring, you can understand the important events that led to each Python exception, be it SQL queries, debug logs, network requests, or past errors. Spend less time fixing bugs and more time building features. You can learn more at sentry.io/for/python and sign up with the promo code REAL PYTHON (all caps) to get three free months of Sentry's team plan.\n\nOne of the things that you touched on there is the idea of companies coming forward and having these needs and wanting to contribute. In this case, they are contributing to a non-profit. But in some cases, if a company wants to contribute to a particular project that they're interested in and maybe that project is not organized in that way, they're not a non-profit or maybe it's individuals or some other kind of collective thing. Is there anything that gets in the way of them being able to even think about how they could contribute?\n\nI'm so glad you asked that because this touches on something we were talking about a little bit before the show. I've talked about these nonprofits, these foundations that steward open source projects for us all, and I've left open the question of why do they exist, why do we even need them? The reason that we have, broadly referred to as open source foundations, is that they provide a neutral territory for multiple stakeholders to come together around a shared interest in a project. For example, Git is a project that calls the Software Freedom Conservancy home. Because Git calls Software Freedom Conservancy home, there are guarantees about its governance, licensing, and community management that provide stability and predictability for the use of that software in the future.\n\nThe foundations provide a neutral home and serve as a neutral arbiter between stakeholders like hobbyists, startups, and large corporations, ensuring a level playing field for engagement. The Linux Foundation, for example, allows for-profits to collaborate on projects without issues of anti-competitive behavior or anti-trust concerns. It takes the complexity and risk out of the equation by providing a shared assets organization to commune and contribute around.\n\nAdditionally, it is hard to pay open source maintainers. Maintainers often start as volunteers, creating projects to solve their own problems without anticipating the additional responsibilities that come with open sourcing a project. Large companies may rely on these projects, requesting features and reporting bugs, but may not provide compensation for the work needed. This leads to maintainers, who started as volunteers, taking on the role of community managers, release managers, and security researchers without financial support.\n\nThe concept of accidental leadership or maintainer arises when a project creator becomes responsible for additional tasks without prior expectation. Maintainers may find themselves in a situation where they have to fulfill the needs of users without being compensated for their work, ultimately leading to challenges in sustainability and maintenance of open source projects.Okay, well, you need to pay me for my time so that I can do this because it doesn't cost me anything. By having these foundations and projects that belong to foundations, those foundations provide things like a bank account, accounts receivable, and accounts payable, right transparency for how funds are used, expense policies so that we can be confident the funds are used wisely.\n\nA company typically cannot cut a check to me, random number five for your meetup, right? That doesn't work. For anybody who hasn't had to deal with corporate procurement processes, they're very fortunate because they're awful. But it really prevents companies from paying me, hobbyist maintainer of a project, and writing a check that I deposit in my personal bank account. Chances are Software Freedom Conservancy or the Linux Foundation is already in their procurement system, and they can pay them, and then those organizations can then, in turn, pay me.\n\nThese organizations provide that neutral territory; they provide ways to steward financial resources. They will hold the trademarks, the copyrights, and also provide legal support for projects. Typically, when someone creates an open-source project, they're sort of transitioning from a complete hobbyist to setting up a profile for their project on Open Collective, which is a lightweight fiscal sponsor. It is a great option on the way to transferring a project to a foundation because then it gives a way to receive funds and use them transparently.\n\nIf the project grows and downstream users need more guarantees or legal support, it might be time to look at moving to a more hands-on, full-service foundation. There is a whole spectrum of options for projects from the lightweight Open Collective model to organizations like the Apache Software Foundation, the Python Software Foundation, Software Freedom Conservancy, which have more services and opinions about how projects should be run.\n\nMany of the people that Tidelift works with are somewhere along that path where they have created an open-source project, people are starting to use it and rely on it, and suddenly there's a need for additional work like implementing a responsible security disclosure process or providing assurances about the project's license. Tidelift works with them to pay them to do that work so that downstream users have what they need, and the maintainers are compensated for their work.\n\nAs an organization like Tidelift, we provide guidance on implementing a code of conduct for open-source projects, implementing a responsible security disclosure process, and running that process for projects that may not have the resources to do so on their own. We receive security reports discreetly and work with maintainers through resolution to provide security guidance and manage risk for downstream users.\n\nIf a maintainer needs help in these areas, we provide guidance and support, connecting them with resources or other maintainers who can assist in those projects.One of the benefits of doing this work is that it is extremely relationship-oriented. We work across all of the ecosystems, so if somebody came to us and asked about the standard or best practice for a specific corner of the ecosystem, we know who to talk to and can provide guidance. We are also glad to chase down questions and connect people across ecosystems to ensure we are comparing notes. \n\nThere is a lot of encouraging work happening in every corner of the ecosystem, but there is not much cross-pollination. When someone comes to me with a question, I am eager to show them how things are done elsewhere so we can learn from each other.\n\nFor the open-source initiative, working across different ecosystems like Go, Python, JavaScript, and more is vast. Tidelift works on partnering with maintainers and lifters to provide assurances, code of conduct, and security risk disclosure processes. We want to work with foundations to ensure they are getting income for projects being used and provide support beyond just monetary assistance.\n\nFrom our maintainer survey results, about half of maintainers get paid nothing for their work, finding it stressful and financially unrewarding. Maintainers want help with documentation and other skills like marketing and building a community. We aim to partner with maintainers and lifters to improve documentation quality, user experience, and contributor experience.\n\nAdding a person to focus on documentation can make a significant difference in how a project is perceived and increase involvement. It can be a barrier to entry for potential contributors if documentation is lacking. We are exploring ways to provide support to maintainers in various areas to help them succeed.I mean just to keep on the theme of documentation, the documentation is a force multiplier. Not only does it help make the right first impression, but for every answer you put in your documentation, that might save you 10 to 100 issues being filed down the line. So it can have a huge impact and you're stopping misinformation from happening outside of that zone too. \n\nThis week, I want to shine a spotlight on another Real Python video course. It covers a powerful concept in Python titled \"Python Inner Functions.\" The course is based on a Real Python article by Leodinis Bozo Ramos, and in the course, instructor Christopher Trudeau takes you through how to provide encapsulation and hide your functions from external access, how to write helper functions to facilitate code reuse, how to create closure factory functions that retain state between calls, and how to code decorator functions that add behavior to existing functions. I think it's a worthy investment of your time to learn how to nest functions inside of other functions, a feature of Python you will see more often the further that you explore the language.\n\nReal Python video courses are broken into easily consumable sections and include code examples where needed. All lessons have a transcript including closed captions. Check out the video course - you can find a link in the show notes or use the newly enhanced search tool on realpython.com.\n\nOne of the things I looked at, I looked at a couple of surveys just to get an idea of what they were in. It went from a terminology I don't know which one was first - it was like a managed versus a professional open source project. I didn't know if those were different or if it's just a change in labeling and how they're thought of. \n\nI confess I haven't thought a whole lot about what it means to be a professional open source project. But certainly, when I think about managed open source, I think about projects that are working with organizations to provide assurances to their downstream users. That might mean working with Tidelift to provide guarantees about security and licensing, and really improving and professionalizing the continuous integration and deployment pipeline. Managed open source, I really think about what I think when someone mentions managed open source, aside from Tidelift, I think about Red Hat. The way Red Hat provides support for a massive cross-section of the open-source ecosystem, whether or not they're the ones creating the software themselves. That's the pitch for Tidelift - work with Tidelift to help provide managed open source, help you with your open-source software supply chain, and give you greater confidence in the software you're using.\n\nI have these weekly questions, and the first one is - what's something that you're excited about in the world of Python? It could be an event, a book, a package, an editor, what have you. \n\nI've been very excited in Python to see how much is being invested in paying staff to support the Python ecosystem. The amount of headcount that's growing that is paid to work on supporting the Python ecosystem is just such a fabulous example for the whole of the software industry. \n\nThe next question is, it doesn't have to be Python-specific, but what do you want to learn next? \n\nI've had this long-held desire to go on sabbatical and take some time to research some of the social sciences that underpin our industry. I came up as a community manager, and the community manager profession is a wonderful and fascinating space. Yet, while I was in that space, I couldn't help but feel like we were missing out, like we were reinventing things because community is as old as time. There's a great deal of research and work that's been put in there, and I would love to have the time to ground myself in the work that's been done so that we're reinventing the wheel a little less often. All the social experiments and communities that have proceeded, I'm sure there's lots of interesting things to study there.Absolutely, the last point is, do you have anything you want to shout out or call out specifically? Yes, I love these questions. One of the things that I'm really passionate about is this ecosystem, this notion of an ecosystem where we have all these different stakeholders of various shapes and sizes. We have the downstream users and the large corporate users, we have the maintainers, we have hobbyists, we have just so many different stakeholders in this space.\n\nAnd I gotta say, as somebody who spent maybe 15 years in this industry before I even realized that there was a whole world of non-profit open-source foundations that really undergirded the whole thing. And as open source continues to be used to even greater and greater degrees, these non-profit foundations are carrying a greater and greater load. So, one is, and I call those foundations hidden infrastructure, because for the developer working in their IDE, working on the command line, you don't really think about those foundations, and yet they're so important. So, my ask of everybody is, if you have built a career in this industry, if you built a career on Python, please go to python.org and become a supporting member. I think it's like $99 a year, just pay into that communal infrastructure. Better yet, make sure that your employer who is using Python is a sponsor of the Python Software Foundation, because this hidden infrastructure, if it remains hidden and is not well supported, we all suffer for that. And so, as it grows in importance and use, it's just so important that all of us do our part to make sure that those organizations are well supported so that they can continue looking after the projects that we love.\n\nTotally agreed, yeah, definitely. And if you're interested, do you want to share your social connection information?\n\nOh, absolutely. I am on Twitter, LinkedIn, Facebook, Instagram at either Josh Simmons or Bluesomewhere. You can also find me at joshsimmons.com. Okay, great. Well, Josh, thanks so much for coming on the show. This has been a fascinating and really awesome talk. Yeah, thank you so much for having me. I had a lot of fun. All right, thanks.\n\nThis episode was brought to you by Sentry, helping developers see issues that matter, solve those issues in minutes, and learn insights to keep their applications running at peak performance. You can learn more at sentry.io or for/python and sign up with the promo code REAL PYTHON (all caps) to get three free months of Sentry's team plan.\n\nI want to thank Josh Simmons for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "gVBp5X8IwSU": "Welcome to the Real Python Podcast. This is episode 75. Can you make a version of Python that fits within the memory constraints of a microcontroller and still feels like Python? That's the intention behind Circuit Python. This week on the show, we have Scott Shawcroft, who is the project lead for Circuit Python. We talk all things Circuit Python. While working with the language on several projects, I have developed many of my own questions to ask Scott, and he answers my questions about bootloaders, packages, the bundle, and Bluetooth Low Energy. He also talks about the struggle of fitting the language and board-specific libraries within tiny memory constraints. We discuss projects, boards for beginners, and many other resources to learn more.\n\nThis episode is sponsored by Rev AI, the most trusted way to build global speech-to-text to insights products and workflows.\n\nAlright, let's get started.\n\n[Music]\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Scott, welcome to the show. Hi, thanks for having me. So, I've been mentioning your name a bunch of times, so I've been excited to get further with Circuit Python, and I thought this would be a great way to go to the source in a way.\n\nI am somewhat to blame for it.\n\nYeah. So maybe we could talk a little bit about your background and history with Circuit Python specifically.\n\nSo, my background is that I got a computer engineering degree from UW. I spent six years at Google. And then, what I like to talk about as well is when I was at UW, I'd already done Python, and so I was a TA for the intro course. I actually did for a quarter or two, I can't remember, like a Python version of the intro course because the course was Java. So, that was some pretty early on, like teach people how to program with Python. And so after I left Google, I spent a year doing more embedded programming. For those who don't know, microcontrollers are these little inexpensive computers that are all-in-one chip, and they can cost just a few dollars or even less. That's how I learned how to program those. And then, I was looking for a job because I hadn't had a job for like a year. And I went to Adafruit, and I was like, \"Hey Adafruit, I'd love to work for you.\" And they're like, \"What do you do?\" And I said, \"I'm a software person.\" They're like, \"Well, there's this thing called MicroPython, and we'd love to have it on our boards.\" And I was like, I hadn't heard of MicroPython, but of course, by that time, I'd been a long-time Python person. So, combining this newfound love for microcontrollers, which are these very low-level, much easier to understand sort of computers, and then combining that with Python was just amazing.\n\nYeah, and that was in the fall of 2016 that I started doing that.\n\nOkay. So, we don't have to go too deep into MicroPython specifically, but that project predates it just a little bit further back, right? I think it's two or three years.\n\nYeah, I think Damien first, Damien's the original creator of MicroPython. I think he started in 2013 sometime. Okay. And then it was kind of funded by, by that point, two Kickstarters that they had done, really helped drive Python development. And MicroPython has its own constellation of microcontrollers that it runs on, right?\n\nSo, the first Kickstarter was centered around a board called the PyBoard. Yeah, that was produced by Damien as well, and that was running an ST Microelectronics chip on it in particular. And then the second Kickstarter was an ESP8266, which is a Wi-Fi capable chip. So, when Adafruit brought me on to bring it to theirs, it was another chip family that MicroPython hadn't supported. Okay. It was kind of like my first task to bring it to a chip that was already on an existing Arduino and already on a number of Adafruit's existing boards as well.\n\nOkay. And Adafruit, I listened to a recent interview with, I want to call her Lady Ada.\n\nThat's her moniker, Lamor.\n\nLamor. She was talking a little bit about the history, and I was like, \"Wow, you guys are over a decade old as a company,\" which is really kind of amazing. And then just like the scale of that business, right? They've been making, like you said, Arduino-based sort of boards, but other microcontrollers that were programmed with C or other languages.Adafruit's history originates in her dorm room. She found herself creating projects out of electronics and documenting them on ladyada.net, her personal site. People came to her saying they would love to buy all the parts for the projects she posted. Adafruit's origins are really in kitting, where you buy different parts, put them together as a kit, and sell them. As the company grew and Arduino came along, Adafruit created sensor boards and provided everything needed to get started, including tutorials, software examples, and libraries.\n\nArduino made it easy for anyone to program a microcontroller. Adafruit created sensor boards with temperature and pressure sensors. They focused on providing hardware and resources to get users going quickly. The company grew by building on the Arduino ecosystem, expanding into different sensors and technologies.\n\nThe shift to Python was exciting, as it is a more approachable language without having to manage memory. The speaker recently gave a talk at the Python Language Summit, diving into the essence of Python and discussing the differences between CircuitPython and CPython. CircuitPython is a subset of Python with a smaller standard library, prompting discussions on what truly defines Python.\n\nThe speaker highlighted the differences in size between CircuitPython and CPython, emphasizing that despite the size difference, CircuitPython still feels like Python. The talk aimed to challenge CPython developers to consider what is essential to Python and what can be separated. Discussions with other developers, like Brett Cannon, focused on distilling Python to its core components and defining what makes Python Python. The goal is to understand what truly defines Python and what can be considered separate from the language.I think the core of it is that the way CircuitPython works is, after you've installed CircuitPython on a device or you buy a device that has it pre-installed, you'll plug it into your computer and it will show up as a Circuit Pi drive. On that drive is a code.py file, and in there is a print hello world, usually by default. It is Python so you can do all the standard syntax that you're expecting - if statements, for loops, all that stuff. And it works just like CPython would. Once you save, CircuitPython will actually rerun your code automatically, similar to the watch systems that a lot of JS things do. It just makes it super quick to iterate and it's just Python.\n\nThe math is the same, although it's a subset. You will get into new APIs with the stuff that CPython doesn't handle, but generally all of that core stuff, if you're not importing anything, it's going to be what you would expect coming from CPython. People have been requesting things of CircuitPython, and there's a decision process to decide where to draw the line in bridging the Python world and the hardware world. Requests come from both sides, and there's a community of folks working on CircuitPython.\n\nIf somebody wants to add something and it fits, that's okay. If it's an API that CPython has, it must be a strict subset of CPython to ensure knowledge transfer. F-string support was added by a community member, expanding formatting options. The challenge is to be a strict subset, ensuring compatibility between CircuitPython and CPython. Under the hood, f-string support works like a string format call.\n\nI've talked with Brett about the minimum viable Python ideas and having a test suite for PEPs encoded in the minimal version of Python. It could be a great resource for alternate Python implementations. CircuitPython has become more aligned with MicroPython recently, with minimal differences on the Python VM side. Damien and the MicroPython folks have done a great job with test coverage for the VM core. The divergence is more in the workflow.Micropython does not have the auto-reload feature like CircuitPython. We are currently strict about only using USB or BLE workflows to ensure consistency across all supported devices. There is more variation in how we integrate hardware with Python rather than the Python engine itself.\n\nI have been experimenting with different boards and initially tried hybridizing some projects on my own. It's a great way to start. After talking to Nina, I decided to explore the Playground Express more to learn about the libraries. This led me to a question about updating the bootloader when someone gets a board from Adafruit, like the Circuit Playground Express.\n\nTo update the board, you need to visit circuitpython.org, find the board, and download the bootloader and CircuitPython files. The bootloader's purpose is to load new code onto the device easily.\n\nThe UF2 bootloader allows you to drag and drop a UF2 file to flash new code onto the device. It recognizes the new file and updates itself safely. Each block in the UF2 file contains information about its position and where it goes in flash memory.\n\nUpdating the firmware of the board prepares it for CircuitPython. By downloading the specific CircuitPython bundle for the board, it includes sub-packages for the hardware components on the board, like the Neopixel and motion sensor.\n\nWhen you have a specific board, you need to download the corresponding CircuitPython bundle tailored to that hardware. This ensures compatibility with the board's components, such as Neopixel, motion sensor, and USB port.But then you're adding additional libraries again, things that you said are not going to be part of Python per se. Things like being able to act like a keyboard or have USB MIDI, or what have you. Am I explaining all that right? I think at this point, I would avoid the term \"bundle,\" okay, sure, because we use that for something else. Okay, great. Yeah, but I think what you're getting at is that the UF2 file is a version of a binary. So imagine you were compiling C Python and you get a .python or python.exe out of it, right? Like that's what the UF2 file is equivalent to. But what's different is that we build a different version of CircuitPython. We actually build over 10 versions per board, okay, because we also do translations. But basically, we produce a lot of those binaries. And there we do have some control about which native modules or which modules are built into each binary.\n\nSo for example, if we don't have flash space for our numpy equivalent, which is Microlab (shout out to Zolton for creating Microlab), but typically, especially on the SAMD21s and the Express, they have a total of 256 kilobytes of flash space. And it's really hard to fit everything in there. So we have to be a little bit more rigorous about which built-in modules we support on those boards. Yeah, that makes sense.\n\nOne of the things you do is you start to do something beyond printing \"hello world,\" right? In there, you want to access things that are part of this little board. I've seen a divergence depending on the tutorial sometimes, which I was a little confused by. Where some are saying import board, which is a general term for talking to the hardware and the pins or physical connections on it. And then occasionally, I've seen for something like the Circuit Playground Express, importing the Circuit Playground Express and then giving it an alias as cp or something like that. Are you accessing different parts of the binary package underneath there?\n\nSo it's a matter of abstraction layer, sure. The CPX thing you're referring to is a big library written in Python, and its job is to abstract everything away from you. Whereas what the board module is doing, which is built-in, is just a minimal layer on top of the standard APIs. Largely, what board is doing is mapping the names of pins on the board back to the pin objects brought in by the microcontroller. So by contrast, when you've done something with importing via the CPX version of it, it's abstracted and maybe has slightly friendlier naming and less direct accessing the modules.\n\nFor example, with the accelerometer functionality, there's something called \"tapped,\" which is addressing that particular part of the circuitry. What it's doing is running the initialization code for the sensor when you say \"tapped\" or create the CPX object, which happens on import. What \"tapped\" is doing is using the library for the accelerometer under the hood to determine if it has been tapped. And that's where the CPX library comes in as one of the highest levels of libraries in CircuitPython, where it gives you a high level of abstractions on what you want to do with the board.\n\nAnd then below that, you have all the drivers for different things on the board that you can initialize yourself. These drivers talk down to the native modules that handle transactions, without you needing to know whether it's an accelerometer or not. Yeah, okay, that's cool. I think about that with another example. About a year ago, I bought the NeoTrellis, sort of an all-in-one, maybe the M4.So, it's the one that has all the four by eight buttons instead of buttons. I did a couple of basic projects more on the Arduino side with it, doing stuff in C. I was really wanting to play with it in Circuit Python. The new product came along, the RP2040, the macro pad. Yeah, the RP2040 is a particular microcontroller from Raspberry Pi, but we made a macro pad out of it. That's a really neat project. I've been watching a couple of projects come through, and I was thinking about making it be like an Ableton controller, you know, control something like Live and send out MIDI commands with it.\n\nI was able to get it sending MIDI and lighting up the Neopixels inside of it. I was having a lot of fun with that. I just need to go a little bit further. Through that process, I was watching John Park. He was doing demonstrations. I saw two different demonstrations over the last couple of weeks. In one, he was addressing a lot of things directly from the board or directly from USB MIDI. In another stream, there was a separate edition where he was able to import just macro pad, and a lot of those things were built in the same way as the CPX library for the Circuit Playground.\n\nIs that something that people just take on board and say, \"Alright, I want to do that, I want to figure out how I can combine these things and abstract them?\" It's something that, for our flagship products, we'll do the highest level of library that puts all the pieces together for you, which is what the macro pad library is. It's the same kind of tier as the Circuit Playground Express library.\n\nThrough that, I was kind of going in and out of GitHub and looking at the libraries and trying to learn as I went along. Often, you may need to add a library, and in those cases, you can get the compiled version of all the different types of packages. For the general support of Circuit Python for these different hardware devices, there's a big file that you can get that has all of them in there. This is what we call the bundle. For Python folks, the way you install a library in Python is pip. MicroPython has had micropip, but the challenge with having something on the device is that a lot of the devices don't have network connectivity.\n\nWhen I was thinking about how we would do packaging in Circuit Python, there are two pieces that led me to this world where all we do is provide a zip file with all the libraries in it. That's what the bundle is. It's just an automatic grab all the libraries we know of, put it in a big zip file. It's not even that big. There's been a couple of tools recently that our community has created, one in particular called Circup. Circup is like the pip equivalent for Circuit Python now, where it can take a look at everything on your USB drive and offer to update them for you. It can install something and all the dependencies because the libraries are now generally available on pip as well.\n\nSo, on a Raspberry Pi running Linux, you could use pip to add them just for that. But that's not for a separate Circuit Python device. We have a library called Blinka that is this layer between how Linux does hardware stuff and the Circuit Python APIs established at the microcontroller level.So our libraries work in both places now, and it's been quite the testament to our hardware APIs that we were able to move this ever-growing catalog of libraries from microcontroller land up into Linux and Python land as well.\n\nYeah, I imagine that's a pretty big project to migrate all those different pieces. It wasn't that bad actually because by being a strict subset of C Python, we knew that we could move upwards.\n\nThe one tricky spot we had was due to the way Linux exposed some particular things. We could do it on a microcontroller but couldn't really do it on Linux. So there was one specific API change we had to make, but besides that, it was pretty straightforward.\n\nGoing back to the bundle in this zip file that you can uncompress, the idea isn't to grab the whole thing and toss it on the board since there may not be space for that. It doesn't work anymore, it used to.\n\nIn this case, if you need something specific that this thing's going to do, when you get your Circuit Pi drive named, not only does it have the code.py file that runs on it, but there's also a subfolder, lib, where you would add these additional pieces of code. They can be MPY files, which are a MicroPython compiled version.\n\nMPY files are nice because the parsing process can take up a lot of RAM, and MPY files require less RAM to import than PY files. So, you end up with the equivalent Python code in memory, but the maximum RAM usage is less when importing an MPY versus a PY file.\n\nIf you have a SAM D21 board, I recommend using MPY files, but you could try using PY versions on the RP2040, which has 256 kilobytes of RAM. It's easier with PY files because you can see the source code and edit it.\n\nThe Circuit Playground Express is a bit weird because it's RAM-constrained. We use frozen modules to store Python libraries in flash to save RAM when importing them. This allows us to use the Python code from that library without incurring a RAM overhead.\n\nThe Circuit Playground Express, with its 32 kilobytes of RAM threshold, is the minimum we do. The experience in CircuitPython gets better with more RAM, and 32k is quite small now. I recommend the Bluefruit instead for anyone looking at a Circuit Playground, as it has more RAM.\n\nI guess there are two divergent things I wanted to dive into next, which is actually programming it. One way you could theoretically program this is a text Python file that you could open up in a text editor, but there are certain ones you shouldn't use because of the way they save stuff.But if you use something like Sublime Text or whatever, you could use that. \nI felt like the integration with Mu is really great, awesome. I was really impressed with how that works and the ability to kind of open up a sort of terminal where you can see the code running. That part was really powerful and it kind of gives some basic key commands too, like if you need to reset the board. I was playing around with the touch sensors and I think you were saying that when it does an import of the library, it does a calibration of a lot of the circuits that are on it. So occasionally you need to do that, right?\n\nYeah, the CPX library does. Okay, I just think that was really cool. And then again, I don't know if that's part of the bootloader thing or this watch process where it knows that you've hit save to start rerunning the code again, right? How's that done?\n\nSo what CircuitPython is doing is the bootloader doesn't know anything about this. CircuitPython is pretending to be a USB drive or it is a USB drive. That's the way it works. But what we see is what we get. We say, \"Oh, the host computer just wrote to the file system.\" And we have internally in CircuitPython just a countdown timer that says, \"Okay, we're gonna restart the code 700 milliseconds from now.\" We don't care what file it is. We have no idea what file it is because the USB protocol is block-based instead of file-based.\n\nAnd so we just start this timer and then if you're writing a big file and there's multiple blocks that it's gotta write, the timer just gets reset. So you don't necessarily get a lot of auto-reloads, but you may actually see more than one reload happen depending on your host behavior. It's possible, although not very common, to see a syntax error happen in one of those reloads as the host OS writes the rest of the file.\n\nI noticed that when I was going through one of the tutorials and I was dragging these very small audio files onto it because the device has a little speaker. As I dropped them on it, it would restart the code even though I wasn't really playing with the code. It was just moving files onto the drive itself. That's part of that whole process.\n\nOne of the things I haven't followed this thread, but I was watching the Twitter feed and kind of seeing stuff come up. I bought a Bluetooth board mostly because I have this foot twitch project I'm gonna build. It's sort of like a YouTube controller for a guitarist so they could be hands-free controlling rewind, playback, pause, and stuff like that. It could do whatever else you want once you get into keyboard stuff. I thought I should make this Bluetooth so I could do it on an iPad or a phone. This should be fun.\n\nBut then I saw and I'm not sure how far along this is or where it's at, but the idea of programming it via Bluetooth, actually talking with a code editor to it wirelessly. So, you've got a Bluetooth board which is really exciting. I've been wanting to do this for a long time. CircuitPython's goal is to bring programming in any form to folks who haven't programmed before. One of the challenges with that goal is access to a laptop or a computer, in particular. What a lot more people have access to is a phone or a tablet.\n\nSo what I wanted to do is I wanted USB support on a phone and tablet, but the real way or a better way to connect to one of those two things is actually over Bluetooth Low Energy, which is called BLE.The APIs for that have improved significantly. This summer, I revisited some work I did a few years ago on making it possible to do the two core pieces of the CircuitPython workflow over BLE instead of USB. These two pieces are transferring files and getting serial feedback back, so the serial output and input to the device as well.\n\nI have been working really hard on this and made a lot of progress this summer. However, the challenge with Bluetooth is that there is no standard for these two things. This means that there is not an app that we could just use by default, regardless of the platform you're on. It's all new, and the challenge is that we have made progress with USB because we have stayed within the standard parts of USB. We do USB mass storage, which makes it show up as a drive, and it just works.\n\nGetting all that going with CircuitPython was challenging, but once we get the device to work like a USB stick, it just works after that. With Bluetooth, we have made progress on the Bluetooth side, but the challenge now is making the host side easy to use and accessible on different platforms. It's a long-term goal of ours to bring programming to phones and tablets, and BLE is a great way to do that, but it's a lot of work.\n\nI need to get back to that this week. I took a break because it's pretty brutal work. I have an Itsy Bitsy board that has Bluetooth, the NRF52840. I used the other version for my first version of this footswitch, but then I bought the battery charging board. I noticed that it is primarily designed to sit in an area of the board with buttons. I wondered how often I need to access those buttons with BLE.\n\nWith BLE, is there a similar pairing process where I need to press a button on the board to have it connect? That's the standard part of Bluetooth that we get. The way it's working currently is that we used to be strict about CircuitPython being USB boards only, but we have loosened that restriction for boards that only do BLE.\n\nFor boards that only do BLE, they will go into the discovery process by default. They will start advertising that they are there. For boards that have both USB and BLE, you will need to hit reset to advertise. Once you advertise, you can connect on your phone, pair, and establish a secure connection.So, next time you can auto connect, right? So at that point, if I power on the device, it just connects to the computer or tablet or what have you. Hopefully, I mean I can go and look in the menu and check. Yep, and via BLE, the types of protocols that it could speak. It could act as a keyboard, correct? It could act as a MIDI device, which we were talking about earlier. Yep. Are there other areas of the BLE standard? There's a pseudo-standard for the serial stuff that we're using as well. Okay, the device manufacturer that we use is called Nordic and they have kind of a standard example that lots of people use for the Nordic UART service. A UART is a more technical name for serial, but there's not a whole lot. There's also, for iOS, we have examples where you can get the notifications from your phone over BLE. Okay, which is pretty neat. You can also get the current time from iOS that way as well. Nice, so there's some neat things there, but a lot of people just use it for HID, which is like the keyboard, mouse, gamepad sort of stuff. Yeah, those seem to be the majority of the projects that I've seen use it and actually the area that I'm most interested in and start playing with, right? Because I can think of a lot of music things that are iPad or phone-based also. And a MIDI is kind of a nice protocol because it is rather simple also.\n\nIn some ways, it's simple, but at least it, as far as transmitting information and doesn't require like mass bandwidth and stuff, which is great. It's kind of nice. Yeah, BLE does not have a lot of bandwidth, although with the newer versions of BLE, they have ways of getting more bandwidth out of it. Cool, but it, you know, first and foremost, it's meant to be low power.\n\nThis week, I want to shine a spotlight on another Real Python video course. It covers a subject directly related to this week's episode. It's titled \"Getting Started with MicroPython.\" The course is based on a Real Python article by Chris Garrett and in the video course, Darren Jones takes you through the history of MicroPython, the differences between MicroPython and other programming languages, the hardware that you'll use to build devices, and the process to set up code and deploy your own MicroPython project. As we've covered in the show, CircuitPython builds on top of MicroPython and if you're interested in using Python to program microcontrollers and build projects, this course will get you up and running with MicroPython. Real Python video courses are broken into easily consumable sections and include code examples for the techniques shown. All lessons have a transcript, including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the enhanced search tool on realpython.com.\n\nYou said you were very interested in microcontrollers. Would you consider yourself a maker? That was something that I was very interested in, you know, 10 years ago or before. I was following kind of Make magazine and the idea of crafting and DIY projects and stuff like that. Yeah, I think I do consider myself a maker. I found Adafruit when I was after I had bought a house. I wanted to have a bunch of sensors around the house to tell me like temperature and humidity over time and things like that. So that's really how I found Adafruit and I've always dabbled in the hardware side of things. For example, the thing I was doing in the year between Google and Adafruit was creating PCBs for drone flight controllers, so I was doing electronics on that. Oh, okay. So I do enjoy dabbling in the hardware side, but I have been in the software side so long that I'm way more effective and hardware is really hard. Yeah, you know, software is great because you can scale once you have something done once generally, whereas hardware, like if you actually want to start a hardware company, you got to build the stuff, yep, right? Like you have to build each unit, you have to track all the different pieces that went into it and how much they cost so that you know like what your profit was and like and then you have to sell it to someone and support them and maybe it got knocked in the mail and now it doesn't work or they haven't managed to get it working on their computer or things like that. Like the hardware world is really hard. Yeah, I've been watching Stargirl over the last year and a half go through all of that with the Winterbloom, yeah. So that's pretty intense. Yeah, yeah, yeah, and like now even a lot in the last year, this new chip shortage, it just made it that much more difficult. Yeah, we're very lucky that Adafruit's investment in CircuitPython has meant that we support a lot of different chips and so we're able to take the Adafruit product line in the direction of chips that we can still get and still use all this software that we've created that runs on CircuitPython as a result. Yeah, I want to get a macropad and they're all out. [Laughter] Yeah.I got my name on the list so they'll get notified. Right, that looks like a perfect little product to do these sort of musical and other keyboard projects. Yeah, I like that it has a display, that's very cool too. For folks who don't know, a macropad is like a mini keyboard, like a 10-key looking kind of thing, right? So this is like it. It's got an OLED screen in the upper left-hand corner, and then it's got a rotary encoder, which is like a knob that you can spin infinitely in each direction. And then it's three keys wide and four keys tall. Each key has an RGB LED, we call Neopixel underneath it as well. So that's kind of what a macropad is, and you can use it for doing all sorts of keyboard shortcuts and things. I just set mine up so that I can play and pause my Spotify based on a key. \n\nYeah, totally, it's been really handy. There are so many neat little projects, and then the idea that it doesn't have to be designated for that for its life, the reprogrammability is so cool. What are there other hardware projects or pieces of gear that excite you in this realm right now that Adafruit's offering? The macropad is the thing that we're pretty excited about right now. The thing that I'm excited about that I want to do at some point, like the BLE stuff, is a long-term thing I'm very excited about. But I'm in the weeds of it right now, so I'm somewhere between excited and not excited. One thing I really want to do is I like pushing the boundary between Linux, Python, and CircuitPython, and microcontrollers. One thing I want to do to blur that line even more is I'd like to bring CircuitPython to the Raspberry Pi.\n\nBut that means no operating system, that means just CircuitPython itself, okay? In my mind, it occupies a space that's very similar, like a modern version of a single-task operating system like what the Commodore 64 had or the Amiga. You turn it on, and it's ready to go. Turn it on, you get a Python prompt, it plugs into your TV. This is why the Raspberry Pi is the thing that I'm thinking about, it has really good HDMI support. So I bought a 400 recently, the keyboard, exactly one. Imagine plugging in a 400 and being very much like a Commodore 64, where it's a keyboard and a computer all in one. You plug it into your TV, and now you've got a computer.\n\nI think CircuitPython's strength is that there are a lot fewer layers between you and the hardware. I think that's really good for people who are getting into computers, so I think it would be really interesting to see how people use CircuitPython in that kind of environment. It's going to be really awesome because it's like gigs of RAM and very, very fast. So it's going to blow people's minds in CircuitPython who have come from a smaller microcontroller. But then at the same time, I think people are going to be like, \"Wait, I don't have a web browser.\" \n\nRight, and that's really where Linux does a good job of multitasking and desktop environments and things like that. So I'm excited to push that boundary. Theoretically, could that happen just by exchanging out the card you boot from? Yeah, so the Raspberry Pi usually runs its operating system off the micro SD card. Yeah, so yeah, it would just be, hopefully, I'd bug the people I know at Raspberry Pi to say like, \"Hey, put us in your imager or whatever it's called.\" So that, right, there's choices, right? You could select Raspbian or Ubuntu or whatever, or CircuitPython and flash that onto your SD card.\n\nAnd then you would get CircuitPython on a Raspberry Pi. One of the challenges is that we'd still like this USB or really workflow to work, and a lot of the Raspberry Pi's themselves don't expose the USB device side where they act like a USB device. What they have instead is USB host where you plug a USB device into it. So there is some weirdness there, but they've come out with the Compute Module 4, which is a really neat little version of the Raspberry Pi but in a module form. So we could create or people have created kind of boards that those go on to that do expose the USB device side, okay?\n\nThere's a crowd supply called Piunora, which is done by Timon, who's a person I met at a Supercon, I think, and we got talking about this idea, and so he made it happen. There's an Arduino form factor, the Arduino Uno form factor, which is also an Adafruit land, the Metro. There's a version of that, but it fits barely a Raspberry Pi 4 Compute Module instead. It's very much like blurring the line between single-board computer and microcontroller, which is really neat. So that potentially could have that HDMI out and stuff too then, right? So it does have a full-size HDMI port on it, okay.But it also has a USB port that has a USB device, so you could treat it like a metro, but you get HDMI out. Wow, cool! You could have Arduino shields or something on it as well. I'm excited to push the boundaries of what that is and learn about how those systems work because they are a different tier of system on a chip. I'm excited to start learning more about Cortex A arm chips instead of Cortex M.\n\nThat's like a whole other scale, a whole other world because Cortex A's are what you would expect to find in a phone or a tablet, and they're really meant to run Linux. So a lot of the documentation is just like, \"Here's our Linux kernel,\" and there's not a lot of great docs because not many people use it outside of that environment.\n\nOne of the other areas I was thinking about is, do you have suggestions for a good starter board? I would start with the Circuit Playground Bluefruit if it's in stock. It has more memory, Bluetooth, and provides more RAM, which really helps and is faster as well. The Playground Express is fine, but for more complex projects, the Circuit Playground Bluefruit is better.\n\nI was asking you this offline, but did you have a suggestion for feather wings or other add-on boards to attach to the microcontroller for higher quality audio or other features? As a software person, I think we should think about hardware form factors as APIs. A feather is a board with particular locations for pins, and a feather wing is an add-on designed to interface with that API. Stemma QT boards are also common for sensors and use I2C.\n\nIf they don't fit into those form factors, they're generally known as breakout boards, which are PCBs with chips that need to be controlled externally. For audio, the DAC on low-cost microcontrollers may not be great, so for better audio quality, you'll want more speed and RAM for higher bit rates and sample depth.\n\nI don't know of any great DACs on the devices themselves.I would suggest looking into an i2s stack. i2s is a protocol for audio between a microcontroller and a dedicated chip that does digital audio conversion. They will do a better job than anything built into a microcontroller for potentially adc analog to digital conversion or digital audio conversion. The microcontroller would be used for sending commands, not the actual conversion part, which might be too slow. It will send digital data for sample values, not voltage.\n\nGenerally, for audio out, things can be done that way, but for microphones, microphones that output audio or i2s directly can be used. However, keeping up with all that data can be a challenge. A co-worker has been spending time solving audio playback problems on the rp 2040, which has been a challenge due to concurrency and loading samples.\n\nComputers are good at moving numbers around, and working at the hardware level in microcontroller land feels like working with machines. Displays have availability issues due to the chip shortage, with three classes being oleds, tfts, and e-ink. The macro pad has an oled display, and other options include pi portal, pi gamer, pi badge, and the clue.\n\nCircuit python shows serial output on displays by default for troubleshooting purposes. This feature provides a Commodore 64 era computing experience. Adafruit has an electronics show on Wednesdays, which is how I got the job.Oh, okay, cool. So for a long time, Adafruit has been doing their Show and Tell. It's a half-hour. We did do an hour for a while during the pandemic, but we're back to half an hour. You can join the video chat and show off your project. It's run by Phil and Lady Ada, who are the folks that started and run Adafruit. When I was doing my drone stuff, I was going on there kind of every week and showing off the drone stuff I had done. When I realized that's not what I wanted to do, I went on there and said, \"Hey, I'm looking for a job.\" The next day, I got an email from Phil, and the rest is certified in history, I guess.\n\nI always encourage folks who want to get more involved in our community to join that Show and Tell. It's at 4:30 Pacific time, which is 7:30 Eastern. It's followed up by \"Ask an Engineer,\" which is an hour-long show covering top-secret stuff they're doing, news from around the web, and all the new products that went into the store that week.\n\nThere's an event coming up celebrating CircuitPython as CircuitPython Day, which is on the 6th of August. It may vary the day; we were in September last year. We're just going to be doing some extra streams and show off any projects that people have done. It kind of originates from Arduino Day, and they actually do physical meetups for Arduino Day as well. There have been some CircuitPython Day meetups that folks have done too, but on the Adafruit side, we just facilitate it and do some streams. I normally stream Fridays at 2 PM Pacific on the Adafruit channels.\n\nI'll be doing that, and it's being advertised as a special edition, but I'm not sure how I'm going to make it special. By the time folks listen to this, hopefully, I'll have figured it out and made it a special stream. There will be some other streams not regularly scheduled on CircuitPython Day as well to highlight everything. I use multiple channels when I do that. YouTube seems to be the simplest one for me. I know it's being rebroadcast on some other tools. Are you on Twitch or Discord or what are the other ways that it's being connected?\n\nWe have a Discord server, an Adafruit Discord server that we've had for four or five years now. We started that because as I got more involved in Adafruit, I found people that I was chatting with during these live streams on a regular basis. The problem with the chats, especially on YouTube, is that the chat goes away when the stream is done. At some point, somebody said, \"Look, we should have a Discord server.\" We're over 30,000 accounts now, nice. If folks want to join, you're welcome. It's the URL adafru.it/discord or discord.gg/adafruit will get you there too.\n\nThe way we live stream is we use a service called Restream. I use OBS on my computer, so OBS connects to Restream, and Restream connects to YouTube, Twitch, LinkedIn, and Periscope, which is Twitter. We used to do Facebook, but there were credential issues. We get the streams going to a lot of places. There's a lot of chats to pay attention to, but that's what I was watching you do, and I was wondering how you do that. You're pretty skilled at it. It's taken some practice.\n\nUsually, on my stream, it'll be at least YouTube and Discord. We get a lot of folks watching on YouTube, so it makes sense to do that. Off-screen, I have the Restream chat, which aggregates the other two services. I can see Twitch messages and LinkedIn messages there as well. They just won't show up on the stream because I have more trouble moderating those messages. I wanted to make sure I can moderate the messages on the stream, and it's a little less ephemeral in the sense that you can keep a log of all those messages.\n\nOn the Restream, I don't keep those. Usually, the volume is really low. If it's a question or something, I'll read the question off anyway because my stream tends to be two hours or so. I know that people aren't watching with their eyes necessarily.So I do try. If I'm going to answer a question or if there's something in the chat, I'll try to read it off so that people who are doing something else and listening in can follow along. \n\nI have these weekly questions I like to ask everybody, and the first one is, we've talked about what you're excited about in CircuitPython and the developments there, but what are you excited about in the general world of Python itself?\n\nI think I'm very excited to see more people come to Python. I've seen some people be hesitant about how many data scientists have come into the CircuitPython world. But as somebody who is trying to be on the forefront of bringing more people into programming and understanding computers are not magic, and the decisions that computers are making are because a human told them that was a good decision to make, I'm really happy to see Python grow with a wide variety of people who are working on it. I think my partner is a data scientist, and I think data scientists are soon to rule the world because we see so much AI stuff. The people who are deciding whether an AI is good or not or doing a good job or not are data scientists. So I'm very excited to see Python be an ambassador for computers and programming to fields that are not just programming, yeah, hardware, and software. CircuitPython is definitely part of that as well, cool.\n\nSo what's something that you want to learn next? It doesn't have to be Python-specific, but what are you interested in learning next? Well, I already talked about the Raspberry Pi stuff, that is definitely part of it. Maybe I'll talk about non-CircuitPython stuff, which we talked about before the stream as well. But I've been really digging into how internet systems work, how broadband works, and I've been learning a ton about both policy, particularly public broadband policies in the United States, and how cable companies have messed with that, and how certain organizations in the US are doing a really good job of providing high-speed affordable broadband to everyone. Because, like my previous answer, I'm a very big believer in the power of technology, and having internet access everyone having internet access is critical to that. So I've been learning a lot about how broadband systems work, how legal systems around that work, and how you could potentially start or run or do an internet service provider for folks so that everyone can have access. \n\nThat's awesome. Do you have any additional shoutouts that you want to give or plugs? If you liked what you heard about Adafruit, I am sponsored by them, meaning they pay me to work full-time on Adafruit and CircuitPython, which is all open source. Adafruit pays the bills and my bills via open-source hardware. What that means for hardware is that you can see how all of the things on a circuit board are connected together, and you can actually take the files that produce the circuit board and modify them yourself. So if you're new to the idea of open-source hardware, it's a good thing. Adafruit is one of the leaders in the open-source hardware world. So if you want to support them and me, there's kind of two ways to get into it. Adafruit.com is where you can go to purchase stuff from Adafruit, that's where you can get these Circuit Playgrounds, either the Express or the Bluefruit. But the other way I like to encourage people to get into this if there's something that sounds interesting but you haven't yet is actually go to learn.adafruit.com. I talked about the origins of Adafruit, and it's all in these guides, which are tutorials on how to make something. So Learn is really cool in that it's all the tutorials that we maintain that show you all the different things that you can do with stuff that you can buy from Adafruit. If you're not sure where you want to start, learn.adafruit.com is a great place to go and just browse and find that MIDI pedal that piques your interest. It is advertising for Adafruit, so what will happen is that you'll see all of the instructions, all of the code for doing this project, but you will also see all of the products and you'll be able to add them to your cart from there. That's the best marketing, I think there can be, to teach you how to do all of that. That's a great way to get into hardware as well. \n\nWe were talking before also that you guys have this thing called the AdaBox, which is right, is it quarterly-ish? Maybe you could tell us about that. Okay, so AdaBox has had some struggles with chip shortages and COVID. AdaBox is a subscription service that Adafruit does that tries to be quarterly, tries to be every three months. It is a box where we put something cool in it and we'll teach you how to do a number of different things with it. Circuit Playground Express was one of the earliest ones. One of the more recent ones is we have a product called the MagTag, which is a Wi-Fi connected e-ink screen that you can put on your fridge, so it has magnetic feet as part of it in the box as well, okay.So in some ways, it is like a mini Kickstarter every three months from Adafruit. It's kind of like one of our core flagship things in that box every three months. And I did give caveats that it's not always every three months, but don't worry. We don't charge until we're actually shipping. So if we ever do miss our mark or push back a box by a month, you just won't get charged until it's actually ready and shipping. Cool, so that's what AdaBox is.\n\nIf you pay a bit more attention, we do tend to gear the stuff that we're working on in CircuitPython towards upcoming AdaBoxes. Maybe it's a little bit of a dirty secret, but it is meant as a forcing function for us to get our software side of things set for the sorts of projects that we want to do.\n\nNice. I think Adafruit's success has largely been because it's very project-driven and like, how can we write a guide and then what? Or what do we want to do and what software and hardware do we need to be able to do it?\n\nYeah, and that's a really good way to do it, I think. Absolutely. It's useful for something at that point.\n\nDo you have any, we mentioned a lot of the different streams and other ways that people can kind of find you online. Are there any other social connections you want to share? Well, I'm on Discord. I go by TanNewt online, T-A-N-N-E-W-T. It was randomly generated in like 1999 and not taken. All right, I was almost, I can't wait, which I kind of wish I just stuck with. But I think somebody had already had it on Twitter or something, so I was like, I'm gonna come up with something else. But I've been that for a while. So my personal website is tanoot.org. It's kind of old and not updated. I don't even know if it says that I'd worked for Adafruit for like five years, so I should update that. But I'm Tanner on Twitter, I'm TanDu on GitHub, so you can find me that way. I'm Tandy on Discord as well. And if you want to stop by, we do the streams 2 PM Pacific on the Adafruit channel. So you can go to youtube.com/adafruit to watch every Friday at 2 PM. Those are all great ways to get a hold of me if you want to jump into this awesome community of hardware and software. Yeah, definitely. Hey, thanks so much for coming on the show. This has been really great. Thanks for having me. And putting up with a bunch of garbage trucks. Don't forget, you can try out Rev AI with your first five hours for free at rev.ai. That's dot rev.ai. I want to thank Scott Shawcroft for coming on the show and I want to thank you for listening to the Real Python podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "G3X7FAFW-6Y": "Welcome to the Real Python Podcast. This is episode 82. Earlier this year, the Python Software Foundation announced the creation of the Developer in Residence role. The first visionary sponsors of the PSF have provided funding for this new role for one year.\n\nWhat development responsibilities does this job address?\n\nThis week on the show, we talked to previous guest, Wukas Lang about becoming the first Python Developer in Residence. We talk about how the first months in this role are shaping up. Wukas discusses the need to address the backlog of open issues and pull requests. He also talks about how he's working to help the project's volunteers move their contributions forward.\n\nWe cover his PyCon 2021 talk about generating real-time FM audio synthesis in Python. He also shares his experience developing a similar synthesis engine for an embedded hardware project.\n\nThis podcast episode is brought to you by DataStax Astra DB built on Apache Cassandra, now made easy in the cloud. Get 40 gigabytes of storage free every month at astra.dev.\n\nPython, alright let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Welcome back to the show, Wukash. It's a pleasure to be here.\n\nSo, I wanted to start off talking about your PyCon 2021 talk \"Generate Buzz with Real-Time FM Audio Synthesis.\" I thought that was a really fun talk that you did.\n\nNo, thank you. I also enjoyed doing it. It's kind of a little off the wall. It's not my typical work in Python. And it seems like you've taken that project and somewhat merged it into the other talk that you had the year before about asyncio and the AI tone sort of library, which we discussed when you were on the show almost a year and a half ago now.\n\nYes, I've been doing sound work for quite a while. So, this is just an evolution of what I've been doing in the past. People think of Python as this interpreted slow language where you can do a bunch of stuff, like for example, MIDI sequencing, which is not very heavy in terms of real-time processing. But then, obviously, everybody would like to also create and mangle sounds in their programming languages of choice. And for the longest time, I would think that Python isn't, unfortunately, not up to the task. But turns out I was wrong. You can actually do real-time audio synthesis in Python, and this is what the talk was about.\n\nIt was really cool, and I would guess that in some ways using FM synthesis, I don't know if that's easier or harder than say other forms of digital synthesis.\n\nWell, they're all quite different from one another. FM synthesis is quite unique in the sense that it doesn't try to model electric circuits that you have in the analog world. It just goes digital all the way, and this is what Yamaha did in the 80s with the DX7 synthesizer, one of the most famous synthesizers in the world in history. It's kind of still considered cheesy here and there because of how overused that sound was in the 80s. But at this point, we are so far from the 80s that it's also becoming quite nostalgic. So just recreating those sounds was quite a pleasure to me, and it turns out that you can actually go and create pretty indistinguishable sounds from the original. It's pretty passable, I would say.\n\nDefinitely, I totally understand what you're saying. Like I think a lot of people when they think of 80s music, they hear that crystal piano kind of thing.\n\nYeah, but I love the way that people were using it with video games and trying to generate all the different parts of the music, the funky drums and bass, and other things that you can emulate in FM in its own kind of funky way.\n\nAbsolutely. For a short while before memory was very cheap in large quantities, having long samples of a big library of sounds was not really that feasible for sound cards. So instead, you had sound cards in PCs in the early days that were also rocking Yamaha chips that were FM chips. So those games, those early 90s to mid-90s games very often also have wonderful FM heavy soundtracks. Some of the Sega consoles also have Yamaha chips in them. So this sort of sound is really nostalgic to a large audience.\n\nDefinitely. Think the Doom soundtrack or Command and Conquer, or things like that. I could think of.\n\nCool. Kind of looking at the timeline as an outsider, it looked like you started to play in the FM world with Python and then you got more involved with this company called Polyend. You had mentioned the Tracker when you were on the show.\n\nYes, that I think you had bought one and then you kind of got involved with working with them.\n\nYeah, like so what are trackers? Just like a minute on that so.Yeah, sure. Those are programs made famous in the 80s and early 90s that allowed for programming music using very short samples. The music could be used in games and other programs at the time for Commodore 64 and Amigas. They are kind of weird in the sense that they are sequences of four tracks, and time goes down in the sequence, so it really looks like you're programming music in Excel.\n\nBut what that gives you is a notation that has the verbosity and richness of music notation, just with all the effects and settings needed for computer music. My first steps in producing music on a computer were with trackers way back in the 90s with the Amiga. Polyend, a Polish company, released a hardware tracker, a device that you can bring with you wherever. It has a screen and controls tailor-made for this workflow. It is very power efficient, allowing you to make music for tens of hours on end using any USB power source, including power banks. It also has an FM radio, line-in sampling, and more, making it a standalone audio workstation. I got very excited as a user and wanted to have that device.\n\nI was nostalgic for trackers of the past, but this device sounded very focused. Nowadays, you can have a phone or a laptop that does everything, but it can be challenging to focus on just one thing. Until the M1 Macs, talking about tens of hours of battery life seemed like fiction. I was excited about this device, bought it, and found out it wasn't perfect. It was great for what it did, but I found some bugs and reported them.\n\nAfter a while, they told me I could look at the code and maybe fix some things because I seemed technical. I have some C Python experience, but C++ was something I was wary of. However, looking at the code, I realized that embedded CPUs programming is much different from regular desktop or server-grade programming. You simplify a lot because you can't allow yourself to run out of memory in a real-time device like this.\n\nProgramming for this device turned out to be much more pleasurable than I expected from C++ code.So I ended up being quite productive in this, even though there were not many new features I could add to the tracker since it was already a pretty mature product. However, I also received Medusa, a synthesizer that Paulie and Dread, a Greek synthesizer manufacturer, had created two years before. It turned out that the MCU, an integrated system on a chip used by the synthesizer, wasn't heavily used because a lot of the sound generation came from actual analog circuits, making it an analog-digital synthesizer.\n\nAfter talking to the owner of the company, I convinced him that we could add FM synthesis to the device. This would add a new mode of operation to the existing product. After about two or maybe three months of work, we released Medusa 4.0, a big firmware upgrade that added FM synthesis. Some musicians I know and admire, like Geraldo Bernocchi, who worked with Brian Eno and Harold Budd, used this new mode of the synthesizer and contacted me to express their appreciation.\n\nDiving into C++ and working on an embedded machine required a narrowed version of the language. I recently had a conversation with Scott Shawcroft about CircuitPython, which felt similar in some ways. Working on embedded devices allows you to focus solely on what the hardware does without the overhead of an operating system.\n\nThe nice thing about starting the FM experiment in Python was that it provided a comfortable feedback loop for understanding FM synthesis. Translating this to C++ was a matter of transferring the knowledge gained from Python.\n\nOverall, working on embedded programming allows you to have full control over the device without the complications of different operating systems or libraries. It provides both a big responsibility and a sense of freedom to understand the device from start to finish.Yeah, it turns out that even though Python was able to generate some sound with some polyphony for me, when I wanted to use my Python-grade synthesizer to record music, I ended up accelerating it with Sython. I bumped up the number of voices that could be heard and played at the same time by moving a small part of the algorithm to Sython. This made it very easy for me to later map out the process in C++.\n\nThe embedded system I was working on had very little memory, with only 64 kilobytes for essentially everything, and 256 kilobytes for memory. There was a lot of code golf to fit everything into the memory of the device, but the biggest challenge was the limited memory. The algorithm was rewritten from my Python version to the C version and it worked seamlessly.\n\nPython excels at letting you think about what you're trying to do before executing it. It was much easier to work on this project this way than if I had started in C++ from the beginning.\n\nIt's been a theme lately among developers to appreciate Python for its flexibility in translating ideas into different languages or platforms. I enjoyed working on this project because it was a tangible device that musicians could use as a musical instrument in real-time.\n\nThe role of developer in residence is a dream come true for me. I have advocated for the Python Software Foundation to fund the development of Python, as it plays a crucial role in the future of the language. The PSF protects the trademark and funds infrastructure, without which Python would not be as successful.Right, so all of this is important, but the missing piece was actually sponsoring core development. I've been at this problem for quite a while. Actually, back in 2016, I ended up organizing the first course sprint, like a seven-day event only for core developers, where we could meet in person and develop the next version of Python. The first one at the Facebook campus in Menlo Park was shortly before the release of Python 3.6 beta. Beta is the feature freeze. It was very important for us to finish the unfinished features so that they could actually be released as Python 3.6. I think to this day, still, this has been the most productive week in the project's history in terms of merged commits and finished PEPs and actual closed features. This is one of the reasons why Python 3.6 was such a leap from Python 3.5. It's still a quite popular Python version because it was a good release.\n\nI've been at this, that we should sponsor Python to be also developed by the PSF. In fact, the PSF did sponsor sprints in 2016, and since, if it weren't for the pandemic, it would probably be doing that yet. Since 2020, we had to move to sprints that are online, and this year we're going to have that another time. I'm going to be helping with this in a quite different role right now. I very deeply believe that there is a big difference between a hobbyist project where you can spend a little bit of your time here and there and a project that is run day in, day out for eight hours a day by a bunch of developers and actually maintained in this well full-time manner. You can see how a new programming language has sprung up in the past 15 years and essentially overtook Python in terms of developer efficiency and velocity of releasing new features. However, the big difference is that they are mostly controlled by either single corporations or by groups of corporations, so it's a much different model for funding.\n\nI've been kind of whining about the fact that, yes, the model is different, but we still should be having somebody who is helping other core developers who are not full-time so they cannot spend the same number of hours on, I don't know, untangling a merge conflict or fixing some CI problem that is not actually their thing but is simply read on their particular pull request and so on and so on. So, I did that for quite a few years.\n\nIt turns out, I learned early this year that Google is sponsoring a first developer in residence position for CPython. I was very happy to hear this, and a bunch of people asked me, \"Hey, will you apply for this?\" I was kind of wary and terrified at first because I understood that, well, first of all, I've been asking for this a lot, so maybe possibly I should also be the one that says, \"Okay, I'm going to now put my money where my mouth is and actually apply.\" I wasn't at all sure who is going to get this role, but at least I should apply. But at the same time, I felt like, now I'm living in this house in Poland, quite in the middle of nowhere for most of my friends from the US and Berlin, but a comfortable life. I have everything that I need to keep my family secure and healthy. Maybe there are other core developers who need this funding, who need that money more. I was quite worried that I don't want to take this away from somebody who might need it more.\n\nAt the same time, I had a few talks with other core developers about this, and they let me know that this might be true or not, but this is not for you to decide, but to the steering council and the PSF actually deciding who is going to get that role. So, this is not your responsibility. Don't worry about it. What we need to worry about is that the person who is going to get that role has a decent chance of showing that this kind of role makes sense, that it pays to sponsor this for the next year, because this is for now a contract for 12 months. In the end, I thought, would I want to do this? Yes, that's my dream job. I've been doing this as fun as a hobby, kind of in bursts of activity. I was never very regular in my contributions, but that's mostly because I was in my job.Right, so I decided that I really want to be a part of this, at least to put my resume out there. I had to write a cover letter, which was probably the first one in 10 years. In the end, there was a round of interviews with the PSI and the student council, along with a bunch of other people. They ended up choosing me, which was wonderful news because I believe it is important for Python. Google made a wonderful setup for this role, which means it pays Bay Area grade money, without any localization. This is the best of business grades for this role, something I would do for free, especially spending time with core devs who I've known for more than a decade.\n\nAnother thing to mention is that Google sponsors this without any demands. There is no list of features or bugs they want us to implement or prioritize. It's a clean-cut sponsorship where the project gets funds to use as needed. This is the best model I would come up with, as it's how large users of Python can pay back for the value they're getting.\n\nThere are different directions to go from here, but I thought we could talk about your blog post titled \"I am the new seat Python developer in residence\" and discuss the expected responsibilities in this role. Ever since the announcement, we're almost two months in, and I have a better view of the ideas versus the reality. The role of a developer in residence can be used in various ways, and one of the main responsibilities is to address the influx of pull requests that pile up daily on Python.\n\nThe biggest pain point currently is the overwhelming number of pull requests that need to be reviewed and merged. Some need fixes, some are bad ideas that should be rejected, but some are ready and just need someone to review and merge them. This is where the developer in residence role can make a significant impact by addressing these pain points and improving the overall development process.This is worth the risk because every change is a risk, like it's a responsibility to merge something obviously, but there's not enough reviewers. So instead of being a wannabe Leonardo da Vinci, what you should really be is this kind of project janitor. This person makes sure that the pipes are flowing, everything is good, there's electricity, the walls are clean, and everybody who is doing the real work is able to do their best job. This was my original idea. Obviously, the steering council had the realization that you can lose a lot of time doing something that doesn't pay off well because it's hard to say where the biggest needs are right now.\n\nApart from blindly merging pull requests and reviewing pull requests, I'm also looking into where the most energy of the project is going. I'm putting together a blog post about libraries with the most activity, files that are changed frequently, and pull requests for files that almost never get merged because nobody looks at them. Python is over a million lines of code, with half being C and half Python. It's a myth that everybody knows everything about Python when contributing. There are parts of Python that contributors may never touch until seeing a pull request for that part.\n\nThe role of the contractor for 12 months is to accelerate the experience of existing contributors, including core developers and those with good intentions to fix personal issues. Many people want to contribute to make Python better, but their bug reports go unanswered or pull requests remain stale. While I cannot fix all the issues, I can try to make it better.\n\nI've been watching from the sidelines, trying to educate myself, leading up to Python 3.10. I've seen terminology I wanted to define for the audience. You mentioned bugs and pull requests as separate channels, with bugs being defined as BPO. Python has evolved since its release in 1990, with changes in version control systems and bug trackers like bugs.python.org.\n\nThe bug tracker was developed for the project when migrating from sourceforge to svn. There are still issues in bugspython.org with unnaturally high numbers.So, now the actual issues that you open in the bug tracker are in the thousands, but there are ones that are over a million. Like, what is that? Well, those are the ones that we imported from SourceForge way back when, like 20 years back. So ever since we had this bug tracker and now that we have GitHub, it is kind of weird sometimes. GitHub is a viral system, right? It really invites you to do everything on GitHub. So when you have pull requests, it's very easy to just put comments there and keep the conversation going on the pull request alone.\n\nIn the end, what we want to do is migrate again from bugs.python.org to use GitHub issues, like many other big modern projects. However, this is going to be a big migration. It already takes a long while. I believe Seo Melody is now quite busy actually trying out migration scripts that will enable us to still keep issues that we have in bugs.python.org today, alongside with the comments that were made historically on those issues, to actually have all this in GitHub. So, that's going to be very good for the kind of developer experience, including the so-called drive-by developers. So, somebody who just notices a typo and they're like, \"Oh, I can just fix that from the GitHub UI,\" because now you don't even have to have a checkout, you can just do it straight from the website. This is going to become much easier.\n\nBut today, we still have bugs.python.org, so BPO, and they have their own numbering of issues. It's a system for which you need a separate account. It's got a timeless UI, let's call it that. It's nice parts where the search is super powerful because we have many fields that can slice and dice issues however you like. But at the same time, it's kind of intimidating for many people. So yeah, we're going to be moving to GitHub issues. I hope soon, it's gonna make my job easier. But when that's going to be, well, that's a little bit outside of my jurisdiction. I'm the user of that workflow, I'm not working towards changing it.\n\nSo, those are literally things that people have found that are potentially they are including a fix with it, but in many cases, they're just sort of reporting it as a bug. And that's a very different process than someone coming into GitHub and actually creating a full-on pull request. If people aren't familiar with that, once we're migrated, it's going to be the difference between choosing the issues tab versus the pull request tab. Obviously, for the latter, you're going to need some code that you're going to change.\n\nCurrently, if you only want to report a problem that you're seeing, you should go to BPO to bugs.python.org, log in, otherwise you cannot really submit anything. Then you just fill out the form. The form is pretty verbose, it asks you a lot of questions, but you can put a lot of information already there. And a lot of people are doing this. So yeah, our issue gathering system is pretty great to also track how the discussions on an issue were taking place. However, currently, this is already one foot in GitHub because as I said, it's very easy, it's very tempting to just continue the discussion on GitHub already if you're already there on a pull request because it's simply a very nice to use UI. It's very inviting, it's very rich, supports markdown and what's not. You often just forget to come back to bugs.python.org where historically we would want all conversations leading to a change to happen because it's also the history of the project, it's important.Okay, now this is sort of halfway between GitHub or BPO already so it just makes sense to move everything to GitHub so that we have it all in one place. Do you think you were kind of hinting at this idea that maybe there could be stronger forms of metadata about the PRs being submitted so they can be aggregated or looked at in certain ways? Are there things that you see potentially, not right now, but in the future, that could improve that process? This is actually, from what I'm hearing, one of the challenges of the migration where some fields just don't map to functionality that GitHub has. So we're going to have to drop some information in a normalized way, as some data sets because it's a combo box or a special field for some information. During the migration, we will only be able to put it either as a label, which is not the same thing, or as text in the original reported issue. Some data like we won't be able to use anymore in such an easy way as before. The obvious question is, is that a deal-breaker? I believe it isn't because many of those fields were low quality to begin with. Humans fill them out, so if you provide too many fields, some will never be filled regularly enough to depend on them. For example, when closing an issue on bugspython.org, there are three separate fields to look at: the state of the issue, the resolution, and the stage of the issue. It's a little too verbose, in my opinion. Maybe this has some marginal use sometimes, but most of the time, you can infer the stage of an issue just by looking at whether there are open pull requests on it. Without all this automation now, I need to look at three fields every time I close an issue, and I close around 15 of them a week. It's not the end of the world, and being paid for this makes me really relaxed about a lot of this manual work. It's part of the job, but not having to do that will make it faster for me to plow through the existing issues that are reported. It's a matter of UX, like making the developer's life easier by streamlining how the issues are worked through, because there is a workflow through every issue. It's being opened, we need to look at it, decide if it needs a patch, someone writes a patch, we review it, merge it, or reject it. It's different kinds of closing. I believe it's interesting because now that you're in this role, and there's a person in front of this stuff, that person would realize that there are different optimizations that could happen to this process. People who only contribute occasionally won't see it, and the person who's always involved will have a different idea of how it could be more efficient. All that makes sense to me. Of course, one thing I decided not to do is to have too many opinions too early. I was a drive-by contributor for years, with a bunch of PEPs in my name, but that was over 10 years. Now I'm sitting in front of the computer eight hours a day, looking at pull requests and coding myself. I tend to steer towards reviewing others' changes rather than writing my own because it takes so much time to come up with a sensible change. In the same time that I write a single change myself, I can probably review three or more.So it's just better for the project to accelerate others than to work on your fun thing of the day. In any case, now doing this, I would sometimes be tempted to say, \"Hey, I personally would like it if this worked like this, right?\" Am I in any way better informed about those things? Like, I'm not sure yet because I only ever started to do this day in, day out in July. So I'm giving myself some time to decide whether parts of our bigger workflow make sense or not. Because if they were really so unworkable for hobbyists, they would probably already do something about this.\n\nWhat I am working on, though, is, for example, addressing breakage of bots. Where if the bots that help us merge more requests faster generate backboards to different branches, if for some reason they're offline or they're not doing their job, or they are out, everybody is slowed down. So now having somebody doing this full-time allows that somebody to spend time on fixing the problem. Obviously, if this is your hobby, you don't want to fix infrastructure for the project. You want to work on your hobby feature that you want to see finished. This is different for me now.\n\nI've done some changes to the bots. I'm now kind of able to see the exceptions that we are getting occasionally on them and improve on that and so on. For example, a build bot. If I see that some build bot is dead, it might be for many reasons. For example, just the other day, there was some Windows build bot which started airing out with really weird failures of our unit tests. The root cause of this was that some Windows update needed user interaction on that particular build bot. If it didn't get it for a long time, it just hogged all the CPU power on that machine, so it ended up timing out things that never timed out before. I reported this in great detail to the owner of that build bot, and they were able to fix it quickly.\n\nFor example, I would report that some build bot that we have marked as stable, so it influences releases of Python, is not really stable for a reason or another. We would decide if this is something we can improve or should that build bot be excluded from this set. One of those issues that I feel like I'm going to have to tackle at some point is async I/O on Windows. I don't mean with Windows Subsystem for Linux, but actual Windows. It ends up being a little race conditioning on our unit tests, so we have spurious failures on Windows just because of that. We need to fix this.\n\nI already did a Windows 10 install from Microsoft, and I'm going to be looking into this in the coming weeks. Hopefully, we can fix this problem once and for all because it upsets our contributors every now and then when a change that is totally unrelated to async I/O would somehow fail or async I/O tests on Windows.\n\nThis week, I want to shine a spotlight on another Real Python video course. If you want to learn more about speech recognition or add those types of features to your projects, I think you'll get a lot out of this course titled \"Speech Recognition with Python.\" The course is based on a Real Python article by David Amos, and the instructor, Darren Jones, takes you through how speech recognition works, what speech recognition packages are available on PyPI, how to install and use the speech recognition package, and how to work with input from a microphone or sound files.\n\nIn the end, you also get the experience of creating a \"Guess the Word\" game to learn how to put it all together. Like all the video courses on Real Python, the course is broken into easily consumable sections. Plus, you get additional resources and code examples for the techniques shown, and all course lessons have a transcript, including closed captions. Check out the video course; you can find a link in the show notes or use the enhanced search tool on realpython.com.You mentioned the idea of watching for patterns and directions that you feel the language is headed in. I know that it's only two months in and that you were saying that you would probably gather those things and report on them later. Are there some that you could speak to now? One thing that I was pretty surprised by is how many changes were made to very low level parts of the language. For example, the eval loop is one of the most popular files that we are currently touching. This was unexpected for me. \n\nThere is also a lot of churn that was fixed by automation in the form of argument clinic. This allows us to automate generating nice doc strings and argument parsing for C modules that include parts of CPython itself. This work was done by Larry Hastings and, at the time, it was controversial. However, it ends up saving a lot of time because many changes are done by argument clinic. \n\nThere are trends where suddenly someone starts showing interest in typing, leading to a flurry of activity in that area. Currently, there is a new interest in improving unit testing, an ancient library for unit testing that is now seeing a lot of activity to make it better. \n\nThere are also discussions on a PEP that Christian Hymns wrote about dead batteries. This PEP argues for removing things from the standard library that are not being maintained. Christian lists a lot of libraries in that PEP and surprisingly, there is activity in almost every file. \n\nSome changes in the codebase are sweeping, where someone goes through the entire codebase with a tool to find non-matching parentheses, including doc strings and other areas not compiled by a compiler. Even libraries without maintainers still require maintenance by the entire team. \n\nOne of the things I wondered about, which was mentioned in your interview with Talk Python with Michael Kennedy, is how to keep up with the changes.I don't think we need to rehash that much, but what I wanted to do is ask a question that's kind of about it in general. Do you feel that now that someone is in the position of reviewing those things, the traffic has amplified? Unfortunately, I can only talk about correlation and not exactly causation because at the exact time when I started the work, some increased activity could be seen from, for example, the team that Guido is working in right now at Microsoft. Mark Shannon, Eric Catriel, and Eric Snow are working on Python performance. They were recently joined by Pablo Galindo Salgado as well, who gets part of his full-time job at Bloomberg to work on Python performance right now. It's wonderful to know, and you can clearly see this in the rising amount of changes that we're having right now just from those five people alone.\n\nBut there are obviously more changes from others. It's wonderful to see that there are new contributors popping up, essentially from my perspective out of nowhere, but they're sticking to it. It's not like they made a change that they wanted and went away. They're at it, submitting change after change, proving my point from the blog post that I wrote initially. A good first impression where your change is getting reviewed and merged inspires you to do more of it. There's a lot of that, and I have some things to do with this, but mostly not because it's a living project. I started in July, and many of those contributors started earlier on, so they were already invited and contributed by others. I am now simply one of those who review all those things all day in, day out.\n\nI have to admit that there was a week where I tried to kind of, you know, 40 hours per week be damned. Let's see how many pull requests I can actually land in one week. Let's try to just force it and see how much is this kind of physically possible for a single person. Obviously, making this reasonable in terms of software quality. It's not about how fast you can press the green button. It's really about reviewing it and making sure that this is a change that we should be having in how many branches and whatnot. There's an entire ordeal here, and it turned out to be just shy of a hundred. That's not something I can promise to do every week. That was really a lot, and the annoying part about this is that it let me fall by like 30 something pull requests from the number we had before to just below 1400. I was very proud of this, but by the time I woke up on a Saturday after this marathon, the number was already back up in the 1400s because more people started putting more changes in.\n\nIt's not possible for a single person to get that number to zero. I guess it's simply too big of a project seeing too many changes from too many actors at this point, which suggests that maybe we should have more people like me, and we could spend more time on this regularly just to ensure that the pipeline we have right now, the backlog, goes down to zero. Some of the pull requests could really be closed in bulk at this point. There are many that have merge conflicts or were outdated in other ways. For example, the issue on BPO is already closed, but the pull request stayed open for whatever reason. There's some cleanup of this sort I could also do, and with the data I'm gathering right now, I'll be able to do that still this year. But I didn't want to start with this sort of thing right away because I really wanted to have a human eye on those issues. Sometimes it's really just pinging somebody even from three years back and saying, \"Okay, are you still interested in getting this in?\" And more often than not, people are like, \"Oh yeah, why not? Let me just split this into smaller things for you so it's easier to review.\" I've had very good experiences like that in August where big parts of our Tkinter documentation were essentially rewritten because somebody believed that some improvements are necessary. There was a very nice pull request from 2019 about this, but it no longer emerged. It was a big change, and it was very hard to bring this in. But that person was kind enough to not only revive that pull request but to split it into parts that were trivial for me to pull into maintenance branches as well.\n\nSo, we're going to get our act together with the pull requests, but it's going to take more than just me, and it's going to take quite a while. I thought about that. You kind of mentioned that in the other interview also, which I'll link to.I was thinking about the need to figure out if something is successful and working. You're working hard on that, but there also needs to be additional funding to make it happen. My question is, with more time in the chair, what would you look for in candidates for these roles? What skills or backgrounds would be helpful for moving forward in this role?\n\nI don't feel qualified to specify who the perfect candidate should be or make decisions on that. This role requires the ability to make a significant impact, whether positive or negative, on the project. It would be best for someone with previous experience in the Python project, particularly in understanding CPython internals.\n\nHaving some understanding of CPython internals is essential, and previous experience with the project is key for this role. The future is uncertain, and having experience with the project will be beneficial. My current contract is for 12 months, ending on July 12, 2022. The future is uncertain, but I will continue to do my best.\n\nI need to write my third invoice next week, and it's surprising how time has flown by. It feels like I've just begun, even though I've been doing this for a while now.\n\nIf there were additional roles in the core role you're in now, what areas could those people help with? Having another person like me would not change how I work much, as Python is great for remote work. With a larger team, our approach could be different, focusing on reducing the backlog of pull requests.\n\nHaving four people would make us an entire team, and our approach could change significantly. It would be challenging to subscribe to a goal of clearing the backlog of pull requests at this point.Oh, I could probably be unrealistic, right? Like, to promise such a thing. But in four people, it's totally realistic. Like, totally doable. Like, you can actually bring this down. And at this point, that would obviously be my first goal. Because with all those changes, we want to see them down. Like, I remember this number used to be not 1400. It used to be under a thousand. And before that, it used to be under 400. Like, it's not been like this for super long. So, I still see a future where we're better off the backlog than we are now.\n\nBut if you're already done with this, right, four people, you can spend, I don't know, six months on this and be done. Like, what else can you do now? Well, now having full-time core developers, you can actually start thinking about this much differently. You can start doing kind of bringing PEPs to some resolution. Like, there are quite a number of PEPs hanging in limbo. There are drafts. Somebody wrote them and fought for them for a while. There were discussions on python-dev, but they have neither been rejected nor accepted. So, we could essentially decide on those. There's a bunch of those.\n\nWhat we could also do is fix a number of non-fun issues in some of the libraries that we have. Like, I just mentioned some edge cases of async I on Windows. But it goes kind of deeper than that. There's a number of changes that would be welcome but nobody ever had the time to really sit down and look through those things from start to finish. One small example is just like PTY support. Yeah, so plenty of areas where we could make Python better for all our users in places that are unlikely to be attractive for a volunteer to tackle.\n\nIf people want to follow along on your journey here making these weekly reports, I'll include a link to a couple of them. Is there a direct link on your site? Since they are just weekly reports, some of them are more wordy than others. I decided not to make my blog entirely about that. I do lots of other stuff. If you're going through the hashtag, you're gonna get to them. But otherwise, they're not listed in the latest programming posts I have. The posts are usually more fine-grained, more hierarchy, higher quality, let's say. But the weekly reports are weekly. You can see a full list of them on discuss.python.org. In the commenters section, I always announce that there's a new report. That's an easy way to see them. The hashtag on the blog also has an atom link. So, if you're still using RSS for whatever reason, you can subscribe to that. And on the HTML side, there's a list of posts that's obviously gonna be up to date all the time.\n\nI don't necessarily announce all those weekly reports on Twitter because they're weekly reports. It was very interesting for the first three or four ones, but at this point, there's a lot of road there. So, you know, kind of these are the issues I closed, these are the pull requests I closed. I try to also put some highlights there. But none of those are groundbreaking blog posts for me in particular. So, if you're interested in them, totally read them. I'm very happy to answer any questions about the work I'm doing and I'm very happy to hear any feedback about what you would like me to do differently or maybe you have a particular favorite issue you would like me to look at. Let's do this.\n\nThe blog is gonna still have some larger blog posts every now and again. Just right now, I'm writing about the rate of change in different parts of CPython. That sounds totally interesting. I was wondering one other kind of question on the idea of going through the backlog and queries. I noticed a note about the SQLite data format and I don't know if that was related in some ways to querying those databases and if there are tools that you're working on or visualizations or other things that you're thinking about that might help in this process of analyzing what's there and working through it.\n\nIn theory, all of this data is already open source because it's on GitHub. There's a public API.You get a repository where you\ncan download it yourself and just\nanalyze it in whatever means\nbut getting to a consistent state with\nthis data\nis a little tricky, like\nit takes some work.\nSo since I already\ndid this, it just feels sensible to me\nto publish this data alongside\nwhatever particular highlights I'm going\nto have about the data so that\nother people can also look at them.\nWhen I did this originally, I created a\nbunch of data classes, just put\nthem in a pickle, essentially\njust using shelf because even though\nit's a toy for production use for me\npersonally on my personal computer, that was the fewest number of lines I\nneeded to have a reproducible database of all the things I\nalready downloaded from\nGitHub and kind of scraped from the git\nrepo.\nBut is that a perfect bundle\nfor anybody to look at? Well, arguably not because first of all, pickles between versions can be a little weird and also that would tie\nthe data to the\nmodels, to the python script that I\nused to get the data from the\noriginal sources. So instead, I thought\nSQLite alongside\nSQLite utils and dataset project by\nSimon Willison\nseems like the perfect thing to do right,\nit's tabular so some of the\nqueries are a little awkward to do for\ncharacterical data but other than that,\nthere's plenty of plugins for dataset where you can see data in a\nvisual form, there's graphs that are\ngoing to be just drawn for you if you\nclick the right thing on\nthe web UI. But SQLite is really like JSON right now, it's\nuniversally understood, your\nwatch and your fridge probably have some\nsecret database at this point, so\nit just seems like this library of\ncongress compatible long-term storage\nsolution, I should just\nput the SQLite file out there and people\ncan do whatever they want with it, yeah.\nSo that was my line of thinking, me myself using dataset was hit or miss, the tool is\ngreat but some of the more\nanalytical queries really take\nages to complete, that's kind of a SQLite thing, even though\nI spend a lot of time, oh index this,\nmaybe model the data a little\ndifferently or whatnot. So for some\nthings that I have in the blog,\nI essentially ended up just writing\ncustom 30-40 line Python scripts just to\nhave the data exactly as I like it, but\nother than that, I think SQLite is going to be the most\nreusable format even if somebody needs\nto write a Python script later to do\nsomething very weird with the data,\nSQLite is something that is really built\ninto the interpreter, so it's going\nto be very easy for somebody to use this\ninformation in any\nprogramming language they want, cool.\nDo we hit most of things that you want\nto touch on? I guess this is\nstill a role that is being shaped as we\ngo, so I want to stress that if\nanybody listening to this podcast has\nsome feedback like,\nhey, you're not doing this thing which I\nthink you should totally be doing or\nyou're doing too much of this which I\ndon't think you should be doing, just write me an email and write me on\nTwitter, just let me know, we're all\nlearning, right? I do consider this a\n12-month contract, if it ends, it ends, but\nmaybe hopefully, it'll become a longer\nterm position for me, and if so, yes, we\nneed to keep sponsors interested in this,\nbut also we need to make sure that\nthere's value for you, so there's just one person doing this with\nsome level of management\nfrom the PSF, but it's also pretty freeform, I'm not being micromanaged by\nanybody, so how we think about the role and what\nit does in the future\nis pretty much what we decide is worth doing, yeah, that makes sense.\nSo I have these weekly questions I like\nto ask everybody, and the first one was,\nwhat's something that you're excited\nabout in the world of Python, could\nbe an event, a book, a package, what have you? So currently, this is the time of release of\nPython 3.10, and for me as the developer\nof residence, this is going to be amazing because one more branch is going to be another bug fix branch which\nchanges the rate of change I can do for\nmany pull requests, like it's going to be making my life much\neasier, it's probably also\nan amazing relief to the new release\nmanager, Pablo, because obviously the\nfinal version of 3.10 is a big event, yeah, so there's a number of nice changes\nthere in that particular version of\nPython, it's a big release, there's the\nmatch statement which some people are\nafraid of, some people are excited by, I\nthink it's going to go very similar to\nhow the assignment expressions went.There might be some controversy, but after that blows over, you're going to see that this is something with very specialized use cases. When you have one of those, it's a magnificent upgrade over what we had before. There are plenty of typing upgrades in 310, among which we finally have shorthand union syntax using the binary operator, the pipe character. This is what we should have had all along. It makes expressing non-trivial types so much cleaner. It is a very big upgrade to the usability of typing, so I'm very excited about that. Maybe surprisingly, alongside the new parser that enabled the match statement, a bunch of errors that Python reports became easier to understand. Many syntax errors that were puzzling before now make more sense. If you mistype a variable, it will suggest what variable name you actually wanted. The quality of life of a regular statistically average Python developer is about to improve, so I'm excited to hear actual user opinions on how Python 310 works for people.\n\nThere are a couple of things I wanted to touch on when I was researching a lot of stuff for this Python 310 show that came out just before this one. I noticed that the terminology, the BPO thing, and almost all of those enhancements of error correction or syntax stuff were all mentioned as BPOs, as opposed to PEPs. I thought that was really interesting, and I think they're going to be really great. That's where those kind of came up for me. I thought about it, and there are two things with how the peg parser can parse forward and not simply stop and point. It's able to go forward a bit and say, \"Oh, I kind of got more context here of what you were trying to do, and I can make a much more positive suggestion.\" It is definitely a much more advanced parser, both in terms of performance and what you're actually getting. Many people don't know that we have not been using an LL1 pure grammar for a long while in Python. We had a grammar that used LL1, but then a bunch of things that were allowed by it were invalid Python. We actually had to have another pass where we would later reject some of the things that the parser accepted, saying, \"Hey, this is actually invalid. We don't allow this. This is not good.\"\n\nFor example, what is allowed on the left and right side of an assignment. In the LL1 grammar, there was essentially no difference between the two, but as Python programmers know, there's a world of difference. Now, the peg parser removes the necessity of hacks like this but also adds a lot of flexibility. One of the surprises in the match statement functionality is that the match and case keywords aren't actually true keywords. They are contextual keywords, meaning you can still have code that uses match and case as names. You can still have variables, methods, classes, and modules like this. In fact, `case.py` is right in the standard library, part of the unit test package. This is now a totally new level of flexibility for the language.\n\nI'm not worried that we're going to be overusing this, but the flexibility it gives is crucial in ensuring that the language can still evolve. For example, imagine a match statement feature that we were supposed to add. If we couldn't make contextual keywords, there must be hundreds of thousands, if not millions, of lines of code that have match in them. I'm thinking a variable name. There must be many regular expressions or whatever where they're just using match as a variable name. This feature would be paralyzed by having to choose a keyword that is not used by the code in the wild, which is virtually impossible for a language that is 30 years old. The parser essentially enabled this entire new era of development in CPython.\n\nI am very excited about that too. What I'm thinking about for the next one is what do you want to learn next? There are a bunch of things, right? I'm not sure how many things I'm going to actually get into. Looking at how people are using Python, for example, the arguably biggest user right now has to be data science. It's a very important use, and I haven't ever done much data science in any meaningful sense. I've done a little NumPy, and that's essentially it. I've never used Pandas, I've never used TensorFlow. Some of the terms floating on Twitter could maybe fool you in a conversation that I know what they're about.I don't actually, so fixing that is also a responsibility of somebody who's the developer in residence and is supposed to make life better for all users of Python. I come from this backend world, so async IO, typing, I understand that and this is definitely my comfort zone. But when we're talking about tensors, matrix multiplications, or unsupervised training, all of those things are totally new for me. So that's definitely something I would want to look closer into, probably starting with the new year. Yeah, that sounds good.\n\nAnd so we kind of end each episode with shout outs or plugs. Do you have any things that you want to shout out currently? Yeah, sure. At this point, I'm pretty impressed with some of the contributors to Python that we just recently gained. They're very consistently good at the number of changes they're making and at the quality of changes they're making. So I just want to go ahead and thank them for it. Let me just bring out their names so I don't misspell them or mispronounce them, since I know that can be a little embarrassing.\n\nFirst of all, we have Andre Kulakov. Thanks, Andre, you're being great. Another person that I see a lot is Nikita Sobolev. Thanks, Nikita. And the third person doing a lot of typing-related changes that I see recently is Yuri Kagabas from Levith in Ukraine. So those three essentially spend crazy amounts of time on improving CPython right now. I am very happy to see this new activity. I cannot be sure just looking at their profile pictures, but they look like they're quite a bit younger than I am myself. So that's also reassuring that hey, we're not working on a dying project. This is not the new cobon. Essentially, new people are still interested in this. There's still kind of life here. So yeah, thanks for that. This is very important because it also shows that the project keeps being used and important to new generations.\n\nAnd plugs, well I don't really have anything to plug myself at the moment. I'm essentially living the dream at this point. But what I would like you to look at is Textual and Rich. Those are libraries that I didn't know I needed until they were created, and now pretty much every piece of Python code that I write has them because they're just nice. Textual is the newest one because it's still something that is kind of early in development, but it's already rethinking how I create command-line tools. Until very recently, I was mostly creating very bare-bones tools where they were nice Unix-type tools that they got some input, they generated some output, or they just did something on the side as is very popular right now. But there wasn't really much interactivity to them. Textual changes that now you can actually think of your application as something interactive and do it with relatively little code, and also still composing very well with async IO, which is increasingly important in my life for some reason. So yeah, if you haven't looked into Textual, have a go, try some of the examples. Those are very well-thought-through projects.\n\nIt was a fun conversation I had with him recently, and I'm excited by his continued development. He's sort of taken time off from his other roles to focus for a little while, and also he's doing this sort of give back to the community and open-source by looking at other people's code and giving them reviews. This is amazing. Yeah, like thanks, Will. You're doing this much better than I did. When I quit Facebook in December 2018, I decided I actually need some time to stay with my family, to decompress after moving from first North America and then spending six months in London. I wanted to essentially be this family man for a while, see where I'm at, decide what I want to do next. And then suddenly, after almost two years of doing nothing, I started the next job and I really don't have much to show for it. It was really kind of a waste of time. I still enjoyed it, I'm not saying it was bad in any meaningful sense, it was pleasurable. But it was pretty empty in terms of meaning. Will essentially has a better idea of how he wants to use his time, and I can admire this.\n\nYeah, I think it's super cool. I'm intrigued to see how it goes for him. Well, thanks so much for coming on the show. It's been fantastic to talk to you again. A pleasure. And don't forget this episode was sponsored by DataStax Astra DB built on Apache Cassandra, made easy in the cloud. Learn more at astro.dev/python. I want to thank Wukishlanga for coming on the show again.I want to thank you for listening to the Real Python Podcast. Make sure that you click the follow button in your podcast player. If you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review.\n\nYou can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "H9WRFkvYduQ": "Welcome to the Real Python Podcast. This is episode 86.\n\nDo you remember the One Laptop Per Child program? What went wrong and what can we learn from the program's failure? What are the potential pitfalls of charismatic technology, and how can we avoid them when introducing students to programming? This week on the show, former guest Al Sweigart and author Morgan Ames are here to talk about her book, \"The Charisma Machine: The Life, Death, and Legacy of One Laptop Per Child.\" We discussed the OLPC program and how idealized versions of our programming backgrounds can become traps. Morgan explains how these utopian visions are still used to attempt to disrupt education. Along with this cautionary tale, we also talk about educational programs that are working and how the entry points to programming are changing.\n\nThis episode is brought to you by CData Software, the easiest way to connect Python with data. SQL access to more than 250 cloud applications and data sources. Alright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nWell, I want to welcome back Al Sweigart to the show again. Hello.\n\nHey, you had this idea that you had sent to me a few weeks ago about this book that you had read, \"The Charisma Machine: The Life, Death, and Legacy of One Laptop Per Child,\" written by Morgan Ames. I reached out and was able to get Morgan to come on the show. So welcome to the show, Morgan. I'm so happy to be here. Thank you for having me.\n\nCool. So we initially wanted to talk about the book a little bit in the sense of how this relates to learning programming and kids getting introduced to programming. But not only that, like adults getting introduced to it also. But I thought maybe I could ask you a little bit about your background, which I found kind of interesting as to leading into your research and your own personal background with computing. So I was looking on your site, and you have a BA in Computer Science and an MS in Information Science, and then a PhD in Communication with a minor in Anthropology, which I can kind of see how that all connects to the types of research projects that you do.\n\nYes, it kind of runs the gamut, which is really kind of cool. Just quickly, what are some of the differences between Computer Science and Information Science? \n\nVery happy to talk about that. Information Science is my current home department or home school, I guess, as well. Information Science departments or divisions or schools around grew out of library science. They grew out of cataloging, training librarians basically, and kind of cataloging information that is stored in books. But in the 90s and early 2000s, a lot of library schools pivoted to include digital information. Of course, this makes them overlap some with Computer Science, with other disciplines that focus on digital information. But I would say Information schools are much more applied, much more grounded in real-world applications and real-world implications. That's really where we dwell and where we find a lot of meaning, where we put a lot of importance. Some faculty in Computer Science departments might also be applied and focused on those kinds of things. But in general, and certainly my own training, kind of pointed towards this. Computer Science often almost prides itself on being separated from the real world, being abstracted, being something that is more theoretical perhaps. Individual sub-disciplines within Computer Science and individual faculty members might take different approaches. But I would say as a field, Computer Science is a bit more abstract, a bit more theoretical, a bit more focused on the ins and outs of maybe programming languages or maybe the limits of computation, computability, these kinds of questions, rather than what effects do these systems have in the world.\n\nDefinitely, I can see that. It's funny that that shift happened while I was in school in high school, the idea of a library being turned into a media center or whatever they wanted to re-title things. The idea that a lot of the computers that are in some schools at the time were in those places in the media center or in the library. That was a big thing in the 90s too. My experience was getting computers in the classroom and this idea that if we just dropped a computer in every classroom, this would somehow improve education in some vague and ambiguous way.\n\nYeah, well in the 1980s, in fact, when I was an elementary school student, I used one of the precursors to the One Laptop Per Child project, Logo. It was rolled out nationwide, including my completely ordinary, somewhat underfunded public school in suburban Salt Lake City, Utah. So we had our weekly session on the Logo computers in the back room of the library.Yes, I'm very familiar with that trend generally as well as the kinds of computing imaginaries that my elementary school held for us.\n\nWe had an Apple II lab in my junior high, which was the first place I saw that. This was in a suburb of Denver. When I moved back to Arizona in high school, it was actually a much smaller computer area that they had. It was a set of like maybe TRS 80s or something, so again, aging myself.\n\nI think we all have that background of getting into programming as children. That's the main thing that struck me about the charisma machine in this book. I saw so much of my own childhood in this under a much more critical lens. I learned how to code in BASIC when I was a kid and then later moved on to other languages such as Python.\n\nWhen I first heard about the One Laptop Per Child project, I immediately thought this is a great idea. Kids will learn computing and how to code, and even if they don't become software engineers, they'll become more capable adults. The magic ingredient is putting computers into kids' hands, because that was what my experience was like, learning to code in BASIC.\n\nAbsolutely, I'm glad that you highlight that because I think many who joined this project, certainly employees of One Laptop Per Child, saw themselves reflected in these stories too. It was a very conscious part of the design process, from what I heard and gleaned from extensive online discussions about it.\n\nWe should probably go into what the OLPC project actually was for people who aren't familiar with it, as it was announced 15-16 years ago. It's a project that came out of the MIT Media Lab, spearheaded by Nicholas Negroponte and Seymour Papert. Its goal was to put a low-cost, easily repairable, open-source software computer with educational software in the hands of every child across the global south.\n\nThe idea was that once they had this laptop, they would be inspired to explore it, learn programming languages, connect with other children, and leapfrog past the adults in their lives. The laptop had a mesh network, a view source button, and various charging options. Originally, it was said to have a hand crank for charging, but that was not feasible.\n\nI bought one of those emergency flashlights with a hand crank, and you realize you can't generate enough electricity. It's not practical for charging a computer. The OLPC project aimed to provide a low-power computer that still needed power.It sounds like a great idea honestly. One of my motivations for going into computer science myself was to make the world a better place, so I really understood why people were so attracted to this project in very concrete terms trying to make the world a better place. And in a way that really resonated with computer scientists in particular.\n\nThere were a few other pieces of this project. They really wanted children to own the machines, and this was kind of a cornerstone of Seymour Papert's philosophy that goes back to developing this particular, really most popular branch of the Logo programming language - Turtle Graphics as a part of that. They wanted kids to be free to explore things as deeply as they want, so kids own the laptops. They were targeting elementary age kids, not high school. They wanted these to be connected to the internet. This was not a requirement, different projects on the ground would have to work on those logistics themselves, but that was the idea. They wanted all kids in an area to have them. And then, as I mentioned, they were committed to free and open-source software, and that is what the laptop shipped with. It's Sugar, which is a kind of windowing system on top of, I believe, Fedora Linux. And then there were a number of applications that had been developed over the years by either MIT Media Lab or other affiliates, such as Scratch, the TamTam Music Suite, Turtle Art (renamed Turtle Blocks), E-Toys, Alan Kaye's project, and other things that have been developed over the years shipped on this machine.\n\nIt's interesting that you bring up turtles because I'm using the Scratch programming environment, which is also from MIT and is headed up by Mitch Resnick, who I believe was a grad student of Seymour Papert. About a year ago, I think they released Scratch Version 3, and one thing that I noticed is that the pen tools, which were basically the turtle tools that would let you draw lines and spirograph art, and sort of things, they now have those hidden by default. You can still add them in, but they're not part of the code blocks that you can use normally. From what I gather, the turtle graphics features of Scratch just really aren't that popular with kids who are using it.\n\nYeah, I think back in the 1980s, I remember as an elementary school student a lot of it was over my head at the time. I gotta say, and I didn't have that kind of open-ended opportunity to explore at the time. But I think it was a novelty in the 1980s when displays were still often just four colors, right, or maybe even just one color. The fact that you could move things around on a computer screen was like \"whoa, really?\" And of course now, kids have touch screens, they are very used to cursors, they are very used to the idea of interactivity, they are very used to a really rich multimedia environment. So I think in many ways, things like moving a turtle across the screen just aren't necessarily as compelling. In fact, a lot of the things that many of the OLPC people remember from their childhoods and the way they mythologize their childhoods are not necessarily true for today's kids. It's a very different media landscape, it's a very different kind of programming computing environment.\n\nText-based games aren't really that they don't have the same hold on kids anymore. Exactly, um, and so many games, of course, that use in some ways the same mechanics as a text-based game, right? There's an adventure game, but there's an expectation of these rich graphics that accompany it. So, yeah, I think it's changed a lot. So I'm not surprised in a way that Scratch and Mitch and his team made that decision. I think in many ways, even though Scratch and Mitch's projects more generally are very much in their tradition of Seymour Papert's philosophy, in fact, Mitch Resnick holds the Seymour Papert Endowed Chair at the MIT Media Lab, he and his group have really done their best to learn from the mistakes of One Laptop per Child, of Logo, of other things, and really try to make a more inclusive environment. That said, I think they still tend to have a fair number more boys than girls in that Scratch environment. Some of the most active members are girls, interestingly, but there's still some kind of cultural baggage around who gets to program, who is seen as \"natural\" that influences things like Scratch, and even with the changes.\n\nOne thing I do like about Scratch is that they tend to focus a little bit more on storytelling and kind of theatrical aspects, right? You move this cat around, you tell stories with the cat, there's a kind of natural theatricality to Scratch. It's not just calculating Fibonacci sequence numbers. Yeah.Or maybe I mean making pretty pictures is a wonderful motivation for some in logo. But it really doesn't grab some people, whereas telling stories also doesn't grab some kids. I think we tend to think in stories, we tend to make sense of our lives and our surroundings in stories. So, I think that lends itself a little more naturally to being a good entry point into programming.\n\nI have a question about, you mentioned that one of the ideas behind the direction of where they were going to implement this project of one laptop per child was the global south. I guess I haven't heard that defined. Is that South America and other places like Mexico or what are the different places that were included in that?\n\nYeah, I think that many people would say, quote unquote, the developing world. Okay, what we used to say, the third world. The third world was a kind of Cold War legacy, the first world being the democratic nations, the second world being communists, the third world being the places where those two were jockeying for position. That was kind of replaced by the developing world. But there's so much baggage around development and the politics of development, who developed for whom, who sets the bar for what is developed, etc. Anthropology and other fields tended to move away from that and say the global south instead. And of course, this has its own politics. Any term we use for this kind of thing will have its own politics. But the idea is, you know, in a way, talking about, quote unquote, the developing world without those connotations of, well, here's what's developed and here's what's not developed and here's the path you take to development. It really takes into account all of the legacies of extractivism that have shaped many places across the global south. Certainly the countries in Africa, especially Central Africa, but also Latin America, South and Central America, the Caribbean, the Pacific islands, South Asia. There's a lot of different places that would be counted as, quote unquote, the global south. And yeah, that term just nods to that history a little bit more.\n\nOne of the big focuses that you have from the title of the book is this idea of charisma. I kind of want to get your interpretation of that and how these charismatic models have developed over time and are held up, if you will, as a bit of a pedestal of, like, this is how it's done.\n\nSure. When we think about charisma in a colloquial sense, we often think about people who are charismatic, like a cult leader, maybe a religious figure, certain politicians. They have a kind of magnetism, they attract attention, they draw people to them and to their cause. One move that my core discipline, Science and Technology Studies, makes is to use some of the same analytical tools that we use for people on objects and to think carefully about what that might serve. Science and Technology Studies acknowledges that objects like laptops, like infrastructures, other things, end up having effects in the world beyond what the designers intended. It's not just a conduit for whatever the designer wants. There's a kind of back and forth between technology and a user. Of course, the design of the technology initially is also something that doesn't happen in a cultural vacuum. There's a kind of back and forth between what the designer thinks the world needs or a particular user base needs, how they understand the world, how they understand those technology users, and then how they kind of instantiate that in design.\n\nWhen I thought about this as I was following the One Laptop for Child project, I kept coming up against these ideas that seemed to have a kind of life of their own in the world. Certainly, Nicholas Negroponte as a spokesperson for One Laptop per Child and others who were part of the project were promoting certain ideas. But the laptop itself came to symbolize a kind of future, a kind of utopia that in some ways took on a bit of a life of its own. So I thought, you know, this laptop itself kind of has charisma. It symbolizes a particular world view and a utopian hope that maybe takes slightly different shapes among different communities but still is kind of charismatic in how it resonates with them.\n\nThe idea of charisma ties closely with utopianism in the case of One Laptop per Child. Now, utopianism, as a literary idea, often is about a construct of a world that is very separated from our own. But within technology, utopian ideas are very common.This idea that we can solve racism by creating an app, right? Yeah, exactly. And it sounds, when we put it in such stark terms, it's like okay, that's probably ridiculous. But various forms of these stories circulate. They get co-opted into different projects, in some cases really the same story. So what I found interesting with the One Laptop Per Child project, this laptop was charismatic in a way that really resonated with existing world views of the open source community, among those who consider themselves part of the hacker crowd of MIT. These are hackers not in the breaking-into-computer sense, but in the passionate technical tinkerer sense, which has a long history at MIT and elsewhere.\n\nMoreover, this wasn't the first time that these stories had been embodied in a project and in a piece of hardware. The same stories were told about Logo, the same stories have been told about other pieces of children's technology, the same stories have been told since too. So even though One Laptop Per Child, in many ways, failed, the same stories came up when we talked about MOOCs, maker spaces, or tech-heavy charter schools. There are a lot of different movements that promise the same kind of inspirational tinkering to children that One Laptop Per Child promised, without really taking into account why it didn't succeed.\n\nWe see this continue today in other spaces in tech. A lot of hype around AI, deep learning, blockchain, cryptocurrencies, virtual reality, and augmented reality. Those are things where we think, hey, we can just add a VR headset and suddenly the metaverse is cool and practical and a good idea when really, you just end up getting motion sickness and have a sweaty set of goggles strapped to your face for three hours at a time.\n\nWe tend to see the great appeal of it and not the impracticalities of it. Absolutely. I think virtual reality, in particular, is one that has certainly been in the news a lot the last little while. Ethan Zuckerman wrote just a wonderful essay. He is a former MIT Media Lab professor but just really thoughtful about his own contributions from the 1990s onward in the realm of virtual reality and augmented reality, and why those ended up failing.\n\nI think they failed for many of the same reasons that you talk about but more broadly, I would say that many of these utopian visions don't connect themselves to the messiness of real life. We rely on holding them at arm's length and saying, oh, here's this shiny, very different vision from our everyday life. The role of utopia as a kind of escapist view is, of course, well established in literature, but I think it tends to be a little under-examined in technology.\n\nThe lack of connection between our everyday sitting in front of our computers for Zoom meetings, whatever it might be, and that shiny vision of the hyper-modernist Mark Zuckerberg room or playing cards with your friends online or whatever it might be. There isn't really a connection with what do I have to do day to day in these spaces, how would that be different in virtual reality, how would it be better, how would it be worse. A lot of that gets shunted away in these utopian visions.\n\nDo you feel like they don't have the wherewithal to do a longer study of that thing as opposed to rushing to shove it out into the market, like actually have a group of people use it for a year or whatever and think about it? I think of the mission to Mars kind of things, like, how long can people stand being together, these kind of biosphere kind of experiments that happened over the last year or two?\n\nNo, indeed. Every project ends up being run a little bit differently. There have been many experiments with how these ideas bear out on the ground in various iterations. Certainly with VR, there are lots of people who have been studying this for decades. Similarly with getting computers in the hands of kids, lots of people have done one-to-one laptop projects. They have maybe followed Seymour Papert's suggestions in really giving kids full access in some cases. Other ones, the laptop might be owned by the school or might be locked down in various ways.\n\nOne troubling trend today is that these laptops from schools are often packed with surveillance software where teachers and administrators can track remotely what kids are doing on the laptops, at school or even at home. And I would say this is a dystopian vision that is very close to reality, unfortunately.It is reality in many cases, but more broadly, I think both of these visions really rely on being separated from reality when you account for what those teams are actually doing and exploring on the ground. The utopian vision ends up kind of falling apart because you realize there's a lot of messiness that goes with this project. There are people who don't want to engage in this way, what's going to become of them? There are people who may co-opt it or abuse this platform in various ways, what happens then? All of this gets shunted away in the utopian story. So, in effect, even though people have been on the ground doing the kind of work that is needed to understand how this would actually fit in the messiness of day-to-day life, utopian stories persist and they get retold again with a lot of similarity across a lot of new technologies.\n\nI think Python plays a large role in a lot of this because right now, and for the last several years, actually for the last several decades, \"learn to code\" has become this idea where if we just learn to code, then people can automatically improve their lives. I'm the author of \"Automate the Boring Stuff with Python,\" which is a book aimed at office workers and teaching them how to code, or people who aren't necessarily software engineers. One thing I've noticed is that there are a lot of self-published books trying to cash in on this trend. When I look at Amazon, I can always pick them out because they have an amateurish cover design, long titles to capture search engine terms, and a dozen five-star reviews the week they come out and then no reviews after that. It's pretty clear they're just buying reviews to promote them. This is one reason why I thought \"The Charisma Machine\" is such an important book because this will keep happening over and over again where technology makes promises, and we get caught up and mesmerized by the charisma of it all without asking if it actually works in the real world.\n\nI love Python, it's my scripting language of choice. I lean on it for spaghetti code scripts like needing to download a bunch of articles from a website without doing it manually. I love having that skill set to lean on, and I think there is power in it. As a code, I remember talking back to when I first learned it in the early 2000s with some of the people contributing to the language design at Berkeley at the time when I was there as an undergrad. One of the goals of Python was learnability, making it really clear and not obfuscated like Perl was at the time. Python was a wonderful alternative to that, and I think as a learning platform and even as a core programming platform, it's really wonderful. However, the movement to teach everyone to code is one I worry a little bit about. I do think there is value in it.I think everyone knowing a little bit more about how their machines work, understanding the real limitations of them, and figuring out what they're doing if there are concerns about privacy or surveillance is important. Knowing how your machine works allows you to investigate and understand what's going on. However, a missing component in many learn-to-code initiatives, such as the Hour of Code, is critical awareness of how computing environments fit into our lives more broadly.\n\nSurveillance, even of school children, is common today, and our data is often harvested and repurposed. While there may be a lot of useless data, the promise of AI is that with enough data, valuable insights can be gained. Despite doubts about the effectiveness of targeted ads, AI has improved language translation and brought about many other positive advancements.\n\nI believe that kids who learn coding should also gain critical perspectives on computing environments, surveillance networks, and the political economy behind them. They should learn how to discern truth from fiction, verify information, and understand the implications of technology in their daily lives. This critical media literacy is often neglected in technical education but is crucial for navigating the digital world.\n\nI try to incorporate these critical perspectives into my classes alongside technical skills, and I believe they should be included in learn-to-code initiatives. The focus on technical skills without considering the consequences and ethical implications of technology is a significant oversight.\n\nThe lack of emphasis on critical perspectives may stem from a lack of charismatic role models in this field. The older generations' concerns about video games seem trivial compared to the challenges of misinformation and privacy invasion in today's digital age. It's essential for kids to understand what information is being gathered about them and how to navigate the complexities of technology.\n\nOverall, there is a need for a balance between technical skills and critical thinking in education to prepare the next generation for the challenges of the digital world.Right, same story we heard about video games, same story we heard about television, same story that was told about novels back when novels were kind of new and kids were not reading the Bible, they were reading novels. Right, and it's going to rot their brains.\n\nI love kind of historicizing that a little bit and saying like yeah, we've told those same stories over and over. In a lot of ways, those dystopian stories can be flip sides of utopian. Both of them are removed from reality. I think you're really insightful and on point in saying that this kind of critical digital sensibility doesn't have a charismatic story. You are absolutely right. I feel like this is a common problem with a lot of movements that end up really grounded in people's lived experiences. It can be hard to distill that really messy reality with a lot of different competing desires into a crystalline and really compelling image, into that charismatic story.\n\nI think that we should have more movements that try to galvanize people around maybe labor conditions. I do feel like there have been some shifts within the technology industry in the last few years towards unionization, towards attention to labor, towards attention to what kinds of precarious labor platforms like maybe Amazon Mechanical Turk enable. And what that means for the economy more generally.\n\nSo I feel like there are some stories around that in particular, but there aren't a lot of really compelling stories around like, yeah, kids using tech. It's not a drug for their brain, anything's fine in moderation. The flip side of that, of course, is kind of connected to, as you mentioned, the technically precocious boy idea. This is the idea that kids take to technology like fish to water, right? They're naturals, they're so good at it, they pick it up so easily. I've certainly worked with a lot of children, and many of them are really fearless when it comes to technology.\n\nYeah, I do think there's a worrying illusion though between that fearlessness and real technical knowledge. Certainly, there are a lot of students who come to college, for example, having kind of learned a little bit about code and written some programs, and they have a lot of confidence, but they don't have a lot of good technique. It's like somebody tinkering around on a musical instrument being like, \"Oh yeah, I'm really great,\" without being able to listen to others playing that instrument or to really have any kind of music technique behind it. This isn't a perfect analogy, but you know, that idea of the self-taught coder. One thing that I tell people over and over again is that, you know, I was one of these kids who quote unquote taught themselves how to code, but really everything I learned about programming between the third grade and graduating high school, you could probably teach yourself in about a dozen weekends or so. Like it turns out, my head start wasn't really that big of a head start, and I didn't know nearly as much as I thought I did.\n\n[Laughter] Yes, yeah, I had lots of friends. So I was not a coder in high school. I came to it in college, but I had lots of friends who considered themselves very good hackers in high school. And as I got into computer science, I was like, \"Oh, is that all? That's what they were talking about? Oh my god, it's like really, they only knew that one weird trick.\" Yes, exactly, yeah, they were a headline ahead of their time, the one weird trick.\n\nThis week, I want to shine a spotlight on another Real Python video course. It uses a real-world project to help you hone your skills with wrangling data using Python. The course is based on a step-by-step Real Python tutorial by Brian Weber, and in the course, instructor Cesar Aguilar takes you through how to load and merge data from multiple sources with Pandas, how to filter and group data in Pandas data frames, and how to calculate and plot grades in a Pandas data frame. Along the way, you'll practice many of the skills you need to work effectively in Pandas, like working with CSV files, aggregating values, and how to assemble it all into a real-world project. Like all the video courses on Real Python, it's broken into easily consumable sections. Plus, you get additional resources and code examples for the techniques shown. All of our course lessons have a transcript, including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the enhanced search tool on realpython.com.\n\nSo I want to get into that story a little bit though about the technically precocious boy because I think the way we tell stories to ourselves and to others about our past is incredibly important for how we see ourselves, how we act in the world. And in the tech world, that story of teaching yourself to program, of falling in love with the machine, of really it being about you and the computer, has a couple downsides. One is that it tends to exclude people like me who came to it in college. I really liked math before that.But it wasn't until college that I took my first programming class. It tends to exclude others who find different routes, right? That don't have that neat and tidy mythology that you're able to fit into. Here's how I taught myself to code when I was fairly young.\n\nIt also obscures all of the things that helped you along the way. Of course, I don't know your story in particular, but in many cases, there's somebody who gave that person, that child, a computer in the first place. Maybe someone who gave them access to coding magazines, especially in the 1980s. They were at the back of Scientific America and had basic programs you could type in, run, debug, and figure out why it wasn't working the way it should. Many magazines were dedicated to this at the time, and that's how a lot of people learned to code. But somebody brought those into the house, right? Somebody enabled that access. And of course, today, it's more about Stack Overflow or other tutorials online, like the Hour of Code.\n\nThere are big teams, like a whole Google team, devoted to Hour of Code, as well as other volunteers. This gets deployed through teachers, parents, and others who support these activities. And of course, there's somewhere these people go when they have trouble. The computer's not booting properly, or they run into a bug in their code. Maybe they look it up, but they have to figure out how to look it up.\n\nThis really came to the forefront when I ran a summer camp with a colleague of mine, Jenna Burrell. We ran a Minecraft summer camp in Richmond, California, a low-income, historically redlined community just north of Berkeley. Most of our kids were Black or Latinx children who were passionate about Minecraft. They had played it a lot on mobile devices and tablets, but when they came to us, many hadn't used computers much. Installing Minecraft mods was a technical process, involving copying JavaScript files into a particular folder on your machine. That's not something that's available to a lot of kids.\n\nEven the stories we tell about Minecraft fostering computational thinking tend to obscure all the other resources that factor into people learning to program. The Minecraft background can lead to learning skills useful in dev ops, like server maintenance, package management, and more. Kids learn about infrastructure and technical challenges beyond just programming.\n\nThe Minecraft admin to IT transition involves dealing with mods, versioning conflicts, uptime, monitoring, community moderation, and even cybersecurity to prevent attacks on the server. It provides motivation to get into dev ops roles.Absolutely, there's so much that has to go into it. I found that for a lot of our students, many of them had kind of one broken down computer at home. Maybe it wasn't even functional or maybe it was barely functional, but it wasn't connected to the internet because people only had internet connections to their phones. They weren't allowed to tether, for example, so their computer was kind of an isolated thing. They were typing, some of these usually brothers or sisters of the people in the camp, because they tended to be a little bit younger. Some of them were in high school or early college, and they were literally typing up essays for their classes on their phones because that was their computing device. They would go to the school to type things up on very overused computer labs, or they would go to Richmond Library, which was only open for four-hour chunks a couple of days a week because they were underfunded.\n\nThese are the kinds of computing environments that are so common across the United States and the world but get overshadowed in visions of virtual reality or remote schooling. It's kind of a pain because we have such a huge e-waste problem. I have desktop machines and even laptops that are half-built just in the room that I'm sitting in right now. Just because we have plentiful computers everywhere, the hardware is there, that doesn't mean that it's working or operational, that people will have the tech support needed, or the internet connectivity. Even if they have internet on their phones, like you said, that's not the same thing as having a desktop computer or a laptop computer with internet on it that they can use.\n\nThere's such a wide range of all these devices, and unfortunately, it's nobody can really make lots of money by recycling old PCs and putting in all the labor and effort into getting people's old computers up and running. It'd be much better just to have a million-dollar deal to have a school district buy iPads or that sort of thing. Yeah, and I gotta say, the million-dollar deal to buy iPads or 10 million or whatever it might be is a lot flashier and a lot more utopian than the ongoing care and maintenance of those iPads and the training that teachers need, the training that students and families might need. All of those pieces aren't the exciting parts of those projects.\n\nThis is a big problem, certainly a big problem in the One Laptop Per Child project. There was a lot of focus on getting the machines into the hands of kids. Seymour Papert, in a talk in 2006, literally said, \"eight-year-olds can do 90% of tech support, and 12-year-olds 100%, and it's not exploitation, it's a valuable learning opportunity.\" This was not true in the field. It turns out eight-year-olds aren't just going to swim in technology so easily that they can repair microchips. The most common breakage point were chargers, the cables were not chosen well, they were these plastic cables that can stretch, and kids swing things.\n\nIf you've interacted with kids and machines, they fiddle with stuff, they break stuff all the time, they break cords, especially in the Minecraft camp Jenna and I ran. We had headphones for all the kids, and boy, those headphone cords just took a beating. I worked at a school for recording engineers, and it was post-high school but a mix of things. The guy was sort of the main technician to take care of all the equipment. He said you can never make anything student-proof, you can just make it student-resistant. That's a great claim.\n\nIn much the way that water-resistant things, you don't actually want to get them wet, yeah exactly. It's funny that you bring up how we got all these laptops into the hands of kids and then just walked away because all the other stuff isn't the fun part of the project. I think a lot of programmers can relate to this because it's a lot of fun to write code, it's not a lot of fun to write documentation, comments, unit tests, or promote your open-source project on forums and social media, and all these other things that are absolutely necessary for a working piece of software, but aren't as fun as writing the initial code.\n\nAbsolutely, well, and you look at how project software maintenance, in particular, goes out in the world too. I have a friend, Marissa Cohn, who did this wonderful study of long-term NASA projects, a lot of these rovers that get sent or probes that get sent are launched.But then, it's 10, 15, 20 years until they actually reach their destination, right? And all during that time, there is maintenance work that needs to be done on the project. She found that these maintenance teams were largely staffed by women. They were incredibly technical and dealt with all kinds of software faults and other things that had to be pushed to some probe. That's the light takes maybe a half a day to get there right? The message takes that long to come, and so it's a whole day before they get a message back knowing whether they succeeded.\n\nThese were not the \"sexy\" projects at NASA, right? There were a lot of men jockeying for promotions who were on the launch team, and then the maintenance team ended up being more often these kind of long career women on the project. Anyway, that's a... and that goes back to the history of computing as well, where it was considered like hardware design was the cool part, and so that was men's jobs, whereas actually writing the software was seen as clerical work. So, a lot of women, a lot of the first programmers were women, absolutely.\n\nI'm glad you bring that up. I love in some of my classes going over a little bit of that history of computer science, of programming, and talking a bit about how this was a woman's job up until the 1960s, really. And women were incredibly technical, incredibly in many cases pretty well-paid because if they left, the project would be kind of entire straight, but were generally not kind of well-regarded because that was the culture of the time. As you said, it was seen a little bit as clerical work, and then of course, there was this shift in the 1960s and 1970s that many historians have traced in detail. Nathan Enzminger has wonderful histories on that. Fred Turner also talks a bit about how ideas of computation ended up getting attached not to these huge government projects which really defined computing in the 1950s and 1960s, often with defense ties, but ended up being connected to the counterculture, of all things, right? And this idea of hackers being kind of counter-cultural was something that was really actively fostered in part by the very people who were behind One Laptop per Child. Seymour Papert joined MIT in the 1960s, joined Marvin Minsky's lab. Minsky's lab, of course, is famous for enabling self-described hackers to use all of the big timeshare PDP computers overnight, and they programmed space war, they programmed all sorts of fun games, they played pranks on one another. This was part of the culture of MIT as well, but this really became a kind of source of a lot of both computational mythologies and also a source of this shift from programming being kind of women's clerical work to programming being this kind of macho thing to do, almost an alternative to the jock sort of persona.\n\nYeah, I mean I would say that certainly programming is not something that has to be masculine. And one reason that I love telling that story to my students is because it really blows away some of their preconceptions about even some of the movements to bring more women into computing. There's a lot of movements around like, \"Well, we just need to make sure we get more women in the pipeline early and make sure they don't drop out and make sure...\" And it's like, well, what have we done to change the cultural assumptions around computing? These are not natural in any way, right? They were something that were the product of especially a kind of late 1960s into the 1970s and also into the 1980s shift in computing cultures, and knowing that history can really be beneficial.\n\nI talk about that with my own history of learning how to program because I was really into Nintendo, like the 8-bit Nintendo Entertainment System, and I looked into the history of video games and how Atari Pong was really popular in the 70s, but then there were all sorts of cheap knockoffs and really low-quality games, and it culminated into the video game crash of 1983 where video games almost just stopped being a medium or a form of activity. It was, I think, 97% of the revenue for video games just fell out in that one year. And what really sort of saved video games in that period was Nintendo from Japan. They took the time to develop well-designed games that were really accessible but also changing in the way that they marketed it. In order to create Nintendo games, you had to be licensed from Nintendo so they could have quality control. And instead of selling these Ataris and other video game consoles in the electronics section of stores, they wanted to sell video games in the toy section of stores. And all toys were split into boy toys and girl toys, and so there was just a decision of, well, video games will just be sold in the boy toys section. And that has had a lot of repercussions to this day where video games are seen as something that predominantly boys do. Like most gamers are considered to be men, even though when you actually look at the numbers for video games, it's pretty much split evenly across the population.Absolutely, I'm so glad you go over that history and that decision to put the consoles and the games in the boy toy aisle fits a century of marketing technical toys to boys. We think of erector sets, early engineering applications, and chemistry sets. There has long been an association with particular toys, play, and freedom. Especially after World War II, there was a movement for kids' rooms to be full of toys, aspirational toys, and a focus on individual creativity as a value. However, toys are also a site where parents inscribe their hopes on their children, and children use toys to explore and make sense of the world.\n\nWhen it comes to marketing toys, there is a lot of adult projection and hopeful anticipation of what their child will become. This history, going back before computer games, is gendered and continues to be so. Individual kids may break through these molds, but they often have to push back against cultural messaging that encourages or discourages certain fields.\n\nMy own history with learning programming was influenced by subtle cues and comments that may have discouraged me. These little things can accumulate and have a large effect, planting seeds of doubt in a child's mind. Sometimes there is explicit gatekeeping or exclusion, but often there is more implicit messaging that discourages certain interests.\n\nI witnessed this firsthand in Paraguay while doing fieldwork on One Laptop per Child. There was a coding club that was only attended by boys, despite efforts to include all children. It broke my heart to see a precocious girl being excluded because her mother felt it was not a safe space for her. This kind of exclusion happens all over the world, but initiatives like girls robotics clubs provide a safe place for girls to explore their interests and find camaraderie with others.So, I find that really promising, has a new direction, a new way that people are getting into it. We talked about historically entry points for programming. I thought we could talk a little bit about wrapping up potentially other possible entry points for programming. You mentioned robotics and the girls clubs for robotics, which I think is fantastic. I did a little survey online on Twitter just to get an idea of my small audience and tried to have people retweet to get a bit of reach.\n\nDefinitely, the older crowd, they were all models of what you have in the book, like precocious boys from vic-20s to spectrums, if they're from England or other early computers that were brought into the home. The kid was allowed to play with them and grew up with them. Being in that, what I see from the younger audience that I have is very different entry points. One mentioned Minecraft. I thought a really fun one was that they were using a game called Club Penguin. Oh, Club Penguin, I remember that. They wanted to automate it and figure out a way to do that, which was their entry to programming. Another one was a lot of them got into science in college and were frustrated to the point where they were like, \"I need to automate these experiments and other things,\" and turned to programming and fell in love with it from there.\n\nI wonder about that, and you mentioned several times this idea of the why of programming isn't really there for the idea of spending an hour of code. It's like, \"Well, why?\" What am I getting out of it? Well, you're learning how to code. What can I do with that? That was a problem that I had early on because I dropped out of electrical engineering because I didn't find computers that interesting at the time. I got into a band and was totally into the music kind of thing. That's where I swam, sort of music technology. Now, computers can do all those things, but I feel like the entry points into it aren't always explained. You mentioned a couple that I wasn't familiar with, like the TamTam thing sounds kind of interesting because a music entry. Video games have been one, and Al's written several books about trying to get people interested in programming through creating games. Do you have other ideas for entry points that maybe are kind of outside there?\n\nYeah, a colleague, a friend of mine, Christo Sims, wrote a wonderful book about this. It's focused on a tech-heavy charter school that was started in New York, and its original mission was to foster entry points for underrepresented students of various sorts. They had a big Latinx population, a lot of girls. One thing he found in his ethnography of this school was that a lot of kids loved music remixing and coming up with clever memes. Sometimes, there is a lot of richness that happens in these spaces that is underappreciated as a technical entry point. He was under the umbrella of connected learning, a movement headed up by Mimi Ito and others that tries to use children's existing interests and communities as entry points to scaffold into learning of different sorts. It doesn't have to be programming, but I think music mixing definitely lends itself to a certain kind of computational thinking.\n\nSadly, what Christo found at this school was that those technical expressions were almost systematically undervalued by teachers who are well-meaning. They were working at this progressive school and really wanted to support these kids, but they would say that's not the idea I have for a technical activity. What you need to do is program a video game or something else. There's a focus on that, but it's also important to have entry points grounded in the cultures that diverse children exist within and take those cultures seriously as starting points. That's one thing I love about cultural studies, which is a strong influence on my scholarship. It takes popular culture, including children's cultures, seriously. These things have real influence on people's lives and world views.\n\nThat is a sad tale, but I think there's a lot of potential in scaffolding up from TikTok culture, music remixing into computation.I feel like there is a wonderful opportunity for addressing some of the critical angles of quality control and community building. Maybe using restorative justice models when things go south. I love movements towards that. I see girls robotics clubs and organizations like Black Girls Code. Their mission is more directly about coding, but they start with the culture of black teenage girls, which I love.\n\nSometimes, the answer might be giving yourself more power over your life, jobs, and time. How are you being tracked? Using technology to empower yourself more, rather than just being a consumer. Pushing STEAM back to STEM by taking the art out of it is interesting to me because the artistic side of computers is what's interesting.\n\nI was drawn to programming because it felt powerful. It was talked about in a powerful way. I find it limiting when it's only about the economic side. It's frustrating that it's all about apps that save the world and make it a better place.\n\nPeople study computer science for economic reasons, which I understand, but I wish humanities and social sciences were better funded. The focus on economic benefits is prevalent, especially among privileged white parents in Silicon Valley.\n\nThe messaging from tech parents to their kids is not tech-critical. It's very instrumentalist, focusing on getting a good paying job. The tech industry ends up just recreating itself through these means and the focus on outdated narratives.\n\nThe socially imaginary of the technically precocious boy persists, despite there being many entry points into coding today. The focus on metaverse by Facebook is just a reiteration of old ideas from the novel \"Snow Crash\" from 1992.Let's create that, but it's really a limited imagination of just their own nostalgia for things that were popular 20 years ago. Oh yes, and the metaverse, like that was a dystopian world. It is totally dystopian. I can think of it, it's so crazy. But yeah, I mean, I think William Gibson and Neuromancer defined so much of the cyber-libertarianism of the 1990s, right? Cowboys, this idea of manifest destiny, all of the kind of colonialist connotations of that, that of course were unquestioned by many then. But we can look at it with a little bit more critical eye now.\n\nYeah, we are still playing over some of those same kinds of whether utopian or dystopian literary worlds, whether it's Snow Crash. I heard so much reference to Diamond Age in my research on One Laptop per Child. Again, a kind of dystopian world. But they talked about the Young Ladies Illustrated Primer being a kind of motivator or model in some ways for what they were trying to make. The Diamond Age is also a novel by Neil Stephenson who wrote Snow Crash.\n\nAnd I know we're at the end of this episode, I could just keep talking for hours and hours. But yeah, I also personally knew Alex Peake who was behind the Code Hero Kickstarter project. This was one of the first Kickstarters that hit the six-figure realm in how much money it raised, $170,000. And it wasn't necessarily a scam, although there were a lot of questionable things and nobody knows where that money went. But it was this idea of creating a video game that teaches kids how to code, and they raised a lot of money for it and it went absolutely nowhere because Alex was very much enamored with the idea of the Diamond Age and this idea of having this software that could teach, he said, not just coding but he wanted his project to eventually be used to teach anything.\n\nWhich kind of dives into that whole idea with MOOCs and online classrooms that were also really popular a decade ago. This, I mean, in so many ways the Code Hero story is almost a perfect recapitulation of many of the stories that were told about One Laptop per Child, right? Kids who fall in love with this, they teach themselves everything. Of course, One Laptop per Child didn't have a 3D world. This machine was so underpowered it could barely limp along with playing an episode of anime.\n\nYeah, it was like a one gigabyte hard drive and 256 megabytes of memory, which even back in 2005 was pretty sparse. Yeah, it was off, but you know it's enough to make text-based games in BASIC, so you know it should be enough today, exactly.\n\nSo yeah, I'm glad you mentioned Code Hero just because it's again such a wonderful or terrible, depending on how you look at it, recapitulation of so many of the same ideas. And one hope I have for all of this work is that even just reading this history of One Laptop per Child and reflecting a little bit on it helps people recognize when these same stories come up again, whether it's in Code Hero, whether it's in maker spaces, whether it's in the next new kind of edtech project. Certainly VR, I think some of those same stories get retold. My hope is that in recognizing those stories, we're able to maybe resist falling into that charismatic trap.\n\nI recognize that charisma, in a way, is important for getting funding for a project, for galvanizing support for a project. But I do feel like falling into that utopian vision really separates you from the lived experiences of people on the ground with diverse needs and desires and daily lives. And that is often what is missing in these kinds of projects. That good grounding and honestly a little bit of humility from the parts of developers, admitting that their solution might not work, that they don't know everything, that they really need to listen and to put themselves in the background as much as possible. It's quite the scarcity of humility out there right now. [Laughter]\n\nI'll create the humility app and a daily dose of it.\n\nYeah, well, I don't know how much time we have, but I at least would like to give you a chance to do any shout outs or social connection information that you'd like to share.\n\nYeah, sure. Gosh, if I were to do shout outs to people who have helped me along the way of all of these projects, I feel like we'd be here another hour at least. I do think I've mentioned some along the way. There's some wonderful other literature, one that I haven't mentioned that I feel like has just been really inspiring for me as well is a lot of Lillia Rani's work. She's a professor at UC San Diego and wrote this great book \"Chasing Innovation\" where she kind of breaks down this idealism around design thinking. Oh, cool.But she's doing a lot of great activist work now around the San Diego Street Light Project, which put these surveillance street lights all over San Diego without much oversight at all. A lot of other areas right, she helped write her copticon and continues to help run that world, that way of workers organizing Mechanical Turk workers organizing and pushing back against exploitative practices.\n\nOh gosh, there are so many people, I retweet many of these kinds of people, so I encourage people to connect with others, feel free to follow me. Yeah, I'll include all that information.\n\nI tend to be pretty leftist on my Twitter presence at least, but I do try to retweet a lot of useful things along these lines. Cool. Do you have anything you want to shout out here briefly?\n\nMostly, I just wanted to shout out \"The Charisma Machine\" because it's such an incredible and relevant book for me. I want to teach people to code and also, I lived in the San Francisco Bay Area and Silicon Valley for about 12 years. There are a lot of naked emperors out there, so reading this book and getting the ideas in it is important to avoid the next hype cycle. I really want to shout out that book. Also, I write my own books teaching people how to program in Python, and you can read them for free online under a Creative Commons license at inventwithpython.com.\n\nThanks again, Morgan, for coming on the show, and thanks again, Al, for bringing this to my attention. This has been fantastic. Thank you both for this opportunity. It's great to get a chance to talk with you. Thank you.\n\nDon't forget you can get simple cloud data connectivity to SAS big data and NoSQL from Pandas, SQLAlchemy, Dash, and Pedal. Learn more at seadata.com.\n\nI want to thank Morgan Ames and Al Swaggart for coming on the show, and I want to thank you for listening to the Real Python Podcast. Make sure you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "Iz0VmfKw09U": "Welcome to the Real Python Podcast. This is episode 102. Would you like to build visualizations that allow your audience to play with the data? How do you effectively use Python's assert statement during development? This week on the show, Christopher Trudeau is here, and he's brought another batch of PyCoder's Weekly articles and projects.\n\nWe talk about an article that shows how to build interactive visualizations with Pandas, Seaborn, and IPywidgets. These widgets allow you to add sliders, buttons, and drop-down menus to your Jupyter notebooks. Christopher shares a Real Python article titled \"Python's Assert: Debug and Test Your Code Like a Pro.\" It covers how to use assert statements to document, debug, and test your code while in development.\n\nWe cover several other articles and projects from the Python community, including a news roundup, code review guidelines for data science teams, a project to manage your to-do list using Python and Django, a Python 4 dream list, a static site generator based on Django, and a book of practical Python projects.\n\nThis episode is brought to you by FusionAuth. FusionAuth is an authentication and authorization platform built for devs by devs. Try FusionAuth for free at fusionauth.io.\n\nAlright, let's get started. The Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at RealPython.com. After the podcast, join us and learn real-world Python skills with a community of experts at RealPython.com.\n\nHey Christopher, welcome back. Hey there. We're gonna keep the trend going of starting with some news items, and you had the first news.\n\nYep, my first bit is about the TOML parser getting added to the standard library in Python 3.11. This is based on PEP 680. If you haven't heard about TOML before, it's yet another text-based configuration language. TOML stands for Tom's Obvious, Minimal Language, and if you've ever played with INI files (I think those are .INI files for the cool kids in Windows), it's kind of like that. TOML isn't really a Python-specific thing, it's in a whole bunch of different languages, but it started showing up a lot in the Python world. The format is being used by a lot of the newer packaging tools. Yeah, if you've ever seen PyProject.toml files, that's what I'm talking about. And there are other libraries that have started using it a lot, so Pytest, Black, Coverage, and a bunch of others are all using it to configure them. So, it kind of really brings the question out of what took so long. This is one of those cases where the third-party libraries have actually gotten ahead of the standard library, so the standard library's really just catching up now. That sort of makes sense, so yeah, it's all part of Python 3.11 and it'll be included in October's release. And I think it's already in one of the alphas.\n\nOkay, cool. Yeah, the first places I was seeing it several years ago was for like Docker container sort of instructions and setup stuff, right? And then Brett Cannon has a good article on his blog about TOML. I think I've mentioned it before, but I'll include that too. Yeah, I like it. I find it a little easier than YAML. It's a little less picky, so for quick config stuff, it does the trick.\n\nYeah, so mine is building off my conversation with \u0141ukasz Langa, and he was on Episode 82 where I was welcoming him as the Sea Python Developer in Residence, and we talked a lot about what he's doing day to day. A lot of the work is on issues and bugs and other things that are happening. There's been a resource called bugs.python.org or BPO for the cool kids, as you say. He was mentioning at the time that they were thinking about moving that along with all the other tracking and so forth to GitHub, and that process is moving right along. He had a post recently talking about it, and so I'll include the links to it. They're looking for feedback on it. They will continue to have sort of the legacy in a read-only state on bugs.python.org, but pretty much everything else is going to be on GitHub. And a lot of it has to do with getting people to be involved in the project is easier through GitHub. It seems and also it's nice to have everything kind of in one place. So check it out. It's coming soon, and there are some important dates that are listed on there. Friday, March 18th, they're doing like a final end-to-end test migration. There are a lot of stuff they have to move, so it's not going to just move in one day. If you'd like to learn more about that, again, here's the link for you in the show notes.\n\nYeah, I always find that I will hesitate to fill in a bug report if I have to create an account because you're immediately into that mode of okay, who is this and what are they doing with my email address? Whereas if you know, the flip side of it is, you know, GitHub owns everything now, yeah, but you know, everyone's there, it kind of just sort of makes sense. Yeah, definitely. So what was your... we have like a couple little short ones here too.\n\nJust a quick hit on Python 3.11 keeps chugging along. Alpha 6 came out on March 7th.So, if you want to play, there are more features available. The endless march towards October continues, definitely. Mine popped up right while we were planning this episode. Brett Cannon mentioned on Twitter that PEPs have a new home with a shiny new theme. We were talking so much about PEPs in our last episode together that I thought this would be a nice item to share.\n\nNow, you can go to PEPs at peps.python.org and check out the new site, the new home for PEPs. You land on PEP 0, which is the index. The index is really handy, with lots of ways of organizing them. Not only by what's accepted, what's been rejected, or what are different ones that are kind of in there.\n\nIf you want to learn more about the language and the future of the language, this is another great place to do research. It's nice to have a new home, and it looks a lot more modern than the old home.\n\nThat brings us to topics. You were starting with a Real Python one, right? That's right. I'm going to talk about the article \"Python's Assert: Debug and Test Your Code Like a Pro,\" another one by Leodonis Ramos at Real Python. He's one of our more prolific authors.\n\nAs you probably figured from the title, it's about how to use the assert statement. Assert is kind of like a debug statement, but with some teeth. It allows you to do a sanity check, verifying some condition is true. If the condition isn't true, it raises an exception, forcing the program to exit.\n\nOne of the things I had to get used to, I think this is because I've come from other languages, is it's a statement rather than a function. Which means if you use parentheses, it can screw you up because those parentheses will actually be treated as a tuple. Okay, and non-empty tuples always evaluate to true. So you end up passing to assert a true value rather than the thing you're actually trying to test, which is a problem. The newer versions of Python will throw a warning to tell you that you probably aren't doing what you want to be doing, but the older ones don't. So, depending on what version of Python you're on, you have to be a little careful about that.\n\nAssert takes two arguments: the thing being asserted to be true and an optional message to include in the exception if your condition fails. It's a good practice to put that message in because it can be helpful when you see what went wrong. The conditions themselves can be pretty much anything that you might evaluate for truth units. So, the same kinds of stuff that you put in an if statement. You can compare values, check for membership in a container, call isinstance, you get the idea.\n\nThe cool thing about this is you can actually turn them off, so you don't have to hunt them down in your code and remove them when you're done. When you use one of the optimization flags, which is zero or -O on the command line, the Python interpreter automatically ignores these. You can also do this with an environment variable, and the article explains how to use the flags, how to use the variable, and even some of the underlying mechanisms about how all this works, having to do with dunder debug and other interesting bits about how the stuff works in the background.\n\nHow often do you use this in your code, like with having the flags as options? I will admit it's not a tool I use. I also tend to be lighter on debug than a lot of people. I leave debug in that I know I might want my logs for later, but I tend to turn it off quickly. I am an old man, and debugging used to be print statements. I tend to use the things I was taught when I was younger, and old habits die hard.\n\nI wonder about it a little bit, the idea that you're potentially leaving something in there and you need to think about it. I think it's no different than having debug statements with a debug flag or a warning flag. In production, you say only spit out the stuff that's marked as error if you set your environments up correctly to handle this. It's just another environmental flag, so I think it's just another way of doing things and use what works for you.\n\n[Music]\n\nAuth is a necessary component, but is it really a differentiator for your application? FusionAuth solves the problem of building essential user security without adding risk or distracting from your primary application. FusionAuth has all the features you need with great support and a price that won't break the bank. You can either self-host it or get the fully managed solution hosted in any AWS region. Get started for free at fusionauth.io.\n\n[Music]\n\nMine is building on something I talked about with David Amos way back in episode 60.He actually had mentioned an article by Matt Wright about IPI widgets, and it was a fairly short article. It just shows the idea that if you're in Jupyter Notebooks and you would like interaction in your Jupyter Notebooks, things like sliders, drop-down menus, or even text strings that you could enter in and have be interactive inside of a notebook, IPI widgets might be useful.\n\nSo, my article that I'm going to talk about first is called \"Interactive Visualizations with Pandas, Seaborn, and IPI widgets.\" It's a Medium article by Zoltan Guba. I really like this; it was fun to play with. I think people know that I enjoy messing around with visualizations, and I did a course on Bokeh a few years back.\n\nThe problem very often with data visualizations and things like that is that you're sort of stuck very often with a certain state that they were in. The idea with Jupyter Notebooks very often is that you might be sharing that or having a web version of it, or what have you. It might be useful if it was interactive, that if it had checkboxes for true/false kind of values, text fields, or drop-downs, that it might be more useful.\n\nIn the beginning, the article just shows you the fundamentals of setting up the IPI widgets, then it dives into the visualization library. It has a nice dataset that they got off of Kaggle, which has lots and lots of data. It's IBM HR analytics employee attrition and performance, with lots of fields. It's a nice dataset to mess with, and it's about a quarter of a megabyte, so not too huge but some good information that you can try things out with.\n\nIt dives deep into building these interactive plots and graphs. I find it really easy to think about, and once you have to make something interactive, literally once you've imported IPI widgets, it's a really easy layout. You say, \"Okay, make this interactive,\" and then you put in the different items in there.\n\nI think it'll be great for you as a data science type person or if you're doing other forms of analytics for individuals to be able to let the user explore the data without them having to do a lot of programming. If you've thought about getting a little deeper into interactivity with your visualizations, IPI widgets I think is a great library for that, and it's a nice fairly short article diving into it.\n\nOne of my little favorite corners of the internet, which has nothing to do with Python, is a blog by Bartosz Chenowski. He does physics explanations, and he's only got about a dozen things on his blog. But one of the things he does beautifully is when he tries to explain something like cameras and lenses, he's got little sliders (I'm assuming it's all done in JavaScript) where you can change the position of the lens and it shows you the scope and how it changes as you move those things around.\n\nSo, there's a lot of power in explanation by having these tiny little tools. If you're trying to build something in Jupyter that is trying to show these pieces, being able to have certain lines go on or off a graph interactively means the user's going to be that much more invested in what they're looking at, and it's a lot clearer to them.\n\nThat's the thing I found when I started to create that I felt there's a different ownership compared to just leafing through a bunch of graphs somewhere where the person suddenly says, \"Oh, I can adjust this and I can kind of drill into something.\" Like you could set a minimum maximum range and say, \"Okay, I really want to just pay attention to over the age of 40\" or something like that, and allowing people to zoom in on that stuff.\n\nOutside of Bokeh, which has this thing where you can make a lasso and zoom in on data, but to actually have it interactively remove portions of it or filter things, I found people really liked it, and it was something that was really common that needed to be added to different projects and leaving it in a notebook is really nice.\n\nSo, what do you got next?\n\nWell, not that I don't like hanging out with you, but I have a day job. My marketing folks pitch it as a fractional CTO, so what that means is I do consulting for technical teams to help them improve both their technical chops and their processes for producing higher quality code.So, this next article just sings to me. It's by a gentleman named Tim Hopper and it's called \"Code Review Guidelines for Data Science Teams.\" I don't care that it says \"data science teams\" in the title, it applies to everybody. If you're coding on a team, a code review is a really important part of that process. It allows you to have a second set of eyes looking through what is written, hoping to catch bugs or design flaws.\n\nOftentimes, code reviews end up being about nitpicky stuff like tabs versus spaces, line length, or how to spell color. You know, all those things that have obvious answers. For the record, spaces 80 and with a \"u.\"\n\nThis isn't really what code reviews are meant for. That's why I'm a fan of tools like Black. Love it or hate its choices, it causes the team to say, \"We're using it, we're not going to argue about the formatting stuff, we're just going to do Black.\" The article covers all the good purposes of a code review, such as sharing familiarity over supported sections, getting design feedback, and protection from regressive defects.\n\nIn addition to talking about what gets reviewed, Tim also talks about what a typical code review process looks like, including an important section on what it shouldn't be used for, sniping at your co-workers, for example. The article is short, mostly using bullet points, which is nice and makes it pretty easy to read.\n\nEven if you're familiar with it, there are some decent little things in here that you might be able to use to brush up your skills. At the end, it has some links to other articles on the same subject, so you can dig around and see other people's opinions and delve deeper if you want.\n\nI like the inclusion of a handful of other organizations' review guidelines, which you can agree with or disagree with, but they've obviously had to think about them with large teams. I think that actually may be useful for somebody trying to develop their own code of conduct, where there are standards that are out there and a lot of people share those standards. I would imagine code review would be a really common set of things that have worked and avoided full-on breakout fights in our organization.\n\nI like Google's code review guideline note that a key point here is that there is no such thing as perfect code, there is only better code, which I agree with. It's always going to be improving. Every single line I write is perfect, I don't know what you're talking about. Hopefully, we can avoid reviewing each other's code. [Laughter] Yes, we'll stay friends that way. That sounds good. Excellent, right. I'll just review your videos.\n\nMy next one is a Real Python step-by-step project by a brand new team member, Charles DeVa. It's a project in Django, which I dig every time I play with it, I get a little bit further in. In this case, you're building a to-do list manager app titled \"Manage Your To-Do Lists Using Python and Django.\"\n\nIn it, you are building a full-function to-do list manager that can not only have multiple lists, but the list items, your actual to-dos, have quite a few details in them beyond descriptions and due dates. I really see it as a jumping-off point where you could really see, okay, well, my to-do manager needs these additional features or whatever that you could kind of enlarge a project and make it much more detailed.\n\nI found it a really thorough project. I went through it yesterday afternoon and built the thing. The first steps are as usual, setting up your virtual environment and Django, testing to make sure that Django's up and running, and everything there. Then you're scaffolding the project out, building your data models, deciding what type of database you're going to use.\n\nAfter that, you do a little bit in the admin interface and make some simple to-dos that you can kind of see things in there. From there, you spend a lot of time where Django, the heart of it, is building views and templates, working with request handlers, and updating the models to do additional features like okay, we still need to be able to delete things and define those connections and confirmation URLs.\n\nIt's a really nice project, and I think people will get a lot out of it going through and learning a little more about class-based views as how he approached it in this particular case. There's a bit of object-oriented programming that you see in often a lot of Django projects, and it's nice looking.I think it's something that would be a nice project to share. He used another CSS library that I wasn't familiar with. In the next steps, he talks about how you could go in and enhance it even more. It's called simple.css, similar to Bulma. The one I did a couple of weeks back with Martin Bootstrap is the one I've used the most. It's like adding a one-liner to your base HTML to get nice results.\n\nHe has lots of suggestions for next steps on how to make it multi-user, even deeper with class-based views, hosting, and adding additional features. It's another nice step-by-step project to get you deeper into working with Django. It's helpful for new users to have something to work on and learn from, especially with a big framework like Django.\n\nThe Django project's first project is a poll, which is interesting. Other famous projects involve building a portfolio app. It's nice to see Django used in different ways, like creating applications where users interact differently than with a portfolio.\n\nThis week, I want to shine a spotlight on a Real Python video course about making predictions with Python AI. The course covers machine learning, deep learning, neural networks, weights and vectors, reducing prediction error, and building a neural network from scratch using Python.\n\nIn a Reddit conversation about a potential Python 4, there were interesting ideas like deprecating all string formatting except for f-strings and standardizing the standard library against PEP 8. I personally would like a way to have indented multi-line strings without extra function calls.\n\nOverall, it's important to have projects to work on and learn from in order to deepen your understanding of Python and frameworks like Django. It's also interesting to see different perspectives on potential future developments in the Python community.I had to think about this for a while and I don't have any real strong opinions or items on my wish list. My biggest wish list item is that we don't move to a version four anytime soon. When I got my first job in Python in 2018, there was still some uncertainty about projects in Python 2.7 or 3.6. I had to ask my potential future employer what version they used, and they said they were on Python 3, which was a relief for me.\n\nFrom the sidelines, I watched the drama of Python 2.7, with people joking about the \"death clock\" and organizations having to deal with migrating code bases. I'm not interested in breaking changes in a version four. I see many core developers are not keen on moving to a version four either.\n\nI hope future versions focus on speed improvements, and I'm not sure about the future of the GIL in later versions. I don't want a non-compatible break in a new version number. I would like Python to work better on mobile and have a better GUI framework, possibly outside the standard library.\n\nThere are discussions about Python being compiled, but I'm not sure if that's the direction we should go. I have reservations about moving to a version four too quickly, as there's still scar tissue from past transitions. Learning from the two to three transition could make a future transition smoother.\n\nThe GIL may disappear for pure Python, but it could impact C plug-ins. Including GUI frameworks in the standard library may not have been the best decision, and using an external framework might be more practical.\n\nPython's popularity and diverse user base lead to differing opinions on new features. Progress is made by addressing different needs, but it can also make it challenging to learn everything about the language. Some additions to Python, like the walrus operator, have sparked debates, while others, like the match statement, have been more accepted over time.I just feel like it wasn't as intense as what was happening with something like the wallish operator and some of those other changes. Even in our own conversations, type checking is still something that I don't know. Is that something that would help with a new version to make it even deeper, or does it need to be something like the JavaScript/TypeScript thing where it's a completely different language at that point? And you kind of are developing something that is type-specific. I'm not a computer science major and I haven't studied the origins of operating systems. I definitely want to learn more. These changes to the parser have been super interesting to me, and I've been learning more about that. I want to get a few people on the show to talk about that a little more. I've thought about getting Pablo on to talk about it because he's been adding a lot of really interesting stuff using the new parser for much better error messages in Python 3.10 and I guess that is continuing in 3.11, which I think is going to make the language more approachable in some ways. It always depends on what you want to do with it, like data science, which is a whole other beast. Learning about how to use that and so forth is going to be a separate journey that you're going to go on. I don't know if there needs to be a separate Python language. It can be just these packages and other things that people use in those circles. Yes, I guess the conversation is good that people are talking about things, but again, I'm in no hurry for a Python update with this release schedule of every year. I'm just interested to see the things that they're adding in the next upcoming versions.\n\nThat brings us to projects. The project I'm going to talk about is Django Distill. I was super happy to put this project on our recommendation list. It deserves more love. The creator goes by the handle \"Meeb\". I couldn't find their real name. Their home page is a funky animation with an email address and a link to GitHub, so \"Meeb\" it is. If you haven't come across this one before, it's a static site generator. Static site generators are templating mechanisms for creating websites that don't require any server-side code. So, you can include browser-side interactions like JavaScript, but the server is only responsible for serving the pages. This typically means no database interactions. A big number of websites can actually just be static sites. Years ago, I worked at a company that had about a dozen web properties for kids and parents of young kids, and about 80 percent of their content was static. You'd use editing tools to create it, but when a page is published, it's simply output to the right spot in Apache. You can get crazy scaling out of this because there's no database application and no application servers. We were handling 40 million hits a month using this kind of tech with very few servers. As CDNs have become popular, that allows you to put the content out on the CDNs, which puts your content local to the users as well, so it can be a huge performance gain.\n\nA couple of years back, I needed to redo my company's site, so I went looking for a static site generator because it's really just marketing stuff. Most of them expect you to learn some new templating language and tool set, but then I stumbled upon Distill. So, how Distill works is you write a Django project, test everything locally with your Django dev server, and with a few small changes to the URL routing code, you're ready to go. You run a management command and Distill goes through all the URLs in your project and creates static web pages in an output directory. The beauty of this for someone like me who does a lot of Django is I didn't have to learn anything new. Ten minutes with the instructions for changes to the urls.py file and I was good. If you've already got a Django site, there's a good chance you could turn this into a high-performing static site with very little work. And if you don't have a Django site but you're familiar with Django, it allows you to build the site using the tools that you're familiar with. So, go give \"Meeb\" another star on GitHub. This project really deserves it.\n\nAt that point, you've created a static site. How would you serve it up?\n\nFor my corporate site, the hosting account I have gives me access to an Nginx directory, so I simply zip up the output directory and unzip it in the correct Nginx directory. Things like CDNs work in a similar fashion as well. You need the account with the CDN or however they're all picked up, but you're essentially just transferring the files. SSH to the right place, and you're good.Yeah, that sounds good. I think that might be handy for a lot of people. I know there are other solutions for making static sites, but some of the projects that we've been sharing lately have been Django-based. If this could work for you to add new content, then you would just go through the process of distilling it, quote unquote. That's right, yeah, okay.\n\nI've used it for vacation photo albums, digital photo albums, and you just go back in, add another page the same way you would in Django. Instead of having to set up a server somewhere running Django and all the rest of it, you rerun it. If you're a Unix geek, you can use tools like rsync that are smart enough to just send the different files rather than the whole thing, so yeah, you can get pretty efficient with it.\n\nMy project is a whole book of projects that was on PyCoders this week, and it's really a neat book. It's available for purchase as well. The author, Jesus Khalid, it's called \"Practical Python Projects\" book. That's its title.\n\nI'm just going to look at the numbers here. If I go through the table of contents, there's like 12 different projects, there's 14 different chapters. I'll just read off some of them, but again, on the show, we've shared the idea that if you really want to get better as a developer, you need some projects to build, try things out, and even if you take existing projects and modify them to your own needs or update them in your own way, it's such a great way to not only learn and get more comfortable with stuff but to showcase your work. This is a really good set of them, and it uses a lot of technology and definitely would show off your ability to integrate.\n\nChapter three is all about making invoices, and in that particular case, you're generating PDFs from HTML. It actually uses a library that I wasn't familiar with, it's called Wheezy Print with a W. I started looking at it, and the project is supported by Open Collective, which builds on this conversation that I had with Josh Simmons in supporting open source projects. So, it's one of those that there is this need to have PDF support and ongoing printability and so forth as an open source tool, and have support that it continues to be maintained. I'm interested in trying that one out and seeing what it can do, but the idea is to take HTML and pretty easily turn it into PDFs. This one is making dynamic ones that you can get values from a client and kind of build up there.\n\nOne of them is playing with the Twilio system, and it's a FIFA World Cup Twilio bot. There's a few that are kind of aggregators like an article summarizer, an automated image generator, a bot for Reddit and Facebook, a cinema pre-show generator which is basically grabbing a whole bunch of trailers. All this stuff is fun. I have talked about this with Al Swigert before that often when you make projects, one of the biggest tricks is, is this something that is just a proof of concept but you're not interested in probably showing other people? Would a friend of yours be interested in seeing this project running? I think something like the cinema pre-show generator would be kind of fun in the sense that it's going to grab all these trailers and stuff. That was something I would do on a Saturday afternoon with my wife. We would just sit down and all right, what are all the different trailers 'cause we haven't been to the movies in so long, you know, like what's up, what's going on.\n\nUnderstanding decoding JPEG images, making a TUI (text user interface) email client, a music video downloader, another one where you're deploying Flask to production, and almost all of them, it looks like every one of them has a \"next steps\" section. How could you enhance this? How could you continue on from it? So anyway, he's been working on this thing. It looks like by reading the beginning of it since 2018. I think you'll get a lot out of it. I found that there is a GitHub repository with the projects on it so you can kind of get the code listings and maybe the requirements files and so forth to learn a little more about it if you need some help following along with it or do you want to see how it looks all assembled. So yeah, it's a great book, great resource, and yeah, if you can, I would suggest supporting him. But again, it being available as a website, I think is great too. If you do check it out, give them some feedback and let them know that you like it.\n\nI like how it's organized too, right? So the chapters are divided up into little sections. For example, if you want to pick up some Qt but you don't want to do the full music download project, there's a section titled \"Basic Qt App\" underneath that, and even as a standalone article, it shows you, okay.How do you get Qt going and how do you use that in Python, right? Yeah, and there's a lot of depth here too. So, the chapter on JPEG is hardcore. He gets into how encoding works and how to deal with binary data in Python. Normally, a tutorial like this would, like when you see the heading JPEG decoding, you'd be expected, \"This is how you use Pillow.\" Yeah, this is actually talking about the binary format of JPEG. Right, so he's right down to what the headers look like, all the rest of it, and how to interact with that with Python. So, there's some really deep content in here for all sorts of levels of programmers. So, if you're just getting started, there's stuff here. And if you want to learn something deep about how JPEG data works, that's there for you too. Yeah, there's one scraping steam using lxml, which is another scraping sort of tool. And I think this might be fun. Again, both of us are into video games, but the idea is that you could have it go look through like new releases or other things like that and kind of pull information out. But I think the power of this thing is you playing with all these other libraries, and then maybe that's going to spark ideas for you to see how you could maybe incorporate that technology in other places. And again, if you add all these things to your portfolio, it really shows that, I don't know, for me, like a most common thing that happens as a programmer is that you're presented with a problem and then knowing what the different tools are that are even just available to you to try to solve that is the most common thing. And often it involves these third-party libraries or open-source tools, and just getting familiar with how they work and kind of implementing them a little bit is just going to make you a much more flexible programmer.\n\nYeah, there's really sort of three levels, right? There's learning the syntax of the language, learning the functions and things that come with the language, and then there's learning all the libraries that go with the language. And that last one is never-ending, right? Yeah, totally. And, you know, so it's always like a survey of like, okay, well, when was the book written? So, this is a really recent book, came out in January, so you're going to be seeing pretty recent tools that are out there and being used. And, so anyway, I think it's a great resource and check it out. Yep, good stuff.\n\nAll right, well thanks, Christopher. It's been fun talking again, and I look forward to us improving on this new format that we have here. Well, two episodes from now, we'll be talking about Python 5, so be ready for it. Oh, okay. And don't forget, do you have a side project that needs custom login and registration, multi-factor authentication, social logins, or user management? Download FusionAuth for free at fusionauth.io. Download.\n\nI want to thank Christopher Trudeau for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "kwk4BmnYs8I": "Welcome to the Real Python Podcast. This is episode 107. What goes into creating those enhanced error messages in the latest versions of Python and how does the new PEG parser help to pinpoint where errors have occurred? This week on the show, Pablo Galindo Sagaldo talks about the work that goes into creating these improvements. Pablo is a core CPython developer and is the release manager for Python versions 3.10 and 3.11. He also is serving his second term on the Python Steering Council. Pablo is pleasantly surprised by the positive feedback for the new error messages in Python 3.10. He shares some of the upcoming enhancements for Python 3.11 and we talk about how the new PEG parser allows for greater context when defining errors and where they occur. We also talk about how he started contributing to CPython and he shares some of his programming experiences while studying physics at university.\n\nThis episode is brought to you by Linear B. Their free worker B for pull request Chrome extension gives your team context about your PRs so that they can pick it up and review it faster.\n\nAll right, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Pablo, welcome to the show.\n\nHey, thanks for inviting me.\n\nSo you've been really busy with lots of different things going on. The first thing I wanted to talk about is congratulations on becoming a member of the Python Steering Council.\n\nOh, thank you. Thank you very much. It's been an honor to be serving the community for the second year in a row and I'm very thankful for everyone that has put their confidence in me and the rest of the Steering Council.\n\nYeah, it's been interesting watching that sort of evolve over the last several years. I'm really liking the direction things are going. So you guys are steering things well.\n\nNice to hear that. That means that everything that we have been doing has passed unnoticed.\n\nNow, let's start with a little bit of background. I know that you have a background in physics. Were you using any other languages before you started using Python in that research?\n\nI actually started using Mathematica, but now it has evolved to be much more than that. I don't know if you even qualify as a language, but let's call it that. It was Mathematica. And I used a lot of C because, like, unfortunately, actually, for whatever that, hopefully, I don't need to touch it again. But yeah, so it turns out that in physics, especially Fortran actually is very common and it's kind of like a self-replicating language because your advisor made the Fortran program in the 80s and now you need to maintain the thing or evolve it. So, and it's so weird because all these programs start with some kind of log at the beginning of the file, like a poor man's git that says everything that has changed. It's so weird. These are all the commits to it. These are all the people that have suffered in this file. Right? Like, you can, there is a counter of number of hours spent in this file and then you just increase it.\n\nThat's cool. But yeah, C and C, so mostly C.\n\nOkay. And are there different flavors of C that are more popular for that or just straight C?\n\nNo, it's normally C99. Like, especially in academia, I mean, nowadays it's changing a bit. Also, people have clearly steered into C++ and especially because the programming I used to do in my PSD was mainly to be run on supercomputers and things like that. And clusters, and in the day, they were very restrictive on what you could run there. Especially because, you know, they also need to check that your program is worth it, let's say. Because every hour of those CPUs is like a team of people that you never meet that check the code and say, \"Yeah, your program is worthy to run on our cluster.\"\n\nThat makes me think of the shared computers of the 70s and so forth. You know, waiting with a stack of cards or something to load into them or something.\n\nWow, okay. In our case, the joke is even, I think, a bit funnier because we used to submit things to a supercomputer in Spain called Mario Nostrum, which is in Barcelona, if I remember correctly. But the funny thing is that the supercomputer is inside a chapel. So, like, the sacred, the secret supercomputer or something. They usually use the chapel to hold the supercomputer. Going to church to run some software, the sacred, the secret code.\n\nBut yeah, they were a bit restricted and they normally allow... Used to allow a lot of things, but normally it was like Fortran, C, and these people need to read your code anyway. But nowadays, I think they have even an econometrician by the floor, which is great.And they have used very extensively Docker and whatnot, so things have changed a lot for the better. In my time, it was just good old Fortran and C99.\n\nThat's interesting. How many years would you say it's been moving toward Python, Anaconda, and those things in those places? I don't know when they switched over. Academia moves slowly, so this has clearly been after Python has exploded in the scientific and numerical realm outside, although obviously related. I think in the past five years, it's been pretty common. Since I moved, obviously it's been a while since I was doing any research. Now I've moved to the industry, and the touch points I have are because my friends that are still doing research tell me about or ask me to solve things, and then I need to log into these places and try to fix things. It's like when your father says, \"Fix my printer by academia version.\" There are other people, like previous colleagues that you were working with, and you're kind of giving them an assist here and there. Yeah, exactly. Like, \"Fix my Python installation in my cluster,\" or \"I have this code that runs in Python 2, and I cannot use it anywhere anymore.\" It's like, \"Okay, let's fix it.\" But you know, it's not the most glamorous work. That's what friends do, right? Yeah, tech support is never all that glamorous, it should be. Right. What types of tools were you using in Python to do your relativity and black hole physics studies? Like, what kinds of libraries and things like that were you using? Right. So, just to clarify a bit, I'm a theoretical physicist. Most of my work was with pen and paper, but also with computers, more algebraic systems, equations. But then there is a time when you hit some equations that you cannot do anything else than simulate them. That's when I started to do the computing. In that part in particular, I think the most typical areas I used at the time were obviously NumPy, System, a lot to reach the code written in C++ with other things, and a lot of PyCUDA, which is like the bindings for CUDA, this language by NVIDIA. And now there is like a lot of things. Every time I go to Python, there is like a new super cool thing that I wish I had at the time. Regarding graphics card, but at the time, PyCUDA was the thing. It was not a good story. Like, it took me hours just to install a version because you need to compile things, and you know, there are no wheels. Now I understand much better the situation, but at the time, it was always a pain. Good times with those tools, yeah. Cool. How did you get involved in Python as far as becoming a core Python developer? And then we could talk a little bit more about how you kind of took on the role of release manager. Of course. I think this story is not super fashionable, but the way I did it is because I saw something wrong, a bug in the documentation. It was something super ridiculous, like some code example was missing an import. I submitted a pull request because it was so trivial. Like, how is this missing in official documentation now? As a developer, I look at the community and say, \"Wow, that was the least bad problem.\" But I assumed a pull request and had a great experience. I was contributing to open source before, but I had a very cool experience there. I got immediately hooked into contributing, and then I used my previous experience with C. It's also different, the scientific C code than kind of like programming language C code. It sounds like I should be there and roll, but no, it's very difficult. There are many skills that differ on right. But obviously helped. So I normally tend to gravitate towards the more internal parts. Obviously, now I'm fully immersed into that part of Python. At the time, I got attracted by the more C parts, some modules written in C or the interpreter itself or something like that. Nice. Yeah, it seems like your background would help. I would guess there needs to be lots of different backgrounds in this group of core developers, right? Why did you take on the role of release manager? I normally like to see different ways of contributing to Python, not only because I think it's a fantastic way to learn and go out of your comfort zone, but also because it's different ways to help the community. In particular, the release manager role was fitting because I was and still am looking at what is called the billboard fleet. So CPython has a brutal CI, let's call it.Apart from the CIA that we're having it, have you noticed how we have all these specialized machines running different OS's and compilers? The combination of things is enormous. I usually keep an eye on that and for many years, every time something breaks, I go on fixing it myself. This is part of what the release manager has to do. They have to ensure that these machines are running smoothly because if any of them fail, the release cannot proceed. This is just one of the many responsibilities.\n\nI've discovered that there are many extra tasks that need to be done as a release manager. It's a huge time commitment, lasting about five years. It's not just about the initial release, but also about releasing security patches and backfix releases. It's a continuous process for five years of your life, ensuring everything runs smoothly.\n\nBeing a release manager also involves a substantial social aspect. Apart from handling the releases themselves, which are time-consuming, there's also the responsibility of ensuring the release is stable and everything works fine. This involves checking the bug tracker and sometimes pushing people to fix things or resolve disagreements. Sometimes, you even need to revert changes that are broken and cannot be fixed in time for a release. Social interaction is a significant part of the role, requiring people skills more than technical ones.\n\nThere are many challenges that I didn't expect as a release manager. One unexpected incident was when we were renaming the branch from master to main in Python 3.10, and it broke everything, even GitHub. It was a funny but nerve-wracking experience. There have been other challenges, but that was the most unexpected one.\n\nOne thing I really enjoy about being a release manager is working closely with everyone. While I already work with everyone as part of the student council, this role exposes me to a different level of interaction. It's more personal and hands-on, especially during the release process.\n\nOverall, being a release manager involves a lot of challenges and unexpected situations, but it's also rewarding to work closely with others and ensure the success of each release.It's been very interesting because it exposes you to a different kind of conversation with your colleagues, contributors, and even third-party projects. Many people are affected by these releases, and sometimes it's not the most pleasant experience. But most of the time, it is. I enjoy interacting more with people, especially my fellow core developers. They are fantastic in their own ways. My interaction with the rest of the release management team, like Lukas, Ned, and Steve, has been super helpful. We spend many hours together fixing releases.\n\nI've interviewed Lukas twice now, and he talked about handing the reins over to me. The yearly schedule has definitely sped up, and it's now yearly for at least the two versions that we're putting out. We have at least three bug fix releases this week for versions 3.7, 3.8, 3.9, and 3.10. There's a lot of work involved, and it's a lot of invisible work. It requires hours to restart the release process.\n\nI've become more of an expert in CI/CD than I ever thought I would be. Knowing all the PSF machines and infrastructure has been quite challenging. There's a lot to improve, and it's a tradition for the next release manager to improve things. I've tried to automate part of the release process, but there's still a lot of trivia and arcane involved.\n\nOne of the main reasons I wanted you to come on the show is to talk about the enhancements you've been working on, like adding enhanced error messages in versions 3.10 and 3.11. I was interested in taking on that challenge to improve the user experience based on feedback we received. The genesis of the whole thing started when someone complained on Twitter about Python not doing a great job in a particular case. That motivated me to fix it, even though it was quite challenging due to the outdated architecture.\n\nThe tokenizer in Python is the oldest checkout in version 3, and it's very specific to its original purpose. Extending it was challenging because it wasn't designed to be a general-purpose tokenizer.Adding some improvements can be very challenging. For instance, for our listeners to understand, one example is when you don't close a parenthesis or bracket. The error becomes surreal because the tokenizer struggles to understand what's going on. The person is trying to make sense of the program after not closing the parentheses, leading to a surreal error like a function definition being wrong. The error of the enclosed parenthesis is detected later, sometimes showing unexpected EOF at the end of the file.\n\nAnother challenging aspect is reporting an error that occurs before the actual problem. The Python tokenizer is designed to be efficient, only advancing when necessary. It can show errors in interactive mode even before a full statement is completed. However, it discards consumed text once tokens are produced, making it challenging to point out specific errors in the past.\n\nOne challenging aspect was redoing the whole tokenizer to add backwards errors. This improvement was well-received by people, surprising even the most seasoned Python developers. It was celebrated as a significant improvement, leading to excitement in the community.\n\nSome concerns arose about the powerful tool of the pec parser potentially leading to complex grammars and changes in Python. People viewed the pec parser as both a powerful tool and a potential problem, fearing significant changes in Python's syntax.\n\nIn conclusion, the work on the pec parser has sparked excitement and concern in the Python community. While the improvements are celebrated, there is also a sense of responsibility in using such a powerful tool.So, I thought maybe I should use this parcel for something that is celebrated, something that we can only do with this, right? Because I was also just finishing another improvement. I said, \"Okay, let's use this parser for something like reworking the error messages, because now we have this extremely powerful new tool that allows us to create error messages in a much better and more reliable way. The main problem is that many of the error messages are difficult to detect. You normally detect error messages by creating a grammar rule that catches the error message. You need to teach the parser to parse the incorrect Python expression. So, you need to say, \"Okay, if you see this kind of expression, which is incorrect Python, try to identify it and then you can emit an error.\" In the old parser, it was very difficult to do that, not only because the infrastructure wouldn't permit it, but also because detecting these cases is technically challenging. Having an LL1 grammar that allows us to identify these cases is very difficult. The alternative was in one of the parsing phases, when you construct the abstract syntax tree, it used to be a manual process. It was basically transforming one tree into another. The problem was that you could add a lot of error messages in that handwritten code, but we are talking about an 8000 line C file done manually. Maintaining the thing was horrendous, and the probability of messing things up or showing things wrong was high.\n\nEvery function in that transformation had context only for the particular node being parsed, not for the actual language and grammar. It was impossible to add the error messages that are being added now, which are complex. With the new parser, it's possible. In the case of a situation where you're creating a more complex dictionary, like spell checking, it was hard to insert those rules in the old file you were talking about. You potentially didn't have the context around it or had to build some specialized portion of the tree to deal with those things, which could mess up other situations. It was a hard problem to solve.\n\nMaybe we could talk a bit about how the PEG parser functions differently at a root level. It's being introduced in version 3.9. It can look at expressions further and take a different approach. Maybe you could talk about how the PEG parser parses expressions differently.\n\nLet me try to explain. Normally, when you create a parser, especially in Python, these parsers are automatically generated. We use a parser generator that reads a file containing the formal grammar of the language, like correct Python syntax. In both the old and new parsers, we have a program that reads this file and produces the parser code, which is written in C.So we don't write the actual parser by hand. Normally when you do this automatically, as we used to do and we do it now or by hand in any case. What you normally do is start with what is called a context-free grammar. Normally in a version which is called Backus-Naur Form, it's just a format so don't worry about that. The ways that normally parsers are harder to write because the grammar is made into a way that is very easy to use for generating valid programs but it's very hard to recognize if a program is valid.\n\nOkay, normally you don't only recognize if a program is valid, you also generally call out to the program or make sense of that program. But it's more or less the same task for simplifying. Yeah, it's because like imagine that you have a description of what is a language. For instance, you can say, \"Okay, so you can have a production and the production can either be A or B. So if you want to generate random programs, you say, 'Oh, it can be A or B, so I can throw a random number. Sometimes it's A, sometimes it's B, right?'\n\nAnd if you have something more complex, for instance, in this, instead of A or B, it can be Thing 1 and Thing 2. And Thing 1 can be A or B, and Thing 2 can be B or C. So you kind of record it into the tree and say, 'Okay, I will throw random numbers and sometimes I will pick A or B.' So generating random programs is very easy from this, but generating the parsers is hard.\n\nBackus-Naur Form goes into a different way, which is instead of creating a definition of the language that makes it very easy to generate programs from it but very hard to create parsers, let's do the opposite. Let's create a description where generating the parser is very easy but kind of identifying, like generating programs, is harder and other things are harder. And so conceptually, the key difference, I think, that the way most people will understand the difference is the following.\n\nIn a normal grammar, let's say this is a particular example, so you imagine that you have a rule in the grammar. Let's say that you have, for instance, a statement. And a statement in Python can be a for loop, a class, maybe another particular statement is not the best example here, but like in mind that you can have for loops or class definitions or function definitions or something, right? You can have many possibilities.\n\nAnd when the parser, imagine that the person sees the word \"def\". The parser needs to distinguish if you are going to write a class definition, a function definition, a loop, or something else. But because the word \"def\" only happens to be on function definitions, then it needs a way to know, 'Oh, this has to be a function definition.' And the way it does it is that it deduces the correct version.\n\nSo in particular, it has to distinguish if it's a class, function, loop, or something, and it uses math to know which one it is. It's a system which is, in particular, Python because it's used to be a learner one parser. It uses something called the first sets and the follow sets which conceptually will teach you immediately from a token which of the possibilities are.\n\nSo you see \"def\", it knows there has to be a function definition because function definitions always start with \"def\" and nothing else starts with \"f\", right? So that's how a normal parser will do it. It will basically, when it's presented with many possibilities, it will use math to deduce the correct one and it will always know which is the correct one. And if it's not any of the possibilities, then it will say invalid program.\n\nBut PEG does something different. What PEG will do is that when it's presented with many possibilities, so imagine again function definitions, classes, loops, etc., what it will do is that it will try one after the other. So it will say, 'Okay, I don't care if functions are the only possibilities that start with the keyword \"def\". I will try class definition.' And it will say, 'Okay, the first token of a class definition is \"class\", but I have \"def\" now, and then it's not a class definition.'\n\nYeah, I will try a loop. 'Oh, but the first keyword of a loop is \"for\", oh that is not a loop.' And then it will try a function definition and he said, 'Oh, \"def\", functions also start with \"def\", good, good.' Okay, let me see what is next. 'Foo', okay, \"foo\" is a name that looks good.' And he will continue and then he will find out that actually he can parse the whole thing and he will say, 'Okay, this then is a function definition.'\n\nSo instead of like using math to deduce which one is the correct one, it will try one after the other until one of them passes. And that's the major difference between a PEG parser and any other parser in existence. Other parsers are different in how they deduce the correct one. So LL-1 parsers do it in a particular way because they are limited to only pick the next token.When they are trying to decide which one is the correct rule, they are only allowed to look at the next token. But there are other more fancy parsers, like other parsers that have super weird names like LR parsers and LLK parsers, something like that, all of them super obscure. But the idea is that the difference between these parsers is how they deduce many possibilities, which is the correct one, obviously recursively. Tech uses a different approach, it's literally \"I'm going to try one after the other until one succeeds.\" And obviously, if you are into programming, you will immediately say, \"Well, this is cool, but this approach is exponential because if you need to try all possibilities until you find the correct one, you're going to waste a lot of time trying the incorrect thing. If your grammar is very big, imagine Python, right? Like, every time you see a token, you need to try the whole language. So it's not good. \n\nThere are a lot of extra techniques and quite advanced computer science to make sure that the actual time it takes to parse is linear and efficient. That's the main idea, the main idea is that you will basically try things in order. And obviously, as you can imagine, the fact that the parser fails to pass a particular rule is not a failure, it just means try something else. Meanwhile, in a normal person and particularly the older one parser, if the parser fails to pass a rule, it means it's an incorrect program because you will use math to deduce which one it is. And if it fails, then it cannot be anything else because by my math, that this rule is the only possibility. And if the rule doesn't pass, then there is no other possibility. While in PEG parser, failure just means try the next one and hopefully it works. So that helps you get back a lot of the context that allows you to kind of see some of the stuff around it because it's sort of holding in its mind what it's looking for. \n\nThe technical term will be that a PEG parser has infinite look ahead. A PEG parser obviously doesn't do look ahead per se, I mean at least in the same way another parser will do look ahead to distinguish which one it is. But if you kind of try to put them into a framework when you can compare both parsers, another parser can only pick the next token while a PEG parser behaves like it is able to look infinite tokens ahead. So you can mention here will be precisely this look ahead so the parser is able to say, imagine for instance that you are parsing a function call. A function call, imagine foo parenthesis that opens and a bunch of arguments. The errors that can happen on a function call are much different than the errors that can happen, let's say, in a double expression. But both just differ on the fact that the function call is like a double with a name prepended. \n\nIt is more or less the same because a double is parenthesis, we have some things in between right inside of it. And it's just that the function call has a name before, like the name of the function that you're calling. But from the parser's point of view, it looks like a name and a double, which obviously is invalid, it's invalid syntax. The only possibility here is a function call, but in this particular case, you need all these extra contexts because if you are just looking and this may be linking to the example that I put before, if you are in a function call, passing between parentheses, well, as it used to be the old parser, then if you find an error, how do you know if you are parsing a function call or a tuple? Do you just know that this thing between parentheses, you don't know which one it is, so you don't know if you need to solve this error or the other, but a parser knows which one it is parsing, right? \n\nBecause it has all this extra context. I'm trying to hand wave a bunch of things, but it knows more. Yeah, it makes sense, it's more about what it is and how it works.We use this extra knowledge and extra power. Sometimes it is more difficult. This particular example is one of the most difficult ones because Python will first try to pass it precisely as a name and a double. It will say, \"Yeah, this makes no sense.\" Then it will try to pass it as a function definition. The important thing to highlight here is that, as you can imagine, if it's going to try things one after the other until one succeeds. One interesting question that you can ask is, \"What if two of them succeed?\" Well, the answer is that the first one that succeeds is the one that goes, \"Okay, that's how it works.\" So, it is very important. The order is very important.\n\nIn a normal parser, if you say that this rule can be there, be an A or a B or a Z, you will use math to deduce which one is the correct one. So, it doesn't matter that you say it's A, B, A, C, or an A or a B, A, C, or a C, A, B, right? But in a parser, it absolutely matters. So, this is a very tricky part of the parser. You need to ensure that the order in which you put the options is the correct one for two things. One, so it doesn't try things that probably aren't going to work early. And the other is that you may have two possibilities that work, and you need to ensure that the correct one, which is the valid Python, appears first so you don't pass something that is not valid before.\n\nIt sounds like there's a whole bunch of things hiding in there that I think about as far as the error messages that you're pulling out from that. What I wonder about is some of the things that you've been able to add through this method. Not only the ability to earlier on determine that they were actually defining a function at that time, and that's why it's missing that parentheses or whatever, but in a lot of cases, you're able to pinpoint where the problem is and you start printing out these messages back to the developer who is writing this program using these carrots, which I think is really cool.\n\nI think if it's new just because a lot of things fall into place. Like we added from in 310, we added technology to be able to highlight whole ranges, not only one particular character where we think it's wrong, but a bunch of them. So now that we had that, it was very natural to us to join that capability with the whole person, not just to some parts of it. So we can pinpoint where things are happening, but also entire sections. As long as we were working on that, we also improved how internally that works and how we propagate the information.\n\nI think you are more or less mistaken here because I'm discussing how the parser points to places, but I think you're talking about something else. You may be talking about runtime errors. I'm talking about the end result in some ways, like how the person seeing the error being shown to them and you're actually using these characters, these carrots, or whatever the center is to point at the things like right here, like this, you're missing something here.\n\nThis is very interesting because the recent error messages are normally very hard to do. Not only in parsing in general, it's because not only identifying if something is wrong is quite easy, I mean, a parser is doing a versa, right? So maybe not super easy, but at least we know how to do it. But identifying what is wrong is very hard because you need a lot of things and sometimes it's not even possible. Sometimes you need the intent of the developer.Right, we just know that there is a home, like in the sense that you need to now say, \"Okay.\" If we are passing this as a tuple, then there is a comma missing. But what if it's not a tuple? What if it's a function call? And what if the user was trying to create a function definition? Or what if, you know, like, there are so many things in mind that some new user might be trying to use square brackets to put the parameters in a function definition. So instead of doing \"def open parenthesis,\" it has \"def open bracket.\" Because they come from some weird language or they don't know, right? Something else.\n\nYeah, yeah. So how will we say, \"Well, you cannot write a list here,\" but the user will say, \"No, no, I'm trying to do a function, right?\" And, you know, sometimes a lot of times, we need to add error messages when we are very, very sure that the error will be with a high percentage of probability very close to what the user was doing wrong. Because there are a lot of speculative proposals. A lot of people in the community have been doing so. I'm very grateful for that, right? So I'm very happy every time someone proposes new messages that help a lot. But also sometimes we unfortunately need to kind of reject those or don't go with those because those can be actually worse. Like, it can be actually correct that the error is pointing out an actual error and explain what is wrong. In many cases, but in many other cases, actually, it's even more misleading. That's also why some of these errors say, \"Perhaps you forgot a comma.\" They don't say, \"You forgot a comma.\" Yeah, yeah.\n\nYou guys are very polite. [Laughter]\n\nThe politeness, I'm actually kind of enjoying. \"Did you perhaps mean this?\" You know, kind of. It's more, I mean, we're trying to imply that we may have failed, and then you say, \"No, no, actually, I didn't forget that comma.\" Right? You are totally wrong. But, um, so that's why they do it in this context, like, \"Well, maybe this is the problem.\" Right? We are not super sure, but we try to. We treat to other ones that we are super sure. And the comma one, oh boy, the comma one was so hard because in many cases, it was not the comma. Because the error, that's one very good example of what we've been talking about before, because that particular error used to happen. The way we identify that error is when you have two names or two expressions together. So, for instance, \"foo and bar.\" That is incorrect because you cannot have two names together. That doesn't mean anything in Python. And we say, \"Okay, every time we see two names together, it's very likely that the user is trying to put this thing in a collection or a function definition or a function call and forgot the comma.\" Right? Because if you have the comma, it makes sense. But it turns out that error was triggered in so many incorrect places when that was not the actual problem. Like, maybe it was not in a function definition or a... So, we have to change it into a way that requires more context. So, this thing that we discuss about the context. So, we started doing it in a way that even the old parser could have done it. Because imagine that you're doing parse name and then you pick the next one. If you see that it's another name, like a variable name, and then you say, \"Oh, error. Maybe you forgot a comma.\" But now you need more things to know that actually you forgot a comma. Because you need to say, \"Okay, but are we trying, like, are we inside a list comprehension, for instance? Or are we inside a tuple? Or are we inside a function definition? If so, then, yes, it's very likely that this user forgot a comma. But if we are not in those places, like in a for loop, imagine you are doing for full space bar, did you forget a comma there? Well, very likely, but maybe not. Maybe you're trying to do something different. Maybe you forgot the \"in.\" Yeah, right? Yeah.\n\nYeah, so it's not that clear, so, you know, we have to add this extra context. And now we are only emitting that error if you are inside parentheses or some structure that looks like a collection or a function definition. So, this is a good example of how you need all this extra context to not be annoying, because, you know, being the hard part is not only to create the errors in a reliable way, but also to make them identify places when you're not going to probably mislead the person. Especially because, you know, if you are experienced, you may say, \"No, no, I know what I'm doing, and this is just bad.\" But a beginner may be even more frustrated if what the program is suggesting to them is literally incorrect. So they try to fix it in a way and it doesn't work, right?\n\nYeah, totally, yeah. And I mean, in a similar fashion, like you have another example in the 310 documentation about if you're inside of a dictionary.You have z and then space and then w or something like that. Where you're saying, \"Okay, well what's the intent here?\" I think you mean that you need a colon here to identify this next thing. You have to identify all these potential situations. This is also very interesting. Maybe all of them are right, but that one is very interesting as well. No, I think they are. Because you may say, \"Okay, so you see the open bracket and then you start trying to see if there is a colon.\" It is very interesting because you need to distinguish if the user is trying to write a set or a dictionary. You need at least one element, so you're going to trust the first element. If the first element doesn't have the colon, then what happens is that the user is trying to write a set. And if you have the colon, then we need to say, \"Okay, this is actually a dictionary.\" So if we don't find the colon separating the key and the value, then we can say more confidently, \"You are forgetting this colon.\" Because we are pretty sure you're trying to write a dictionary, but we need at least the first item. So if you write the error like you forget the colon with just one item, we don't show anything just because we don't know.\n\nAs we go a little bit further into it, you have stuff for identifying issues with okay, you started a try block but then you didn't get into the other portions of having either an accept or finally. That one also reminds me that one important thing this project has been to collect those situations when it's very hard to understand what's going on or what the error was. Because it's very tempting to just imagine yourself in the situation and say, \"Oh yeah, this looks like a good candidate,\" and maybe it's actually very hard. And then you spend all this time and nobody is triggering that or whatever. So working with people that are learning language and I work with many people that were starting to learn Python, and I asked on Twitter a bunch of times for educators and people that are teaching Python to collect all these cases. And then I had a big list, I prioritized them on how hard they would be to implement, how common they were, and I did some prioritization mechanism and started to implement them as we go.\n\nComing with those examples, that one that you mentioned with the try without the except that happened because someone that is teaching Python a lot. Unfortunately, I don't remember who he, she, or they were that came from because someone pointed that to us and said, \"Oh, this is actually happening a lot.\" And then we said, \"Okay, let us look into that.\"\n\nThis week, I want to shine a spotlight on another Real Python video course. If you're interested in enhancing your data science skills to make predictions from your data sets, this course can get you rolling. It's titled \"Starting with Linear Regression in Python.\" It's based on a Real Python article by Mirko Stoylkovic, and in the course, instructor Cesar Aguilar takes you through what linear regression is and what it's used for. How to implement linear regression in Python step by step. Not only do you learn how to set up simple linear regression, but also multiple linear and polynomial regression. You'll learn how to use methods from the scikit-learn library to assist you in the creation of your regressions. I think it's a worthy investment of your time to learn how to find the relationships among variables and use that knowledge to forecast and make predictions. Like most video courses on Real Python, the course is broken into easily consumable sections. You get code examples for the techniques shown and all courses have a transcript including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the search tool on realpython.com.\n\nAs you kind of go through these, it sounds like you kind of answered this question already a little bit, but you found out that some of these error messages that you kind of had a bit of a top list by surveying the community a little bit. Were there things that were like low hanging fruit that you saw and said, \"Okay, let's do these in 3.10,\" and then maybe ran out of time and said, \"Okay, these are the ones that I can get in under the wire?\" Because a lot of these are not specifically PEPs, they're being addressed through the bpo (bugs.python.org), which is interesting to me because I think of those like, \"Okay, they're kind of an issue, but are you submitting that issue yourself or not?\"\n\nWe are all of them, more or less. I think all of them have issues attached. Maybe there is some catch-all issue that catches a bunch of them not individually. The reason is because there are people that actually care about these things not only just because they know that they happen, but because they could read the \"What's New\".Because they are working on libraries, they rely on tools like a good example is the author of Friendly and Friendly Traceback. He has been super helpful and shout out to him for being supportive and offering suggestions to improve error messages in the code. He subscribes to every issue opened regarding this to make necessary changes in Friendly for better error handling. \n\nIt can be challenging to make changes in the interpreter without compromising its speed. Python still needs to be fast even with better error messages. It shouldn't take too long to show a simple error like a missing comma. Third-party libraries have the advantage of being coded in Python and allowing more time for error handling. Coding in C for the interpreter makes it more complicated to evaluate correctness.\n\nTo avoid slow parsing with error messages activated, we have a structured approach to first parse with basic error messages and then with a specialized version to identify specific errors quickly. This ensures that parsing is efficient even with error messages enabled.\n\nMoving from Python 3.10 to 3.11, there are new error messages being introduced, specifically focusing on function definitions. The new error messages will help identify common mistakes like incorrect syntax in function definitions. These improvements aim to make error messages more informative and helpful for developers.\n\nA significant improvement in Python 3.11 is the inclusion of fine-grained error location in tracebacks. This runtime improvement helps pinpoint the exact location of errors in complex code, especially in scenarios involving multiple variables and mathematical operations. This enhancement, developed in collaboration with Batuhan and Amar, aims to make debugging easier and more efficient.You say okay, I need to attach the wire and start looking around. That is not good, right? Yeah, you're deep in a debugger at that point. Exactly. Then you need to reproduce the thing that happened. Now, it's super difficult to repeat the thing because it just happened with some weird message that you're receiving to your web server. Who knows, right? So, it may be difficult to trigger again. \n\nOr what happens sometimes, this is also very common, you have a nested dictionary, like many dictionaries inside dictionaries, JSON for example. Okay, and then you are accessing a bunch of keys. So, the first level you are accessing key \"a\" and in the second level \"kv\". So, you have a bunch of square brackets one after the other. And then it tells you, \"Oh no, it doesn't have a get item because you cannot get either key or none.\" This means that one of the dictionaries that you expected to be a dictionary is not a dictionary, it is none. But which one, which level is the incorrect one, right? Good luck. \n\nYeah, how deep did it go, right? And even if you attach a divider, if that thing is huge, while identifying which one is no, it's not that easy. I mean, obviously if you repeat the operation, it's very easy. But if just by looking at it, may not be easy. So, you may need to again trigger. \n\nSo, the idea was here that we may be able to attach to the interpreter and make it the interpreter with the smarter to have extra information to record extra information on every operation. So, the technical term here is that Python is a byte-code multi-C Python list. It's a byte-code machine. It just creates vehicles and then it has a big loop that takes every instruction and does something different depending on the instruction. \n\nThe idea here is that in every instruction that the compiler generates, so instructions are things like add two numbers or access this element in a list or call functions, things like that. So, on every of these instructions, the idea is that we say, okay, what if we attach that information that we already know to every bytecode instruction? Obviously, this means that the bytecode is going to be a bit bigger, so pyc files, which are this cache file that Python generates just not to have to compile two times, are going to be a bit bigger because now there is this extra information. \n\nNot much, like we expect it to be a very small amount. I think I don't remember the exact details, but I think we measured less than 8 percent or something like that. And we are talking about files that are megabytes, so this is kilobytes. So, not many cases, people shouldn't care about this. But the idea is that we augment this code objects and this bytecode with these locations. \n\nSo, when your program raises an exception and says, okay, something went wrong, here is the traceback. So, we go and say, okay, what is the operation that failed? Oh, is this addition operation that failed? Okay, let me look where this operation, the line number and the column offsets of this operation. Oh, is this one. \n\nSo, now when we show you the line, we can also point to you with like we can underscore or highlight with some underlying exactly what part of the line is the one wrong. So, now you can know, okay, now it's this key that is wrong or now you can know now it's these two numbers that are. And that's super cool because it happens with everything. \n\nIt's not only adding numbers and key dictionaries, maybe like any operation that you can think like function calls within function code, we got it. Context managers that have three lines and maybe you forgot that said there is something wrong on the startup context manager, we have that. Numpy arrays that are doing super weird operations with matrix multiplication, we have it. So, we cover absolutely everything that interpreter can do and we can show it. \n\nSometimes it's not super useful because you have x equal expression, but obviously the only thing that can fit the expression because x cannot fail, it's just a variable name. But in many other cases, it helps a lot. One thing that happened is that while we were developing this feature, once we have it in a way that more or less work but we were refining it, the fact that it was working was helping us developing it because it was pointing to a lot of problems that we had.\n\nThat's cool. That's nice when the thing you're developing starts to help you. That's cool. Yeah.That was very cool.\nYeah.\nThat stuff sounds super exciting and tree specs have always been a bit cryptic for a beginner, especially for someone coming to the language from a different language. Just understanding how to read them and having this additional highlighting, underlining, and pointing, is going to be crucial for people trying to find some of these things. So that's great. It also has some interesting improvements for other tools. For instance, in Python, there are some libraries that try to do something similar, like traceback context, but in a hacky way. Kudos to the authors for their hard work, but there are cases where it doesn't happen because the information is not there. Now, adding this extra information to the white device also adds APIs for low-level tools like IPython or coverage. Coverage is a good example where there may be cases where only part of a line is covered, and now coverage can reliably detect that.\n\nIf people haven't been following along and watching the updates and progress and would like to get up to speed on what's happening with 3.11, Garana Yela, who's been on the show a couple of times, has been creating this series of updates to keep everyone informed on the progress. It's a great resource for those interested in learning more.\n\nI have these weekly questions I like to ask everybody. The first one is, what are you excited about in the world of Python? It could be a conference, event, or package. I'm particularly excited about the Fastest Python project I'm collaborating on with Microsoft. Bloomberg, my employer, has given me 50% of my time to work on this project, and I'm very grateful for that. We are already yielding interesting results and have good ideas. There are smart people working on this project, and there is a lot of momentum and excitement around it.So, that's probably one thing that keeps me very excited recently. Some of those things coming in in 311. Oh yeah, yeah, absolutely okay, great. Yeah, it's really one three eleven already. We measure, I mean it depends a lot on how you measure things, but like within the official benchmark that we have, the geometric mean, which is more or less an aggregation of all the different benchmarks. Okay, it's already 20% faster, which is good because before maybe we'd say, \"Oh, see, Python is 10% faster on this very specific thing and only under this, you know, the fine print is very good.\" But now we can say confidently, \"Well, it is 20% better overall.\" Which is, I mean, maybe it sounds a bit lame, but 20% faster is not easy in a language as well as Python and as dynamic as Python. So, we are quite excited. Yeah, it's nice to see improvements already kind of coming through because, again, that project is not that old. A lot of it was laying the groundwork. I'm guessing with the PEG parser has helped with that immensely also, right? And in some parts, yes. In some others, it's just a different area. Like most of these improvements are in the compiler and the what is called the virtual machine. Which, I know a lot of people confuse with actual virtual machines and Docker, but normally the interpreters, the interpreter itself normally is referred to as a virtual machine. Just because the Python interpreter and all those things actually simulate the machine, like the chip, how the CPU works. So this is called a virtual machine. So all these improvements are in the virtual machine. And also, it is very interesting to highlight very shortly as well that this is not only challenging because this is a hard thing to do and find improvements and things like that. But it's also hard in a way that doesn't break third-party packages, right? Because people, it turns out that we expose a lot of things. This means that a lot of people can call C code that the interpreter uses for specific things. And some of those are super specific. And it turns out that when you try to make them faster, you can break them. And also, it turns out that many tools are actually using implementation details of the interpreter that are not even fully officially exposed. Like, for instance, Python or even profilers. But it turns out that, you know, even if those people know what they are doing and know that they're in, you know, not super clear territory, it turns out that we cannot release 311 and know that Cython is going to be broken, right? Even if it's on this weird line. So it's a very challenging thing because many of the cool things that we want to do, well, it's not that we are not smart enough to do them or we are not trying to put our best effort into that. But it turns out that many of these things are hard because we need to do them in a way that doesn't break people. And some of them are just impossible because it requires it will break so many people that, you know, what is the point that we have a 311 that is 40% faster if you can use NumPy? Not acceptable, right? Yeah. So you would hope that through the process of having alpha releases and even beta releases that all the different package maintainers and open source projects are kind of paying attention to that. But I'm guessing that can be depending on the amount of time they have to follow the schedule. I wonder if the yearly release schedule has affected that somewhat too. Yeah, it helps. Right, it helps. We are also trying to be a bit proactive as well. Like the people in the Microsoft team, like Bran, for instance, is putting out the forum also trying to, if we decide to break these kind of fine lines when it's not an obvious backwards incompatible change, just a change in an implementation detail that just happens to be used by a lot of people, we try to submit PRs to those projects and fix them. But obviously just to the most common ones. So, Cython, for instance, or NumPy, even things like that. Sometimes, if you're doing a project that is relying on implementation details, so I mean, I'm very sorry, but that is nice. You're not lucky. But we are at least trying to make sure that the big packages that are important that are doing this not super legal things, let's say, they are not broken, right? So, yeah, we try to do our best. Obviously, we will see. This is the first time we do our release since the project started. So, this also makes my work as a release manager much harder, as you can imagine. Yeah, hopefully we have a nice story to tell here. Good. So, the next one is, what's something you want to learn next? And it doesn't have to be Python specific or programming specific. No, it can be whatever. What are you interested in learning next? So, I've been playing guitar for a lot of years, especially the Spanish guitar and a bit of electric, but since the pandemic started, I'm very into learning electric guitar again. Oh, cool. So, I didn't start from zero.But now my objective is to learn sweep picking, a technique in the guitar that is notoriously annoying to learn. It requires a lot of practice and dexterity. You need to be firm and do it every day. I'm chasing that. \n\nI have a guitar called a Variax Shuriken by Line 6. These guitars have extra features that allow you to change the tone and tuning easily. This is a lifesaver for rock and metal genres that require low tuning. \n\nI've been happy with the Variax, although they are not cheap. People can contribute by suggesting new error messages through the Python dev guide. It can be tricky to add errors in a way that is reliable, so reviewing is important. Some errors may not be possible to implement due to the complexity of parsing. \n\nOverall, the focus is on making it easy for people to suggest new error messages and ensuring that they work correctly in the parser. It's important to consider how changes may affect other rules in the grammar.So we can allow it. Both, I'm trying to make both things easier. One, trying to make people understand how they can add it and also trying to tune people's expectations when they add new error messages. Yeah, I think that's great having a decent set of expectations coming in is important. And hopefully we've set that level, that this is not a super easy task where you're just adding that error in there. There's a lot of reading through the subtitles to get to where we're at.\n\nAlso, it's Python we were talking about, right? Like, it's important to, like, we cannot just, like, a lot of there's so many people using this language, right? I mean, yeah, again, it is one of the most popular languages now. And so, we cannot, it's not even like the standards that a lot of people have in companies, which are very high, this is even higher because we need to make sure that we cannot just have, you know, and oh, I just turned this error, just make this part of Python incorrect. That would be horrendous, right? Like, so the bar is very high. So, yeah, fortunately, that leads to some stuff that we are not sure not to pass, but I hope that people understand that doing things in the interpreter is probably the most complicated things. And the past one, we need to be more careful. So, I hope that people understand that it's not that their goal is not good enough, it's that the bar is super high with this.\n\nOkay, yeah, definitely. So, how can people follow along with the work that you do? I have, so they can go to my Twitter. I tend to tweet all the developments that we're doing and when we put the exciting things, it's \"bibliogsal.\" P-I-B-L-O-G-S-A-L. Okay, and I did it right, but yeah, if they do it Pablo Galindo Twitter Python, they have it. I'll have a link for it too.\n\nAnd also, if you feel generous and you think that the work I'm doing is good, I have one of these GitHub sponsors pages where I normally try to also send like some emails with summaries of what's going on and what I'm working on when there is enough momentum. Okay, cool. Yeah, if you are feeling generous, that would be another way. Awesome. Well, thanks so much for coming on the show, Pablo. It's been really fantastic talking to you.\n\n[Music]\n\nThis episode was brought to you by Linear B. Their Worker B for Pull Request Chrome extension gives your team context about your PRs and estimated time to review. Get it free at linearb.io.\n\nReal Python. I want to thank Pablo Galindo Salgaldo for coming on the show this week. And I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey. I look forward to talking to you soon.",
    "CiyrZdmBHfE": "Welcome to the Real Python Podcast. This is episode 123. How does a code completion tool work? What is an abstract syntax tree, and how is it created in Python? How does an AST help you write programs and projects that inspect and modify your Python code? This week on the show, Merida Luff, co-founder of Anvil, shares his PyCon talk on building a Python code completer.\n\nMerida talks about his experience building a code completion engine for the Anvil platform. The conversation leads us to discuss how Python parses the code you type. We examine tokenization, abstract syntax trees, and how parsing has changed in Python. We cover additional projects you can explore once you have a tool that inspects the Python code you're writing. Join us as we dive into multiple rabbit holes of research and exploration.\n\nThis episode is brought to you by Sea Data Software, the easiest way to connect Python with data. SQL access to more than 250 cloud applications and data sources.\n\nAll right, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Meredith, welcome back. Hello, it's great to be here. Yeah, it was so nice to talk to you back in episode 63. We were talking about creating web applications using only Python, working with Anvil. Then we finally got to meet up at PyCon 2022 in person.\n\nYes, I have owed you a drink for a very long time, and it was lovely to be able to deliver.\n\nYeah, that was great. You also had a talk that you gave there, talking about some new things that you were working on within the Anvil platform. Your talk was about building a Python code completer, and you were doing that yourself inside of Anvil.\n\nSo, this talk was about a subject I really love because it was about code completion, which is one of those things that almost every programmer uses. It's that little pop-up box you see in your editor offering to complete your variable names, your identifiers, and so on. We almost all of us use it, but a lot of us don't actually know what's under the hood. You know, it's magic to us. And for reasons that I'll get into about why Anvil specifically needed this, I ended up having to build one of these things myself. And what that meant is I got to work out how they actually work. And it turns out these things are really cool. They are in this magic overlap between things that feel like magic and things that are actually really simple. In the talk you saw, I talked about why code completion is a thing and then how it works. I'm not going to try and do this on a podcast, but I then built the code completer live on stage in about five minutes just to prove that it wasn't actually that hard.\n\nYeah, that was a really fun talk. We'll definitely include a link to the YouTube talk there.\n\nSure. All right, well, let me try and explain the basics then. The goal of code completion is to answer the question, \"What might the programmer type next?\" So, if you're building a programming environment, you're building an editor like VS Code or PyCharm, what you want is to have some idea of what might happen next where the cursor is. Because then you can offer these pop-up code completions. And what that means you need to do is to understand this half-written program that's sitting there in your text editor. This is a pretty daunting task if you're thinking about it as, \"Well, I've got this string of text and somewhere in it is a cursor and I've got to work out what they might type next.\" Because that means understanding the program they're in the middle of writing. You know, what they might type next might be a local variable. Well, is that cursor in a place where a variable would be an appropriate thing to type next? What local variables are defined in that program? And if you wanted to step through your text character by character to work that out, that would be not quite impossible but incredibly difficult.But if you think about it, that's actually pretty much exactly the same challenge that you have when writing a programming language. When you write your Python script, it reads in the file myscript.pi and doesn't go through it character by character as it executes. It also solves the problem by turning that code into a more useful representation.\n\nIt has a piece of code called a parser, which feeds the string to the parser and produces a tree of objects representing your program. Instead of a series of characters, it has objects representing function definitions, arguments, and statements inside.\n\nThis tree of objects is much easier to work with. The Python interpreter reads the code, gets an abstract syntax tree, and walks over this tree, generating bytecode. Any compiler works in a similar way, translating the program into a format that's easier to work with.\n\nAs a developer of code completion, we can use this technology to take a half-written program, replace the cursor with a random special symbol, and feed it to the parser to get back an ast that describes the half-written program.\n\nYou can walk over this ast recursively, building up a representation of what's going on in the program. This allows you to offer contextually sensible completions. The fundamental basis of code completion is using a parser to work out what's going on in the code around the cursor position.\n\nRecursively means repeatedly looking at the code and refreshing what the tree looks like. In this case, it's about iterating through the statements in the module and drilling into statements that have more statements inside, like if statements or function definitions. It calls itself recursively to walk into those statements.And then, I feel like one of the steps that it's going to need to do in this process of structurally creating this tree is to define what objects are what. Like, the term that I've seen because I went down a whole rabbit hole after your talk and into this whole thing. I actually suggest you if you're interested in this stuff, the abstract syntax trees (AST) documentation from python.org is really good. It actually, as you're talking about this stuff, to have it open while we're talking about it might be a cool thing unless you're driving, to kind of look at. You can see it's really well done inside there. But I think part of it is going to have to create these sort of tokens as a tokenizer part of that process.\n\nOkay, let's talk about parsing. I just talked about parsing as this black box. A parser is a program or a chunk of code that, you know, you give it a string and it gives you back an AST. Now, of course, there's a lot of machinery inside that. The really cool thing about a parser is that most parsers were never written by a human being. Instead, if you go to the Python documentation, you can find something called a grammar file. That is a text file specifying everything that could make up a valid Python program. It will say, for example, an if statement in Python is made of the word if, then an expression, a colon, and a block of Python code, and maybe an else statement. \n\nYou will find reams of this stuff describing every building block of the Python language, every way you could possibly put together a valid Python program. You feed that into something called a parser generator, and that parser generator spits out code for a parser. Python recently got a new parser generator, moving from the previous pilot to something called pg (parser generator).\n\nThe process, if you break it down, is you take this string of stuff and then feed it into something called the tokenizer. What the tokenizer does is it breaks the string up into chunks that are slightly more semantically meaningful than just a string of bytes. It could be variable identifiers, a string literal, or even understands indents and dedents in Python. The tokenizer's job is to count spaces at the start of a line and emit a series of tokens. Instead of a file of bytes, you get a sequence of tokens that pre-processes your text into objects.\n\nCan I ask you a quick question on what you were building inside of Anvil, this tool you were creating? Is the tokenizer a separate step? Like a common way people would see in an IDE, where it starts to color code your text as you go, identifying and highlighting Python. Was that a separate thing created?So, it's an anvil specifically for those who have not gone back and listened to the previous episode with me. Shame on you. Also, a quick summary of anvil. This is what we're talking about: Anvil is an online environment for creating web applications entirely in Python. It has a drag and drop editor for building user interfaces and a code editor where you write Python code. Some Python code runs in the web browser, some on the server, and you can call functions in one from the other. There's a built-in database, and you can deploy it all without needing to know HTML, CSS, JavaScript, React, Redux, or webpack. You can build a web application even if all you know is Python.\n\nThis means a couple of things. One, I maintain an online code editor which has some syntax highlighting. Another is that this is why I got interested in all of this in the first place because we also have our own code computer that runs as part of this editor.\n\nRegarding the online editor, as you're typing, if you type the word \"for,\" the editor will syntax highlight that. Many editors do this in different ways. Sometimes the editor component has a rudimentary parser built into it, so it has some sense of what's going on in your code. It knows about your indents, dedents, and can work out how far you should be on the next line.\n\nA full parser works by turning a stream of tokens into a tree that people can use. A table-driven parser produces a concrete syntax tree, which doesn't know about the semantics of your programming language. Another piece of code then goes over this concrete syntax tree and generates an abstract syntax tree. For example, with a \"raise\" statement in Python, there are different ways to write it, and the ast.c code unifies them into a single ast node representing the \"raise\" statement with meaningful semantic attributes.\n\nThe old way involved tokenizing, creating a concrete syntax tree, running the ast.c code to generate ast nodes, and then compiling as normal. Python recently moved to a new parser with a different strategy for parser generators. It approaches things differently, but the specifics are not explained here.Well, I think I could do my own short version of it. I recently watched some talks on it. The original parser, the LL1 parser, focused on one token at a time. Part of the reason was the earliest design. When Guido kind of came back, he started to see this idea. He decided to take a break from Python for a little bit. He stepped down as the BDFL and said, \"I'm gonna take a little break.\" During his retirement, he couldn't stay away and started getting interested in the idea of a different way we could parse. Computers have changed. It's been almost 30 years. Memory is no longer as big of an issue. Parsing a text file is not a big deal compared to graphics and other things computers are doing now. What if the parser could look further ahead and deeper into the context?\n\nWith this new methodology, instead of going token by token, it can have infinite lookahead. That's the concept of it, which is really wild. That's a good summary. That has helped a lot with all these cool things that have been unlocked. The grammar used to get stuck on certain words. The new case switch statement, the match statement, potentially could be given a different token. Now it can read ahead and figure out through syntax errors what you were trying to do. It can help with syntactical issues and syntax errors.\n\nThere are some really interesting things happening with the PEG parser. It was introduced in 3.9 and then in 3.10, it became the parser. Everything going forward is PEG, allowing new functionalities. It might be part of why we can speed up. That's probably a separate conversation. My goodness, you were not kidding when you said you went down the rabbit hole. It's been fun, but my brain hurts a little bit. I was reading legal contracts with all these big words that nobody's defining for you. You have to go and find them like EBNF, Extended Backus\u2013Naur Form. It can be abstract, but it doesn't have to be scary.\n\nCompared to the English language, you can read all the grammar on a page, which is pretty cool. You can play with it, import AST and IAST.parse like a simple Python program in your repo right now. There's a website, python-ast-explorer.com, where you can see it building as you type Python in one box. It's really neat. Something powerful happens when you write a program that does it yourself. Don't just look at it, really do it.They're like and once you realize that you can have programmatic access to what your code is doing, there are suddenly so many projects that you can take on. Like building a code completer seems impossible until you realize, \"Oh wait, I can use a parser like Python has it there at your fingertips.\" There's so much fun you can have once you actually pick this tool up and start playing with it yourself.\n\nTo kind of get back to your parser, there are a couple of questions I have about it. One issue is about scope, and kind of navigating a lot of that in your talk, which I think is great. And then, also, the data structure that's going to hold these options for the code completer to put in. Maybe we could talk a little bit about those things.\n\nAlright, okay. Well, in which case, if we're going back, we should probably finish the train of thought we were on originally, which is the difference between how the parsers work. The only salient difference I wanted to call out among the other great features of the peg parser is that it goes straight to AST. So, this parser generator goes from your tokens to splitting your AST straight out, which I think is really quite cool.\n\nEspecially as I'm also one of the maintainers of the Sculpt Python to JavaScript compiler. And that means I maintain a Python implementation, which means I deal with the concrete AST compiler all the time. It's going to be so great when we adopt the peg parser into Sculpt. It's going to be a quality of life improvement for people who are working on the interpreter, I bet.\n\nSo, we were at scope and sort of a data structure to hold these potential code completions. This is the fun challenge of writing a code completer because you have to decide how you're going to represent what's going on as you walk your way through the program. In my talk, I built a very simple completer that used a set object to hold the names of all the variables in scope. It was pretty easy to complete what variables might be used.\n\nBut actually, you want to do a lot more than that. You want to know some stuff about types. When I say types, think about everything we know about what could be in this value. So, think about types in the academic sense.Yes, you could know that for sure. The variable x currently contains an instance of the string class. So, if you type x dot, you should probably offer all of the attributes that string instances have, like to lower and trim, and so on. That's a simple version of type information, but you can record a lot more than that. For example, you can know that this is a string constant defined here. Another example is dictionaries. You can have two dictionaries that have different sets of keys, and those are both going to be instances of the dict class in Python. As far as the Python interpreter is concerned, they have the same type. But from the perspective of a human writing code, those are two different types of dict. \n\nYou can use square bracket lookups to look up different keys in each of them. If you are building code completion, it might be useful to know what options to offer when somebody types my dict and then the left square bracket. You would want to offer them the keys that dictionary has. So, what you need to store is type information about that variable that is more extensive than just the Python type that value will have or just the Python type hints of that variable. \n\nYou have this challenge. You want to store basically arbitrary amounts of information about these values, and you want to be able to update them as well. If you think about how Python works, when you're writing a Python class, you define what attributes that class has in the init method. Everything in Python is so dynamic. If I'm writing a class for a potato with attributes like weight in grams and temperature in degrees, I define that in the dunder init method. \n\nYour autocompleter has to recognize that structure. The structure we ended up with involves a recursive call for every block of code handled by a function called walk block. It walks a series of statements in a block and recursively calls another walk block for sub blocks like inside an if statement or a function definition. We also store the top-level module scope as a dictionary mapping variable names to objects representing their type. These objects have attributes like the Python class name, attributes of that class, and other information like if it can be looked up with square brackets. \n\nThese objects are mutable because as you walk through a program, you may learn new information about them. For example, if you define a class potato and create a new instance of it, the top-level module scope will have a class potato object with its init function. As you walk through the init function, you have to update your representation to reflect the new attributes being added to the class. \n\nIn conclusion, you have to create your own data structure to store and update type information about variables in a program.I don't know for sure what other completion systems are used. There are a bunch of completion systems out there, some of them are proprietary, like the open source completion built into PyCharm. There are various code completers used by VS Code, and there's one called Jedi, which is a cool Python code completion package.\n\nEverybody does it slightly differently because everybody wants to represent what's going on in their code in a different way. But you've got to make this decision on how to represent a language as dynamic as Python. Python is full of dynamism, it comes up all the time. You can dynamically add extra attributes to objects, you can dynamically decide whether you define a function, like putting a function definition inside an if statement, which is perfectly legitimate behavior.\n\nSo, your code completer is always looking at your code and guessing. Yeah, and you think about it needing to be dynamic. This code completer needs to be extremely dynamic, like it's having to change stuff. Well, it's not just dynamic, it also just doesn't know what's going to happen. There is a theorem in computer science, the halting problem and incompleteness. The idea is it is provably impossible to understand what will happen when you run a program by looking at it. If you're not running the program, you do not know what it will do, or even if you're halfway through running the program, you don't know what it will do.\n\nWhich means that your code completer doesn't actually know for sure whether some piece of code that adds an extra attribute onto the potato class will run every time, sometimes, or never. And so, it has to make a guess about when these attributes will actually exist on various instances of potato. And that's okay, it's guessing all the time because it doesn't matter, well it matters to get it right, but if you're building an autocompleter, it's like making the graphics for a computer game. You don't need perfect physical accuracy, what you need is to make the human in front of the computer happy. So, when you're faced with a language as dynamic as Python, it's not just that you have to be dynamic yourself, you have to acknowledge you don't know exactly what the program is going to do, and you have to approximate, you have to guess.\n\nThis week, I want to shine a spotlight on another Real Python video course. Each version of Python adds new features to the language, and for Python 3.8, the biggest change was the addition of assignment expressions. This course is titled \"Python Assignment Expressions and Using the Walrus Operator\". It's based on a Real Python tutorial by previous guest Guerra Garanajiella, and in the course, instructor Darren Jones shows you how to identify the walrus operator and its meaning, avoid repetitive code by using assignment expressions, convert between code using the walrus operator and code using other assignment methods, understand the impacts on backward compatibility when using the operator, and use appropriate style within your assignment expressions.\n\nWe're a couple of years past the controversy surrounding the introduction of assignment expressions, and you're likely seeing their use in code more often. I think it's a good investment of your time to learn how to take advantage of this operator and how to understand its use in the code. Like most video courses on Real Python, the course is broken into easily consumable sections, you get code examples for the techniques shown, and all courses have a transcript including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the search tool on realpython.com.\n\nWhen you went through this process of thinking about diving into this, was it the first time you worked on the code completer? Also, did you go and look at other systems? Some of them were open source, were they useful to look at, or was that something that you approached when you did this project?\n\nI'm not going to say I didn't take a glance, but it was mostly a from scratch implementation. I think part of this is, as you alluded to, in how you want to represent your types. When we were building a code completer, specifically for a web-based editor, there's not a lot of time between keystrokes when a programmer is really going for it. You don't have 300 milliseconds to go back to a web server, do some code completion, and come back with a set of possibilities. Your programmer is three words in by the time you've come back to them. It goes back to your computer graphics thing, if the controls are going to be that floaty, you're just like, ugh.\n\nIt is more important to get the float controls non-floaty than to get that perfect iridescent sheen off the protagonist's head. So, we went, okay. That's one reason for writing something that would run in the web browser, which means we couldn't use something off the shelf like Jedi because that's expecting to see a set of files in a file system. So, that's one reason for it.But the other reason that I think is more interesting is that we wanted to build a code completer for the same reasons that we wanted to build Anvil itself. Ansel's goal is to solve this problem where you have to write scripts, talk to your database, write Python for the server side, munch everything over HTTP, write HTML, JavaScript, and CSS, and make them all work together with all sorts of frameworks for the graphical user interface stuff.\n\nWhat that means is that in a typical program, you don't actually know what the database is going to give you because your code editor doesn't understand the SQL you just fed the database. So it doesn't know what kind of data it's coming back. When you're writing your front-end, you just hit an HTTP endpoint, your code editor doesn't know what shape of data is going to come back. But because Anvil is an integrated environment, you write the server and the client code, which means that when you call server code from the client, we've seen that Python function we've passed it, we know what it's going to give back. So we wanted the code completion to reflect that.\n\nLikewise, there's a built-in database, so when you query the database, you get back these live Python objects. You use square brackets to look up the columns, and then you can pass these objects from server to clients and again they come out, and you can look up the columns on them, you can search them, you can update them live. And that meant that the code completer for this system wanted to have a really good idea of the types of things. Deep typing, as I say, it's more than just the Python class of \"Hey, this is actually a database row from the x table and so it will therefore have these columns of these types.\" And then if I ask for a restricted column view that's only got these three columns, well that will then give me a new table type object that when I search, it'll only give me these three columns. And so having that kind of level of information about type information in excess of what Python's class is or the typing module would give you is something that it's really good to have a custom auto complete.\n\nIt's a lot of assistance you're providing. Yeah, it was a couple of years ago at Python, we were talking to the VS Code guys on the Microsoft stand and they were saying, \"Hey, you should totally have a VS Code plugin for Anvil or write stubs for it.\" And then we showed them some of what our code completion does, and they went, \"Oh, that would be difficult in our architecture.\"\n\nWe built it for this purpose. So yeah, obviously this is unique. Yeah, there are things where those code completers are more advanced, more complicated than ours, but one advantage we got is our representation of this internal state of types has a lot of space for knowing about things like what components are on your screen, being able to work out when you've built a user interface in Anvil, the class that represents that page has a set of attributes depending on what objects you've dragged and dropped onto your screen. And so it can live update the types of those objects. The types of, if you have a repeating chunk of user interface and you feed it a set of database rows, it can look through your code then look through your UI definition and work out, \"Oh well, when I'm editing that the chunk of code that represents each row for this database, then the self.item which is this element from the list is an instance of that. It is an instance of that row from the database.\" And having it tightly coupled, meaning that we can design our data structures to reflect the stuff that's really important for building user interfaces in Anvil was a thing that was really valuable for us.\n\nTotally like one of the things that makes me think about that, you have this luxury of it all kind of being together and knowing what the parts are and the database is part of the system and so forth as opposed to being external. It makes me think a little bit about one of the arguments people have for typing in Python and adding it is okay if you add types to your programs or your packages and your modules that the code completer in an IDE is going to have an easier go of it if you will. You can kind of figure things out and I feel like that's something that I wouldn't say without knowing that your stuff has got types in it across the board but I would guess that it's kind of a similar process where you can kind of know the architecture a little bit better.\n\nI mean I think so, Python's type hints, I mean this is a fascinating topic all on its own. I'm sure you could do several episodes probably with people who are more intimately connected with writing than I am. The interesting thing about type hints is Python's type hints can express some stuff that the Python type system doesn't already know, which is itself interesting. But they're also capable of lying.You can tell my pi or whatever type pens you're using that are variables of a certain type, and then give it something a completely different type, and nothing's going to explode at runtime, right? Well, unless you are using pydantic and then you're using the type annotations to configure a type checker that runs at runtime to make sure you've got the right shape of data. It's a very flexible mechanism, it's Python.\n\nThe idea of having these type hints in your code, being explicit about making a promise that then you still are on the hook to follow, is a very interesting design choice. I can see why it's gone that way and why it kind of fits with the Python philosophy.\n\nYou see this actually as well in there's a very similar question with JavaScript and TypeScript. If you're using an editor that knows about TypeScript, if you're using the JetBrains WebStorm package, the code completer in WebStorm will often know more than TypeScript does about what type a variable is going to be because it has inspected your code and it's done just that little bit more inference and it's being just that little bit smarter than the TypeScript typing rules are. So, you will find that it will happily autocomplete code that the TypeScript compiler will then barf on.\n\nAnd again, basically, when you have a dynamic language and you try to put promissory types, types that are just assertions about what's going to be happening in this dynamic language at runtime, you end up with all these really interesting corner cases. We don't currently lean very heavily on type hints in Anvil. It's partially, you know, we will get there, we all move that way but partially, you can often do as well inferring by actually parsing and reading the code as you can by reading the type hints.\n\nI feel like there are so many avenues we could go down and we already kind of, I know like this is one of these wonderful topics and I hope listeners, I hope you're holding on. We are just having a great time here. I hope you're keeping up well. I will provide a ton of links, you know, not only the talk that you did but all the other kind of avenues that I went down and explored and lots of tools for you to play with.\n\nChristopher Bailey going down the rabbit hole and reaching back and yanking everybody in after, come on, let's go. We're late. One of the things I thought about is beyond building a code completer which, you know, I think is potentially a task that might be a little outside the abilities of some intermediate developers, they might have a little hard time with it. Well, so yeah, I'm going to go ahead and disagree with you there. I know you want to take this elsewhere, okay, but I don't think it is outside the abilities of an intermediate developer. Like watch my presentation, watch what I did on stage. It was a simple recursive function. Having the AST module there means it's not beyond your abilities of an intermediate coder. Having said, we just got to get deeper into it.\n\nIt might not be a thing you need to do all the time. There are other projects available like my introduction to, you know, really bashing around with ASTs was, I mean, I took some compiler courses at university but my proper hands-on introduction was writing a code completer because writing a code completer is what I needed to do at the time. But there are all sorts of other fun things which I think is where you were going with this. There are all sorts of other fun things you can do once you realize, oh hey, I've got a parser, I can throw it to any code I like.\n\nOne of the things that kind of came up in my search was that in the AST documentation from Python, they had this link to a kind of an interesting site called Green Tree Snakes. It has examples of getting to and from ASTs modes fixing and so forth, a whole section called meet the nodes and then working on the tree. And then at the end, it had examples of working with ASTs. So they had a bunch of different things that you could kind of check out. We already mentioned the AST Explorer that you can play with a little bit.\n\nOne of the things they brought up was a linter, and the one they had as an example which I think looks, I just love the name, it's called Belly Button. So, what does this thing do? A linter, if you're not familiar with the terminology, you might have heard of things like Flake8 or pylint, but basically, the idea is that it will go through and look at your code and I don't know exactly if it auto is auto formatting the way something like black would but in many cases it's basically highlighting what it considers to be potential errors or potential things that are not following the some of the rules of Python.There's a set of rules that you can dig into from there. If you use a variable before you define it, a linter could complain about that, unlike the Python compiler, which won't until runtime. Having an AST makes detecting undeclared variable use in a Python program straightforward.\n\nA good project to look at is Black, a code formatter driven by the AST module. Another idea is a testing tool diving into the same kind of stuff as Pytest. Pytest is a bit unpythonic, but it uses heavy inspection of the AST and bytecode of the program.\n\nA potential project could be a tool to search for security flaws. At PyCon, I met a company that does code analysis for security vulnerabilities. Friendly tracebacks is another tool using the AST module to help beginners learn from mistakes.\n\nTools like PT Python and B Python offer code completion and highlighting. Exploring command line tools using the AST module is a great way to learn more about how the language functions.That would be a good alternative name for the podcast. When you're dealing with rebel tools that have auto completion in them, it's interesting to look at them and try to work out if they are actually doing parsing on your code and working out what completion options to give you that way, or if they are looking at the live objects in your program and offering you completion based on those. They often do both at the same time, so you'll be halfway through typing an expression using the parser to work out what you're typing because you haven't executed that code yet. But if you are typing x dot, it's going to go look in the scope in which you're executing that expression, find out what actual object instance x is, call dunder on it, and give you the actual list of attributes of the live object.\n\nThis can be great, but also kind of confusing, as dunder has all the extra dunder methods and other things that you may not use. It's not just the dunder methods, it's also the way that tools like GitHub co-pilot operate at the other end of the smartness spectrum. It feels like sometimes it's a better programmer than me, but I still have to code review its code before I accept it. Co-pilot picks what it thinks you might type next, treating your program as though it was a language and writing the next line of the code, which can be unpredictable.\n\nCode completers are really good for using in an editor when you're in the zone and typing quickly, as you start to trust them and get into a rhythm. It's important for completers to be predictable and consistent in these situations. Mixing results from past code completion and inspecting the object in memory can lead to second-guessing and confusion. These are two different ways of doing code completion, and each has its strengths and weaknesses in different scenarios.\n\nExploring pylance inside VS Code, one of the features it had was very aggressive in suggesting things that had not been imported yet and auto-adding the import statement for that thing. If you didn't mean what it suggested, it could still have that import statement there, which could be overwhelming.Whoa wait, wait. And so there was some tuning they had to do to kind of chill that out or settings that you could adjust. I thought that was interesting. Oh, yeah, potentially bad news.\n\nWhile we're talking about code completion inside something like VS Code, I find VS Code's auto completion strategy really interesting. It brings to the fore this difference in basically if you're in a programming editor, it's either a text editor or an IDE like PyCharm that wants to know about everything in your project. It knows your virtual environment, all the files in your project because you've told it about them.\n\nWhen you open up a project, you could see it crawling across that stuff with the progress bar. It's done that, it's gone indexing your entire environment. An IDE has a high degree of knowledge about your project, which is why Anvil is definitely an IDE. It knows more about your project than typical IDEs because it knows what your database looks like.\n\nIf you're basically a text editor, like VS Code, then it's all a bit more approximate. VS Code has language servers, like the Language Server Protocol pioneered by VS Code. It talks to a program that knows how to parse a Python program and offer code completions.\n\nAt a certain point when it's not sure what's going on in your program, VS Code will start suggesting words you've written elsewhere in your program. This can be aggressive but can help if used properly.\n\nThe advantage of integration in IDEs is the level of integration and project knowledge it provides. While talking about aggressive VS Code completion, my friends occasionally have a dinner where it's all side dishes and no main dish.\n\nI'm most excited about Raspberry Pi releasing the wireless Pico, a microcontroller device. This is a big development in the world of Python right now.This is stuff that's smaller, much more power efficient than a full-on pie, cheaper like six dollars or something ridiculous. And it now can talk to the internet and you can drive it with MicroPython. So, I have one of these on order already. I can't wait to get my hands on it. I really want to have all sorts of little battery-powered Python gadgets around my house that can talk to the internet and then do really cool things.\n\nSo yeah, the Pico W, yeah, it looks like around six dollars. That's pretty amazing.\n\nWhat's something that you want to learn next? Doesn't have to be programming or Python-specific.\n\nYes, so I think I'm going to answer programming because I've been thinking about programming. I maintain a web-based development environment, as I may have mentioned once or twice during this podcast. What I'm really focused on now is different ways of doing state management in traditional web applications. React, Redux, and other interesting approaches like Facebook's experimental one called Recoil are intellectually fascinating. Dealing with this kind of churn and complexity is the alternative. I am dealing with this so other people don't have to, and this definitely falls into the strategy. But I'm also totally down the rabbit hole and fascinated by how different people choose to manage state in a web application. So, that's what I'm learning next.\n\nHow can people follow the things that you do?\n\nThe biggest thing I do is Anvil, that's available at anvil.works. I am @meredith on Twitter, so that's m-e-r-e-d-y-d-d. But I try to tweet as little as I can get away with. Other than that, we tweet at Anvil_works. I have a bunch of really interesting colleagues who tweet much more and much more interestingly than I do, so go check them out.\n\nIf you're interested in the Skulpt Python JavaScript compiler, check out skulpt.org. It's an open-source project, and we are interested in having people join us on GitHub, submit pull requests, and have some fun if you want to play with the inside of a Python compiler and parser.\n\nWell, Rod, thanks so much for coming on the show. It's been really great to talk to you again. This has been a fun episode. Thanks very much for having me.",
    "8zhFu-pGafg": "Welcome to the Real Python Podcast. This is episode 124. Have you wanted to understand recursion and how to use it in Python? Are you familiar with the call stack and how it relates to tracebacks? This week on the show, Al Swigert talks about his new book, \"The Recursive Book of Recursion.\" Recursion is one of those concepts held as a tenet of high-level computer science priesthood. Al explains the fundamentals of writing recursive functions and a critical missing piece in understanding how they operate, the call stack. After completing his research for the book, he concluded that it's a technique that you should understand but rarely use. He also shares the few cases where recursion is an appropriate solution. Along the way, we talk about directed acyclic graphs, solving mazes, exploring file trees, and creating fractal images. Alright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Al, welcome back.\n\nHello. I feel like I need to invest in some jackets for my five-timers club. Has it been five times?\n\nNot yet, no. This is the fourth time.\n\nOh, wow. Yeah, it's great to be on this show. Thanks, I'm excited to have you back. And you've been working on a new book. You kind of hinted at it before, and then I think we talked a little bit about it at PyCon that you were working on this, that it was coming up close. So maybe we could set up a show. I'm excited to have you here and talk about your new book, \"The Recursive Book of Recursion,\" which should be out by the time this comes out. Amazon has it coming out on August 16th, but right now you can buy it directly from the publisher, No Starch Press, at nostarch.com. It's really nice when you pre-order a print book from them because they'll also give you the PDF and Kindle ebooks for free, without any DRM locking it down. So you can just put it on whatever device you have. That is nice. I really like that ability to kind of use it in multiple places. Owning the content that you buy is quite a nice thing.\n\nI guess maybe just a quick thing on it. You had a talk at North Bay Python in 2018 that covers a lot of the initial concepts here. What it made me think about was, did that talk inspire the book, or was it more of a starting point for you? It was sort of a starting point. That was 2018, was it? Because I had the idea for the book, and then I thought, like, well, I can just make a little PyCon talk about it. I originally thought, okay, well, this book on recursion, how much can one write about recursion? This will probably be 100-150 pages. I can knock this thing out in six months. It'll be fine. And here we are, four years later, and okay, it's finally coming out. That's great. It turns out that there's quite a bit that you can write about recursion. The publisher also thought it'd be great if I just threw in a lot of project ideas, so I have a lot of fractal drawing programs, this Drost image creator. Yeah, it goes back to a pretty common theme for you, including projects. To paraphrase JFK, I do these things not because they are easy, but because I thought they would be easy. Nice.\n\nI think it's a very interesting topic because one of the things that you kind of hint on initially is those of us like myself who didn't go through computer science classes officially and maybe are trying to catch up on the sly, see these topics and think about them and kind of want to know how much of that do I need to know as a Python programmer. And I really feel like the book is answering a lot of that, and also kind of the idea that if you're looking for a gig and potentially facing an interview, this is like a common sort of place that you've seen. Have you ever had that experience of a job interview where they asked you a recursion kind of question? I don't think I've personally had that happen to me, but I do know that recursion is one of those topics that do get brought up in job interviews. And in fact, one of the ways that I try to market the book is saying, like, well, you know, you'll need to know this for coding interviews. But recursion is one of those things where no programmer will ever actually need to know it, but every programmer should know it, and no programmer should ever actually use it. So it's paradoxes within paradoxes, which is appropriate enough, I guess.\n\nDo you want to dive in with like an initial concept? Because I like using this forum of the podcast as a way to kind of feel free to ask any kind of questions. And I think the first one would be, okay, well, what is recursion?So what is recursion? A lot of people are really intimidated by this topic, but I feel that a lot of people have an intuitive sense of it. A broad definition of a recursive thing is something whose definition includes itself.\n\nThis is going to be very interesting to describe on a podcast because it's often a very visual thing. If you've ever seen the Sierpinski triangle or played the Legend of Zelda games with the Triforce, you'll understand recursion. It's like a triangle with an upside-down triangle inside that forms three new triangles on the corners. Keep putting upside-down triangles inside those triangles to form Sierpinski triangles in the corners. This produces a fractal image, a recursive shape.\n\nA Sierpinski triangle contains three Sierpinski triangles. It's a thing whose definition includes itself. You could also think of the movie Inception where people have dreams while dreaming again.\n\nFor programming, a recursive function is a function that calls itself. Why would you want to do that? If you try, you'll get a stack overflow error, named after the website Stack Overflow.\n\nThere are useful things you can do with recursion as a programming technique. But many programmers use recursion to make their code convoluted and hard to understand, calling it elegant code.\n\nTo understand recursion, you need to grasp concepts like functions and stacks. Functions are like mini programs that your program can run. They help avoid copying and pasting code everywhere. Functions can call other functions, making it easy to reuse code.\n\nFunction calls aren't one-way trips for program execution. When a function returns, the execution goes back to the line of code that calls it. This creates a stack of function calls that the program follows.\n\nA stack is a data structure used to keep track of function calls. If you've used a Python list, you've used a stack.If you just had a Python list and you only ever use the append and pop methods to put something at the end of the list or remove something from the end of the list, that's essentially using a list as a stack. You can only examine the last item in the list, so it's a lot more restrictive than a list. You might wonder why you would want to use that instead of just a list. This goes down into computer architecture and machine language, where the programming constructs are simpler. We've built up these simple concepts to create elaborate things like Python lists or dictionaries, which are much easier to use when making an application.\n\nOne of the things I thought about with stacks that your talk shows and the book gets into is the stack overflow. I was wondering about something as you ran this program, which was this shortest thing we were talking about before. Shortest is calling shortest, and so forth, and then you get the error at the end of that. It will show that it ran 996 times and then there are four times above it showing in the traceback of the error.\n\nPython has a limit of a thousand, which is an artificial limit. Functions themselves are constructs that we take for granted. Originally, when writing code in assembly, you don't necessarily have functions, just a go-to instruction. You tell the execution when to jump to another address in memory and start running the program from there. Having functions is nice because you can see the call stack and trace back to the original problem.\n\nStructured programming added functions, which is much nicer than having a bunch of go-to instructions everywhere. Spaghetti code was the term for the messy path of execution with go-to statements strung all around. The traceback provides information in the call stack of when the error happened. The call stack is a stack data structure that keeps track of that.\n\nA stack is a data structure where you can push data onto the top of the stack and pop data off the top to retrieve it later.So it's sort of like a very restricted list where instead of the end of the list, you have the top of the stack. We call it a FIFO data structure because the first value that you push onto the stack will be at the bottom of the stack, so it'll be the last item you take out - first in, last out, okay? \n\nA stack is pretty much one of the simplest data structures you can have in programming. It's just a large contiguous area of memory, and you just need to have a pointer at the beginning of the stack and a pointer at the end. It doesn't take up a lot of memory, which is really important for embedded computing and back in the days where 64k was a lot of memory.\n\nThe call stack, which is completely invisible, handles adding function calls in the background automatically for you. It's a blessing and a curse - convenient to have functions, but hides away details you might need for debugging a program. Recursion is dreaded and intimidating to many people because of the fear associated with it.\n\nRecursion is confusing and can lead to stack overflow if not managed properly. Python, being an interpreted language, sets a limit of 1000 function calls to prevent crashes. You can increase this limit if needed, but excessive recursion can still cause issues.\n\nA stack overflow occurs when a function keeps calling itself without returning, causing a memory overflow. It's easy to write yourself into this situation, especially with recursive algorithms. While complex, recursion can be satisfying to understand and implement in programming.\n\nOverall, understanding the call stack is crucial for mastering recursion and avoiding stack overflow errors. It's essential to grasp this concept to write efficient and bug-free code.And they just, it's all implied, so that's confusing. There's a critical section of this concept that isn't even being addressed or pointed out, so that's confusing.\n\nI also thought, well, what is recursion actually good for? Yeah, that's what I was wondering about too. There are two examples that I feel like every recursion tutorial uses over and over again, and it's factorial and Fibonacci. Factorial is when you basically have a series of multiplications. Five exclamation mark, which is how you write it out, would be five factorial, equivalent to five times four times three times two times one.\n\nThis is used in mathematics, not very common in day-to-day arithmetic. Hopefully, you're not using this to calculate your taxes because factorial numbers get pretty big pretty fast. But if you think about it, there is a recursive nature here. For example, 3 factorial is 3 times 2 times 1, and 2 factorial is 2 times 1.\n\nSo really, you could think about it as 3 factorial is just 3 times 2 factorial, which is 2 times 1. And if you just generalize this, the factorial of any number in is just that number in multiplied by the factorial of n minus 1.\n\nAgain, it's sort of like, okay, now you have this recursive definition. If you wrote a factorial function, it would call the factorial function just with n minus 1. You can't have this call itself forever, of course. Eventually, it gets down to one, and the factorial of one is simply one. This is what we call the base case. It's the set of circumstances where your recursive function stops making recursive function calls to itself, and the other cases are called recursive cases. Every recursive function needs to have at least one base case because otherwise, it'll keep calling itself and never stop, causing a stack overflow.\n\nSo, if you have to write a recursive function, thinking about what the base case is and what the recursive case is often a really good starting point. The big problem with factorial as a recursive function is, what if you want to get the factorial of 1001? Python only lets you do 1000 recursive function calls before it causes a stack overflow. If you have the factorial of 1001, it's 1001 times the factorial of 1000, and then that has to make a recursive function call. You're going to have 1001 recursive function calls, causing a stack overflow. With recursion, it's going to crash the program, even though if you put this in a loop and calculate the factorial iteratively, Python can handle that easily. Recursion seems elegant and fancy, but in reality, it's completely impractical and will crash your program.\n\nThere's a whole other technique called tail call optimization, also called tail recursion or tail call elimination, that gets around the stack overflow issue. But at that point, you're patching together all these additional concepts to make up for your already complicated concept.\n\nRecursion has a way of making simple things complicated. The Fibonacci sequence is where you have a sequence of numbers that begins with one and one or sometimes zero and one, and the next number in the sequence is the sum of the previous two numbers. If you start with one and one, the next number would be one plus one.Two and then, so now your sequence is one, one, two, and the next number would be the last two, which is just one and two. That would be three, and then the last two then is two and three. So the next number is five, and then the next number is three plus five, which is eight.\n\nThis is one of those things where it's a mathematical concept that's easy to grasp and is also used in a lot of illustrations. There's something about sunflower seed arrangements or pinecones having an arrangement that follows the Fibonacci sequence. If you think about the Fibonacci sequence, writing a loop to do this is simple. However, it could be made more complicated with recursion if you want to find the nth Fibonacci number.\n\nThe nth Fibonacci number is just the sum of the (n-1)th Fibonacci number plus the (n-2)th Fibonacci number. Each call to the Fibonacci function results in two more calls to the function, leading to an exponentially growing number of function calls. A loop to find the 50th Fibonacci number would run in half a millisecond, but a recursive Fibonacci function to find the 50th Fibonacci number would take longer than the universe has existed to finish that calculation.\n\nThere's a workaround for this. When calculating the nth Fibonacci number, you can create a cache of results to avoid redundant calculations. This technique, called memoization, saves on execution time by storing previously calculated results. It's a trade-off between memory and CPU power.\n\nRecursion often gets a reputation for being complex, but it can be tedious and not always useful in practical programming. Despite its prevalence in tutorials, recursion may not be the best approach for real-world code, especially for large numbers.\n\nProgramming advice often includes half-remembered information, leading to misconceptions and passing off opinions as facts. While recursion has its uses, it's important to understand its limitations and consider alternative approaches.Recursion isn't all bad. I feel like it's overused in places where it doesn't need to be used. Another thing to consider is that there is nothing that a recursive algorithm can do that you can't do with a loop and a stack. Essentially, a recursive function is using the call stack as its stack data structure and running the function over and over again. Every single thing that can be written as a recursive function can be written iteratively using a loop and a stack. There are some recursive functions where you don't even need the stack.\n\nIf you have a recursive function that doesn't need a stack, it's a sign that you shouldn't be writing it recursively, as you're making it harder on yourself. Recursion is useful for problems involving a tree-like structure and backtracking. For example, a maze solving algorithm is a good example of this. When you come to an intersection in a maze, you have multiple paths to choose from, and you recursively try each path until you reach a dead end.\n\nThe base case is when you reach a dead end, then you backtrack to the previous intersection and try another path. This recursive approach creates a tree-like structure that helps in solving the problem. While solving this with a loop and a stack is possible, using recursion can make the code easier to understand.\n\nFunctional programming concepts, like recursion, can be useful in Python. While languages like Haskell may not have taken off in popularity, there are still valuable concepts to learn. I cover some of these concepts in Chapter Seven of the book, including memoization and dynamic programming. The book also includes classic recursion examples and explores different applications of recursion.\n\nThe idea of filling a space, like in a paint program, is similar to solving a maze with no exit. The goal is to explore every possible path, similar to exploring every hallway in a maze. Recursion can be a useful technique in solving such problems.Flood fill is an earth thing where the code, the recursive code, is actually easier to understand. However, with images, you can have large images, which may cause a stack overflow if you try a recursive flood fill algorithm. This tool is commonly used in programs like MS Paint or Photoshop, where you can click on an area and fill it with color.\n\nThe flood fill algorithm doesn't strictly require a stack data structure; you can use any data structure, such as a Python set, to achieve the same result. Recursion is something that may not always be necessary, but it's important to understand because it can be useful in various scenarios.\n\nRecursion also plays a significant role in parsers and compilers, especially when creating a programming language. Understanding recursion helps in forming an abstract syntax tree, which is essential in programming languages.\n\nComputer science education provides a solid foundation for understanding these concepts, making one more effective as a software developer. Learning about caching strategies, such as the LRU cache decorator in Python, can significantly improve performance in coding projects.\n\nGraph theory, directed acyclic graphs (DAGs), and other higher-level concepts may seem intimidating at first, but they are essentially extensions of simpler concepts like tree structures. Understanding the basics can help tie these advanced concepts together and enhance one's understanding of computer science principles.I try to focus on practical examples or at least running code. The other thing about this book is that it's not a Python book, it's a general programming and computer science book. I have all the code examples in both Python and JavaScript. It's very important for me to have runnable code as the examples in all of this. If you just talk about abstract classes or concepts, the average person may not grasp it. \n\nI've started using playing cards as a prop for explaining these things in my books and tutorials. Playing cards are cheap, familiar, and easy to manipulate. For sorting algorithms, using playing cards to run the algorithm in your hand can make it more understandable. Drawing out diagrams like a stack data structure being compared to a stack of playing cards can help visualize the concept.\n\nPlaying cards are an excellent prop for instructors or self-learners when coding. Zach Gage, a game developer, often starts by using physical objects like playing cards before jumping into programming. This hands-on approach can help simplify complex concepts. The examples in this book are designed to be easily visualized and understood.\n\nComputer science can be abstract, but once you grasp the concepts, it becomes easier to work with. Recursion and programming, in general, can be challenging to teach because of the abstract nature of the concepts. It's important to break down these complex ideas in a way that is easily digestible for learners.So there is a book called \"The Little Schemer\" that I believe came out in the 1980s, written by a couple of MIT professors. This book teaches Scheme, a functional programming language that starts with recursion. You don't even use loops in it. There's a small population that loves manipulating abstract symbols according to arbitrary logical rules just for fun. My brain is kind of like that, but for the rest of society, people may just be confused. I feel like a lot of people who love this book get it and appreciate how it teaches you how to think and points out ideas. However, the majority of people may read it and feel dumb for not understanding it, which worries me. \n\nI wanted this book to be a counter to that mindset, showing that there are small concepts that can be demonstrated with examples step by step. It should have actual runnable code that you can type in, run under a debugger one line at a time, and see how it works. \"The Little Schemer\" is beloved by many computer scientists and people at companies like Google, but I gave it a one-star review on Amazon. I got through about three-fourths of it and felt that it needed an editor. I worry that people may find it confusing, despite its cute drawings of cartoon elephants on the cover. \n\nMy controversial opinion on recursion is about tail recursion. I believe that tail recursion should never be used. If you find yourself using tail recursion, it means you've made a mistake and should use a loop instead. This realization made me aware of the deficiencies in my education on recursion during my computer science degree. Tail call optimization may seem like a clever hack, but it often leads to more confusing and convoluted code without providing much benefit.\n\nIn conclusion, recursion has its uses, but tail recursion should be avoided in favor of simpler and more straightforward solutions like using loops.Yeah, you never need to use this and it turns out I think this is not a controversial statement because Python, the Python interpreter, specifically the CPython interpreter that you download from python.org, does not implement tail call optimization. So even if you wrote your code in a way to do this, it really depends on the compiler or the interpreter detecting this and then applying this optimization behind the scenes to prevent stack overflows. Python's interpreter doesn't do this at all. Guido has written a couple of blog posts about why this is. He says that it really interferes with the traceback messages that appear when you're debugging.\n\nBut I looked into this, and I think every major JavaScript interpreter also doesn't have this as an optimization. If you open up your browser's debugging tools and write a bit of JavaScript code where you just have a function that calls itself, or you write a recursive factorial function that also has tail call optimization, it's going to crash in a stack overflow because that JavaScript interpreter doesn't actually use this. I think also the latest versions of the Java compiler also don't have tail componentization. So like Python, JavaScript, and Java purposely don't implement this.\n\nI kind of realized that this is not actually a technique that you should use. Of course, in functional programming languages where essentially you don't even have loops, you just use recursive function calls as your loop, tail call optimization is very much necessary. But I feel like this is a reason why nobody really likes to use functional programming languages or why they're not as mainstream because it just makes your code more complicated, and there are easier ways to do it. So why not do it the easier way?\n\nWhen you're thinking about writing this book, were these some of the things that you were most excited to write about?\n\nI originally thought that this would be a super short book. I approached No Starch Press with the idea of like, \"Hey, what if we just did a 70-page or 100-page book? It's really short.\" Recursion, how much could I possibly talk about that? But then it just kind of grew into a regular-sized book, and I started looking at all these related concepts like tail recursion, stack overflows, and memoization. That led me to dynamic programming.\n\nI realized dynamic programming itself sounds very fancy. Apparently, the name came about from a computer scientist Bell, who wanted to get funding from the Department of Defense back in the 40s or 50s. But one of the administrators just really hated spending money on research, and what he wanted to do was just programming research. So instead, he said, \"Well, it's dynamic programming,\" which is sort of a meaningless name.\n\nI always thought, \"What exactly is dynamic programming?\" It's one of these terms I kept hearing all the time, and it seemed to use recursive algorithms. It took me a long time to finally boil it down to a simple sentence that I could never find in any dynamic programming tutorial. So dynamic programming is the set of programming problems where you want to use recursion to break your problem up into similar smaller problems, but there's overlap between these problems. Fibonacci is an example of this. If you want to find the 10th Fibonacci number, you have to find the 9th and 8th Fibonacci numbers. You're recalculating the 8th Fibonacci number multiple times, so there's overlap right there in your recursive algorithm. The way around this is using memoization. Dynamic programming is just recursion and memoization because you have these overlapping subproblems.\n\nIt took me a long time to figure this out, and that's why this book is something I've been working on for about four years. It took me on several journeys. It's amazing how much effort it takes to simplify concepts and show that it's really easy to give it an intimidating reputation as this mysterious technical advanced topic.Yeah, it does boil down to much simpler things. I also found out this is another weird thing. Also, why I say that a lot of programming is just people repeating the wrong advice they heard from others. You'll often hear about top-down recursion and bottom-up recursion. I've realized that there's no such thing; these are misnomers. What people actually mean is top-down dynamic programming and bottom-up dynamic programming.\n\nThe idea is the Fibonacci algorithm is an example of top-down, where you start with finding the 10th Fibonacci number. You break it up into smaller problems of the ninth and eighth Fibonacci numbers, and then break those up into even smaller problems. That's the top-down approach; you start with the result you want and work down to smaller problems until you've solved the base case, at which point you can reconstruct the total solution.\n\nBottom-up, if you think about it, all recursion is top-down recursion. The concept of bottom-up dynamic programming is the other half of dynamic programming problems, where you start with the small cases. This would be like starting with one and one, the first two Fibonacci numbers, adding them together to get the next Fibonacci number, two, and then building your way up. This is really bottom-up dynamic programming, and there's another technique in bottom-up dynamic programming called tabulation, which is another optimization.\n\nThe point I want to make is that there's no such thing as top-down recursion or bottom-up recursion because all recursion is top-down. When I started looking for examples of bottom-up recursion, people would show starting from the base cases and building up, but their actual code doesn't have any recursive function calls. It's not recursion, it's just getting these terms mixed up, and it's a common misconception.\n\nThere are many tiny misunderstandings when it comes to recursion, which is why people think of it as difficult. It's not an arcane, super genius topic; it's just poorly taught. When I was writing the book and coming up with examples, it wasn't difficult to switch context between Python and JavaScript. I tried to keep the code as simple as possible because every programming language has variables, functions, and arrays. The examples are mostly one-to-one, so it's easy to understand.\n\nI had an idea for a programming book that acts as a Rosetta Stone for Python and JavaScript, two popular languages. Learning multiple languages is like traveling abroad; you learn about your own language's unique aspects. Python and JavaScript do things differently, and it's good to explore that. I stick to simple concepts to appeal to a broad audience, not just Python users. For JavaScript programmers listening, this book has code examples for you.\n\nI always have five or six book project ideas in mind. The Rosetta Stone book was one of them. I've had this idea for years now, and my friends tell me about it. I might have mentioned it on a previous show. It's essential to have projects and ideas brewing for future work.I eventually finished the recursion book, which took me four years, but I finally got it done.\n\nYeah, like an idea of a programming book that teaches programming and Python using illustrations instead of words, similar to an IKEA instruction manual or a LEGO manual teaching how to build things. I have no idea how to convey all these topics, but I thought it would be nice because then you don't need to understand English in order to program. It's a different way to teach concepts, but it might be too esoteric. \n\nI am also working on a book with gentle programming exercises, gathering basic examples for people starting out. For example, converting between Fahrenheit and Celsius, a common exercise for programmers. I want to gather 42 of these exercises into a book that I am publishing as a 99 cent ebook, also freely available under a Creative Commons license on my inventwithpython.com website.\n\nI have been neglecting Pi Auto GUI, a Python module that allows Python programs to control the mouse and keyboard for automation. It's part of robotic process automation, which involves simple scripts that click on things and type for you.\n\nI had fun working on the projects in the recursion book, including programs that generate mazes and solve 15 tile puzzles. I also included a fractal art maker using Python's turtle library for programmatically generated art.\n\nThe last project is the Droste effect, where an illustration or drawing contains itself. The name comes from a Dutch hot chocolate powder can featuring a recursive image of a nurse holding a tray with the can of hot chocolate powder.So I'm using the pillow, the Python Image Library. You can take any image and just draw magenta pixels over an area inside that image. This program will then recursively keep filling in that magenta area with the image itself. But of course, that smaller image will have its own magenta area, so it just recursively calls itself on that. You can create these interesting little mirror into mirror images with any photo that you have. \n\nI thought that was pretty nice. It turned out there were a few different issues I had to solve, but I came up with a Python program that can generate those fairly easily. It's nice, and it's like, okay, you just have to figure out all the hard parts and then explain them. I feel like it's a lot easier once you see the code in front of you; you can see, oh, I understand how this is working now.\n\nI went and brought up that book, \"The Little Schemer\" book has one on it, actually. The elephant is holding the book, and of course, the book has the picture with the ongoing. When it came to the cover design of this book, I also have that where it's a picture of a robot reading a book, and then of course, the book is the book itself. So there's a robot on the cover reading a book, right over and over again. I felt like I can't not have that as the cover. \n\nI love this book. That's funny. This book was pretty exhausting to write, but it's now done. It's coming out on Amazon in August. But you can actually get the early access eBook from No Starch, and I always recommend people buy the book from the publisher directly because you get those free eBooks as well. I believe the early access eBook has all the content of the main book. Just because it's not yet officially released, they still call it early access, but it's essentially the full book. You'll also get the full book when it comes out if you buy the early access one. \n\nThat takes us to the weekly questions. What's something that you're excited about in the world of Python since we last talked? Textual is a project that I've been following. Will McGugan has done a lot of that work. The term TUI for text user interface, as opposed to GUI, the graphical user interface. This is for applications that have windows, buttons, and checkboxes, but in the command line. Using text characters to draw lines, we could create these very primitive-looking graphical user interfaces that way. \n\nI do like the simplicity of them, and they offer even though they look very basic, it's easier to program and deal with them, which is great if you have simple programming tools you're creating. It's sort of like how Minecraft has a retro aesthetic, but it's really easy to build things in Minecraft because there are discreet blocks. It's not like a full CAD tool or a 3D modeling program like Blender that you have to learn. It's really easy just to play around with blocks. \n\nI've only dived a little bit into the hello world examples of it, but I'm excited to get more involved in that. Also, the Beware project for putting Python on mobile devices is something I've been looking at for quite a while now. Your conversation about that or your talk about that made me think about the idea of creative restraints. Having constraints is always kind of nice in the sense that when there are a million possibilities of a way of doing something, you can have that overwhelming amount of choices. It's nice to say, let's just learn how to do it this way and dive into it, which is really slow. \n\nIt really cuts down on the possibilities that can paralyze you. Get something done. We actually met up at PyCon this year, and I think the big news from that was Python in the browser.I feel like a lot of people are very excited about the presenters stressing that this is an alpha release. I'm also excited about the idea of Python running in the browser. Definitely, I'm playing with it a little bit. I'm thinking about talking with Russell from Beware because he's indirectly connected in some ways. He got funding through Anaconda, which is helping him with his project. I'd like to hear a little bit about that as the last time I talked to him was over two years ago. I'm glad to hear that he has some funding to keep working on the project and that there are some nice tools that can be generated. The idea of writing Python once and deploying everywhere, including the web, is great.\n\nPython is such a great language and an accessible language. I really want to see it being used in more domains, like the browser and mobile devices, areas where Python hasn't conquered yet. I'm excited about any gains that Python can make there.\n\nWhat's something you want to learn next, not necessarily Python or programming-related? It's always programming-related for me. One idea I've been kicking around in my head is that all my hobbies are cheap. Writing software, going for walks, or playing Pokemon Go are all cheap hobbies. One of my cheap hobbies is origami. It's great to follow along with YouTube videos and learn some folds, unlike when I was a kid with just origami books.\n\nOne issue with videos is that there are big hands in the way or they move too fast. I thought it'd be great to use cloth simulation algorithms to simulate folds on paper. I want to write software to simulate folds and record the movement of the paper as you fold it. You could play it back and view it from any angle, creating instructive interactive websites or applications.\n\nThere was a talk at PyCon that went into Blender, the 3D modeling software, and constraint satisfaction problems. This idea of origami folding is something I want to explore. It sounds fun, and I should start looking into it again.\nDo you have any favorite channels on YouTube for origami tutorials? There are a bunch of them, like Joe Nakashima. Search for origami tutorials on YouTube for simple folds. If the video is longer than 20 minutes, it might be too much. Set aside an hour when first learning a fold, pausing and rewinding as needed.It's one of those things where I guess it's sort of the opposite of computer programming because learning all these cool programming things, especially if you want to do machine learning or AI, requires massive data centers to crunch through all these numbers. That's something that we can only do here in the 21st century. But with origami, it feels like there's something nice that I could go back a thousand years and all I need is a square sheet of paper to recreate the most complicated origami models. If I just knew how to fold it, it's something that doesn't really require technology, just knowledge and a little bit of insight. Yeah, there's something I really like about that. Also, paper is cheap. Those are the types of hobbies that I generally like. That's cool.\n\nSo what's the best way that people can follow the things that you do online? My website is inventwithpython.com, where I publish all of my Python programming books, and they're all freely available under a Creative Commons license. You can read the entire book for free online. There are also links to the publisher's site where if you want to buy a nice print book or a much better formatted ebook, you can buy it there. From there, I have links to the occasional YouTube video that I'll create or online courses that I've also created. But yeah, inventwithpython.com is where people can find me online. That's great.\n\nWell, Al, thanks so much for coming on the show again. This has been a lot of fun. Yeah, thanks for having me. This is kind of a hard concept to relate in the audio-only format, but hopefully I've at least sparked an interest for people to learn more. Yeah, and not be scared off as well. Definitely, you answered some more of my questions, so that's great. Thanks a lot. Thank you.\n\nI want to thank Al Sweigert for coming on the show again, and I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "T72m-ODuXJ4": "Welcome to the Real Python Podcast. This is episode 126. Are you interested in using Python in an industry outside of software development? Would adding a few custom software tools increase efficiency and make your co-workers' jobs easier? This week on the show, Josh Burnett talks about using Python as a mechanical engineer. I met Josh at PyCon 2022 in Salt Lake City, which he attended for the first time with several co-workers. He suggested we do an episode to shed some light on ways Python is being used professionally by people who aren't primarily programming for a living.\n\nJosh works as a mechanical engineer and equipment manufacturer where he needs to perform repetitive tasks and generate copious logs. He explains how he moved his team away from Matlab and towards using Python. We discussed his progression from writing scripts to developing packages and eventually hosting his work on PyPI. He also shares his explorations with CircuitPython for personal and professional projects.\n\nThis episode is sponsored by Deepgram, the preferred speech-to-text API of Python developers. Get accurate transcripts from any audio with features for understanding. Try it by transcribing 200 hours free at deepgram.com/realpython.\n\nAlright, let's get started. The Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Josh, welcome to the show. I'm glad to have you here. Thanks for being a listener of the show.\n\nYeah, we ran into each other while I was working at the booth at PyCon in Salt Lake, and you said you had brought a team of people from your work to PyCon. Maybe we could talk a little bit about that experience and your interest in coming to PyCon 2020 because you used to live in Pittsburgh.\n\nI was interested in coming to PyCon, even though my background is a little non-standard for the typical Python or PyCon crowd. I feel like a lot of people who come to PyCon usually have a programming background, but I'm a mechanical engineer, and most of my team consists of various types of engineers. We use programming as one of our tools, but it's not our job description per se.\n\nI was excited to try to come to PyCon back in 2020, but it got canceled due to COVID. I was looking forward to going back to my hometown and visiting the campus of Carnegie Mellon. I believe the current plans are to go back to Pittsburgh after this next year in Salt Lake City.\n\nI was happy to bring a whole team of people from my company to PyCon this year. We had mechanical engineers, process engineers, and systems engineers who all work together to make new products. I work at a company called Orphan that makes healthcare diagnostic equipment, focusing on different kinds of blood analysis.Yeah, I saw the buzzword there of Next Generation instrumentation platforms and I was like, okay, what does that mean?\n\nMost of the time, if you're in a company that makes laboratory instrumentation, then each of those products that you make is usually based on a platform that the company has previously developed. You're taking something that's already been made and released, maybe tweaking it, making some incremental improvements, or targeting a slightly different market by adding new features. It's fundamentally an incremental update to what you did before.\n\nBut if you're lucky and you're at the company at just the right time when they need to redesign the whole platform, like with my last company and my current company now, it's happened where the product they're selling is based on old electronics. You don't want to have to change that underlying platform too often because there's a lot of investment that goes into writing the firmware, the low-level code that runs these embedded systems. They don't want to redo that more often than they have to.\n\nI have a friend who writes for Real Python, Jim Anderson, and he works in video with a platform that builds firmware. We were talking before about photography and how rapidly it changes, almost becoming obsolete. In the case of the tools you work with, what's the lifespan of a platform? With my current company in the healthcare industry, it's all FDA regulated, and there's a lot of effort that goes into qualifying your product to ensure it does what it's supposed to reliably. The FDA is very stringent about their quality levels, so you want to avoid having to revalidate as much as possible because it's a lot of work.\n\nAs such, the lifetimes of these products can be in the 10-15 or even 20-year span for a given platform. We're working on updating them and figuring out how to create a long-lived platform. Over the course of those 20 years, it's not just the same product that's the only thing you sell, but you base other things on that same platform. Now, we're starting to see that these electronics are getting really old and some may go obsolete.\n\nGiven what electronics were capable of 15-20 years ago compared to modern computing hardware, we have the opportunity to redo the whole platform from the ground up, including more automation, better user interfaces, and user experience.\n\nThe Next Generation platform allows us to rethink the whole thing and have fun with it from an engineering perspective. One shift that has come along is the connection to other computers and platforms, especially in certain medical equipment. In the last decade, in the laboratory instrumentation space, there has been more networking of big expensive equipment for centralized monitoring and data storage.\n\nFor equipment in the tens to hundreds of thousands of dollars range, networking allows centralized monitoring to ensure uptime and worth of investments. If a lab has multiple pieces of expensive equipment, networking helps in verifying they're in good working order and maximizing uptime.Yeah, they'll invest in some kind of central monitoring software that's able to check them over the network and see which ones require maintenance. You can plan those things out ahead of time. That just wasn't possible with older technology, right? 10, 15, 20 years ago, it was like a spark that people thought of, but it wasn't necessarily being implemented at the time.\n\nSo that's really interesting to me. Number one, that you have to think about really long-lived products and platforms. But then also that you kind of came to me because you were like, \"Hey, we're really getting into Python.\" So I kind of wonder, maybe we could do a little super quick background on your background in programming.\n\nWhen I went to school, I graduated from my undergrad in '01, kind of right in the middle of the .com Boom. As an undergrad, I had to take, for the engineering curriculum, the intro to computer science. At the time, we had the option, depending on which Professor you had, to learn C++ or Java. Thankfully, I ended up with C++. That was my first experience with that level of coding. I had some exposure to Logo Writer and Q Basic as a kid, but didn't do much with it. One semester of C++ and a numerical methods class where we used Matlab for numerical processing.\n\nMatlab is a language and runtime environment optimized for numerical computing. It's a popular platform for scientific computing and heavy-duty data analysis. I ended up using Matlab more and more, familiarizing myself with it during my final semester in school. In the mechanical engineering program, the MathWorks company, which makes Matlab, wants graduates to be familiar with it. They provide free licenses for students, which is beneficial since it's expensive in the professional market. It's a valuable tool with a cost associated with its use.But it's going to save money in developing whatever product you're doing. If you're doing digital signal processing developing algorithms around that or controls work, then they have all kinds of specialized add-ons, they call them toolboxes, that are targeting various particular computing tasks. I can think of lots of little industries that are like that, having worked in video, audio, and in the sort of. If you are going to school, in my case, I worked out of school for recording engineers, students had to come out and know Pro Tools, they had to be familiar with it. Or if they were going to work in film, they would need to know Avid and be familiar with those platforms. Even though there were other platforms around, it made sense. And then they would literally have certifications for those kinds of things. So there's always that kind of interesting hook. That's part of it. And there are side cases where other things are popping up, and I thought that was kind of interesting that this is one of the focuses that we thought we could talk about is that you started to transition away from using that. Maybe we could talk about how you were using Matlab at your company now or sure previously in the previous transition. Yeah, yeah, so I was doing a lot of the log file processing, or I was collecting data in the lab. A lot of what I end up doing, I'm creating or designing new parts. Mechanical engineer, right? So I'm not just making circuits and things, but I'm making physical parts that we designed with CAD software. And then once we are putting everything together, we need to start testing it and making sure things work properly. A lot of the equipment that I design and work on has lots of automation and lots of motors, gears, and mechanisms that are moving mechanisms around. We were collecting some information from those, basically using some small embedded computers that would give us log files. And I needed to parse those so I could pull the data out of those and create some graphs and make sense of what was going on with my test setup. I was initially doing all that in Matlab, but my workflow was that I would go to the lab in another part of the building and run all my tests on some computer there, on a computer that I wasn't responsible for. It was a different part of the company, so I couldn't just install whatever I wanted on that computer. It's job-specific for doing that sort of work, and I couldn't install Matlab because there are licenses required for every install, and it's thousands of dollars per seat. So they weren't going to install a license just for me to do that. So I would go to that machine, capture these text files, put them on a thumb drive, and walk back to my laptop or walk back to my desktop at my desk and fire up Matlab and do my analysis. Well, that's a lot of walking back and forth and pretty inefficient, right? Good old sneakernet. So I had started when I was in grad school just before that job. I had played a little bit with Python as personal projects, so I had gotten a little bit of exposure to it. When I was in this particular situation, I'm thinking, I wonder if Python would be able to serve the need here. So I started looking into that, and sure enough, this is in the early to late probably late 2000s. The numerical computing story for Python was really maturing heavily at the time. They had consolidated it, used to be not just NumPy, I think it was numeric. I think it was another library at the time that were competing within the Python space. So they had consolidated to just NumPy, and Matplotlib was coming along nicely. I found that all the things that I was using Matlab for in this case, which were not the super specialized code that Matlab tries to hook you on, but it's just the plain vanilla. I need to open a file and parse it and make plots from it. Python was able to do that very well for me. And in fact, I found a portable distribution of Python that I was able to run right off my thumb drive that had an IDE associated with it. That's no longer around now, but I could just walk down with my thumb drive, use that same machine that I didn't have the ability to install software on, and just run everything I needed to right off the thumb drive. And then right there, I could capture the files, I could do my data processing all right in one place. I didn't have to worry about any licensing fees. So that was kind of the gateway drug, the foot in the door for, hey, I think this could work here. And then sure enough, I kept finding more and more uses for Python, usually doing various kinds of data analysis, but especially cases where I was not at my main PC where I had that Matlab license.And then I found that over time I was opening Matlab less and less. Finally, I realized that I could either have the company cancel my Matlab license or give it to someone else since I wasn't using it. I hadn't opened it in a year at that point. It was over a decade ago. I don't have my Matlab licenses anymore at my new job because I do everything I need in Python.\n\nI started with Python 2.5 or 2.6 in grad school. Transitioning to Python 3 wasn't painful for me, as our usage is localized. We usually write software for ourselves or a small team, so compatibility with older versions wasn't a concern. I stuck with Python 2.7 until the main libraries I needed were ready for Python 3.\n\nI often use F-strings for debugging and logging in Python. For small scripts, printing is quick and dirty, but for larger projects, I use logging from the \"logging\" package. It's easy to use and doesn't require much configuration.\n\nThe initial spark for me to start using Python was during a robotics class in grad school. I needed data structures that weren't available in Matlab, so I found a Python library that implemented them. I used Python for the project, which involved mapping a space with small robots and sensors.\n\nMatlab syntax is similar to Python, with a lot of dot syntax and not many extraneous characters, similar to Java. It's not as complex as languages like Perl.It was making the transition from the Matlab syntax over to Python was pretty straightforward.\n\nPython developers from companies like NASA, Volley, and Spotify chose Deepgram's speech-to-text API for accurate, usable transcripts to power their voice bots, podcast analytics, and video platforms. Deepgram automatically transcribes any audio with understanding features like summarization, topic detection, and language detection so you can do more with your voice data. Get an API key and transcribe your first 200 hours for free at deepgram.com.\n\nSo then, I guess I'd like to journey deeper into your almost evangelism inside your organization for Python being this champion. What were the kinds of things that you were suggesting to other people? Maybe we could start with using it for logging tools and other things. Were there other projects that you started to implement going beyond that?\n\nYes, I ended up using Python in a lot of small and large ways. Early on, a typical task for me was measuring the consistency and accuracy of a mechanism moving a probe along two axes on a table. We used a spring-loaded gauge to measure how far we were compressing the tip accurately.\n\nI was able to automate this process using the PySerial module to communicate with the gauge and programmatically control the mechanism. This allowed me to take thousands of measurements quickly and efficiently, getting statistically significant data without manual effort.\n\nThis was just one example of how Python could be used for automation and data collection, impressing others with the capabilities it offered. Additionally, I used Python to verify the torque output of stepper motors used in chemical analysis equipment in the lab.\n\nWe wanted to ensure the motors were strong enough to move mechanisms efficiently for our products. By automating the testing process with Python, we could assess the torque output of different motors accurately and quickly, allowing us to choose the best supplier for our needs.\n\nIn conclusion, Python played a crucial role in improving efficiency and accuracy in various projects, showcasing its versatility and power to colleagues in the organization.It's especially important with the stepper motors. The circuit you're using to drive them will have a direct impact on how powerful they are. You can't just take the manufacturer's word for it in the spec sheet. When they test it, that's with whatever driver chip they were using, and that may not be the same as the driver you should be using. So, you really need to use your own circuit in that process.\n\nWe bought some equipment from a company that would allow you to take torque measurements. But it was a really manual process. Either you or your poor Co-op or summer intern would have to sit there for many hours straight and take these measurements. It involved pushing a bunch of buttons on this big machine and then looking at a digital readout that was coming off of it. At the same time, bending over to your laptop usually in the lab and typing some commands that would tell the motor to spin up to a certain speed.\n\nWe were able to buy an expansion card for that piece of equipment. Instead of just having buttons and led readouts and a digital readout, now we had digital inputs that mapped to those buttons and digital outputs that corresponded to various LEDs. An analog output would produce a voltage output corresponding to what normally would have been on that digital readout.\n\nNow we could combine it with a data acquisition box from someone like National Instruments or some other companies. They also have a Python API. Now we're able to use the laptop to take all the same readings that we would have had to manually write down. We get much better data as a result out of this and at a higher sample rate.\n\nOnce we were able to automate the process of running the test and collecting the data, I was able to make a GUI for it. Driving the whole setup using pi QT and a module called piquity graph for real-time data visualization. It's much faster than matplotlib and allows graphs to update on the screen at 30 Hertz.\n\nThe end result is a test setup that anyone can use. You can set it up and walk away for 10-15 minutes while it goes through and does all the tests without messing up. When showing people this tool, they start to see its value. Selling the company on the benefits of Engineers having a good Python background was easier when they saw what we were able to accomplish remotely during covid.So I said some webcams and set up remote access for my computers that were running equipment in the lab. Then I was able to control everything using Python even though I'm logging remotely from home. I'm basically writing control programs that would make these mechanisms go through the various tests that we need them to do. I was able to work on all that from home and still get a lot accomplished even though I wasn't right there in the lab.\n\nNow, that's not necessarily the success story for Python. The fact that the work was happening whether I was there or not, that was really the success story with Python. We were in the early design phase of this project where we didn't have robust and complete firmware, which is the low-level code that will drive the equipment when it goes out into the field as a product. They're not going to use my Python code to drive this thing, thankfully. They will use C or some other typically C++ code, although Python is coming in there as well in some places.\n\nOur team exposed some Python bindings, basically a Python API where I could control individual motors or read individual sensors with Python. Even though they don't have the full behavior of the system implemented in C++, they gave us all the building blocks necessary with Python, all the touch points, if you will. Our non-firmware team, familiar with how the thing is supposed to work, could prototype a lot of that behavior and verify that the mechanisms we've designed work the way we want them to.\n\nWhen our management saw that we were able to accomplish a lot even at a very early prototype stage with Python, they saw the value in it. We've run three or four training courses in the last year and a half to get more people up to speed on Python. We're working with an outside company that provides remote training with a live instructor and an online platform. The courses are live remote and we've had at least 40 or 50 people go through the training across different parts of R&D.\n\nMy early work in Python was just scripts that barely qualified as programs, accomplishing one task. As I did more, I started reusing code across projects, eventually creating modules that I could share with colleagues. I got tired of constantly updating them, so I started learning about packaging and tooling to make them more widely usable outside the organization.\n\nThis journey from script-like code to creating reusable packages was a gradual process that involved realizing the potential for reusable code, pulling out common modules, and eventually sharing them with others. I also had to learn about version control systems like Mercurial before transitioning to Git and GitHub.My colleagues would be asking me, \"Okay, what's the latest version of that file?\" So I keep sending that, and then eventually I said, \"Well, I wonder if I could. This isn't anything that's proprietary. It's pretty generic, and I probably could just release that to something like Pi Pi. Then I can just tell them, 'Hey, go pip install it' rather than constantly bugging me for the newest version of it. It also makes it easier for me, right? If I'm setting up a new test setup, I don't have to go track down where I saved the newest version of that file. Instead, I just know. Yeah, makes it very portable, right?\n\nI started learning about some of the best practices, whether it's just a requirements.txt or whatever so that if I'm sending someone my code that's not necessarily a module they're going to install, but they're just trying to look at a data analysis that I did, then I can list, 'Here's all my requirements' in requirements.txt. In that way, they know they could just pip install that in a new virtual environment, and they're kind of off and running. So, it took time though to get to that, for sure. \n\nWhat does that timeline look like, you think? So I mean, I look back at this particular module I'm thinking of. The first one that I ended up releasing to Pi Pi, my first release to Pi Pi was in 2016. Amusingly enough, it was immediately, like the same day, followed up by three bug fix releases because I had gotten some of the metadata wrong in Pi Pi. That's always the way it happens. But it wasn't my first release of that code internally, so it actually was released at version 1.3 because I had some version 1.0 that was just internally that I was using as my own version numbering system before I released it publicly. But yeah, so I had 1.3 and then 1.3.1, 1.3.2, 1.3.3 right away. But if I look back at that code, I actually 1.0 would have been in 2010. That was the first time I started kind of putting at least that particular module together in something that I could easily package up and send it to someone else as, 'Hey, here's a standalone module that you can import these sort of utility fun functions from.' It was for implementing scanf, so you know in C or in, of course, I was coming from Matlab, there's a function for just taking a string and maybe that string has some numbers in it interspersed with some other text, and you want to be able to just pull those numbers out of it. You can provide the scanf function a template saying, 'This is what it should look like,' and then there's a couple special formatted strings that you put in there to say, 'There's an integer here, so I'm going to stick a percent I here, or if there's a floating point number here, so there's percent F there.' It's just really simple and straightforward to use, and like I said, coming from C, they use that scanf function, and then in Matlab, there's an SNF function as well, so I was familiar with that. Familiarity's there, yeah. But I was looking around, again, this is back in 2010, looking around and couldn't really find any packages that did that off the shelf, nothing in Pi Pi. The solutions that you would get from looking at some of the core team dev discussion boards basically said, 'Yeah, you should just use regular expressions for that.' And that's true, you can use regular expressions for that, but it felt like using a sledgehammer to try to push a tack in. It's just really overkill. And you have to go through the arduous task of learning regular expressions that you'll eventually forget, yes, and just forget them every time, which I have done probably three times. Yes, and some of those can be surprisingly complicated to come up with a robust regular expression that will work in all cases where you're trying to look for a floating point number, even if maybe it has scientific notation in it. You know, it gets pretty complicated. These are things that even if you're going to do it as a regular expression, you're going to end up either copying and pasting that code all the time or you're going to put it into a library. So I ended up finding a recipe that someone had written on Active State or something that did what I was looking for. So I took that and kind of cleaned it up a little bit, made sure I put a link in the top of the file to where I had found that solution so I could go back and find it later if I needed to. I added a couple other formatting options as well that weren't covered in there that were part of the Scana spec, and then packaged that up. So great, now there's a scanf package on Pi Pi, and it's actually pretty widely used. I was surprised to realize that. That's cool. I got an email, you know, a couple about a month ago now, saying, 'Hey, this is a critical package.' So I went looked.It barely squeaks into that category. I think the top one percent was considered critical. I got the Pi Pi message about the news recently. It was at point nine percent. It was barely in there, but yeah, I was like wow. So you're getting a key I guess. Well, I just turned on the two-factor authentication. I was worried about the key if I would lose them or whatever. I already do 2fa with some other stuff and just use an authenticator app, so I figured I can turn that on, no problem. I didn't see it as being too much of a hassle.\n\nOne of the things that a lot of organizations do instead is host the stuff internally. You said there was nothing proprietary within the first couple of libraries that you've put up on Pipi. It just made more sense to not have to think about it. Maybe the organization wouldn't have the infrastructure set up to create their own little solution for hosting packages and so forth, potentially correct.\n\nAt the last company I was at, they were starting to go down that road where they were doing enough internal Python releases of packages. They set up initially using an identify server, which is basically a small local mirror of Pi Pi. You can configure your local pip so that it will first look at your local Dev Pi server before it goes out to the global Pi Pi server. They eventually moved to a solution with the artifactory, which has some plugins for handling Python packaging. My current company doesn't do anything like that, but we're looking at some solutions. I see why you would do that, especially if you want to package up some proprietary code.\n\nYour experience with experimenting and first releases and having to do lots of updates with the tools that we're using, how has your experience been with that? Do you have a solution that you're happy with now? It's been a little difficult getting going at first. The documents were okay at the time, but they've gotten much better since then. There was a recent major update to the whole Python packaging recommendations. I found a template that someone else had used and adopted it for myself, which mostly worked fine for me. I made some notes for myself on what the steps are for me using twine or something to update it. With the changes to pipeproject.toml, I need to start taking a look at that. It's clearly the way of the future, so I'll start looking into that. I'll link to some resources on real python for you.[Music]\n\nThis week, I want to shine a spotlight on another Real Python video course titled \"Building Python Project Documentation with MKDocs.\" The course is based on a Real Python step-by-step project by frequent guest Martin Boyce. In the video course, instructor Darren Jones shows you how to work with MKDocs to produce static pages from markdown, pull in code documentation from docstrings using MKDocs, follow best practices for project documentation, use the material for MKDocs theme to make your documentation look great, and how to host your documentation on GitHub Pages. I think using tools like this can make what seems like a daunting task so much easier, and I think it's a worthy investment in your time to learn how to automate the production of your project's documentation. Your users will truly appreciate it.\n\nReal Python video courses are broken into easily consumable sections and, where needed, include code examples for the technique shown. All lessons have a transcript, including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the enhanced search tool on realpython.com. \n\n[Music]\n\nOne of the things that we talked about at PyCon was that you've been experimenting with prototyping and using CircuitPython for some of the mechanical engineer things, not only for work but also for playing around with it at home. How's that going and what do you think of CircuitPython as a platform? It's fun to play with. I had been reading about it, trying to think about what I want to try this out with and what opportunity do I have. During early COVID when I was working from home a couple of days a week, the room that I made at home has a pellet stove for heat because it gets pretty cold. It's kind of a three-season room. During the winter, though, it'd be getting really cold overnight because we leave the heat off in that room. In the morning, I would come in and turn that pellet stove on, and I was wondering how long does it take this to warm up in the morning and how effectively was the temperature regulated in this room. I mean, come on, that's how engineers think about these things. So I ordered some stuff off Adafruit, got a little itsy bitsy M0 and a temperature sensor and a small OLED screen, made a little breadboard setup that would take the reading of the current temperature and humidity from that sensor, display it on the OLED screen, and produce a little graph of what the temperature had been for the last two hours so I could see as I'm sitting at my desk. It was fun, I really enjoyed doing that, and it was definitely a bit of an adventure. I found that a lot of the functionality I wanted was there in CircuitPython, and I could cobble together something pretty quickly that would at least read the temperature and display it on the screen. But then the graph started getting interesting. There are some rudimentary drawing operations available within CircuitPython, but making a graph which is a bit more complicated didn't exist. So I ended up writing my own little module that would create a graph instead. It was fun to have to think through the logic of how to figure out where the tick marks need to be and how to auto-scale it so it makes sense. Initially, as the temperature in the room is coming up versus once it starts cycling, it was a fun project with CircuitPython.I had enjoyed doing that enough that I went ahead and picked up again from Adafruit. They had the MagTag, which is an ESP32 device that has an e-ink display and Wi-Fi. \n\nMy kids are always asking about the weather for the day. Some of my kids are still young enough that they don't have phones. I thought it would be cool to have a display in the house showing the current temperature and a graph of the temperature and precipitation forecast for the next 24 hours. \n\nI was able to pull that together in CircuitPython as well. It goes over Wi-Fi to the Open Weather website and uses their API for weather forecast information, which is free for the amount I use. My kids actually walk past the display and look at it, similar to having a thermometer outside the window in my childhood home. \n\nThe MagTag has a magnet on the back, making it easy to mount on a fridge or use with magnetic feet. It uses very little power when not updating the e-ink display, making it efficient. \n\nAt work, we use CircuitPython for simple prototypes, controlling solenoids and DC motors. We have multiple controllers for different situations, like a toolbox of options. \n\nPrecision is crucial in our industry, so we often use 3D printing for brackets and prototypes. We also have a machine shop with skilled machinists for more precise parts. \n\nDesigning a part in CAD and then holding the physical part in your hand is like Christmas. It's exciting to see your designs come to life in metal.I feel like we hit a lot of the core ideas that we wanted to touch on. If you want to share a few of the other projects that you've created and put up in PyPI, sure. \n\nI mentioned the scanf module or package, but there's a couple. Probably the one that I use the most at work is somewhat specialized for data processing. I create a graph to visualize what's going on, and then you might want to throw it in an email, chat message, or report. Without this module, you'd have to save it to a file, find the file, and attach it to your email. It's a multi-step process. \n\nA lot of the work I'm doing is interactive, where I generate a graph, make changes, and it's similar to workflows with Jupyter notebooks. I found a solution to copy a figure from matplotlib to the clipboard, which led me to create a package named add copy fig Handler. It simplifies the process and works specifically with matplotlib. \n\nDepending on the platform, you need to use QT or TK as the plotting back end. I use it all the time, and my colleagues do too. It's satisfying to see others find it useful. \n\nI enjoy making tools that make life easier for others. It's satisfying to see them appreciate the solution and save time. \n\nOn PyPI, I have some older projects and a newer one called Canaveral, an application and file launcher. It's one of my more ambitious projects, akin to a spotlight search on Mac or Windows key search. I created it because existing tools didn't work well for me. \n\nIt's all in Python.So it's available on Pipi although I would recommend probably using a tool like pipex to install it. Yeah, we had a whole episode about tools Dad. That's very cool. It's really great. So that's awesome if people are interested in checking it out, they're welcome to. There's like about 10 projects or nine or ten projects up there that people can check out.\n\nI have these weekly questions I thought I would ask you, and the first one is, what are you excited about in the world of Python? The keynote at PyCon about Pi script just blew my socks off. Okay, so cool. Just this year, not audacity but the, I know, it just took a lot to do that kind of a live coding demo that was, yeah, I know, it just really was trying to take on an awful lot and man he nailed it. That got me thinking more about wasm and things that are with webassembly that Pi scripts uses to accomplish what it needs to do. So they started looking into that and then learning more about this to go along with webassembly or wasm. They have this Wazzy, the webassembly systems interface. I think that because webassembly, if you're able to run Python code in the browser, which is sort of where this eventually ties back into, yeah, that is running in a virtual machine in your browser. So if you were able to run that code locally, you would still be running a Universal machine that doesn't have any way of talking to the rest of your assistant resources like your file system, sort of in a sandbox. So there's this other standard that they're working on called the webassembly systems interface, and that then is the appropriate interface for webassembly to talk to other resources on your local machine. That's sort of cool. If you combine all these together with something high dyed, maybe this starts to become a lot of potential as being a way of being able to distribute Python applications. Yeah, in your field would need that kind of connectivity. I don't, you know, it's not necessarily that that's a professional thing that I care about, but just, I'm really excited to see where that goes, just because I have tried to make some small utilities again, whether it's personal or professional, to distribute and use, you know, Py2app or Py2xc, Py installer, and they can work, they have their limitations in various places, but being able to do something that's even cross-platform through this webassembly, that sounds really intriguing to me. So I'm very curious to see what happens with that. Yeah, I haven't heard of that. I'm definitely gonna find some links and connect that stuff up, awesome.\n\nWhat's something that you want to learn next? In this case, it doesn't have to be Python, it could be whatever. I've got a number of ideas for little projects, I'm sure that'll be surprising given that, but in particular, you know, I mentioned we've got these boards at work that we use circuit Python to control higher power loads here. So you've got your feather or whatever that just has a 3.3-volt logic output on it, but you want to be able to switch some, say, a 24-volt Power signal coming from somewhere else, whether that's with solid-state relays or FETs or whatever. We've kind of had to make just hand-soldered some custom circuits for doing that in these cases, but I have a number of places where those would be kind of handy, whether that's at work or in hobby uses where you want to turn solenoids on and off or something and a little DC motors. I haven't really found any good solutions for that that are sort of pre-packaged. You know, I want something that I can either is packaged as like a feather Wing that I can drop on top of one of these feathers from Adafruit or a hat that I can put on top of a Raspberry Pi, and the solutions I see are either ones that only handle maybe one or even two outputs or they're really expensive and they're aimed at like OEM customers because you're trying to make you actually integrate this into a real product and they're 100 bucks or something. So I want to learn how to use like a PCB layout tool like kicad or something and be able to design like a nice compact board that can handle, I don't know, four to eight outputs or something that just has nice connectors you can just plug a solenoid in and then control it with the PWM output of your microcontroller using circuit Python. I think that'd be really slick and would be something that a lot of people could use in different situations. I had her on really early in the show, Thea Flowers, Star Girl, she is really deep in kicad now and doing lots of interesting stuff. So I'd definitely check her blog out. I know she had like resources for learning more about it, but that has been one of those things where I fooled around with soldering guitar pedals and other things together and so forth.I've thought about the same thing, like man, I really would like to because. I think I mentioned this on the previous show, but the idea of manufacturing anything used to be like you have to make a thousand, and it's going to be insane. I'm thinking of the days of creating CDs or DVDs or whatever. Yes, and the idea that you can just one off two off circuit boards, it's like insane to me. I bought kits to etch my own boards, and it was just this biohazard situation of creating all this stuff, and then how am I going to dispose of this? The idea of just in the tens of dollars making these is amazing.\n\nSo yeah, that's what I want to learn how to do. It's totally outside my comfort zone. I've hand soldered stuff before, made little circuits, but this would require me to learn how some of these specific circuits would really need to be made, and then due to layout, that's a whole new area for me. And you can do double-sided boards and all the graphics. It's amazing. Cool. \n\nSo how can people follow the work that you do? Well, they're welcome to check out my GitHub profile or my IPI profile. There's not much going on in Pypi, but definitely GitHub. It has links to all these different things we've been talking about today, including links to those. And if they want to hook up professionally, then look me up on LinkedIn, okay.\n\nJosh, thanks so much for coming on the show. It's been really fantastic to talk to you. This has been great. I've been listening to the show for a long time, so long-time listener, first-time caller. Absolutely cool. Thanks, thank you very much.\n\nAnd don't forget, Deepgram is the preferred speech to text API of Python developers. Get accurate transcripts from any audio with features for understanding. Try it by transcribing 200 hours free at deepgram.com. Real Python wants to thank Josh Burnett for coming on the show this week. And I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player. If you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey. I look forward to talking to you soon.",
    "HeuiKKSuJh8": "Welcome to the Real Python Podcast. This is Episode 129. Where should you use an ellipsis in Python? How does it behave as a placeholder in a script project or stub file? What are the next goals for the faster C Python project? This week on the show, Christopher Trudeau is here bringing another batch of Pi Coders weekly articles and projects. We talk about a Real Python article that covers when you should use an ellipsis in Python. We discussed the similarities with the pass keyword and how it's used for type hints within stub files. Christopher shares resources covering the goals of the faster C Python project. We're on the cusp of the release of Python 3.11, but the project keeps moving forward as they look at ways to continue speeding up Python. We share several other articles and projects from the Python community, including a news roundup, hosting alternatives for Python-based applications, creating custom Python strings, a discussion about aging programmers, creating a structural diff that understands syntax, and a project for refurbishing and modernizing Python code bases. This episode is sponsored by InfluxDB. InfluxDB time series platform is built to handle the massive volumes of time series data produced by sensors, apps, and systems. Are you building real-time applications? Check it out at influxdata.com. \n\nAlright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Christopher, welcome back. Glad to be here. We have a couple little short news items to kind of begin with. We're going to have a nice good discussion that's very near and dear to our hearts, I guess.\n\nSo our old failing hearts. Spoilers, yeah, exactly. That's right. So the first little chunk of news is there's been a security release for Django, so 4.1.2, 4.0.8, and 3.2.16. It resolves a potential denial of service attack with internationalized URLs. So get your fixes out there before you end up in trouble. And then the second piece of news is a new PEP has surfaced. It's PEP 698, called \"override decorator for static typing.\" The idea here is to provide a decorator that is a type hint for methods in a child class that override their parent's method. If this gets accepted, tools like MyPy or your IDE will be able to warn you if there's an incompatible change between the child and parent. So say you renamed a parent's method but forgot to rename the child method that was overriding it. That would normally only ever show up at runtime when you tried to call Super. With this decorator, the typing tools will be able to warn you about the mistake. It'll be interesting to see if it gets accepted. It's funny how many little pieces of typing and enhancements keep building up every release. Yeah, we'll talk more about that next week with 3.11. Yeah, definitely. \n\nThat breaks us into our topics this week, and the first one was, I guess, kind of a news one, but it's an article written after the news kind of broke. People might be aware that Heroku has changed their pricing plan. They have had a free tier for a long time and they're discontinuing that. Heroku as an organization is owned by Salesforce. I don't know if they're pushing it one way or the other, but one of the things about that is a lot of tutorials, even some of Real Python's own tutorials, have been written with the idea that you should be able to just pop that into a free tier plan. This article is addressing it. It's titled \"Heroku Alternatives for Python-Based Applications\" by Nick Thomasic on testdriven.io. I think it's a really well-done survey of these things. It actually dives a little deeper into what Heroku is and what its specialty was at first. I have liked using Heroku, especially in the tutorial space, because it didn't really require you to get too deep into the DevOps part, which is very nice. It also has a very handy integration with Git, leveraging git commits, being able to watch when you commit something new that it will just version and redeploy and do a lot of the CI/CD kind of stuff for you, which is really nice. And I guess that kind of defines it differently. It's a Platform as a Service (PaaS) versus some of the other things that are out there where you have to provision your own virtual machine, work on the networking, deal with all the other kinds of little things that are really not Python-specific. That's, I think, partly why a lot of tutorials use tools like it to point to. Heroku is great. It's a great service, and people should pay for things, but I totally understand tutorials not wanting to require an investment to get into it.Another note, real Python is hosted on Heroku and it has done really well for us. One thing in this pro and con list that he starts with Heroku, he mentions multiple pros that I've already listed. Its popularity is one of its pros, and its ability to do a lot of scaling for you either vertically or horizontally. It is very dashboard-based where you have a hand on some of the controls, but a lot of it is happening for you behind the scenes, which a lot of people would prefer. It offers more ability to look at the status of things and understand what's happening, so I can see that as a pro and a con. Another real pro is it comes with a very nice CLI that you can install and just do this sort of git commit kind of stuff right from your command line. Pricing is higher partly because it is more of a platform as a service. It is a little lacking in some regions. If you're looking for alternatives, this provides you with pros and cons, mostly leaning towards the platform as a service kind of thing for people who are less interested in becoming a devops pro and more focused on hosting their Python project or Python-based application.\n\nThe first one he gets into after that is DigitalOcean's app platform, which you might have heard ads for. It has a very simple free plan that lets you host like three static sites, but most of the services are charged. It has integrated CI/CD, which works with GitHub and GitLab. He mentions a service called Render, which launched in 2019 and includes Postgres databases. It is great for beginners and has a free tier. Fly.io is another one he mentions. One that is a recent sponsor of our show is Platform.sh, which is known as a platform as a service. It is geared towards bigger organizations, with not much of a free tier. It has a lot more features built into it and is focused on scaling production up.\n\nHe mentions Google App Engine and AWS Elastic Beanstock, which are application-based types of services. Microsoft Azure App Service is also mentioned. PythonAnywhere is a great service for doing simple stuff, like the Django Girls tutorial. It is an online integrated development environment and web hosting service all in one. It has a simple free hosting for one small project. Railway.app, Netlify, and Engine Yard are also mentioned. Opal Stack is a company he frequently works with, which requires a little more devops knowledge.If anybody was to remember the web faction days, there is also another little boutique place created by many of the same people. Web Faction got bought by GoDaddy, and a bunch of them struck out on their own and created Opal Stack. It's not quite platform as a service, which I kind of like. I understand the pros and cons of both. You can SSH to the box and have full access to things, but there is also a dashboard through the web. \n\nFor certain kinds of packages, like Django, you essentially just go in and say, \"I would like a new Django instance, please.\" It creates all the necessary stuff in a directory, and you essentially overwrite the sample directory they give you with your Django folder and reboot, and you're ready to go. It's a bit like a template system, essentially a cookie-cutter style mechanism that preps a bunch of things for you.\n\nI like it personally because it gives me the flexibility to touch the Linux box when needed, but I'm not setting all the servers up by hand. They have a hosted Postgres instance for larger clients worried about the database, and for smaller clients, it stays as a SQLite file inside the operating system. It gives you a fair amount of choice that way, but it doesn't scale for you beyond a virtual instance.\n\nI do a lot of work with customers who are happy with a thousand hits a month. AWS tends to be overkill for that kind of stuff. I recently did a tutorial review of something coming out soon where I needed to walk through setting up AWS. I haven't played with it in about three and a half years because I haven't needed to in my current position.\n\nSetting it up wasn't like riding a bike, but I was able to accomplish it in an afternoon and get everything set up and running. I can see the advantages of platform as a service where I can maintain being a programmer and have a lot of the background stuff taken care of. Having a template with most things already configured is helpful compared to raw configuration.\n\nThere are lots of choices to look through, and they have a nice spectrum for what you might be searching for. \n\nThe first article this week is called \"Python 3.12 Goals: Faster Python Ideas.\" We're right on the cusp of 3.11 being released, so I'm going to skip that altogether and start talking about 3.12. This article, or posting on GitHub, is connected to the Faster Python project and discusses the performance goals for 3.12.So, in Python 3.11, we're going to talk about a new feature called Adaptive op code specialization. This fancy term refers to inline replacement of certain parts of the byte code to improve performance. For example, if you have a loop that operates on floats, Python 3.11 can optimize it by replacing the generic multiply operation with a float-specific one, making your code more efficient. This optimization is done for operations that are frequently visited in tight loops or frequently called functions.\n\nIn Python 3.12, they plan to build on this concept by breaking down byte code operations into smaller intrinsic parts. This will allow for more optimization opportunities and make it easier to implement just-in-time compilation. This idea is similar to what happened in processors a couple of decades ago, where assembly instructions were broken down into micro instructions for better optimization and pipelining.\n\nThe next focus is on improving parallelism by moving the Global Interpreter Lock (GIL) into sub-interpreters. This will allow C extensions to have their own lock, reducing the impact on other extensions and enabling more parts of the system to run in parallel. They are also looking into optimizing the size of key data structures to reduce memory footprint and improve performance.\n\nIn Python 3.11, they have already made improvements in exception handling, which resulted in a memory reduction of 240 bytes per function call. While this may seem insignificant, it can lead to faster function calls and better CPU utilization. By continuing to shrink memory usage, they aim to further enhance performance.\n\nOverall, these optimizations are a result of ongoing discussions and collaborations within the Python community. It's exciting to see the progress being made and the potential for a faster CPython project. The support from Microsoft has also played a significant role in driving these advancements. If you're interested in more details, you can check out the related links and a post from Guido on how to implement these improvements effectively.\n\nAs we look ahead to 2023, it's evident that these ideas and innovations stem from shared interests and contributions from various individuals. The evolution of Python, with features like just-in-time compilers and sub-interpreters, showcases the dedication to enhancing performance and efficiency. It's fascinating to witness these developments unfold and see how they translate into tangible improvements in the Python ecosystem.If we keep speeding up, we'll be able to read into the future. Your answer will be fantastic. The curve will eventually flatten off, but we're still making progress. Truly, that's good.\n\nTime series data runs in almost every technology. Building real-time apps in legacy databases can be a nightmare to manage. InfluxData, creator of the time series data platform InfluxDB, built their platform with tools so developers don't have to make wholesale changes to their product or application. InfluxDB is optimized for developer productivity, allowing developers to build IoT analytics and cloud applications quickly and at scale. Check it out and start for free today at influxdata.com.\n\nMy next topic is a short article on Real Python that turned out to be interesting. The article, written by Philip, is titled \"When do you use an ellipsis in Python?\" An ellipsis is the three dots you sometimes see in a Python script or in type hints. An ellipsis indicates that something is being left out. I use ellipses a lot in my text, almost as a form of humor. I use it to imply a continuation of a story. \n\nI learned that the ellipsis is also written as an actual constant, \"Ellipsis,\" with a capital E. In Python, you can use it as a comparator, and it will return true.\n\nThe article goes through three main uses of ellipses in Python. The most common use I've seen is as a placeholder in code sharing, especially for proprietary code within an organization. It serves as a placeholder for code that would run but doesn't include the actual body.\n\nEllipses are also used in type checking, mainly in stubs like typeshed. This is a way to define functions with annotations for parameters and return types, while using ellipses in the function body to indicate that something will happen there. It's a neat way to define these things.\n\nAnother use of ellipses is in specifying variable length tuples with homogeneous types. For example, \"int, ...\" indicates a variable length tuple of integers.Okay, it could be one or seven instances or something like that that could be sent into this function. The article goes a little deeper into that stuff and kind of shows it. What's interesting is I looked around at other languages, and it seems to be a fairly common use. I think JavaScript uses something similar in some cases to show a list of arguments potentially inside of a callable. \n\nHe gives one other use that I won't go into the details of, but this is another use I've seen in a couple of other languages, specifically in NumPy. He's talking about how it could be used to do a form of slicing, tearing into some kind of matrix of things and pulling everything up to a certain point. You can get into the details of the article to learn more about that if you are interested in that shorthand of that operator. \n\nI had a question for you. There's one last thing that you might have seen, which is like an unrepl. As you hit return if you're not completed in a line, it provides a dot dot dot automatically, but it's just really a secondary prompt allowing you to write out a function inside of a REPL type environment or when completing something along with it indicating a spread of things. \n\nI've seen something like this in bash where it could be used to do all the numbers in between say one and nine. You could do one comma dot dot dot comma nine, which is kind of interesting. I've seen that in some other languages. Are there other uses in JavaScript or just the one I'm thinking of? It's not an operator; it's one of the newer items in JavaScript. \n\nI still don't do a lot of ES6, so I don't know when they introduced it. I've seen it kicking around, but as far as I'm aware, I think it's just there for a variable number of arguments. It seems to be common in lots of languages that way. \n\nIt's one of these things that I have been intrigued by over the last three to four years of using Python. I see it more and more where I was just seeing pass in its place for a function definition, and now we have a couple of different new uses in the case of type hints and stuff. So yeah, it's a nice little article diving into the concept of it and when and where you would use it, growing a lot of people's familiarity with it. I always forget it's there; I still use pass. I'm learning it; it'll save me a keystroke, but I always forget it's there. \n\nAlright, so what do you got next? This is a Real Python article called Custom Python Strings Inheriting from Str. So last few episodes, I've been talking about my own courses, and this week I promise I'm not doing that. Of course, now I'm talking about a Lia Donna's article because what else is there, yeah. \n\nI don't know if he intended it, but this article is kind of a little sneaky. Nominally, it's about writing custom features for strings and how you can override them, but it ends up being an accidental tutorial on object-oriented ideas in Python and how it all fits together. It starts out showing you how to write your string class that has a word count method. So you inherit from the Str object and add a new method that counts words on the internal string. \n\nThe next step is to attempt to write a new string class that automatically returns whatever you constructed it with into lowercase. He walks you through what you might think is the first logical approach, overloading __init__ like you usually do with classes, but it fails. You can't do this; it results in an exception because in Python, strings are immutable. \n\nTo get around this, you have to do something a little deeper, using __new__ instead of __init.This is what I mean by sneaky. You just learned a little more about how objects are constructed in Python. Every once in a while, I come across somebody who gets cranky with me when I call Dunder init a Constructor because Python is not my first coding language. My vocabulary from other languages tends to leak through once in a while. These finicky people are technically correct, which is the best kind of correct. Futurama shout out. They are technically correct because Dunder new is actually the Constructor, whereas Dunder init is where you initialize your variables. Other object-oriented languages don't make this distinction, hence why old people like me say Constructor.\n\nMinutes ago, I mentioned inheriting from Str versus user string. Python has another way of building string-like things, the user string object found in the collections module. User string is a wrapper class to the Str data type. You can build on top of it by overloading the Dunder init method. Essentially, you can do that if you're inheriting from user string instead of from Str.\n\nThe rest of the article walks you through how to modify a whack of Dunder methods to make a string class behave as if it were mutable. So, not only do you have a better understanding of these string-like things, but you also learn how Constructors really work and some mutation methods like Dunder set item and Dunder delete item.\n\nI've been learning a lot about this stuff lately. There are some really good insights in here. I like the example where you try it out, and it blows up in your face. It's an interesting conceptual thing that you don't see in a lot of languages. It's one of the weird little corner cases of Python. That takes us into our discussion this week, which started with an aging programmer on a Hacker News thread. It's interesting to see different perspectives on aging in the programming industry and the challenges that come with it.But there's also it was very difficult to learn anything about computers without understanding the hardware when I started out because you were operating at that level. When I talk to younger folks, it always surprises me that they've just abstracted it away. Part of me, because it's the way I learned, I'm sure the first people who said, \"Yeah, we don't need to teach Latin in school,\" all when wait, but that's how you teach language, right?\n\nI might kind of be on both sides of it. I think there's value in understanding those things and I think there's reasons why some programs blow up because hey, you ran out of memory and that used to be a thing you had to think about all the time. So I think there's definitely, it's not just age. I think what we've been exposed to and what your first programming language is all influence you over your career.\n\nThat I thought was kind of interesting. Some of it has changed over time as well. Like I'm just as bad as everybody else when it comes to copying and pasting from Stack Overflow and Google answers and all the rest of it. None of that existed when I started, and I suspect that part of my brain that used to have to figure it out for myself is atrophied. Because right, some of that, although there's a generational change, some of us who've been through it have changed with it as well.\n\nI have a weird path. I've probably ad nauseum talked about it on here, but I started very early programming in BASIC and so forth at home. Then went to college and did Fortran and C for a little bit, and then really disappeared completely. Coming back into programming because I always was very interested in it and then diving really deep into lots of languages all at once. So I feel like I jumped in the pool late in life. I am a person who is very interested in constantly learning, but I don't think it matters what age you are as far as that sort of eagerness to learn, which I think is like probably the biggest factor that I always emphasize on here.\n\nDefinitely I'll talk about it again next week with Pablo. We actually kind of went into a nice additional conversation after we talked about memory, seeing that inside a team or a potential employee, this idea of eagerness to learn. Because it is going to be constantly changing, and that is something that I think a lot of people who look at somebody who's an older programmer and think, \"Oh well, they're going to be set in their ways.\" I think that really just depends on the person, and if they've lasted this long in the industry, potentially they're really interested in change and have learned lots of ways of going about it. But it totally depends on the person.\n\nIt's also a balancing act as well, right? So you would hope that with experience, you know when to use the new shiny thing and when not to. There's always that conversation of which side of that am I on? Why am I saying we should use this tool because it actually is a good choice and we're going to get bit if we do something else, or am I saying that because I don't want to learn. There's almost a psychology aspect to it that's hard to suss out.\n\nAnd then there's these interesting junior-senior Dev kind of things in there. All these kids today, they just need to slow down. I'll remove the X frantically copying and pasting and watching them Google stuff and pasting stuff in, and then just like, \"Oh wow, that didn't work,\" and then they don't completely remove it and go on. I think of that when I think of potentially these additional new tools beyond the internet that kind of came in between. What is an older programmer going to be doing but looking at code that's been auto-generated and does this actually compile and run and whatever, which is kind of intriguing to think about. Like I think that's always a problem.It depends on where people are coming from. One of the things they talked about is moving from job to job and building connections and a network. I've mentioned how that has worked well for me. Others have mentioned my ability to learn and be cherry-picked for interesting projects.\n\nPreparing for interviews and exams is important. Some people struggle with simple coding tasks like FizzBuzz. Hiring processes vary, with coding tests and whiteboard interviews being common. I prefer design conversations to assess problem-solving skills.\n\nInterns and co-ops have a different bar compared to senior developers. The industry is a bubble, unlike construction or retail. Ageism is an issue, but increasing contract prices can be a solution. Certificates and portfolios are important, as well as open-source contributions.\n\nNo other industry values these aspects like programming does.But they then said, \"well actually I think that counts against you in certain things.\" I was like, \"ah right, because that means that I don't know what it means exactly what they're thinking behind it, but potentially that you do have other options or that you're going to be working outside or what have you.\"\n\nI love to look at somebody's GitHub profile because it means I can actually see what their real code is like. If you're starting out in the industry and you don't have experience, that's great. If you truly believe in contributing and you get to do that, that's fantastic.\n\nBut we are no other industry. The bricklayers don't come along and go, \"so, how much bricklaying do you do in your spare time?\" It's totally like, I understand. I built a barbecue. I understand the desire of the question because it implies that you're passionate about it, but people need to have lives as well.\n\nI wonder about the influence of the startup culture. Yeah, you should be giving how many hundreds of hours or whatever, and I just think I'm seeing that dissolve a little bit potentially. At least it's being exposed in some of the circles that I watch. I'm kind of maintaining a look at it. Maybe the pandemic is part of it, like people kind of realize, \"Am I burning myself out by overachieving?\"\n\nI honestly think it goes far deeper than that. At risk of sounding like an old man, the Next Generation down seems to have a better idea of what this looks like. Millennials seem to have a far stronger grasp on work-life balance than say Gen X ever did. Which is funny because we're supposed to be the slacker generation, so you'd think it would have been us. But yeah, it is what it is, too funny.\n\nWell, we'll leave that as an open thing because we're old. You can always come back and talk about it.\n\nThis week I want to shine a spotlight on another Real Python video course. It dives further into a topic that we touch on this week. It's titled \"Providing Multiple Constructors in Your Python Classes.\" The course is based on a Real Python article by Leat Eposa Ramos, and in the video course, instructor Darren Jones shows you how to use optional arguments and type checking to simulate multiple constructors. You also get a peek under the hood at how Python internally constructs instances of a regular class and how some standard library classes provide multiple constructors.\n\nHaving the tools to provide multiple constructors will help you write flexible classes that you can adapt to changing needs. Real Python video courses are broken into easily consumable sections and include code examples for the technique shown. All lessons have a transcript and include closed captions. Check out the video course in the show notes or using the enhanced search tool on realpython.com.\n\nLet's dive into projects. What did you bring this week?\n\nSure, so this one I was looking at a tool called Difftastic. Technically not a Python tool, but a tool that supports Python. Difftastic gives you diff information on code with the added benefit that it actually understands the code. It understands over 30 different programming languages, and Python is one of them. You end up with far more useful diffs because it's actually diffing code trees rather than just line by line.\n\nI just finished recording the course on the new features in Python 3.11. Part of that course shows off a new concept inside of async IO called the task group. In order to explain how that works, I had some 3.10 code and some 3.11 code that uses the new feature. When I run a diff on those scripts, if a regular diff would basically just say, \"hey all these lines have changed,\" Difftastic says, \"oh you seem to be using the same Factory here and this part and this part are different base objects, but the function that you're passing into the factory is the same.\"\n\nSo you're seeing things far more specific to how Python actually works, signposting there as opposed to just different. If you think of a simple use case like an if statement, a regular diff would highlight both of those lines because you've added a continuation character and a new clause. Difftastic would actually say, \"oh, this line is the same and you've added the clause,\" and highlight the difference character rather than saying the lines are different.So, there's some interesting kind of highlighting to this and a different way of looking at your code. It automatically detects what language you're processing, but it also supports a --language flag in case whatever you're feeding it isn't compatible. It can compare files as well as directories just like a regular diff and has some fine-grained arguments for highlighting how you change the code and how it incorporates. So, if you're plugging it into an IDE or into git or one of those other tools that integrate with diff, it supports that. The core coder is a gentleman named Wilford Hughes, but there are like 230 contributors, so there's a lot of activity going on. They were updating even just a couple of weeks ago. This might help you find out what's changed in your code or be able to look at your code in a different way from before, so it's another useful tool for your toolkit.\n\nFollowing the theme, mine is a project called \"refurbish\" which aims to refurbish and modernize your Python code bases. It's by a GitHub user named Dosa Dosey (sod), a nice palindrome there. His name is Luke and it's a tool for refurbishing and modernizing Python code bases. It looks at things that have changed in the language to make it more elegant and work smoother and more modern. For example, using pathlib and simplifying code with certain statements. It's not purely a linter or a refactoring tool, but it focuses on modernizing Python code bases.\n\nIt has nice CLI flags that can show you why suggestions are made. For example, suggesting not to cast a variable during assignment in Python. It also has a flag for ignoring certain types of errors and can be set up in a pre-commit way. It's a neat little package called \"refurb\" with interesting features. It was found through a Hacker News conversation with mixed opinions on whether it should be used in a CI/CD scenario due to its opinionated suggestions. It runs in Python 3.10 but can analyze code written in Python 3.6 and up. The underlying implementation uses the new match mechanism.So there's another reason to go looking at this if you want to see a real use case for that new match feature. This refurb refurbs a code base that you can take a look at. Yeah, I think it would have been handy to have a tool like this, particularly as you were saying, going from Python 2.7 to Python 3 because it highlights exactly, \"Hey, we've got a better way of doing that now,\" right? If you're touching older code bases or if you're trying to clean something up, or if you're trying to drop something that's been kicking around since 3.1 and you're trying to drop your 3.2, 3.3, 3.6 support because all that's dead now, running a tool like this could also result in the removal of certain kinds of imports and things as well as getting rid of the older stuff.\n\nAlright, well thanks again for bringing all these Pi coders articles and projects, Christopher. Always fun to talk to you. Soon, and don't forget InfluxDB time series platform is available in the cloud or on-premises. Get started for free today at influxdata.com.\n\nI want to thank Christopher Trudeau for coming on the show again this week, and I want to thank you for listening to the Real Python Podcast. Make sure you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey, and I look forward to talking to you soon.",
    "NFrbbOf-_2U": "Welcome to the Real Python Podcast. This is episode 130. Does your company have a plan for growing an internal Python community? What are the attributes to look for when bringing someone new into your department? This week on the show, Pablo Glendo Salgado returns to talk about the Python Guild within Bloomberg and managing the release of Python 3.11.\n\nPablo describes how the Python Guild started and currently operates inside Bloomberg. We talk about how it fosters community and acts as a way to promote internally developed tools with disparate teams. We also discuss how work groups use it to find new internal candidates for their teams. Pablo talks about his role as release manager for Python 3.10 and 3.11. He shares the intense journey the team has had this year preparing for the release of 3.11. He details updating testing strategies to work with the new specializing adaptive interpreter.\n\nThis episode is sponsored by Platform SH. Discover an alternative to DIY for your web fleet and all the stacks it contains on a single stable platform. Find us at platform.sh.\n\nAlright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Pablo, welcome back to the show. Thank you very much for inviting me again. It's a pleasure to be here as always. It's awesome. We were just recently talking about memory and I had a whole bunch of additional questions I wanted to ask you. Instead of making it like a two-hour episode, I thought maybe we could break it apart a little bit.\n\nOne of the things I wanted to ask about that actually came up in this Bloomberg blog post that was about memory with a mentioning of an internal Python Guild inside of Bloomberg. I thought that was really fascinating. Maybe you could tell me a little bit about that. Is it still going on?\n\nYeah, it is actually part of a bigger program that we have called The Guild program. The idea here is that when you have a big company, like we are not as big as maybe Google or Amazon or Microsoft, but we are quite big with around 8,000 developers and even more people in other departments. What happened here is that big departments like infrastructure and application developers start to not communicate a lot between themselves. Teams are super different from one another, so communicating these changes can be challenging.\n\nTeams can choose their code style and use or not the tools provided by infrastructure. They can even use different languages like Rust, even though we don't have a team in software infrastructure that cares about Rust. People have been using every single language, but they are on their own if they choose a language not supported by the infrastructure. It's a complicated problem to evangelize tools and solutions across different teams.We would like you to use this thing is very hard for evangelization. The U.S. has a hard problem moving knowledge from infrastructure teams to application teams. It was a hard problem because knowledge was not being moved, and people were not using solutions that were developed at a high cost. So, they decided to create the Champs program. The Champs are representatives between infrastructure teams that communicate changes to application teams.\n\nThese representatives go to meetings to discuss new changes or removals, and then relay that information to their teams. This communication method worked well, but there was also a sense of community missing. It seemed like there was a third actor in the model, hinting at the importance of community.\n\nThe idea of guilds started a long time ago. Guilds are groups of people who talk about specific domains, like Python, testing, infrastructure, and machine learning. It's like an open-source community within the company, focusing on how to use certain technologies rather than what is supported or not.\n\nGuilds not only discuss but also work on tools together. For example, if there is a tool that infrastructure does not support but many people want, guilds can coordinate to develop it. This inner source ripple is a collaborative effort owned by everyone in the company, leading to code development that is not just team-centric but involves multiple teams for various reasons. It's like open-source but within the company.Sounds super collaborative in a neat way that people can ask specific questions. It's a different methodology where people of all skill levels have a common goal inside the main company. The interesting thing here is that it's not only about code. For instance, Guild members go to conferences like PyCon or EuroPython and then share what they saw with everyone. There's also a mentoring program for people who want to learn more about Python and get more involved in how Python is made.\n\nGoing deeper into big company culture, it's important to grow technically in your role without jumping into a management role. Companies have different names for technical growth positions like fellow engineer or staff engineer. As you move up the ladder, you need to have a bigger scope of impact, from your team to the whole company and even outside the company. \n\nFinding opportunities to have impact outside your team is not easy. The Guild program allows people to spend company time working on community programs and tools that benefit the whole company. This allows for technical growth and collaboration with people outside your team. It's a way to have an impact beyond your immediate responsibilities without working extra hours.\n\nThe Guild program also allows for working closely with people who share similar interests but are at different skill levels. This cross-pollination of knowledge is valuable for learning and growing technically. Even people in departments like Global Data who primarily use Excel can benefit from learning Python and connecting with others in The Guild. It's about learning from people who can teach you different things and sharing knowledge with others.But it's also about expanding your network and learning about what others are doing. Maybe you start collaborating with someone on a tool that you like, and then you work with them and become interested in what they do. You may even consider joining their team in the future, which is beneficial within an organization. Many people may think about leaving their current team or company if they are not happy, but that may not always be the best decision for the company or for themselves.\n\nMoving within the company is not a final solution or a silver bullet, but it does have advantages. It allows you to understand how things work before joining a new team, which is not always possible from an external perspective. It also enables people to work together, learn from each other, and potentially make a bigger impact.\n\nFor example, in the Python infrastructure team I work on, most members came from The Guild. We hired individuals who were passionate about Python and were actively contributing to the community. This approach not only helped us find skilled individuals but also highlighted their talents within the company.\n\nOverall, moving within the company can be a good way to discover new opportunities and showcase your abilities. It allows for a deeper understanding of different teams and projects, ultimately benefiting both the individual and the organization.So, do you only consider people that you know? But in a big company, that may be a big error. These guilds are super great because they highlight a lot of individuals that otherwise will not have been put in the spot enough. It will give a lot of opportunities for people to be noticed, to move to teams that are closer to the things that they like.\n\n[Music]\n\nPlatform.sh provides the cloud-based solution you need, which allows you to manage, update, and optimize your website and/or online application fleet with our secure, unified, enterprise-grade platform designed for effective building, running, and scaling of web applications. We are the leader in web fleet management. Are you ready to join the Platform.sh community and optimize your fleet operations? There's no time like the present. Find us at platform.sh.\n\n[Music]\n\nOne of the things I think about is a common refrain that I often see. The culture for computer science generally is like, \"Oh my God, you gotta prepare for interviews and so forth, and you have to know that they're gonna ask you all these specific things.\" Yes, there are positions that are very much like that, and yes, you need to know what you want. But often things happen internally inside of an organization. In order for that to happen, it would be nice to know the people that are eager to learn, that are interested in learning new things, that are passionate and improving their skills. Someone who seeks out something like that, they see, \"Oh hey, there's this thing called the Python Guild, and I've heard about Python. I want to learn more about it.\" They join it. You see the spark in them. That's such an immediate thing. Like, \"Oh my gosh, this person can do this thing, is interested in it.\" And they don't maybe have all the skills, but they're at least interested in learning them well. And that, I cannot put enough emphasis on how important that is. The eagerness is such an important resource. I talk with a lot of people, I mentor a lot of people who want to be in the CPython team, that they want to eventually be core developers. A bunch of the new core developers have been people that I have been mentoring over these years. Not exclusively, but I have a bunch of peeps there, and Bloomberg the same. And one of the topics that happens a lot in these conversations with the mentees is that they elevate certain people to incredible pedestals when they say, \"Wow, these people are super smart.\" I always say, \"You could be as smart as these people.\" What happened is that because maybe they admire them, or maybe these people have created something that is very popular, and they think that it's already a genius, I wish I could create this. The reality of the situation is that none of these people really are especially in any way. They are very talented and smart people, but this is not something that, \"Okay, you are talented and smart.\" Actually, what happened is that these people have put a lot of effort into learning the things and skills, and have submerged themselves into the topics in such a way and with enough passion that they have reached these levels. And also, there's a bunch of luck involved that is also important to understand, timing, all that stuff. But the most important thing here and what will put you in those positions that you want to be, if you admire these people, faster, is the eagerness to learn and the excitement. This is such an important thing in open source and in companies. In companies, I would say it's even more important. I would prefer one million times a person who knows almost nothing about Python, but is eager to learn, excited, absorbs information fast, knows what he wants to do, and brings this energy to learning and to the job, than a person who is a super expert but is kind of like a meh. How do you steer that person? It's so fast. This happens to me a lot. I'm a very energetic person. I'm quite introverted in real life, but when I'm across people that I'm comfortable with, I'm very energetic. Sometimes I'm like, for instance, we come from this episode talking about memory. So when I had the first prototype about memory, I came to one of our meetings, and I was super excited about this. It was just a prototype which is printing a bunch of things, and objectively not that cool. If you're very into memory profilers, you will say that it was cool. It's not the kind of thing that you show to your friend, and he will say, \"Wow, man, this is awesome.\" They will say, \"Okay, yeah.\"It's like music, the same thing. If you know another guitarist and you trust them at a certain level, and you can play a couple parts of a song, it's something that if you were to play it to your family, they're going to be like, \"Okay.\" And you're like, \"No, this thing is so cool.\" Yeah, that's a very good competition, actually.\n\nSo, one thing that happened is that people in my team were super excited about that and they reacted like in those videos when magicians go to the street and do street magic, and people are amazed. Some of them may be fake, but some are genuine. When people really like that, wow, this is awesome and this gives you energy.\n\nWhen people in your team or company not only recognize your work but are excited about what you do, it's important. Bringing energy to the team is such an important thing, especially with juniors and people starting in companies.\n\nBringing energy to the team is probably more important than bringing technical expertise because many people join companies thinking they are super confident and smart, but being super enthusiastic and eager to learn is more successful.\n\nWhen you think you know a lot, it's harder to absorb information because you need to admit you don't know much. It's uncomfortable to admit when you are seen as the expert, but being willing to admit when you don't know something is important for growth.\n\nI love to be wrong on things that I'm very confident about because it means there are aspects of things I love that I can learn and grow from. One of the sensations I love the most is when a concept clicks in your mind after struggling with it.\n\nIn computer science, this happens when debugging something and realizing something you thought was impossible is happening.And when finally understanding what is going on, you can incorporate that extra knowledge into your pool of knowledge. That is such an incredible sensation. Approach problems from this point of view when saying, \"I'm an expert.\" Like you're missing so many things. So, my best advice if you are joining a new company or thinking about learning more Python, be enthusiastic, be open to learn, and be hungry to learn. Go closer to the people that know and absorb as much as you can. Don't put those people on a pedestal because teachers are good at teaching you things in a way that you can understand, not because they know a lot. That is an important distinction. So, that would be my biggest advice, which I think is more valuable for everyone in teams to be enthusiastic, even if you're not a junior.\n\nI was really impressed by the whole thing, intrigued by it, and it wasn't exactly what I thought it was. I thought everything was going to be more like a user group or a meetup, but it sounds like a much more interesting kind of structural thing that you've built inside. There are also meetups, for instance, we do conferences, that is the structure we have. Especially now, we have been through a bunch of cycles over how to organize it. We started being a member organization where you either are in the guild or you are not in the guild. We had trials where you could enter the guild if you're good enough that we abandoned quickly enough, I think because not only did it feel a bit exclusionary, but also weird. It felt like an exclusive club that even affected your evaluation. So, we abandoned that.\n\nWe have moved to this other model where instead of having members and whatnot, our idea is that everyone is in the guild. There are group leaders, which is different work groups within the guild. Each work group has an organizer who is in charge of making the meetings happen and organizing the work. There is also a chair who does administrative tasks for the whole group. For example, the chair sends an email at the end of the year to managers, highlighting the contributions of individuals to the guild. This person ensures that all contributions, whether by goal, documentation, or organization, are recognized.This is something that the chair does to help the whole structure. It has worked well because it leads people to self-organize, have a closer impact on things they like, and learn. You can move from one work to another and be involved in many at the same time. This has been much better than the original members-only structure.\n\nOne of the roles you have in the Python community is being the release manager for CPython. How are things going with the recent news of delays? It has been stressful as the release manager for Python 3.10 and 3.11. Python 3.8 and 3.9 were easier, but 3.11 has been challenging due to many changes and more people working on the project.\n\nThe release of Python 3.11 has been difficult due to fundamental changes in the interpreter and core parts. The faster CPython project has led to big changes by developers working full-time. This has caused more bugs and challenges in the release process.\n\nThe responsibility of the release manager is to ensure that the Python release is stable. The goal is to release a stable version, but there will always be bug fixes afterward. It may not be wise to run the first release on production immediately, but some companies, like Bloomberg, do so. They have been running the latest versions since Python 3.9 with success.One of the responsibilities is to ensure that as much as I can, or to the rest of my abilities as a person and release manager, I can ensure that Python is as stable as possible.\n\nThis is very easy if there are not a lot of changes, but this is such a different thing. For instance, we have this concept of a release blocker. A release blocker is an issue in the Python bug tracker that blocks our release. This means that the release manager cannot release if that issue is not fixed. It's like the cord they would pull in the Japanese factories. So we cannot move forward, everything stops.\n\nThe problem is that there have been so many of these. For instance, if I have to do a release on Wednesday, I have to put the release one or two weeks delay just because one after the other, one of these big problems. And these problems are big problems. It's things that, you know, Python just faults or it just breaks if you are two numbers or did you. I mean, it's never having two numbers that would be too easy, but it's always like weird conditions.\n\nTo tell you about how complex decisions can be, one of the things Python 3.11 does is that it does this adaptive interpreter thing. For instance, if you have a function that adds two numbers, the first time you run the function, Python is going to grab the first Python object and see what it is. If it's an integer, it will do a specific fast addition for integers. This is called quickening, and it is part of the adaptive interpreter.\n\nHowever, it is quite difficult to get extra paths to trace down. Imagine you have a bug in the fast path. The test suite needs to run a certain number of times to check the fast paths. It's easy to forget about some of the fast paths or a combination of them. We put effort into the test suite to check the fast paths, but sometimes we may miss a combination of things.\n\nOne error that people submit to us is if you have a class that has an attribute called \"attribute full\" and then you have an instance of a class.Okay, if you put the attribute in the instance as well, that has preference. It's just the rule of how Python works. So, if the instance has another full, you will get the attribute in the instance before activity in the class if they have the same name. But the snag was that if you call the function enough times, when it quickens, it will get the attribute from the class.\n\nOh, wow. Okay, yeah, it was crazy because you keep accessing the same attribute from the instance, and then when the function quickens, it will say, \"Oh, actually, the class has preference now.\" Because we made that incorrectly. And then suddenly, you're getting a totally different thing. Yeah, you're getting something not even initialized. Yeah, right. That was such a difficult thing to... And the person reporting this was clueless because they were like, \"I don't know what's going on.\" But like, if I run my test with why, they don't even know why it would even think that way.\n\nYeah, it's like, right, right. What they were saying is that sometimes when the moon is full, oh, the failure was \"non-type doesn't have attribute\" because what happened is that you were getting \"none\" but that \"none\" was then being passed through something, and that something was using something else. And at the end of the day, something expected a number and it was receiving \"none,\" and then they'll complain. So it was such a difficult thing to track down because if you say, \"Okay, some this thing is not even known,\" but that is impossible because the attribute of this thing is a number, it's not \"none.\"\n\nYeah, so that's the kind of errors that we are dealing with right now. Right, or you know, so the release has been such a complicated thing because there is stages in the release process when I need to freeze things. Yeah, yeah, I was thinking that normally the no new features, you know, shall pass at a certain point, right? That was right. They got Gandalf's style right exactly. I've been watching movies recently, so this is beta phase. So for instance, when we released the first beta, and so we have a bunch of alpha releases in a month, I think it's six of them. So after six alpha releases, so six months of development, we activate the first beta. So the first beta marks the moment where nobody can add new features, like no changes in API, no new parameters. So from that point onwards, it can only be bug fixes and recommendation changes.\n\nOkay, not even like the thought of optimizing anything, just bug fixes, right? Okay. So that's kind of fine, that is okay, right? Like, okay. So any new features go to the Python 3.12 in this case, and optimizations as well, so that is fine. But like what happens is that there is another stage in particular, around the first release candidate. So when we are three months away from the release or two months, well now it's three, but something like that. When we freeze something called the ABI, so the ABI stands for Application Binary Interface, and this is a fancy name to say that the shape of the functions and structures in C cannot change. So this is, if you create a binary wheel, so basically a pre-compiled package, so you don't need to recompile it when we do the final release, right? Because it's not going to crash, this should be the same. But this is a bit challenging because this puts a bunch of constraints on what you can and cannot do. For instance, you cannot add new parameters to functions in C because the other public, because this means that someone calling that function will crash because they are passing less parameters. Like in Python, you will get a value error. Well, it depends on what will happen, but by then you will get an error that will tell you, \"Oh, you are passing three parameters where this function has five.\" But instead, you will check for like, C is not nice about this. It will just crash or it will fail to compile. So when this happens, it means that there's a lot of things that you cannot do. But if you have a bunch of bugs and the solution to those bugs involve changing these functions, then it's very hard because it means that you need to do the fix in a more complicated way because you cannot use it in the easy way. And that's a problem for the release manager, in this case, me, because at that stage, I need to ensure that Python is stable. And the way to get the stability is by not changing things, right? And if you're fixing a bug, you need to add 200 lines of code. I mean, maybe not 3,000, but let's say 200 lines of code. Then you're introducing more, you're introducing the kind of chaos into the system, right? Because now there's these 200 lines of code that are here that before were not here. So how can I know that those 200 lines of code are not introducing weird problems that before were not there, right? Making something else a second, like, for instance, coverage, the tool like coverage.py.net, Batchelder.I think sorry if I'm pronouncing your name incorrectly, but the net maintains that he suffers a lot from this because sometimes we have introduced fixes that break coverage, making coverage not report some lines. He has been diligently raising issues with Python every time we break and correct.\n\nThanks, but this is a good example. As a release manager, I need to make super complicated decisions in which I need to investigate every single change that goes in to be happy with the risk it introduces. This makes me have to review everything, which is very hard because I'm a core developer and know a lot about Python, but I'm not an expert in all areas. For instance, I'm not an expert in IO and have to review a bunch of async IOs, forcing me to learn things I didn't know enough about to make decisions.\n\nThis is super time-consuming and involves a lot when it happens constantly. It's interesting when you have N changes, the way those changes can interact between themselves. The formula is M times N minus 1 over 2, a symmetric amount of combinations. Introducing N things grows quadratically, making it super difficult very quickly as complexity grows extremely fast.\n\nThis is very difficult in a release that was already challenging because of the amount of things we were introducing. I'm in a situation now where I have already released candidate two, which is supposed to be the final release with only documentation changes. We already have two release blockers that need fixing, making it challenging compared to my previous experience with Python 3.10.\n\nIt felt like a breeze in comparison, especially considering the parser change at that time. I felt proud of that change, as changing the parser of a language as popular as Python is like doing open-heart surgery. It's a big piece to change while it's running, and it's easy to get the grammar wrong.\n\nThe amount of bugs we received went almost unnoticed, mostly minor documentation issues. We never received fundamental issues or changes in Python's behavior, which made me proud of the successful change. We were lucky, and it went well. It's interesting, yeah.I mean they're getting their hands dirty and that affects the whole team. Trying to look at ways to speed things up and those seem like really interesting problems. The introduction of those kinds of solutions, like who would have thought that you would have to completely alter your testing strategy and develop new techniques to test? Sort of the endurance and different stages of things, that's very interesting.\n\nIt's hard, it's hard, it's hard. Oh, by the way, I want to clarify something. Also, I don't want to imply that I'm the only one dealing with this. I'm super grateful that the rest of my colleagues in the Colorado element team are helping me a lot. They react super quickly when there are problems, they review the PRs for me, so I don't need to review all of them. They are such a fantastic team to work with. I'm super lucky to have such amazing colleagues in the core development team. Without them, obviously, I couldn't do the release, but it's hard, but we are all pushing together. I just want to take the time to be grateful with the full team and all the people working with me. I don't want to leave things in a dramatic note. Spanish people will be dramatic, we like the drama, like telenovelas, but I think it's also important to know that there are people helping, it's a bit more stressful than normal, but we are super close to having something. We are super proud of 311. We just think that, like my colleague Victoria Stinger likes to say, you cannot make an omelette without breaking eggs, and sometimes dishes, and maybe also the restaurant, but the omelette will be very tasty. So, hopefully, we will get there, hopefully in October as planned.\n\nThis week, I want to shine a spotlight on another Real Python video course. In fact, it's part of an entire series we've been working on for the past several months, based on the Real Python book \"Python Basics.\" This course is titled \"Python Basics: Strings and String Methods.\" It's based on another chapter of the Python Basics book by David Amos. In the course, I'll be your instructor and I'll take you through how to define a string literal, how to index and slice strings, working with user input, manipulating strings using string methods, removing whitespace from the beginning or end of a string, dealing with strings as numbers and vice versa, and you'll get an introduction to F-strings. Like all the video courses on Real Python, the course is broken into easily consumable sections, plus you get additional resources and code examples for the techniques shown. Check out the video course, you can find a link in the show notes or you can find it using the enhanced Search tool on realpython.com.\n\nI wanted to ask you, and you've kind of already alluded to it a bunch, but I wanted to say, where do you find the time to do all these things? It sounds like Bloomberg's been pretty good with helping you to be able to work on these projects, obviously being part of the infrastructure training that helped you work on M memory which we talked about last time, but also this sort of work for core Python. Also, just to clarify, Bloomberg gives me 50% of the time. I spend that time currently mainly to work on the fastest Python, but most of my operational work is outside Bloomberg. Just to clarify that, although I'm super grateful that Bloomberg allowed me to work part-time on Dallas shoes, there's a lot of additional volunteer time. I remember this because it's just giving me more work, like you know, it's also a bit challenging when a company gives you time to work on open source because it's not just, \"Oh, now I have this 50% of the time, technically it is work time,\" which means that you need to report on that and convince your management that you're doing good work and whatever. Do you use a time tracking tool for that kind of stuff? No, man, I'm a total chaos, don't look at me for advice. I don't use any organization, I have a to-do task list, I use a to-do list and I have tasks and whatnot, but I don't organize my time, I just go with the flow. At the end of the day, I know what I need to do, for instance, for the Steering Council, I need to fill this or research this path.I am quite diligent about doing things during the day. Besides that, I tend to drive my manager crazy because he wants to know what I will be working on for the week, but I am unsure. It's just how I am. I may plan something, but end up doing something completely different by Friday. It's the same for open source projects; I can be a bit chaotic to be honest. Being flexible is important for the various tasks I undertake.\n\nI have tried to use schedulers and other tools, but they haven't necessarily helped me. In many ways, they became an extra task in themselves. It's important to clarify that while my approach may seem chaotic, it is not unstructured. There is a level of diligence that allows me to organize tasks in an emergent way, even though it may not be planned or obvious to others.\n\nMany people ask me how I manage my time, and I joke that as a physicist specializing in general relativity, I experience time dilation to fit everything in. As for learning sweep picking on the guitar, I can now do it without causing others pain.\n\nIn the world of Python, I am excited about the upcoming release of Python 3.11 in October. The speed improvements and additional features like error messages and reporting are something I look forward to. It has been a year of collective work, and I am eager to receive feedback on the new version.\n\nIn terms of learning, I have been exploring Rust and now plan to delve into Swift for iOS app development. I want to challenge myself with something outside my usual expertise but with a chance of success. Starting with a simple grocery list app, I hope to eventually build more functional apps for personal use.\n\nI may not have a specific problem in mind to solve with a Microsoft, but starting with a grocery list app seems like a good idea. Perhaps I will expand to creating an app to check Billboards on my Mac, eliminating the need to visit the webpage unnecessarily.But now it's an app in the Mac OS browser. It will tell me which billboards are failing, so I can be more proactive. I'm quite excited, it's a different language, ecosystem, and everything. I delved into it a little bit. When I worked for Apple, not in an engineering role, but as a trainer for internal and team training for retail. I also worked as a repair technician for a while, learning how to take everything apart and remember where all the screws went. It was pretty fun with the secret tools.\n\nI wanted to learn programming to make stuff for the iPhone. However, working for Apple meant they owned everything I created, even retail workers. So, when I left, I started learning Objective C and then Swift came out. It was challenging to learn due to frequent structural changes, but it was interesting. I built a checklist and a few simple games for the phone, following tutorials from a site recommended by someone. The language is intriguing, and I enjoy the feeling of not understanding anything.\n\nPeople complain about Apple's documentation for Swift, feeling it's too magical and integrated. It's similar to Python decorators, where you need to put something in to make something happen, creating a sense of discovery in a new world. I enjoy exploring new languages and borrowing ideas to improve my skills and share through tutorials.\n\nTo follow my work, you can check my Twitter account where I share updates on CPython or Python. You can also search for my blog by googling my name and Python. That's the main way to stay updated on what I'm doing.I try to be as instructive as possible and don't run, so it's quite friendly. If you want to follow me, that's the easy way. I also have this GitHub sponsors page where I sometimes send emails about what I'm doing personally or what is happening. So, if you are generous and cool and you want to support me in any way, there will be a way. But in general, if you just want to know what I'm doing, Twitter is the way to go.\n\nAlright, awesome! Well Pablo, thanks again for coming on the show. It's been fantastic to talk to you. It's always a pleasure. I'm having such a fun time always, so super happy to be here. Thank you as always.\n\nAnd don't forget to test out Platform.sh for yourself with our free trial available on our website. Just search Platform.sh in your favorite browser.\n\nI want to thank Pablo Galindo Salgado for coming on the show again this week. And I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "JULQPNT5Q0w": "Welcome to the Real Python Podcast. This is episode 134. How do you build a REST API using the Flask web framework? How can you quickly add endpoints while automatically generating documentation? This week on the show, Real Python author Philip Xdenny is here to discuss his tutorial series Python REST APIs with Flask Connection and SQLAlchemy. Christopher Trudeau is also here with another batch of PyCoder's weekly articles and projects.\n\nPhilip talks about updating an original set of tutorials to use current libraries and best practices. The series takes you through building the base Flask project, defining endpoints, creating documentation, adding a persistent database, and implementing models with SQLAlchemy. Christopher shares an article about contributing to an existing internal or open-source project by properly preparing pull requests. The article is titled \"10 Tasty Ingredients for a Delicious Pull Request.\"\n\nWe share several other articles and projects from the Python community, including more suspicious PyPI packages, using new tactics method chaining and Pandas tools to find syntax errors without stopping, a library for searching text in videos using OCR, visualizing C Python's specializing adaptive interpreter, and a library for building CLI applications based on type pins.\n\nThis episode is sponsored by InfluxDB. InfluxDB time series platform is built to handle the massive volumes of time series data produced by sensors, apps, and systems. Are you building real-time applications? Check it out at influxdata.com. Alright, let's get started.\n\n[Music]\n\nThe podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Christopher, welcome back.\n\nHey there. So we have a guest this week, a special guest from the Real Python team. I want to welcome Philip Xeni to our show.\n\nHello, glad to be here.\n\nHey Philip, yeah, it's awesome to hear your voice here on the show. Super excited to be finally in this podcast and not on the other side.\n\nMaybe you could give us a little background. We've mentioned several of your articles over the last six, seven, eight months. How long have you been with Real Python now?\n\nIt should be almost a year. I think I started full-time in December 2021. Wow, so yeah, it's anniversary time.\n\nMaybe you can mention a little bit about your background that I thought was fascinating. You had worked kind of in printing but also kind of in fonts, is that right?\n\nYes, with printing not so much. So I studied at an art school where I had a big printing background or history, but I was glad to move to digital stuff as fast as possible and learn type design, which is basically like calligraphy and stuff like this, how to draw letters. And from this, pivoted more into the technical parts to create fonts. The software that you're using to type in Word or in your favorite editor, somebody created this and I did my part here and there and worked for a long time at a company where we did the technical optimization so the fonts look good and work the way they are expected. And the cool thing is this whole ecosystem is basically driven with Python. Oh wow, so that's why I taught myself Python and also stumbled over Real Python. I think it was even in 2012 or something way back, so that makes me even more excited to be a part of the team now.\n\nSo what kind of tutorials do you like to write?\n\nMainly, it's about web development. That was always a passion for me. I started with HTML and CSS back in the days before I learned programming, and now things come together with this. But I'm also interested in the design part, so that's something I'm looking forward to maybe in the upcoming year to show a bit of what you can do with Python to design things.\n\nYeah, so it's an interesting intersection there. Cool. And then you've been working on my side with the video courses a little bit lately. You've done a couple of the Python Basics courses, and so yeah, I'm very excited about what you can add to the team there on the design side also. Yeah, it's exciting, especially the video courses. I've never done something like this, so it's fun to do them. I'm also enjoying the code conversation we were having lately, which is a bit more informal.\n\nYeah, so fun things going on. Those are really cool. Yeah, I've been championing them lately on the show, and then I'm hoping to eventually kind of maybe move into that space myself. We'll see. I partly wanted to have you come on because you have created a very large series that the third part will be coming out this week as the show comes out, and it's sort of a rewrite. But maybe you can talk a little bit about it. It's a series about Flask and creating APIs.\n\nYeah, that was an exciting one. It's not entirely created by me, so it was actually a series that existed on Real Python for, I think, created in 2018 by Doug Farrell. Yeah, he's a former guest on the show also. We talked a little bit about it then.Yeah, this series is a special mix between being a fun topic in general but also slightly out of date. Four years is a lot of time in Internet years, and in Python, that's four versions. So, it was time for an update. We still have people who really like this tutorial, but there were more and more comments about it not working anymore.\n\nWe decided to give it an update, and I took it on as my three-part series project. Formally, it was four parts, but I decided to condense it a bit more. It shows you how to create an API with Flask and uses a variety of technologies. Flask is the framework that we're using, which is a web framework similar to Django but more basic. You build stuff from the ground up, and then you're using Connexion on top of Flask to handle HTTP requests. You can define these requests with OpenAPI, which is a standard to define API specifications. Then, you have SQLAlchemy to interact with the database.\n\nIn these three parts, I walk you through some of the steps. The first part is not a traditional step-by-step project that we have on Real Python but it's kind of step by step. It has three parts, and I basically take you along creating a web app, an API-powered web app where you can create people and attach nodes to that person. In the tutorial, it's fantasy figures like the Tooth Fairy, the Easter Bunny, and the German-centric \"Santa's Little Helper.\" You can also use this app to keep track of gift ideas for friends.\n\nYou use Flask as a framework and start by creating the Flask project. After the first steps, you have a boilerplate for any other Flask project that you start. In the second part, you're adding the first API endpoints and creating a Swagger YAML file for the API specifications. You're using Connexion to connect it with your Flask app and have your first endpoint to read all the people.\n\nIn part three, you're expanding your database by adding nodes. You're creating another table and creating a relationship between people and nodes. You create API endpoints, models, and functions, giving you a good basis for anything you want to build on.\n\nSQLAlchemy is more prominent in parts two and three. In part one, when you're working with a dictionary, you can follow along. But when you're interacting with the SQLite database for this tutorial, SQLAlchemy saves you the trouble of writing literal SQL yourself.Yeah, it comes in part two and part three. Yeah, it sounds like, what were some of the hard parts of the updates that you did? Basically, since it has more moving parts compared to a faced API, for example, or the Django REST framework where you more or less have kind of like a box of things that just work, quote unquote. Yeah, they're written to be one whole thing as opposed to three parts you're gluing together. Exactly, yeah. So yeah, here we have multiple frameworks that need to interact together. If one is out of date or wraps the wrong version, nothing really works. Or there are slight changes here and slight changes there. And that's actually how we ended up with the tutorial, how it looks right now, because at the beginning it was more like, let's update it so everything is working with the current versions. But we soon realized, well, it's more than that. So we had to dig a little bit deeper and yeah, rewrote many parts of it from the ground up, basically.\n\nWere there certain parts that you enjoyed writing more? I kind of like how we're ending, so a bit foreshadowing there will be a part four at some point. Okay, so the three parts focus on the API, but I was very excited to add the front end to it. Yeah, okay, so maybe there's my design side coming. Yeah, I was thinking that. So you have a super simple front end with Jinja, which is coming with Flask for this tutorial. So it looks very basic, but you can already see like you get the list of people back, but all the interaction you're doing with this regular UI API documentation. And in the upcoming fourth part, which is kind of like works as a separate tutorial, then you can interact with it from the front end already. And yeah, this was exciting in that way that like the readers, well, now they know it, but I knew that what I want to build afterwards. So that was exciting to keep that in mind. Nice, because the idea of just having this API and you can basically create it separate from any front end is like the norm or nowadays a normal way of creating a web app where you have the back end with an API and then usually a very JavaScript-driven front end on the other side that just interacts with your endpoints. And so yeah, we will tackle this at some point in the near future. Yeah, looking forward to it, awesome. Chris, what's your first topic you wanted to get into?\n\nI'm starting with the article called \"10 Tasty Ingredients for a Delicious Pull Request\" and it's by a Wagtail developer who calls himself LB. Wagtail, if you haven't seen it before, is a Django-based content management system. The article really is language-agnostic, really talks about pull requests, but it comes sort of out of the Python community, has some great advice in it for anyone who's thinking about contributing to an open-source project, and quite frankly, it's just good practice to adhere to even when you're managing your own commits. So there's a little bit of background. Wagtail is a pretty big project. They've got over a thousand Python files, almost 200,000 lines of code. It's 13,500 stars on GitHub and 3,000 forks, so lots of contributions, right? Since LB is a core contributor, he gets to see all of these commits, particularly the new ones. So his advice is coming sort of from a \"been there, done that\" kind of situation. He starts out, I guess, with the first category, what I might call obvious, but obvious in the way that most of us don't do it, which is you should read the instructions. Most larger projects have some instructions or at least a PR template that explains what the project wants and how it wants to interact with you. And he acknowledges that some of these can be a bit painful. It's 20 minutes now to read this and that feels like, \"Oh, but I just want to commit code.\" But that 20 minutes is probably going to save you hours later because your PR got rejected or you got to cycle through and do a whole bunch of things again. So knowing upfront and re-reading the instructions, good advice for all of us, kind of without even this context. And then he doubles down with some specifics. So most projects include instructions on how to get them up and running. So not just instructions on how to do the PR, but how to run the project. And you really shouldn't be contributing unless you can do this step. You're not going to be able to test your contribution if you can't run the tests. I'll make a small exception to this that he doesn't bring in the article. Occasionally, I'll, you know, here's a PR with some documentation fix. Obviously, you don't need to run the tests for that. But if you're contributing code, it's a good expectation from the community that you are able to test not only your code, but that you haven't broken something else. Okay.So, you need to stand it up on your machine and prove it, and that's really what it comes down to. Quite frankly, this can be a bit of a barrier to entry. It stopped me from contributing to some projects. If it looks like, \"Oh, I need this service and this service and this service and all this running, right?\" You're sort of like, \"Do I want to do all that to submit this code fix? Maybe not.\" But it's a fair thing. If you're not sure, don't submit the fix because you don't know what it's going to break unless you can run through that process. That makes sense.\n\nThe next chunk then he starts talking about branching and forking. I think it's just good practice, so it makes a lot of sense. When you're contributing something to a community, create a fresh branch for any change and keep your changes small and focused. Smaller, separate branches make it easier to do merges and to cherry-pick changes if something needs to change or get rejected. Along with that, your branch name should reflect the change as much as possible. Along the same lines, your PR itself should have a meaningful name as well. This is one of those things that, if you've ever gone through your own git history and found that thing that says \"fixed problem,\" obviously that doesn't tell you what you did, right? You don't have to write War and Peace, but a simple statement can go a long way to understanding what's going on. Frequently with these kinds of projects, there are tickets involved, so there might be a bug ticket or a feature request. You should include a reference to that inside of your pull request because that gives further history and background. Some kind of numbering system may have been set up for it.\n\nThe ticketing numbering mechanism changes from different repos, but most of the major ones like GitHub, Jira, Azure, they all have ways of including the ticket number so that it shows up as a link when you're looking through the ticket system. That might be automatic, and in some cases, you need a prefix like a number sign or something like that. You kind of have to know the tool that you're committing to try and get it into that format. But even if you don't know that, having a reference to the number makes it easier for other people who are looking through to understand how things are. It goes back to reading the documentation.\n\nAnother good piece of general advice is to write unit tests. My favorite approach to this, particularly with bugs, is to write the test that shows the bug exists first, then fix it. I'm not a hardcore TDD guy; it's not like this is my approach to all coding, but particularly for bugs, this can make a big difference for things like regression suites because you want to check whether or not the bugs popped up again. Having a test that shows the bug is there before you fix it is value in and of itself.\n\nHe goes into a few more bits here and there about how to deal with reviews and CI systems, but it's a longer article with like 10 different points in it. I like how it's formatted too; it's relatively easy to read. He's got it all grouped together, and you can pick and piece and skim it fairly easily, which is nice. But he ends with a great piece of advice, which is to be patient. Remember that there might only be one or two volunteers who are inundated with a flurry of PRs. I'm sure your contribution is appreciated, but it's probably one of many, and somebody's got to go through this and deal with this. So, not to diminish the fact that you've worked hard and you're making a contribution, but the flip side is somebody's working hard to manage all these contributions. Remember that as you're going through; it might take some time for something to show up. \n\nIt makes me think of a lot of things. Some of it has to do with core Python and them having a developer in residence now to look at all these tickets and get all this stuff in there. How long these contributors who maybe submitted something when they had time on a weekend are waiting and looking at it. You know, it feels like the type of person you're waiting for an email to be sent or something. The bigger the project, the more this is, you know. And in some cases with really active projects, like Core, where 3.11 came out three weeks ago, and 3.12 is already in alpha, so anything you're contributing might be aiming for 3.13, which won't get released until 2024. There again, there's that patience thing that has to go along with it.Even think like this one could have been part one of the tips to be like, expect that you need time for it. So don't go through all the steps and then make the pull request and nothing happens. But expect to wait for days and weeks. Yes, well, I can find as well that like if you're finding something you're working with a library or whatever and you're like, \"Oh, that's broken. Here's the three-line fix and here you go.\" But other times, if you're looking to get involved with the community, one of the things I would suggest is to start with something smaller. See how it goes, right? Like don't write 4,000 lines of code and then get it rejected and feel all cranky because your 4,000 lines didn't come in right. Start with something small and see how it goes. And once you've got that interaction going, it helps. These projects are all run by human beings too, right? So if you put in two or three small requests and they're all good and they've all been accepted, I bet you might slip up the list if you submit the fourth because, hey, I've seen your name before, I know you contribute something and it's valuable. Yeah, kind of warm and fuzzy feeling, yeah. The human aspect of it kicks into all this, right? Absolutely. Because ask you a question about Wagtail. I've never used it, so you can ask. But I just wonder, what is the direction that it builds on top of Django? I feel like it is more geared for blogging in general and adding lots of niceties for that sort of stuff. Like you talk about going from Flask to something like Django, the Wagtail goes even more directionally opinionated. Yeah, so Django, you could consider Django like, although it's expressed as a web framework, it's very CMS-like. And that's because it was built for a newspaper and the original thing was to get reporters to submit articles. So you could almost talk about it as being a content management building system. Seeing as most stuff on the web ends up just being a content management problem, that kind of makes sense. Wagtail takes it a step further and actually builds out a content management piece on top of it. So it's adding out of the box some of the functionality that's sort of implied by Django underneath. Okay, yeah. So basically, if you want to have a website for a customer and you might not want them to use the Django admin, then Wagtail comes into play and you can build really nice things with it to give it to a customer. Yeah, I suspect it's WordPress-like, okay, more than that. I mean that with love, sure, because that sounds like an insult to a Python. 65% of the web or whatever it is exactly. Yeah, I'm sure that number's even wrong. It's kind of a fun one. It's from my former co-host here on the Real Python podcast, David Amos. Again, he was a Real Python author for a long time. It's sort of an interview with a previous guest, Matt Harrison, who was on episode 103 titled \"Becoming More Effective at Manipulating Data with Pandas.\" And we actually talked about some of the stuff that's here. But David Amos was on Twitter and hopefully it's still up as we talk. Who knows by next week, we'll see. He had noticed this tweet that he had put up there that was a chunk of Pandas code that had a lot of the techniques that Matt likes to use and it suddenly created a little bit of a kerfuffle as far as the reactions. What do you expect? Oh, I know exactly what do you expect. I wrote that. You know, he had a Twitter that drew some criticism then in parentheses, \"What?\" And so David, he was fascinated by the reactions but also about how Matt was handling them and responding to them in a very constructive way. Again, not quite. That's more of like a what? And he wrote this question in his post: \"Was there some disconnect between the folks criticizing Matt's code and the reality that has shaped Matt's lambda-laden method chaining style of writing pandas?\" And so I just liked it as a post. It's well written and kind of interesting interview and asked questions that don't typically show up in interviews before, so I thought it was kind of neat. Matt has written a book called \"Effective Pandas\" and he teaches a lot of these techniques inside of it.It was hard again on a podcast too. I kept kind of pushing him in the show to explain what chaining looks like and see if we can get an example of it. In this case, there's a really long example of taking some sort of housing data information and doing the cleaning, aggregating, and renaming columns all in one big statement. That threw people off, and they're like that's unreadable. Some of the comments suggest that all those things should be separate functions for testability. His response is that he teaches companies, and very often these companies are not filled with programmers, they're filled with professionals doing other things using pandas to manipulate data and do other types of things, which he likes to call recipes. Maybe sort of one-off types of things, but you can still write them in a readable way. If you look at the code and dig into it, there's an entire recipe in there with steps, and this chaining technique can be seen inside of it. I'll include links to that.\n\nI like how he explained why he was doing it and the concept of professionals not necessarily meaning professional developers, but people with jobs who want to automate and move beyond Excel. He talks about organizing and getting people to do useful things with code. He also mentioned a video \"idiomatic pandas\" on YouTube from conf 42, a Python conference in 2021, that Matt Harrison did, which he didn't mention on the show. It could be a nice resource for people.\n\nAt the end of the interview, he mentions \"polars,\" a potential up-and-coming tool written in Rust with some nice features for working with large sets of data. It's all about chaining, which is a technique he used a lot in data science in R. He liked the tidy verse stuff for that because it allows for the same kind of structure with pluses and minuses. It might not be readable for complete beginners, but once you see the structure, it's like putting together a recipe.\n\nThis interview is almost like a religious conversation because chaining is common in other languages like JavaScript. If you're not used to it, it can be jarring in Python. There's a defensive aspect to it, but it's an interesting interview about why he programs in a certain way, even if you're not familiar with pandas. He teaches seminars to large companies adding Python for data wrangling, which is his specialty.\n\nThere are suspicious PyPI packages that can be malicious, and Phylum focuses on inspecting open-source packages for security in the supply chain of projects.Yeah, they found out that there are some infectious packages on Pipi. The interesting thing with this blog post is that they found some sneaky ways how those packages were put to Pipi. The first thing is that those packages use typo squatting, which means changing one character in a package's name and hoping that people will make a typo and download your package. They do a plural version of something. Maybe you have experienced this when typing a URL and ending up on a weird site because you forgot a letter. The same goes for the packages. Some of those packages copy the content from the package they are copying, making it look like the real thing. You have to be careful and look into the source code to find out it's not the real package.\n\nAnother interesting thing is how they introduce malicious code. They added around 300 spaces to the right in the setup.py file, making it hard to see the code without word wrap. Using Vim with word wrap would help avoid this issue. The discussion also touches on the importance of keeping an eye on such packages and the technique of obfuscation. The company tried to execute the code but it didn't work, highlighting the issue of bad code.\n\nThe conversation transitions to a discussion about a Real Python video course on working with Pandas data frames. It covers creating, importing, modifying, and visualizing data frames, crucial for data science. The course is recommended for anyone interested in data science.\n\nThe discussion then shifts to a question about finding syntax errors in Python files. The challenge lies in getting multiple error outputs at once due to Python's interpretation process stopping at the first error. The poster seeks a tool to identify as many errors as possible in a Python file. \n\nOverall, the conversation covers various topics related to Python programming, package vulnerabilities, data science, and tools for error detection.It fix a problem, run it fix a problem, run it fix a problem. By contrast, and this will completely date me, my first C compiler was in high school. There were 15 of us all operating on the same shared Unix system, which was a screaming fast four megahertz processor. Whoa, slow down. If we were all compiling at the same time, it could take like 25 or 30 minutes. So you would output all of the errors into a file and then you would go and try to fix all of the errors that you could at the same time because the next time you ran compile, it was going to take another 20 minutes. So that style of non-interpreted languages tends to keep parsing the language and showing you multiple errors.\n\nI suspect Antune might be coming from a different programming language, and when he hit Python, he may have gone, \"Wait, hold on. Why can't I see more than one mistake at a time?\" So I was wondering about that. I guess my experience is using an IDE, and so I feel like a lot of the stuff I was researching, what are best practices, and they're like install this, install this, install this. So I go, it had linting and had all these other kinds of things ready to go. So as I'm typing, maybe that's the difference here. Maybe this was like already an existing file that he was looking through for syntax errors, but I'm used to the idea that as I'm creating it, it's giving me feedback, and I'm wondering if that's part of the process I'm having that disconnect.\n\nEven if it's an existing file or something somebody's given you in your IDE, you're going to get, depending on your IDE, the little squiggly red lines underneath those parts that are going to be problematic. He may not be using one. I suspect, and you never know without having the context of a post, you never know where this person's coming from. You gotta wonder where these people come from sometimes.\n\nIt's possible that this person is either new to the language or isn't using these kinds of tools. If you've come from other languages, you might not be used to the fact that they're out there. Sometimes what also happens is people in different parts of the world have different things like internet capabilities. So you might be starting out because it came with the operating system on a CD that you installed, and you're not connecting live and downloading the latest copy of VS Code because that might take you a month. So you never know where some of these kinds of things come down to.\n\nI did find it interesting that you sort of scroll through it, and it's a longer conversation than I expected. We've never done anything with this kind of thing. We've talked about Stack Overflow and used a few other different resources like Reddit and Hacker News. This is the first time we think we've done Google Groups, and it's a little more tangential than some of our other conversations. I don't know whether this is an aspect of the community or whether it's just this one causing an awful lot of tangents. I found the tangents fascinating.\n\nThere were some people doing deep dives into teaching others how AST trees work in Python and explaining how you would build a linter. I found it fascinating because they didn't start with, \"Oh, and by the way, there's a bunch of these out there, so you don't have to build it from scratch.\" It was sort of this, \"You could use AST and start building stuff. You could chisel the bits by hand into the hard drive.\" Yeah, you could, but why would you? And then you get the helpful because it's the internet, like just how many errors are you putting in your code, right? It's like, \"Yeah, great, that helps the guy.\" Right?\n\nI think you're not only asking the question, but obviously you're a bad programmer and you're smelling too. It's just welcome to the internet. So yeah, there was one piece of advice that I thought was interesting of running your script to check the syntax, and it was using this Pi underscore compile, which would create all the pyc files. Instead of just purely running the script. I've never used it, Philip. Is it something you're familiar with? I haven't played with that. Sorry, no.\n\nYeah, I like the suggestions like pie Checker, pie flicks, pilot. There's all these other suggestions that I'm like, yeah, those are the kinds of things that I would move into.It's interesting, like a community question, and then, like you said, there's a really interesting subset of answers that we're kind of dancing around. This idea that there's, especially with just the term \"syntax error,\" like you've named something incorrectly or you've had a spelling error. That's what I think of, like some simplistic syntax errors. But obviously, there are other ones that could be in there. So I guess I'm maybe relying too much on my tools.\n\nWell, in fact, that's one of the other tangents that's in there with someone. So the phrase \"syntax error\" generically usually means, like the way he's using it, I think he actually means a compile error. Something that should be caught by the compiler. And there was one person who was responding back with the lesson of what an actual syntax error is in Python.\n\nForgetting an import isn't technically a syntax error, but it's the kind of thing that is caught by the compiler and would be the kind of error that you'd want to have caught. PyCharm underlines that in red. Linters say, \"I don't know what this is, you need to import it.\" So, you're sort of back to who's asking the question in the context.\n\nYou were talking earlier about the pi compile actually creating the pycs. As far as I know, all the linters I've used, and I suspect I can even paint with a broader brush than that, they use the AST so that they aren't actually running the compiler. This is done intentionally because running the program might have side effects. So you don't want to run the program in some of these situations because you might be doing something like connecting to a database when you load the import.\n\nIt's not best practice, but people do it all the time. So there's side effects of loading the modules. You want the linter not to actually load your code. And if you're using profiling tools, you have to run it. But if you're doing something like looking for syntax errors, in my case, I use the linters all the time because I copy and paste some code and I'm like, \"How many imports do I have here? Do I need them all?\" And then the linter goes, \"Oh, you're not using this one.\"\n\nThere's some cleanup stuff that you can use there as well. It's an important aspect of them that they do not load the actual modules because you don't want those side effects firing. \n\nIt's an interesting conversation, kind of a different group of people going back and forth. And again, there's a handful of people coming in and going, \"This sounds really foreign to me, this process that you're using.\" Like somebody asked, \"How does one declare a variable in Python?\" It's not that far from Fortran. \n\nI understand where his comment was coming from because in the older days, trying to do this with JavaScript, you'd get a syntax error, something's not running, it won't load. And it's saying, \"Hey, this is happening on line five,\" and you're like, \"There isn't even code on line five, what is happening?\" One of the techniques for dealing with that is you comment out three quarters of the file and then you run it. You just sort of shrink it a little bit at a time until you get a reasonable answer.\n\nShout out to Python 311 and all the changes there, telling you where it is and being way more specific. I just ran into this recently when putting together a course on context managers. Python 311 tells me exactly what happened, which is beautiful.\n\nIt's interesting, looking forward to seeing what other conversations we can find through these new communities. Kind of look at what's going on out there. I think that moves us into projects. Did you want to go first, Philip?Yeah, sure. My first project is a Python script that might be interesting for Mac users listening. It's called Video CR created by Peter Cooper. Since it's for Mac OS Monterey, which is one of the latest Mac versions, you can select text, photos, or videos. For example, if you see text in a video like a sign, you can pause it and select the text. When I first did it, it was mind-blowing that this is possible. It's a cool feature, and this script is a proof of concept that you can hook into OCR technology Mac OS contains with Python. It's one Python file with some requirements, including ffmpack, a popular compression and decompression tool.\n\nIf you download this and have a newer Mac OS version, you can try out this script to extract text from video files. The cool thing is that this proof of concept exists. For example, if you're creating videos for the web and want to ensure sensitive information like AWS keys isn't leaking, you can use this script to check every video file before publishing.\n\nAnother use case could be for someone who's blind and trying to learn a language through videos that don't have all the code spoken out loud. This script could help extract information not available in closed captions.\n\nMoving on to my project, Python 3.11 added a new optimization called Specializing Adaptive Interpreter. When you run a Python script, it compiles into byte code, which is then interpreted. The new feature adds byte code operations that optimize certain operations for speed, especially inside loops. The project I'm discussing is called Specialist by Brent Butcher, a profiler tool that highlights specializations in your code's byte code.\n\nBy running your code through Specialist, you can see which parts are marked for adaptation and potentially speed up your code. The output is in HTML format, showing annotated versions of your code in a browser. This tool can help you understand how the Adaptive Interpreter works and optimize your code for speed, especially in Python 3.11 with its Adaptive features.\n\nOverall, these projects showcase the power of Python for creating innovative tools and optimizing code for better performance.So, it's happening from the compiler if you can or changing it to a different operation like say bit shifts. You might be able to get some speed up because not only would you get faster code for refactoring it, but you're now going to be able to take care of this sort of adaptive concept. It's an interesting little tool. Of course, Python 3.11 is still pretty new, so I'm not sure I'm adding this to my toolbox quite yet, but it does provide some good insight. If you're interested in the internals of how this works and what it might be able to do for your code in the future, it's a fascinating little experiment.\n\nYeah, Brent, I think is maybe key in actually introducing it to the language. He's a core developer. Ah, okay, I didn't recognize the name. Yeah, yeah, yeah, he's, I think he may be even on the team, the fast, yeah, the Microsoft team. Ah, okay. And so that would make sense. Yeah, yeah. And then I'm wondering if there's like he used it as a tool to kind of learn a little more about it and go from there.\n\nCool. Yeah, he's, I'd like to get him on the show to talk more about this stuff. That would be really cool.\n\nAwesome. So, my project is a project that's been around for a little while. In fact, we actually have a couple articles about it in places that we've used it. But it's a command-line interface builder tool called Typer from Sebastian Ramirez. He is most known for probably FastAPI. He built this on top of Click, which is a very popular, I would argue, decorator-centric CLI. And I think there's lots of nice tutorials and stuff out there.\n\nThe subtitle is \"Typer: Build great CLIs easy to code based on Python type hints.\" He's a big fan of type hints and taking advantage of them. The article that we had on Real Python was from about this time last year. Laodonis Rosa Ramos wrote a step-by-step project called \"Build a Command Line To-Do App with Python and Typer.\" I think that was based around version 0.4. It's already up to version 0.7, but around July of this year, he added a lot of connections to Rich from Will McGugan and his whole prettifying CLI terminal output kind of stuff.\n\nIn order to take advantage of some of these features, he added a new way to pip install it where you add square brackets and maybe another word. In this case, it's like Typer square brackets all, and it adds these four different libraries to get you all the bonus features. I really like his tutorial and user guide for it. I think it's very instructive and gives lots of nice examples and lots of visual output that's sort of animated and so forth of what it will actually pop up and look like inside of there. It has lots of nice starting points for you to kind of, if you're interested in getting into CLI design, Typer just seems to be keeping on going as far as growing and improving, and I think it's a cool project to check out if you're interested in that side of Python playing from the CLI side.\n\nWell, Philip, thanks for coming on the show. It's been really fun to talk with you, and I hope to have you on the show sometime soon. Yeah, thanks for having me, and Christopher, thanks again. Always fun.\n\nAnd don't forget, InfluxDB time series platform is available in the cloud, on-premises, or locally. Get started for free today at influxdata.com.\n\nI want to thank Philip and Christopher for joining me this week, and I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey, and look forward to talking to you soon.",
    "xXPgGSWCHpM": "Welcome to the Real Python Podcast. This is episode 135. How do you prepare a data set for machine learning? How do you go beyond cleaning the data and move towards measuring how the model performs? This week on the show, Jody Burchell, developer advocate for data science at JetBrains, returns to talk about strategies for better ML model performance. Jody starts by defining some terms for the conversation. We talk about targets, features, and supervised learning. Then we discuss three common ways data can alter model performance and which Python tools can help spot and avoid them. Jody shares personal experiences of working through these pitfalls. We also share a healthy collection of resources to explore and learn more. \n\nThis episode is brought to you by CData Software, the easiest way to connect Python with data. SQL access to more than 250 Cloud applications and data sources. Alright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Jody, welcome back.\n\nHi, I'm very happy to be back again.\n\nYeah, you have had a very busy time since we spoke. You've been doing lots of conferences, been out in the world. I don't know if you want to even give a rundown of some of them, or I would guess some of them have videos posted and we can maybe share a few of them. But yeah, very busy.\n\nYeah, I've been quite lucky. I got accepted into four conferences in a row, so yeah, it was exhausting but very convenient. I was in Cardiff, then London, then Porto, then Oslo, and just presenting four different talks on total different range of topics. So yeah, it was a lot of fun, but it was good to get home, I can tell you that.\n\nYeah, you got to meet Garana, that was kind of cool. I kept getting notes from both sides there.\n\nYes, and it's super funny. So I applied for PyCon US and I asked to be set up with a mentor, and Garana was my mentor. So yeah, that's so funny. Such a small world.\n\nTotally, yeah. I think he mentioned that just yesterday to me. I was like, \"Oh, that's hilarious.\" And cool, and very, very cool.\n\nYeah, well, it was also a little bit easier to take feedback from someone when you've met them as well. Not that I have a problem taking feedback, but you know, it always makes it a bit less, you know.\n\nYeah, there's less, you don't have to wonder what's behind it, you kind of go, \"Okay.\"\n\nExactly, that's cool. Nice. So you're back to talk a little more data science stuff, and this I thought is a really cool topic. You want to introduce it?\n\nYeah, so I want to talk about maybe something that's not as focused on data cleaning, which is how you can actually prepare your data in a way that allows you to understand whether your model is performing as well as you think it is. Specifically, you train a model and everything looks cool and looks really nice, but when you put it into production, you end up with a nasty surprise where it's really not performing as well in the production data at all. So just wanted to get into today just a few things to look out for. And of course, because we're on the Real Python Podcast, how we can use some tools in Python to quite easily spot those and avoid them.\n\nYeah, that sounds awesome. I was thinking of a car metaphor. You're kind of like cleaning the car and getting it all prepped, but you're also kind of giving it an additional tune-up and making sure it's all set. That's cool.\n\nExactly. So where do we start this journey?\n\nI think maybe let's just start by defining some vocabulary just to make sure everyone's on the same page. And then we can talk about the topics themselves.\n\nOkay. So I think most people who have done any sort of machine learning would know about this. But just in case people are new to it, when you have a data set and you want to use it for modeling, usually you'll need to divide it up into a couple of different sections. So you'll have a variable which is called the target, and this is the thing you're trying to predict. And then you'll have a bunch of variables called the features, and these are the variables that you'll use for making your predictions. So I like to always be super concrete with this stuff. Let's say you're trying to predict house prices. The target would be the house prices, and the features would be things about the house, like the condition, the neighborhood, the number of rooms, things like that. So we'll be talking about features and targets a bit in this particular podcast. Just wanted to make sure you and people are not like, \"What the hell is she talking about?\"\n\nYeah, I know. That's good. Because features could mean so many different things. It's very specific when we're doing this training and preparing things. \n\nYeah, exactly. It's important to be clear on these terms.And probably, the other thing I just want to talk about is what I mean by model performance. So we're specifically going to be talking about a type of machine learning called supervised machine learning. This is the machine learning most people are familiar with, so things like linear regression models, decision trees, they're all supervised learning. And all it means is you've got basically a ground truth set of labels that you can compare your predictions against. In the case of house prices, you would have the predictions that your model makes, but you would also have the list of the real house price. The performance of the model is how close you are in that prediction to the actual ground truth. The better the model performance, the closer you are, and that's all we're really talking about here.\n\nI have a quick question on something and maybe I'm jumping ahead, that's fine. Can you sort of, we're gonna talk shortly about this concept of overfitting, but can you over feature? Can you have too many features sometimes, and will that sometimes make things a little too noisy? That is a great question. We're actually not going to cover it specifically, so it's good that you asked it now. This is a phenomenon known as the curse of dimensionality. That sounds like a Doctor Who episode or something, the cast of the fourth dimension. But basically what it means is you have so many features, but your observations start to be uniquely described by them. It's easiest to understand, I think, with categorical variables. If you have three categorical variables and you have a bunch of really rare groups within those, if you have a combination of the rarest three levels or groups within your categorical variable, there might only be one or two observations that actually meet that. The more features you add to your model, the more likely it is that you're going to have situations like that. Essentially, what this means is the model can't learn patterns, it just starts memorizing the information that it sees based on one or two or three observations, and then it's obviously going to overfit because it's not learning a pattern, it's just memorizing answers.\n\nYeah, okay. And I guess that's something you need to do a little bit in advance or maybe as you're looking at the data initially you can sort of decide which things hold a true signal versus noise or are too static. Yeah, we will talk a little bit about it actually. I tell a lie, we'll talk a little bit about it at the end when we talk about imbalance features. But okay, basically this is sort of why feature engineering is such a big deal in machine learning because you can't just chuck a bunch of unprocessed features generally into a model and expect good performance unless you have exceptionally good data. Okay, all right.\n\nSo shall we jump into the first topic? Yeah, let's definitely do it. I think I mentioned it already. It's okay, so no surprise, the first topic is overfitting. Something I didn't really appreciate when I first started doing modeling is you have a sample and your sample is a little kind of microcosm of the real world, but your sample will never be completely representative. It'll always have its own little weird quirks and patterns and idiosyncrasies. And when you're training models, the harder you train models to fit your specific training set, the more they're going to learn not just the relationship between features and targets, they're also going to learn these weird little patterns that each data set has. And what this means is that when you go and you try and predict on fresh data, your model is not going to perform quite as well because it's just fit way too hard to the training data. So that's what overfitting is, you've kind of looked too closely at it in some ways, I guess.\n\nExactly, exactly. So I think the way that it was taught to me in a way that I really understood is if you have a scatter plot between two variables, if you just draw a line through them, that would be like a linear regression model that's going to give you a pretty good approximation of the relationship between those variables if the scatter plot is roughly in a straight line. But if you were to draw a line that went through every single point, that's going to describe your data perfectly, but the chances of having those exact same points in a fresh data set is basically zero. So you can sort of see that the straight line model, even though it doesn't fit the data as well, is actually a better model because it'll predict generally as well on fresh data.\n\nYeah, give true direction to things and as opposed to trying to be so precise. It's so weird, yeah.\n\nSo you can sort of see that the straight line model, even though it doesn't fit the data as well, is actually a better model because it'll predict generally as well on fresh data.I'd asked a question in what you had shared with me some documentation to get us started. I said, \"Is there a reverse to this? Is there underfitting?\" Underfitting is basically when you have a model that doesn't learn the relationships between features and targets very well. So, you'll generally just have really bad performance on your training data. Essentially, it just hasn't learned enough patterns, so it'll have quite erroneous predictions. That's what underfitting is. It's almost like being under-trained. Certain models are more prone to overfitting, some are more prone to underfitting. My beloved linear regression is sadly prone to underfitting, whereas things like decision trees are really prone to overfitting.\n\nThe way you can avoid this is by carving off part of your data to have a representation of the real world. This is what's called your test set. You set aside like 20-30% of your data, depending on how much data you have. This set will be used to train your model, while the chunk left for training will be assessed on this test set. However, there's a complication where the test set also has idiosyncrasies. If you keep training on your training set and then testing on your test set, your model starts to mold itself around the quirks in both data sets.\n\nTo get around this, you need to leave your test set so that you only use it once. You need a second test set for multiple assessments. One way to do this is by creating a validation set, where you allocate 60% for training, 20% for validation, and 20% for the test set. If you don't have enough data, you can use k-fold cross-validation. This involves splitting your training set into K different groups, training on all folds except one, and validating on the one left out. By averaging the performance across all sets, you get a sense of how the model would perform on fresh data.\n\nThis process helps in smoothing out potential overfitting issues. Scikit-learn is a fantastic package for data preparation, with standardized syntax across different methods. It simplifies tasks that could otherwise be tedious and manual. The consistency in syntax makes it easy to work with various types of data processing, whether it's text data or other forms of data. Once you're familiar with it, you can comfortably switch between different methods.Nice, there are great sets of tools that follow standards and methodologies. You've shared a bunch of links that dive deep into the documentation, allowing you to play around with the tools. There are also some real python examples included, which is great.\n\nI really like the scikit-learn documentation because it provides examples that go beyond just scratching the surface. You can learn something new even when you were just looking for documentation on something else. It's like going down a rabbit hole, but in a good way.\n\nCData software simplifies connectivity between applications and data sources, making it easier to unlock the value of data. Their SQL-based connectors streamline data access from various sources, both on-premise and in the Cloud.\n\nMoving on to the next topic, creating train, validation, and test sets isn't as simple as dividing up your data. Data leakage is a common pitfall where information from validation or test sets leaks into the training data, leading to inaccurate predictions. It's essential to maintain independence between the sets to ensure accurate model predictions.\n\nData leakage caught me off guard a couple of years ago, and it's crucial to understand how it can affect the performance of your model. Duplicates in the data, like having the same person in training, validation, and test sets, can lead to the model cheating on the test by recognizing the data it has seen before.\n\nThis issue became apparent in a previous job where predictive analysis was impacted by duplicate data entries, leading to inaccurate predictions. Understanding and preventing data leakage is crucial for ensuring the accuracy and reliability of your model's predictions.So what we had were multiple observations for the same person and we had the target, but the target was always the same gender for a person. Essentially, what we did was we didn't think about this. What we had were very similar observations because people's behavior is relatively consistent over time against the exact same label. We just divided our data up happily across the same data sets. \n\nThen we tested out our predictions and we were getting like 80% accuracy. We were like, \"Yeah, this is not great, but it's not bad.\" We were sort of looking at our features and we were like, it was things like the amount of time spent at home, the amount of time spent on weekends, the amount of time spent on Wi-Fi. We were like, it's really crazy that we're getting such good predictions based on these features. Then, yeah, they seem kind of not related. Yeah, kind of, I don't know, weak features, exactly.\n\nSo, what we realized is we had a really bad case of data leakage because essentially, it wasn't the exact same observations, but they were so similar with the exact same label. What we needed to do was obviously aggregate it, and once we did that aggregation, the model predicted at like 58% or something. It was so bad. So, in that way, that aggregation, let's say that particular example, how are you aggregating them? Yes, what were the ways of doing that?\n\nWhat we ended up doing in that case was we realized the problem was the duplication of the label. Okay, so what we ended up doing was per person, we just had one single observation that was their average or some, like depending on the metric, we had different summaries. \n\nYou were able to narrow it down into a single instance of the individual, exactly, exactly. At that point, all the signal disappeared, but it wasn't real signal, it was data leakage, okay.\n\nIs there other ways to notice that? What are ways that someone can try to look for that? I mean, you know, there could be looking for repeated rows or repeated instances of something, but I'm wondering if there's other methodology.\n\nSo, it can be really tricky to spot, and sometimes unfortunately, the only time you're gonna spot it is when you productionize a model and you realize it's not working, okay. But it can be things like, you know, just check the relationship between your variables and your outcome, and okay, you know, the one-to-one relationships. If you feel like, okay, they're actually really weak relationships, but for some reason, my model is performing really well, that should be a massive red flag, all right.\n\nI like that, like the time spent on Wi-Fi or something like that, yeah, yeah. And it's also like a lot of stuff with machine learning, it's just common sense. It's really not likely that you're going to end up with a super strong predictive signal for gender when basically it's like the amount of time someone spends home on the weekend, yeah. It's a pretty non-gendered behavior, so I would think, but I don't know, that does make sense to me, like, you know, maybe it could, like, I suppose it's sort of like a regional thing as well, so, like, I don't know, maybe places where there's more traditional gender roles, yeah, okay, but yeah, like, I would say we were just trying to predict for the whole US population, so I don't think that's really, yeah, no, it doesn't seem like a great feature to, you know, have to do lots of prediction from.\n\nThere's one other kind of thing to be careful of, and this is a bit more subtle with subtle leakage. So, basically, there are a lot of transformations that you can apply to text, so again we talked about those in the last episode when we talked about converting text into factorized forms. There are certain other transformations, so like one is standardization, which is where you might have a bunch of different variables that are on different scales. Certain models are quite sensitive to that, so you might want to scale them so that they have the same average and spread, so that you can compare them.\n\nI could think of an example that having just moved homes in Hawaii, have very, very small bedrooms, they're tiny and that could be an age thing too, like a generational thing when was it built compared to you know more modern homes but homes on the mainland of the US typically the bedrooms are a lot more sizable, yes, which is interesting. So I could see that kind of that imbalance that could happen, but also I would think of like homes that were built in say the 70s or even the 50s or whatever to you know the 2000s I think would be differently shaped in ways of using space.\n\nSo this is kind of like a subtlety, but it is something to be aware of if I were to do that standardization on my variables before I split my data into train, validation, and test.Because I used the mean and the standard deviation from the entire population, it might actually allow my model to have a little bit of a boost when it comes to making predictions in the validation of the test sets. It's a bit of preparation before splitting things apart.\n\nThis is one of the reasons why scikit-learn has this standardized pipeline. If you've used scikit-learn's methods, especially the data transformation methods, you'll see they have a distinction between a fit and a transform function. This is the same for NLP and standard scalar methods used for standardization. The reason for this is that you should fit on your training data and then apply that method with the parameters learned from the training data to the validation and test sets. You should never fit to the whole data and then transform them individually. It needs to learn the parameters only from the training data.\n\nMoving away from scikit-learn, pandas is indispensable. Pandas has a duplicated method, and you can also do aggregation using the group by method for explorations in matplotlib or Seaborn to check the relationships between variables. The duplicated method finds duplicates and labels them for you.\n\nImbalanced data and imbalanced targets can be problematic in machine learning models. If you're trying to predict something categorical with groups where one or more groups are much bigger than the others, it's an imbalance. For example, in house auctions, if 90% of the time the house doesn't sell, it creates an imbalance. This can be problematic because models can cheat by guessing the majority class, leading to inaccurate predictions.\n\nIt's essential to address imbalanced targets in the pre-training process to ensure accurate predictions. This is a critical part of the cleaning workflow and requires attention to detail to avoid issues with imbalanced data.Yeah, the models can get really lazy and they don't actually learn anything. So, if you're looking for something that is, what is the likelihood of this to sell? And you're trying to get a good idea, that's going to be hard to measure when so few things are selling. Exactly, okay, the likelihood of it landing in that is just the current what's happening. So, that's kind of hard to say that this is predictive or not based upon the current circumstance. And how do you eliminate that?\n\nThere are a few different ways of doing it. So, probably the most foolproof way of doing it is to actually balance your data. You try to do something to your data so that you have roughly, in the case that we have two outcomes, 50 percent of each of your observations being in one group or the other - auction sold or auction didn't sell. \n\nThe first way you can do this is what's called undersampling. Basically, you take all those auctions that were not successful, your 90 group, and you basically just randomly choose 10 of them so that you then have a subset which is roughly equal to your smaller group. Again, you need to have a lot of data to do this, and to throw away that much. So, there's kind of an alternative called oversampling and oversampling is just the opposite. You basically try to get more observations in that 10 group, the smaller group. \n\nAn alternative that's quite popular is using machine learning in order to do it. So, there's like a few different ways of doing this. A really popular one is called SMOTE, so it's basically like a statistical way of generating data based on what you already have. But there's also like, in recent times, companies have been coming out with more sophisticated ways of doing this. \n\nI've worked a bit with a guy from a company called Gretel and they basically specialize in creating synthetic data. It's grabbing the set of features and sort of creating randomizations in it that kind of work with the rest of the set. \n\nDepending on the technique you used, it'll be more or less sophisticated at doing that. So, okay, like a really naive way of thinking of doing it is, let's imagine we only have two variables. So we plot everything on a scatter plot, just a two-dimensional scatter plot, and what you would do in order to create new points is you would just start generating points that are close to existing points on that scatter plot. But if you want to do it for 20 features or 20 variables, you would just do that in 20 dimensions.\n\nAt Gretel, they actually do generation of more text data based on GPT3. With image data, you can actually generate more images by doing things like flipping around different pixels, changing the colors slightly, adding small distortions. \n\nSo, yeah, it's just a matter of getting creative and you can also use a combination of under and oversampling in order to even out your data. So, you're not limited to just one. I actually was in a position where I had enough data in this last job where we did have the luxury of chucking out a lot of observations. We had very imbalanced data, but we were dealing with something like 170 billion events a day.\n\nDuring my post-doc, I was doing some work to try and predict people's outcomes when they were admitted to the hospital with a heart attack. Basically, what we were trying to do was optimize their chances of surviving.So I made this model and I was predicting with like 90% accuracy that people would survive the hospitalization. I was like, this model is so great, like this is good, right? And then I found that it was predicting when people survived, but it was really bad at predicting when people actually died. I was like, God, this is a terrible model. \n\nOh, is that like the common Survivor thing that people present in the airplane where the airplanes that returned from World War II had survived but had these bullet holes? People survivorship bias, yeah. Survivorship bias is that kind of it? No, no. So the data was fine, but my model, my model was not fine. And it was because so many people survived the hospitalizations, the rate of death was actually very low. But what that meant was I had to do an adjustment to my model because I wasn't able to balance it in a productive way. It was just too imbalanced. I couldn't drop so much data. \n\nOkay, so the next way you can do this is by actually telling your model that your data is super imbalanced. And you can do this with both scikit-learn and Keras models. Basically, you can set a parameter called class weight and you can say to the model, \"Hey, just be aware this is not a balanced target. You need to take this into account when you're making the predictions.\" And it tends to reduce the impact of this sort of imbalance on your models. \n\nYeah, it's really like, it's elegant. Does that move into the hyperparameter kind of realm where you're adjusting these things to tweak the model in some ways? Or is this happening before that? Yeah, it sort of does happen at the model compile or the setting the hyperparameters. \n\nYeah, it's just passing parameters at the time you train. Okay, great. And it's like if you Google it, I think I've added some links for it, but it's super easy to use in both scikit-learn and Keras because they're both beautiful packages. I'm seeing your fondness for these packages, sorry. Like, scikit-learn has always been good since. But the interface for deep learning has come such a long way since I started in data science. I am actually so grateful for the time that people are put into this because it's now super accessible. \n\nYeah, it's really cool. And again, it's something I think we all love about Python, that it's such a great democratizer and you don't need to be like, what's the thing they say about people in Haskell? You need to have a PhD in Computer Sciences. That's not us, environment. Yeah, Python is for everyone. \n\nThis week, I want to shine a spotlight on another Real Python video course. It's about unifying multiple sets of data in pandas. It's titled \"Combining Data in Pandas with Concat and Merge.\" This video course is based on an article by previous guest Kyle Stratis. In frequent podcast guest and Real Python author Martin Royce leads you through the lessons, which cover using concat for combining data frames across rows or columns, building a multi-index data frame, recreating a new index after concatenation, using merge to combine data on common columns or indices, how to perform inner, outer, left, and right joins, customizing suffixes when doing a cross join, and avoiding common pitfalls when combining data in pandas. \n\nConcatenating and joining data in pandas is a frequent task for anyone working with data inside of Python, and I think it's a worthy investment of your time to learn these best practices. Like most of the video courses on Real Python, it's broken into easily consumable sections, and where needed, you get code examples for the technique shown. All of our courses have a transcript, including closed captions. Check out the video course, you can find a link in the show notes, or you can find it using the Search tool on realpython.com. Thank you. \n\nSo the last thing I just wanted to chat about in terms of imbalance targets is model metrics and how we actually measure performance. We've talked a bit about accuracy, and everyone loves accuracy. It's super easy to understand because it's literally the percentage of predictions that your model got right. The thing is, accuracy hides all sorts of sins, and when you have imbalanced targets, it can actually give you a really deceptive idea of how your model's going, like I was talking about with my survival and hospital model. My accuracy was great, but the model wasn't good because I actually needed to know equally how many people survived and didn't survive their hospitalization. \n\nWhat you can use is a bunch of other measures that are better at taking into account how well both of your outcomes are predicted. So you can use, you know, there's a bunch that people will have heard of like precision and recall, AUC or area under the curve is another popular one. Back when I was in epidemiology, we used to use sensitivity and specificity, which are the same, it's basically like, we're not quite the same, but the same sort of gist that it's how many of the positive outcome, you know, the number of people who survived did the model get right, how many of the number who didn't survive did the model get right, and how good is it at predicting each of those outcomes.I was thinking those terms are real close as far as they're just sort of like. Are they on the opposite side of each other like you're saying specificity? What was the other one, sorry, sensitivity? Yes, that's fine. Okay, yeah. So those two are actually like two sides of the same coin. Okay, precision and recall measure slightly different things but they are complementary measures. Okay, and basically the whole point with these measures is it goes hand in hand with what you actually want your model to do. So do you want your model to be really sensitive to one outcome or the other outcome, or do you want it to be really sensitive to both? And that's what you need to think about when you're choosing your metrics and working out like even if I've got imbalanced data, even if my model weights haven't corrected that well for it, if it really does a good job at predicting the thing that I want, maybe it's an okay model.\n\nWhen were you doing these, like how long ago were you? I feel like you've had an interesting career path. We've talked about a couple of times, and I'm just thinking of how long ago you were doing some of this stuff that was more in the healthcare kind of space. Yeah, that was a long time ago. So when did I start my postdoc? I think I started my postdoc in 2012-2013. So yeah, it was a really long time ago.\n\nNow, you've seen these tools advance quite a bit hence some of the affection that you're giving to them now. Yeah, yeah. And it's also interestingly like many data scientists in academia, I started out in R not in Python. But yeah, I don't know if I told you this story. I actually taught myself Python when I was procrastinating one day during my PhD. I didn't learn it in one day, but like right, I decided to pick it up one day that's like me on R. Yeah, somebody was doing other work, and I said, well, I should understand how they're doing it.\n\nHere, yeah. So it's interesting how you can kind of see the correlations between the two languages. And it's sort of like what I really liked about R, I think when I was first starting is it was, and it still is, like extremely good for traditional statistics. Yeah, whereas I think Python has caught up on quite a lot of that, but it's really made its mark on machine learning, and its ecosystem is magnificent. Yes, the ecosystems. I don't think you could compare it. You could try. That was the other thing I was able to be tasked with often was like, \"All right, we would like this R thing to run in Python, and are we like this Python thing to run in R?\" It was always a little bit of work. It can be done, but it was always hoops and so forth. It would always usually be better if they could stay in their own little ecosystems. Sometimes exactly, yeah. And I think this whole debate about like one better than the other is a bit of a misnomer. Like I think they're just better for different things, they were definitely, yeah. Yeah, and they might be better for different people too. I think so as well, yeah. I think so, okay.\n\nBut yeah, just to round off the discussion about model metrics, as always, there's a whole bunch of in-built tools. One of my favorites is there's a method called classification table in sklearn. So that just basically spits out a whole bunch of different metrics, and if you try to predict more than two classes at the same time, it spits it out for each of them. It's very informative. When you are actually training models in Keras, you can tell Keras which metric you want it to optimize against. So you can actually say Keras, I want you to optimize against the area under the curve, not accuracy, because okay. So it's again, it's super straightforward. The API is really nice. Does that let you check your work then to see if you missed for some of these things or it's either to detect some of these problems that we've just been discussing? This is more sort of a decision that you would come to. So you'd be like, okay, I've got really imbalanced data, right? And it's important for me to be able to predict both things equally well. What I'm actually going to do is tell the model that it needs to optimize not against accuracy because I know accuracy is not going to help me here. Because I'm dealing with a lack of balanced data, balanced, okay, yeah, yeah, yeah. This would be more something you would check again like as part of that data screening. So like if you're going through with pandas and you run a value counts of your target and you realize, whoops, like 90% of my observations are in one group, right? Yeah, yeah, totally, okay. Nice.\n\nYou provide a whole bunch of interesting advice here, like different things to look at, and a lot of this is in your article that you wrote on a JetBrains DataLore Blog, is that right? Yeah, yeah, exactly. I actually gave a talk about this. That was one of the talks that I gave, the one I gave in Oslo. The recording of that one should be up relatively soon, but okay, we could always update to include it.Yeah, I will actually be giving the same talk on Saturday. Oh, wow! Yeah, I'm heading off to Belgium for a conference called Cloud Brew. So, I'll be presenting the same talk that I gave in Oslo. Is that how it's spelled? Is it like the word cloud and then Brew?\n\nOh, it's actually because the conference is held in a converted Brewery. So, okay, yeah, which could be an interesting weekend, it's a confusing evening after your talk, I think so.\n\nI am flying the day after that, the next day. So, yeah, I should be able to make it to your point. It's just from Belgium, it's fine. Wow, that sounds like quite the destination. Please, that sounds fun. I like Belgium a lot, so yeah, I'm happy to go back.\n\nCool, so yeah, I'm super passionate about this topic actually. I'm obviously passionate about NLP as well, but this is more where I cut my teeth and really fell in love with statistics and science in general.\n\nIf anyone listening has any questions they want to chat about, please reach out to me. I would be very happy to talk to you about it. It's a good way that people can do that. I am on Twitter. We'll post the link to that. I have joined Mastodon. So, okay, I've made the leap. Which server are you on there? I'm on a Foster Don. That seems to be the slight consensus in at least my Python group. I saw Brett Cannon was my first leading indicator there and then a bunch of other open-source people. I was like, \"Oh, okay, we're all kind of moving here, which is good.\" I saw the Anthony shows there and then came to you. And then after I moved over, Real Python and the PSF did, and I was like, \"Okay, I chose the right side.\" Yes, okay, good.\n\nWe'll include the links for that in case people are not familiar with it. But yeah, it's been an interesting month as far as how to catch up with people. Talk about signal versus noise. There's way more signal there, which I enjoy. Same, same. I'm just waiting, I think, for the machine learning community to catch up because the machine learning community on Twitter is super exciting, slightly overwhelming. It's a bit like a fire hose. Oh, okay. But it would be cool to see that same sort of energy over on Mastodon.\n\nAny other talks coming up? You mentioned the Cloud Brew one, which I think will happen just before this comes out. Anything else planned? Are you going to be able to take some time for the holidays?\n\nThankfully, I'll take some time for the holidays. The last conference I have, but I'm obviously not presenting there, is re:Invent for AWS. Okay, so that'll be the end of this month. And then I will be settling in and doing all my Christmas baking. Very quiet December planned. Probably heading to PyCon in Salt Lake this coming year. Yes, and you said, do you already have the mentor for your talk for that? That's good.\n\nYeah, I know it's super competitive, so I don't have, let's say, I'm not optimistic about being accepted, but you know, you gotta be in it, so why not? Yeah, definitely. Any other updates there? I actually have a couple of cool webinars coming up. Unfortunately, I think one of them is going to be after this, so I won't mention that. But I've got one at the beginning of December where I've got some guys coming on to talk about sustainability research in data science. These guys I met them at PyCon Portugal, and they're part of a sustainability research group called Holland. Basically, these guys will take on small contracts and look into how to improve problems related to safety and sustainability in cities. The one that they're going to be talking about on the webinar, which is on December 8th, is about how to increase people's uptake of micro-mobility, things like e-scooters, e-bikes, and actually working out whether they're going to make an environmental impact, how that environmental impact can be most optimized, and some of their other cool stuff was they did a study looking at how they could make dark corridors for bats to fly across Bristol. So they didn't make the streets too dark and dangerous for people to walk around, but they also made these corridors so the bat populations could connect together. So they're doing really cool stuff, so I'm looking forward to that one.\n\nThat's fun stuff. So you're sort of hosting that? Yeah, I'll be hosting them. Oh, nice. I'll send you the link for that one as well, and we can add that to the notes. Definitely. I'll include it. Well, I want to say thanks again for coming on the show and sharing all this information with me. It's been really fun to talk again, and I hope all your holiday stuff goes great and your upcoming webinar. That sounds fun, and also your visit to Cloud Brew. It'll be productive. Okay, I'm a professional. Come on and have a couple of brews for me. Yeah, I'll do it.I'll do it awesome. Yeah, it was a pleasure as always. Thanks again for having me on. Alright, thanks. Bye.\n\nAnd don't forget to see Data Software, simple cloud data connectivity to SAS, big data, and NoSQL from Pandas SQL Alchemy Dash and Pedal. Learn more at cdata.com.\n\nI want to thank Jody Burchell for coming on the show again this week. And I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "7a8WrmraBfE": "Welcome to the Real Python Podcast. This is episode 136. How do you start packaging your code with PyProject.toml? Would you like to join a conversation that gently walks you into setting up your Python projects to share? This week on the show, Christopher Trudeau is here bringing another batch of PyCoder's Weekly articles and projects. We discussed a recent code conversation featuring Real Python team members Ian Curry and Garana Yella. The video dives into the officially sanctioned way to configure your project using a PyProject.toml file. We cover how this relatively new method will help you package your code for use on your system or for sharing with others. \n\nChristopher shares a Real Python tutorial about using pathlib to get a list of all files within the directory. We're both fans of pathlib and how it simplifies working with file paths. This tutorial digs into methods to recursively list all directory contents or create a conditional listing. We share several other articles and projects from the Python Community, including the explanation of Python bytecode, why it's always to use closed-open intervals, a discussion about building the monolith before microservices, how to parse natural language time and date expressions, and a project for posting on Mastodon. \n\nThe InfluxDB time series platform empowers developers and organizations to build real-time IoT analytics and cloud applications with timestamp data. Learn more and start for free at influxdata.com.\n\nAll right, let's get started. The Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Christopher, welcome back. Hey, good to be here. Hey, I'm excited to dive in. Today, we are bypassing the news segment and digging right into some articles. So what do you got first?\n\nSo this first one is a general programming article and not Python specific. It's called \"Always Use Closed-Open Intervals\" by Fernando Hurtado Cardenas. It explains why in most programming languages when you specify a range, the pattern for specifying the range has a closed interval at the bottom and an open one at the top. So in Python, if you actually think of the range object function, it's not really a function, but let's not get into that. If you do, say, range(0, 5), you get from 0 to 4. So the pattern is including items in the range that are greater than or equal to the bottom part, but only less than the top part of the range. And this pattern shows up in all sorts of places in Python. You see it, like I said, in the range function, in list slices, in JavaScript, you see it in array slicing, in Java, there's a list sublist method. Even in SQL, the limit operator works the same way. If you ever wondered why, and I hadn't until he asked the question, this article explains it. \n\nHis first explanation for why you want to do this is so that you can easily specify empty intervals. So if you think about range(0, 0), that's empty, right? That makes sense. Well, if you'd use the closed-closed pattern instead, that wouldn't work. The upper boundary would actually have to be less than the lower boundary in order to specify empty, and that's kind of weird looking, right? An inverted kind of looking. It would just be like, what would 0, 1 - 1 mean? And that starts to become messy. \n\nThe second, which is kind of a variation on this, but it's very specific to time, if you want to specify a 24-hour interval, for example, that ends on the hour with closed-open, the upper thing would have to be minutes or seconds before the interval. So, as an example, let's say we were doing 2 AM to 2 AM. If you were doing closed-closed, you'd have to do 2 AM to 1:59:59 to whatever your resolution is, right? So again, ugly, but closed-open allows you to just say 2 AM to 2 AM. \n\nThat comes up often in other computing solutions all over the place. And in fact, I'll come back to that in a second. It's been around for a long time. The other thing is this pattern makes it really easy, particularly if you're dealing with integers, to determine the length of the interval. It's just the upper bound minus the lower bound. So back to my range example, 0, 5, the length is 5. It's 5 minus 0. I think I did that right. I didn't even use my fingers. So there you go. It makes the math nice and easy. It's not an overly complicated or long article.I like this kind of thing that drills down on something that you see everywhere and have never really otherwise stopped and thought about. Fernando closes off by saying that when he was doing the background research for the article, he came across a note from the renowned computer scientist Dykstra indicating that he favored the closed-open pattern at Xerox Park in 1982. They found that when you use this pattern, your code was simpler and less buggy. This idea has been around for quite some time and it's really one of those things hidden inside of programming languages that you never think about before. It was a neat read.\n\nThe time example was perfect. That one really hit home for me because 159, 59, 58, or 99 milliseconds are just awful. It can be very messy. This would then be inclusive in that way and even slicing and other things that make sense. Initially, it's a bit of a barrier for a beginner and that's the one challenge. I was actually doing some teaching for a very introductory course to Python this week. As a programmer who's been doing it forever, the idea of zero indexing, the idea of this kind of stuff, it's just how it is. You don't question it. Then a student goes, \"But why?\" and it's like, \"Yeah, because of history.\" It's nice to have something short to point to in that sense.\n\nOne of these new things that we've been trying out over the last six months at Real Python is the idea of code conversations. The idea is to take something that's not an article, but maybe a thought or an exercise or a question that came up and dive in and have a conversation about it. There's a recent one where Garana was traveling in Europe for different conferences and ended up seeing Ian Curry. They decided to record a code conversation about Pi Project Toml, which has been in the news a lot lately. The title for the code conversation ended up being a video course for us: \"Everyday Project Packaging with Pi Project Toml.\" In the code conversation, you'll learn how to package a project, starting with a small CLI project and moving all the way to how to package it and install it on your machine using pip.\n\nGarana shares his history with Python, which dates back to the late 1980s. Python has had to adapt to the idea of sharing code and packaging, and there have been many different ways people have looked at how to do that. Standardizing it has been a rallying cry as Python has advanced and the sharing of code has become more common. They talk about demonstrating this relatively new and officially sanctioned way of doing it.I really like that there's a set of benefits you get out of it. The code conversation is about 50 minutes long. It's one of the most gentle ways to get introduced into packaging and the concepts. It's a nice way to understand with a whole bunch of resources for you to jump off and go further with. Links to the sites are provided. They spend time talking about not only the history that was mentioned but also why it's important to be able to call your project from anywhere, have consistent imports, a single file that might work across multiple build systems, and structuring files and folders correctly. Understanding the different ways that you can run your script and exploring some of the background behind the packaging world and why the standard is good for that. They talk about the setup tools and how to use that. I found it to be a really great resource, so I talked to Dan. Normally, we share a preview of one of these code conversations or one of our courses for our subscribers. But we thought this is a really great resource that if someone isn't familiar with the types of content that you can get from Real Python beyond the articles and snippets or beginning parts of some of these video courses, maybe we could share this as a complete thing because it really is a complete structure. I had no idea how I could cut it apart and have it be something that someone can walk away from and say, \"Hey, I got something out of this.\" It was really just getting going about 20 minutes in. It's available on YouTube as the complete thing. If you're not familiar with the fact that we have a Real Python YouTube channel, I want to say hello to all the people that listen to the Real Python Podcast on YouTube. It still surprises me that it's a common way, but I'm always listening to podcasts on the go, so I use a podcast app. But I know that it's popular, and I see you guys out there and I see what you're saying. We put out snippets of some of our courses every week. Please check out the YouTube channel if you haven't yet. This is a great resource that's in its entirety on there, and then it links back to some of the resources on realpython.com to learn more. So check it out. It's \"Everyday Project Packaging with PyProjectToml,\" and I'll include links in the show notes, not only to the course page where you can see it formatted and how it's kind of divided up normally, but I'll also include the YouTube link so you can check it out in its entirety there as sort of a holiday gift.\n\nThe packaging stuff is a mess, and the community has slowly been trying to get it under control. My most recent package that I published, up until now, I've been using a fairly old mechanism for doing it. Just a couple of months ago, I put out a new one, and I decided, okay, I'm going to experiment. It was a tiny little open-source thing, but part of my exercise was I'm going to do this a modern way. It was the first one where I actually used PyProjectToml and some of the newer mechanisms for doing it. There were a couple of things where I was trying to fight because I was trying to keep my old way, and I gave up and I'm like, okay, I'll just do it the way it says, and it all worked magically if you follow instructions. There are some good templates there. What I found is that the internet is not helpful because this is such an ongoing thing that everyone's got an opinion, and it's often hard to find from an article what the date of the article is. So you get a little piece of advice, and you'll try it, and it doesn't work. That's because it turns out it was five years old. A big resource for me, just as a shout out, is one of our fellow Real Python users, Dane Hillard. He's got a new book coming out called \"Publishing Python Packages.\" It's in early release, but it is available in electronic form online. We can include a link, and it's a great deep dive. It covers this and how to integrate testing and all these other pieces that you need to know if you're trying to share these kinds of things with other people. It's nice that it's all in one place, and it works from top to bottom, and you've got the sample code. I found it much more helpful than trying to figure that out for myself on the internet because the internet has this is one of those places where there are too many answers, and it's hard to figure out whether or not you're reading the right one.Dane's been on the show a couple times. We talked about that book and his process in writing it. He's also been on the show to talk about the concept of becoming more of a python professional and what that involves in terms of structuring code and moving beyond working as an individual to working in an organization. This led to a much deeper conversation about build systems that I have coming out next week with Benji from pants build, which is a really neat system. There is a lot of interconnectivity there. I'd love to give another shout out to Dane and his new book, so we'll include the link for it there.\n\nAre you building real-time applications? Check Out influxdb Time series platform. Influxdb is optimized for developer productivity, allowing developers to build IOT analytics and Cloud applications quickly and at scale. With its data collectors and scripting languages, a common API across the entire platform, and a highly performant time series engine and storage, influxdb makes it easy to build once and deploy across multiple products and environments at the edge, on-prem, or in the cloud. Check it out and start for free at influxdata.com. Thank you.\n\nWhat's your next one? This is my real python article for the week by Ian Curry, titled \"How to Get a List of All Files in a Directory with Python.\" The article focuses on using pathlib if you're still using the OS module for path-related tasks in Python. If you're using a more recent version, like python34, you should switch to pathlib. It's a superior library that treats paths as objects rather than pure strings. When composing objects together, it overloads the slash operator, making the code more readable. The article begins by showing how to create a path object and then moves to the iterdir method, which is a generator that provides a new path object for each file in a directory when iterated over. It also explains how to use is_file or is_dir methods to filter files or directories inside a directory. The article then introduces glob, a file pattern specifier, and shows how to use it for file patterns and filtering directories based on Boolean conditions. It also explains how to write a file listing filter to skip certain subdirectories. This article is a great resource for those unfamiliar with pathlib.\n\nBehind the scenes, there was a conversation about whether there are too many articles about pathlib coming out.And yeah, just be aware that there's a handful of other things coming along. I don't think it's bad to have a little focus on it for a while. That's pathlibweek at Real Python. There's nothing to celebrate. Welcome to join the path. \n\nAwesome, so my next one I was very intrigued to see this kind of come up and to see lots of different things about it. I don't want to spoil the meat of it because I think reading the article and working through the code are something that you should do and practice if you're interested in getting into this. It's sort of an article/GitHub repo by Michael Moser. The title is \"Python Bytecode Explain,\" but that's just a portion of this larger project that Michael has, which is an advanced course on Python 3. It gets into lots of other things like decorators and other areas of Python that a lot of people would say are advanced. \n\nAgain, I'm not going to do a super deep dive into how it really works because it's very technical. It helps to really look at the code, hence why I'm kind of showing it. The idea is to use some tools to look at how Python code is actually operating. It helps to explain complex things like decorators. \n\nI have had conversations with a handful of other people about this, and it's been kind of a journey. If you've been along the ride, back in episode 39, I was talking about generators and coroutines and learning Python through exercises. The title of it was with Reuben Lerner. Reuben uses this disassemble feature that's built into Python where you can have it show you the bytecode printed out. It's very fascinating to look at. \n\nA real neat way if you're the type of person who likes diving into technical stuff. It's a great self-learning tool to dig through that. Unfortunately, there's some vocabulary you need to understand, and Michael has created a tool to help with that. It explains some of it and provides links back to the Python documentation. \n\nPython is an interpreted language. When a program is run, the Python interpreter first parses your code, checks for any syntax errors, and then translates the source code into a series of bytecode instructions. The bytecode instructions are what are run by the Python interpreter. The bytecode deals with two entities, a memory store that keeps functions and data items, and a stack used for evaluating expressions. \n\nThe Python interpreter works as a stack machine when it evaluates bytecode instructions. This means that values are moved from a main memory store to the stack where the expression is evaluated. Then the result is moved back to main memory. \n\nI just dug this article, I thought it was well done. As a research tool to learn more about what's happening, Michael built a set of tools. This is part of that package on GitHub. He has this thing called \"Pi ASM tool,\" and inside of it, he created a \"prettifier\" called \"pretty dis\" which provides more detail on the line number and what is being called at that point. \n\nThere's a true/false flag where you can have links directly back to the Python docs. This repo goes through learning by looking at disassembled code, learning, and expression evaluation.And then he has examples of function calls, loops, classes, dictionaries, and lists. This is definitely one of those things that I would use to kind of learn a little bit more. I've been interested in byte code and kind of what's happening, and sort of understanding what's happening at the bottom level. I've talked to multiple guests, the other guest I've mentioned before is Brett Cannon, and we've talked about his unraveling Python syntax series. And a note on that, Brett is done, he's finished unraveling it. His most recent article, which I thought was funny, is called \"MVPI - The Minimum Viable Python\". Over 29 posts spanning two years, this is the final post in my blog series \"Python Syntactic Sugar\". It's been interesting to kind of see how sometimes in his unraveling, he would go into the byte code and explain some of the stuff that's happening.\n\nBut generally, in his unraveling, he was very often using Python to sort of explain Python, which is interesting in and of itself. I applaud Michael's work here, I think it's a really good resource if you want to learn a little more about it and some nice little tools. And also, kind of a neat way for you to dig in and learn a little bit more about what's happening under the hood with Python. One of my favorite examples of this, and it often comes up when you're dealing with multiprocessing, threads, and sort of parallelism, yeah, frequently. And we see it in the comments on our articles and courses, it's, there's a single line of Python, how can that single line be a race condition, right? Because it's only a line. So how can I get a race condition out of only a line? And the answer to that is disassemble the line. It's not one thing, it might be four things, and that's why you have a race condition because one thread is halfway through those two, the first two, and the other thread starts and that messes with things. So it's one of those places where as you're getting deeper into the understanding of how these pieces fit and what it looks like.\n\nYou know, I don't think no one's ever going to write the byte code, but understanding, unless you're getting deep into, you know, the compiler and contributing, you know, to see Python itself, but understanding a little bit about how these pieces work. And this circles back to the conversation we had a couple episodes back about the optimizer that was added to 3.11, yes, which is adding new byte codes here. And it does some dynamic replacement of those byte codes in order to give you speed up. So having understanding of where these pieces are if you're getting deeper into the language can benefit you, know how fast your code is and tricky little bugs like race conditions. Yeah, it's always been one of these things where I'll see something and be kind of confused by it and kind of do that self-journey. And this one with byte code, it's there's this whole set of vocabulary that it's like, what does all that mean and kind of understanding it and slowly seeing it unfold.\n\nAnd I think this is a nice introduction to that if you need a place to learn it and if you want to become a language geek, these kinds of stack-based machines are used in other virtual machines. Java's mechanisms are identical and some assembly languages actually work this way as well. So this isn't something that Python invented. This is an old wrench that is used commonly at a lower level than most people code at.\n\nThis week, I want to shine a spotlight on another Real Python video course. It's about a topic we touch on this week, working with files and directories using pathlib. The course is based on a Real Python tutorial by Garana Hiala, and in the video course, Darren Jones takes you through how to work with file paths in Python, reading and writing files in new ways, manipulating paths, and how to pick out and work with individual components of a path. How to move and delete files and listing files and iterating over them. I think it's a worthy investment of your time to learn how to manage files and paths in Python, and pathlib will help you do that in an elegant, readable, and Pythonic way. Real Python video courses are broken into easily consumable sections and where needed include code examples for the technique shown. All lessons have a transcript, including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the enhanced search tool on realpython.com.\n\nWe have a discussion topic this week. It's kind of funny how it kind of came up. We were thinking about, well, what should we talk about this week, and then you're like, well, this might be good. So normally when we do our discussion about discussions, that sounds very meta, we usually find something like Hacker News or a Twitter post where there's a whole bunch of people talking about some opinions, and then we weigh in ourselves. And this week instead, we're going to talk about an article and just weigh in directly. This is us discussing it, and rather than the internet discussing it and us discussing how the internet discussed it. Anyways.Okay, the article is by Chris Klug and it's called \"Build the Modular Monolith First.\" It discusses the pros and cons of monolith and microservice architectures. Mr. Cook believes you should wait before building a microservice. There is some sample code inside, not in Python, but it gives you an idea of the structure. \n\nYou need to do a quick search and replace in your head. Every time you see a brace bracket, think of it as an indent. Ignore the word \"public.\" The class definitions and structure of code are discussed, focusing on classes, users, and inheritance.\n\nMonolith and microservice architectures are opposing approaches to building software. A monolith is a single program, while microservices are a collection of programs running in their own space. Microservices are popular due to their organizational benefits, allowing independent teams to work on pieces and release on their own schedule. However, this also introduces complexity as it is a distributed system.\n\nThe article suggests starting with a well-architected monolith before considering microservices. It questions whether the scale of microservices is truly needed and emphasizes the importance of understanding the complexity they bring. \n\nIn conclusion, the decision between monolith and microservices depends on the scale and needs of the project. Starting with a monolith and transitioning to microservices if necessary is recommended.I think testing is a big factor that has been mentioned several times, especially for someone working on a separate team. Communication factors play a role as well. When they push an update, how do they test how it integrates with the rest of the system? It's important to let people understand that this is new and could cause problems. Making sure that it's more complicated to see from a modularity perspective, how things are imported and used in a monolithic system. Unit tests can provide better confidence in quality, especially with 80% coverage, treating it like a black box.\n\nIn a microservice, testing becomes trickier as you have to figure out how the two services interact. It's common to have multiple services in a microservice architecture, which can complicate things. Services tend to breed more services to reap the benefits but end up with many small services. Keeping it small and focused is the essence of microservices.\n\nConnections to a database in a monolithic structure wouldn't be considered a microservice. Monoliths can face similar challenges at scale with network issues and race conditions. Microservices compound these challenges by having more services. Using technologies like Flask or Django to set up microservices can help visualize the complexity initially. APIs like REST or GraphQL are commonly used to interact with microservices, tying back to technologies like Ninja or FastAPI.\n\nIn the industry, there's a common refrain about the complexity of microservices and the challenges they bring. It's important to understand the intricacies of setting up and managing microservices to ensure a smooth operation.I think the article itself even uses a quote but doesn't attribute it, so I looked it up. It was from Martin Fowler. The first law of distributed object design is: don't distribute your objects. That was like, I don't know when he wrote it, but he coined this, and this article is from 2014.\n\nThe other thing that I saw actually just this morning was a post from a little while ago by Jason Warner. It's a tweet thread basically saying, \"I'm convinced that one of the biggest architectural mistakes over the past decade was going full microservice. On a spectrum of monolith to microservices, I suggest the following: monolith is greater than apps is greater than services is greater than microservices.\" He has a lot of different thoughts.\n\nI had a conversation earlier this week, which will come out following this, with Benji from Pants Build. We talked a little bit about how the structure of your code works and how it can lead to complexity in testing, building, and addressing weird little problems. Structurally, for the team, it can lead to fiefdoms as far as who's in charge of what services, which can add another level of complexity.\n\nI think with the advent of agile methodologies, building small teams has advantages. Having a small team responsible for a chunk of code without having to consult another team for decisions has benefits. Architecturally, you're drawing a box and saying, \"Okay, you get to do whatever you want inside this box.\" Enforcing discipline becomes key in microservices as the interface to another box is an API.\n\nThe question arises of whether the cost of discipline in a monolith system is more than the complexity of a microservice architecture. Projects have been shifting to explore new potential solutions for communication in the internet, especially with the current state of Twitter being a mess.\n\nIt has been a good resource to find guests, communicate with people, and gauge community trends. However, the situation at Twitter has prompted many to seek alternative platforms for communication.I have been checking out Mastodon, and one thing I wanted to share is a Talk Python episode that brought in people who have been using Mastodon longer than Michael. One interesting discussion point was the basis of what Mastodon is built on. I found it fascinating that Mastodon is built on ActivityPub, which is a W3C recommendation dating back to January 2018. This standard is recognized by the W3C, allowing for server-to-server interactions and various types of projects beyond microblogging.\n\nThere are examples of projects like photo sharing and book recommendation sites that can use the ActivityPub service. If you're interested in development, it's a great area to explore. I came across a simple API interaction command-line tool called Toot, which allows for quick and simple posts.\n\nI joined a Mastodon instance called T-o-d-o-n, which was relaxing and calm compared to Twitter. It's a useful place for communication within the Python community. While it may not have all the features of Twitter, it's a great alternative for conversations and sharing information.\n\nFor those transitioning from Twitter, there are tools available to help follow people from other services. Overall, Mastodon offers a different experience and a place to learn about what's happening. As for my project this week, I wanted to share Quick Ad, an open-source project by Acrium for developer-oriented task and knowledge management. Quick Ad is a natural language parsing library for date information, based on CT Parse by David Batista.So for example, you can use the phrase \"beer Thursday at four\" and it will turn that into an interval object that specifies the date and time of the event. It also handles durations, so saying \"beer in four hours\" will give you a countdown kind of thing for the four hours from now. CT parse processes both German and English at the moment, and it's built in a way that you could add other languages if you wanted to. It uses essentially a series of regular expressions and then a rule decorator that ties the regexes to the resulting objects. You don't need to understand any of that to use this, but it was kind of interesting how they approached the problem.\n\nNice, what Quick Ad provides on top of CT parse is more rules and recurring events. This allows you to process things like \"beer daily at 4 pm\" and it understands grouping phrases like weekdays. There are also some additional features for handling the differences between the US and European style dates. For example, \"five three\" could be March 5th or May 3rd depending on where you're coming from. So you can annotate your parsing to tell it that you're talking to a European, rather than the other way around. I gotta get in my American dig, it's a Canadian requirement.\n\nGoogle Calendar kind of has this feature sort of built-in. I don't know if you've ever run into it, where if you're writing time descriptions in a calendar event, it automatically adjusts the time of the event for you. So if you're looking for something similar to provide for your users, these two libraries are worth checking out.\n\nThat seems like such a great tool that you can go into a calendar and just, especially with other things maybe feeding into it like the idea of natural language processing or even voice processing. Being able to speak into it, you get into the, like, I think Gmail had, I don't know if it still has it, for a while there they had some things like if you put certain phrases in your email, you could get a button that was like, \"Oh, I gotta turn this into an event\" kind of thing, right? So it handles that kind of throw it into your calendar. That's great. I definitely like the sometimes it was always such a thing of like, how do I need to speak? Yes. And regexes are not going to be that's it's not like it's full NLP, you have to match the phrase. I suspect it probably works far better if you're doing specific processing, as in, give me a window where I can type something in, rather than if you try to run that over large bodies of text, you're going to get a lot of false positives, I suspect. Totally awesome. Well, thanks again for bringing in all these articles and goodies this week. Always fun. And don't forget, easy to start and scale InfluxDB time series platform is available in the cloud, on premises, or locally. Get started for free today at influxdata.com.\n\nI want to thank Christopher Trudeau for coming on the show again this week, and I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey. I look forward to talking to you soon.",
    "04DIQnsVpCg": "Welcome to the Real Python Podcast. This is episode 137. What advantages can a build system provide for a Python developer and what new skills are required when working with a team of developers? This week on the show, Benji Weinberger from Toolchain is here to discuss the Pants build system and getting started with continuous integration. Benji is one of the core devs on the Pants build system. He talks about the software tools and processes a build system simplifies. We discuss how an individual developer can take advantage of continuous integration, and we also cover some of the expectations when moving into professional software development.\n\nIf you've learned about or started to use tools like linters, code formatters, import sorters, type checkers, and packaging systems, a build system is designed to combine all of those tools into a simplified one-step process to share your best code. Benji explains concepts like fine-grained invalidation, moving to a mono repo, and using a build system for data science projects. He also shares his tips for getting started with Pants and how to find help within the community.\n\nThe InfluxDB time series platform empowers developers and organizations to build real-time IoT analytics and cloud applications with timestamp data. Learn more and start for free at influxdata.com.\n\nAll right, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHi Benji, welcome to the show. Thank you, great to be here.\n\nYou had reached out a little while ago to talk about the build system that you work with, which is called Pants. You had been on Talk Python recently, and so I thought maybe we could steer the conversation in kind of a beginner to intermediate kind of direction. Maybe we could talk a little bit more about how somebody gets involved in using tools like this. You kind of suggested that to me, and I thought that sounds fantastic. It made me think about a conversation that I had with Dane Hillard. He had written this book, the title is \"Practices of the Python Pro.\" We had this conversation in episode 49 about these sort of challenges in developing into that, and it was much more from a software design aspect. I thought, wow, that sounds cool. We could kind of talk about it more from a tooling aspect and understanding some of those things as maybe becoming a little more of a professional in that way, less of a programmer and more of maybe that concept of a developer. I guess maybe the first thing we could start off with is tell us a little bit about the tool that you were involved in creating.\n\nRight, yes, that's right. So I have been one of the creators and core maintainers of a build system called Pants for many years now. The system has undergone several iterations. Its first few years were more of an internal tool, there wasn't much of a community around it. But with what we unimaginatively call Pants V2, we launched in 2020. Its focus, unlike earlier iterations and earlier work I'd done, had a very strong focus on Python use cases. It supports other languages as well, such as Go, Java, Scala, Kotlin, Shell, and there are several others in the works. But there was a huge amount of focus in both the design and implementation phases on Python. There are several reasons for that. Just kind of as an aside, where did the name come from?\n\nThe name has a history that's completely irrelevant now. It started out in its very, very earliest iteration as a python script to generate ant.xml files for use in JVM builds. That's all it was. So it was an acronym of like \"Python Ants.\" Even though not a single line of code remains from that very early legacy, the name somehow carried through all these different designs. It makes me think of Worldwide Pants, David Letterman's company that he had started.\n\nOh, that's right. Yeah, yeah. So I think he just thinks the name or the word Pants is funny. But it kind of suits in some ways.\n\nWell, it's especially funny and odd for me because, as you can probably hear, I'm from the UK originally, and over there, pants means underpants.\n\nRight, so it's much worse. People don't like that word like they dislike other words here. At the time, you were involved in it as more of an open-source thing, and then the organization Toolchain came after that.\n\nExactly. So Pants started out really as, again, that very early version I referred to. Some iterations that came after that were really more of a thing that was hacked together initially internally at Twitter, where I was working at the time. This was about 2010.And then a little later at Foursquare where we open sourced it out of Twitter. Then I was working at Foursquare, it was a very small scale thing, pants V2, which we started working on under the same umbrella but with a different design around 2015-2017. We finally launched it in 2020 as an open-source project, building a large community around Python and Python use cases. The community is large, growing, and very active.\n\nThe company is currently the lead sponsor of the open-source project and Tool Chain exists to provide the necessary commercial framework around this open-source project. People often say their company would like to use it but need Enterprise-level support, Professional Services, or SAS for remote execution and caching capabilities to make the system fast at scale. We exist to provide all of that and help organizations speed up their testing, packaging, and building workflows dramatically, both on the developer desktop and in CI.\n\nIt's a neat solution to help maintain open-source projects running and funded. Organizations like open source but often need additional support, which Tool Chain provides. There's always a tragedy of the commons with open source, and we're trying to provide a way for companies to engage with open source in a commercially suitable way while respecting the open-source community.\n\nContinuous Integration (CI) is something individuals should use as it's never too early to adopt software quality control best practices. When you start building things, the focus shifts to quality control, writing testable code, running tests effectively, and iterating quickly without compromising quality. Designing CI and selecting the right tooling becomes essential in Industry.\n\nIn academia or learning programming, the focus is on building things, but in Industry, the emphasis shifts to preventing projects from falling apart and integrating work with others seamlessly. Structuring code, making changes, and ensuring code can be tested and integrated with other work becomes crucial. Developing into a Python professional involves looking at code structure and post-rewrite considerations.\n\nI entered Industry with little experience and learned the importance of quality control and integration on the job. Internships are more common now, but back then, I had to learn on the job. My initial knowledge was only a small portion of what the job required.I was pretty content with whatever existing tooling was there. When you're very Junior, you don't ask a lot of questions, you just accept things the way they are. A really eye-opening experience for me was after five years at other companies, I went to work for Google. Google is well known for putting a tremendous emphasis on developer productivity, best practices, code quality, and tools to enforce all of that. That was my first encounter with tools that were good by the standards of the time. I'm sure they've improved dramatically since then. It was more of an attitude and a frame of mind that says tooling, code quality, and best practices really matter. That's when I first encountered that.\n\nThat was the example for me. I got personally involved in developing these kinds of tools after I left Google. I noticed that the rest of the industry had not caught up. I was suddenly thrust back into the past with slow, flaky, broken builds, tooling that barely did what it was supposed to do, and everything felt incredibly fragile. People were not adhering to best practices because the tooling wasn't there to support good practices. That's when I started actively trying to fix this problem.\n\nUnlike almost every other profession, the tools we use to build, test, and maintain software are themselves software tools. We have the ability to build our own tools. It takes that flash of insight to realize that we have everything we need to solve this problem, and then actually solve it.\n\nWhen I worked at Twitter, it was more of a local decision for a specific repo, and people were open to it. When I went to Foursquare, they were much more centralized and open to anything that would improve compile times.\n\nThe first tool a developer should know is Version Control, most likely some version of git. I was just beginning to learn git when I left Google because Google internally uses perforce, which is a very different tool with different idioms. Git has become the standard almost everywhere now. My very first job used CVS, which is prehistoric by today's standards. Git is now the standard for all but the very largest code bases where git can't quite scale.Once the person has a good understanding of the fundamental concepts and can use them as an individual, the next step is to focus on Python. The Python tool chain is very rich with numerous tools such as pip, setup tools, Pytest, Flake8, black, mypy, pyrite, doc formatter, and many more. People start putting together workflows based on these tools by scripting them up in some way.\n\nThe next thing to figure out is what the developer workflows look like. Python doesn't have a compile step, but that doesn't mean there isn't a build process. A build includes running tests, linters, formatters, packaging, and handling code generation. If using type annotations and doing type checking with mypy or pyrite, it's similar to a compiler.\n\nType annotations have become essential for working with others and collaborating on code. It's important to put together processes that are useful for both individual work and collaboration within a team. Tools like Pants can help build efficient workflows by supporting over 20 Python tools and running them without needing to learn each one separately.\n\nPants acts as a central tool to orchestrate all the underlying tools, knowing when to use each one and in what order. It can handle changes to code, understand when to use tools concurrently or sequentially, and optimize the workflow efficiently. It's like a shell that can safely combine all the individual tools into a cohesive process for developers.Well, I only need to run these tests and not all of them because I can tell that I have the cached results for the other tests are still valid. None of their transitive inputs have changed. So, there's more than just a shell that helps run other tools. It actually knows when you give Pants a high-level command like \"give me the results for all the tests\" and it will figure out what that means in terms of some of these being cached and some having intermediate results cached. I only need to run the other ones and I can run them concurrently on all the cores on the machine because I know through dependency analysis that they don't depend on each other.\n\nIt's more of a workflow orchestration tool that lets you basically ignore what the underlying tools are doing, how to configure them, set them up, provide inputs, or handle outputs. It chains them all together in the right sequence so you don't have to worry about all these single-purpose tools. You express a higher-level need to Pants and it converts that into potentially hundreds of calls to these underlying tools, abstracting it all to make it simpler.\n\nAre you building real-time applications? Check out InfluxDB time series platform. InfluxDB is optimized for developer productivity, allowing developers to build IoT analytics and cloud applications quickly and at scale. With its data collectors and scripting languages, a common API, and highly performant time series engine and storage, InfluxDB makes it easy to build once and deploy across multiple products and environments.\n\nYour initial page is the \"Welcome to Pants\" page. I just want to get an idea of what fine-grained invalidation means. As I make changes, those changes invalidate previous work that has been done. So, let's say I pulled work from my co-workers on GitHub in the morning to establish a baseline. If I make an edit to a single source file, I need to check the effect of my change. Naively, I would need to run all the tests. Fine-grained invalidation means the system is smart enough to understand transitive dependencies and only run the tests affected by the changes.\n\nIt can identify which tests need to be rerun based on the changes made, such as file changes, config changes, and system changes. The caching is robust, and the system rarely makes mistakes in caching. This approach is unique and solves a problem that other systems may not address adequately.Other systems either run 100 or they let you manually try and figure that out, which is obviously a nightmare very quickly. Right, you'd rather run 100 possible. There are other systems out there that could potentially do other build systems that can potentially do similar fine-grain invalidation but they rely on a huge amount of metadata that you provide. You have to write this metadata in these so-called build files where you say this module depends on this module or this package depends on that package, etc. This is extremely laborious, thousands and thousands of lines of dependency metadata that the system can then use to figure out that invalidation. \n\nBecause it's so laborious, there are often a lot of mistakes in it, particularly mistakes in where you don't remove dependencies that are no longer necessary because it's a little hard to prove that a dependency isn't necessary. Very often they're not written at a very fine-grain level because imagine doing that for every file, that just seems so laborious as to not be worth it. So people do it maybe at the package level or the parent package level and the data starts to get less fine-grained. \n\nWhat is unique about pants is that it does all of this through static analysis. So what that means is it actually at runtime looks at the import statements in your code and figures out your dependencies that way. Okay, kind of builds like a tree of sorts through all of that. And obviously, it does that with a lot of caching, so it's very efficient. \n\nYou can override those, sometimes you have a dependency that isn't reflected by an import statement so you can either customize how pants learns about imports or you can just manually add an input in a build file. But the point is you don't have to do that for every single dependency like you do with other systems. The part that I would say is absolutely unique is you get this fine-grained invalidation where the system can figure out at the granularity of a single file, as fine-grained as it's possible to be, how things invalidate without you having to write huge amounts of metadata to back up that logic.\n\nHaving looked at the process of writing yaml files and things like that, it gets horrific pretty quickly. What people end up doing very often when they're using those other systems is writing scripts or using various tools to try and use static analysis to look at your import statements and then emit them into these build files. But then, you're checking in thousands of lines of generated stuff and these files also sometimes need to be edited by hand. Having files that are partially machine-generated and partially human-edited is really error-prone and difficult. \n\nWe just decided to do away with all of that and that was a deep part of the design of the system and people love it. It's a really great feature. Is that part of version two there? Do you need to? Okay, great. Okay, so we mentioned some of the tools to get started if you were suggesting someone to start today and get going and they're familiar with their linter, their code formatter, their tool for ordering imports, etc. Do you feel that they need to get practice and how those tools work before they move into a more elaborate integration system? Not necessarily, but I do think they need to know why they are using those things. \n\nBecause then when you use something like pants, it's very easy to turn on. Let's say you're using black, mypy, isort, and flake, there's just one line of config to just say make pants do all that for you, run those for me. But you need to know why. You need to have a sense of what you and your team and your organization consider to be good code quality control. \n\nI think once you have a sense of what it is that you want, pants will make it very easy for you to do that and it also sets a good example. The obvious things that everybody should intuit that they need is tests, you need good tests and good test coverage. You have no reassurance that any code you've written is useful unless there are some really good tests for it. A system like pants can run your tests, calculate test coverage, etc. but it can't actually tell you if all your tests are good and meaningful. \n\nThat is a huge part of the skill. So I'd say the number one thing to focus on is are my tests actually reassuring me about the quality of my code.So if someone was going to look at moving into this direction and getting more comfortable with it, they should be familiar with some of these other kinds of names that we mentioned before of tools that look at your code. But the first step may be to get good at just understanding tests and how to integrate them and make sure that they're set up properly. Do you suggest a particular tool?\n\nPi test is basically the standard. Once you have got some tests running with pi test, pants will just install and run pi tests for you. And you can start using pants very early because it takes away a lot of the difficulty of installing pi test and figuring it out separately from all the other tools. But it's more about authorship. So running linters and formatters is easy. I mean, there's very little required. Running my pay is relatively easy, again, pants will make that a lot easier. But you have to write type annotations and understand that world. But writing tests is a skill that needs to be learned, and writing code that is testable is also a skill that needs to be learned. And no tooling in the world can help if your code isn't written to be testable and you are not actually writing good tests for it.\n\nSo it's definitely a skill if you're not familiar with that, that may be where to start before advancing forward. And then the other thing I think that is really worth paying attention to and is a bit of a flesh wound in the Python world at the moment is packaging and deployment. The other side of things, there still isn't a strong story there. For example, the Python standard around that is you build, you set up Pi or similar to build a distribution, a wheel, or an s-dist, and that gets consumed by another repo. But it's clunky because it means that code sharing has to go through versioned publishing in a mono repo environment. One thing that pants offers, which is a standalone tool you can use outside of pants but integrates well with it, is a thing called PEX. It's short for python executable and it basically builds a single PEX. It builds a single file that is a deployable file containing all of your python code and its dependencies from your repo plus all third-party requirements as built wheels. It's a single file executable that you can literally run, and it does this very efficiently. We have attempted to provide a robust answer to the question of how to deploy Python code to production, which is still a fragmented story in the Python world.\n\nIt comes up all the time, we talk about it all the time on here. And that speaks to the idea of an individual moving from writing scripts to writing a project with different components and parts and then working with a group of people. Now we have to consider how someone else would join us, how they would get the code, and how it can be deployed to them, potentially for an organization. The PEX format may be more for internal repository and sharing within an organization, not for code sharing between humans or across repos. PEX specifically is for deployment to servers, for deploying to production, not for code sharing between humans. It's for deploying code to servers.I should mention it's called a Python executable, but it doesn't bundle today. It does not bundle the Python interpreter itself, but we are currently actively working on a solution that bundles not just the code but also the interpreter itself. So now you truly can deploy it to a platform that doesn't even have a Python interpreter on it, and it will run. But none of this is totally about production when it comes to sharing code.\n\nWe can do the thing people do today, which is use paths to build a distribution and push it, publish it to PyPi or to your private PyPi server and share it that way. But we are somewhat opinionated about how code sharing should work within an organization. Pants supports what we believe is often a better solution, which is the mono repo. In a mono repo, everyone, potentially even hundreds or thousands of engineers, are all collaborating on a single large repo. Many different services, binaries, Docker images, lambdas, and whatever are published out of that same repo and possibly contains code in multiple languages and for multiple products and multiple projects. They all share code literally by all being in the repo. This gets rid of versioning hell.\n\nWe're all familiar with some version in the JVM world, called jar hell or dependency hell, where if you share code through versioned published versions code artifacts, which is how on PyPi you have to share third-party code that you don't publish yourself, you end up with these diamond problems where it's hard to find a mutually compatible set of transitive dependencies that work for all of your code. You do not want to introduce that problem to your first-party dependencies in my opinion.\n\nWith a mono repo, the versioning is the same as the git versioning. Essentially, the version you get of everything is the version at the current gitsha you're on. When you build a binary, you completely control the versioning of every single file at the same version at the gitsha. This enforces good coding practices and makes it easy to find and make sure all tests pass.\n\nA mono repo enforces good collegial coding practices. If I make a change, I am responsible for making sure the impact of those changes are not breaking things. Arguments against mono repos are becoming less common, as evidenced by many large companies, including Google, using them for a long time. The arguments against mono repos are being addressed by tools like Pants, making it easier to work with Python tooling in a mono repo.This week, I want to shine a spotlight on another Real Python video course. It covers the topic we touched on this week, which is also a common next step for intermediate developers: beginning to test your Python code. It's titled \"Testing Your Code with Pytest\" and it's based on a Real Python tutorial by previous guest Dane Hillard. In the video course, my frequent co-host Christopher Trudeau shows you the benefits Pytest offers, how to ensure your tests are stateless, how to make repetitious tests more comprehensible, how to run subsets of tests by name or custom groups, and it also gets into how to create and maintain reusable testing utilities.\n\nTesting your code brings a wide variety of benefits. It increases your confidence that your code behaves as you expect and ensures that changes to your code won't cause regressions. This course is a quick way to get up to speed with Pytest, one of the best tools you can use to boost your testing productivity.\n\nReal Python video courses are broken into easily consumable sections and, where needed, include code examples for the techniques shown. All lessons have a transcript including closed captions. Check out the video course - you can find a link in the show notes or you can find it using the Search tool on realpython.com.\n\nYou mentioned several times now, at least I could feel this sort of directionality of this tool moving more and more toward Python type of tooling and so forth. Is that what are some of the reasons for that? Is it more like use of Python or advantages it provides, or are you trying to solve problems like you just mentioned?\n\nSo what happened in the last 10 years? When we first started messing around in this space, as I mentioned in the early 2010s when we were generating ant XML files or whatever, the focus then was very much on JVM, particularly on Scala because that's what those handful of companies happened to be using. But in the intervening 10 years, Python has undergone an incredible revolution. It went from, you know, I remember back in the day that Python was essentially like a nicer bash, right? It was the shell script around the edges of things that you just wrote throwaway scripts in. You didn't apply good software engineering practices to it because it was like the duct tape that you used to duct tape your real code together. But now, Python is, I believe, it's now the most popular language by some metrics, and it is obviously the language of choice for data science and machine learning, and that is one of the reasons for its immense popularity. It's also really popular for building web apps through Django and Flask and things like that. It's also always been, I think, a really popular language for DevOps, but DevOps itself has become more of a first-class use case, and it's no longer acceptable just to have a bunch of throwaway scripts. You're expected to manage your DevOps in production, and even in your corporate environment, you expect that code to be rigorous. Yeah, so Python has just exploded, and the tooling has not kept up. Most of the existing build systems really are focused either on the CC Plus World or on the JVM world, or they're very focused on JavaScript, or they're very focused, you know, Rust has its own sort of very tight tool chain that's really just for building single Rust binaries. So there really wasn't any tool that was focusing on Python, and Python is a rich, interesting ecosystem with a lot of history behind it now, and you can't just jam it into a JVM-oriented system and expect it to work well. It has its own idioms, and so we wanted to build something all the hooks we've been talking about at this point, exactly. So we wanted to build something that could provide an answer for this rapidly growing, really popular language that I think hits a sweet spot for a lot of people. There wasn't really the higher-level tooling. There was all this lower-level single-purpose tooling. We've named a bunch of them already - this thing just runs tests, and this thing just sorts your inputs, and this thing does type checking, and this thing does formatting, and this other thing does formatting but in a different format. But there was nothing to really bring it together into the kind of higher-level workflows that you really need when you're starting to build really significant capabilities and really significant code bases and building entire multi-billion dollar companies around Python. Yeah.And so that is why there was a focus on Python. Now, I should say we support Go, Java, Scala, Kotlin, and Shell. We're looking into Rust and JavaScript. We have a plug-in API, so it's not terribly hard to add support for other languages. People have done that by adding internal plugins for various things they've needed. The strong support for Python factored into the design of this V2 Pants right from the start because we knew it was such an important use case.\n\nI was thinking about stepping several steps backwards because you mentioned a lot of data scientists getting started with the idea of continuous integration and testing. I wonder if somebody needs to move beyond working inside a notebook and explore other ways to implement this.\n\nThat's a really good question. In the early days of data science, it used to be that PhDs and experts in the backroom would write Python code and then hand it over to software engineers to deploy. Now, there's a growing recognition that good software engineering practices need to be followed throughout the data science and machine learning pipeline.\n\nPants has integrations with Jupyter notebooks, and a large chunk of our user base consists of data science-oriented teams. They want tooling to abstract away the pain of code quality and development workflows on data science use cases. Setting up a recipe to run the code and deploying to servers is common. It's much easier for data scientists to just run 'pants test' instead of dealing with multiple tools and command lines.\n\nI think it's funny how people find their specialties. Some are interested in building tools to make others' lives easier, while data scientists are focused on solving scientific problems. It's interesting to get different perspectives and tease out these aspects. I'm also trying to make my life easier by hacking on tools so that I don't always have to do it.\n\nThe space is evolving, and there are many interesting things happening. Higher-level workflows provide order, rigor, repeatability, and performance as code bases grow. Tooling helps adopt and maintain good practices around code quality.Yeah, sort of set yourself up for some success here moving forward. Yep, how did somebody get started using this tool? So you go to pantsbuild.org or pants build as one word and follow the sort of how to get set up instructions. We strongly encourage you to click on the link to the community, which will lead you to our Slack workspace. That is a really good place to come and say hi.\n\nOne thing we maybe didn't mention much about was the community around pants. Toolchain and accompanying co-founded is the lead sponsor, and obviously we've done a lot of work on it over the years. But we are far from the only people working on it. There's a big friendly community of people from many different companies either hacking on pants themselves or answering questions. It's a community where we pride ourselves on being very friendly to anyone. Sometimes open source projects can be a little prickly.\n\nWe put a lot of effort into being very welcoming and friendly. Our unofficial motto is that there are no bad questions, only bad documentation. I recommend coming in the welcome channel, just come and say hi, introduce yourself, and mention how you found out about pants. Mention if you heard about pants on this podcast and what your interest is and what your use cases are. It's a big friendly community, and between the documentation and the community, I think you can get set up pretty quickly.\n\nThe documentation is good by open source project standards. There is still a lot to improve in the documentation, and that's a project we would like to fund and do at some point. Adding more tutorials, etc. Offering to help in those areas is a great way to get started in contributing to open sources. We very much welcome documentation fixes. Contributions do not necessarily mean code; they can mean documentation, helping other users, helping promote the project, etc.\n\nWe have a whole bunch of example repos for people to test some of this stuff out. Come by, say hi on slack, and give us a GitHub style like. That's how I would get started. Awesome. So Benji, I have these weekly recurring questions, and the first one is, what's something you're excited about in the world of Python?\n\nI'm really excited for PyCon, which is in April, I believe in Salt Lake City again. So, yeah, I had never been to PyCon before, and then we did the virtual PyCon during the pandemic, and we actually spoke there. Salt Lake City this year was my first PyCon, and it was such a blast. I am very excited for PyCon 2023. Salt Lake City is a fun city, and the community is very welcoming and friendly.\n\nOne of the many things I love about Python is that pants itself is implemented partly in Python. We are also purely for selfish reasons very invested in Python. I'm very excited for PyCon, it's so much fun. Did you do a talk or anything last year?\n\nI personally did not, but my co-worker Chris did, and it was a very well-received talk. What's something you want to learn next? This doesn't have to be Python-specific.\n\nI want to learn more Rust. Pants is written in a combination of Python and Rust, and the two interoperate really well. The model of writing Python where you want to iterate quickly and then finding the performance-critical parts of your code, particularly the CPU-bound ones, and potentially rewriting them in Rust is such a powerful combination. My Rust abilities are not strong, but I see the value in it.I very much would love to be able to take a month off and go really learn idiomatic rust and just become really good at rust code because it is just what little work I have done in Russ a bug fix here and a feature there has been such a joy. It's a very common answer I'm getting more intrigued all the time.\n\nI thought about we were talking about it recently but the idea of idiomatic version writing of particular code and pythonic is an easy one and I was like, okay what is it for Russ then? Is it rustic? I haven't heard it yet so I hope it's rustic because that just sounds excellent.\n\nSo how can people follow the work that you do online? As I've already mentioned pouncebuild.org is from the open source side. Come say hi there'll be links there to join the community, join slack, come say hi. Then I would say obviously GitHub, so we are pants build slash pants on GitHub, the pants build organization and then the pants repo. GitHub style is always appreciated. Toolchain.com is the corporate website if you want to find out more about the commercial offerings around pants and speeding up your builds, etc. And then finally, for as long as Twitter is still around, you can find me on Twitter at Benji.\n\nThanks so much for coming on the show this has been really fun to talk to you. Thanks for having me on, this was a blast. Don't forget easy to start and scale influxdb time series platform is available in the cloud on premises or locally. Get started for free today at influxdata.com.\n\nI want to thank Benji Weinberger for coming on the show this week and I want to thank you for listening to the real python podcast. Make sure that you click that follow button in your podcast player and if you see a subscribe button somewhere remember that the real python podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey. I look forward to talking to you soon.",
    "atns6v9oeek": "Welcome to the Real Python Podcast. This is episode 139. Have you embraced the use of comprehensions in yourI'm not trying to tie things into a big CI CD pipeline. I'm using the linter primarily for two things. Firstly, if I've written a whole bunch of code without testing, like if I've sat down and written a couple hundred lines, I find it's often faster to run the linter to check for missing commas or other errors than it is to actually run the code. Secondly, I often use it as a clean-up step before I commit, looking for unused imports from copy and paste, among other things.\n\nOver the years, I haven't experimented with anything recently. When I originally went looking for tools, I found that flake8 had too many requirements that I didn't feel like meeting. So, Pi Flex was a nice compromise. It seems to work well for a variety of people I've talked to over time.\n\nWe had a long discussion a couple of weeks back about the idea of using a linter to find issues in your code instead of running the code and finding errors one at a time. The next area he dives into is the style linter, similar to flake8. Another one called PyLint looks at Python's pep8 document to ensure you're following stylistic guidelines.\n\nThere are packaging linters that look at issues related to code distribution, like Pyroma, and a security linter called Bandit. Code formatters like Black enforce specific style guidelines, while complexity analyzers like McCabe or Radon focus on metrics like cyclomatic complexity and Halstead metrics to assess code readability.\n\nIt's nice to see someone's opinion on these tools and audit them. Some tools mentioned may no longer be updated. Have you ever used a dead code linter? It helps find unused or unreachable code in your program, improving code quality.\n\nImport statements can be organized using tools like ISort, which sorts imports alphabetically. This can help maintain a consistent style in your code. Some programmers may not naturally organize imports in this way, hence the need for such tools.Yeah, it's a nice read. If you're not aware of Alice Weigert's books and other tools, his \"Invent with Python\" blog has links to all the different things that he does. A lot of his books are free to read on the web. Obviously, you can also buy them. He has a whole bunch of them for sale.\n\nSo, what's your first one? My first article is from a name that shows up frequently in the PyCoder's newsletter. It's Idamar Turner Ring, and it's entitled \"Who Controls Parallelism: A Disagreement That Leads to Slower Code.\" The article is about the state your code can get in when both you and your libraries are doing concurrent programming. The example that he deconstructs is one with a thread pool and the NumPy library. When he ran the code in a single thread, it took 1.2 seconds. Then he tried a thread pool version, which took 1.5 seconds, going in the wrong direction. Switching to multi-processing mode, it goes up to 2.2 seconds, which is even worse. He's running this on a 12-core machine. If the problem were the GIL, the multi-processing would have fixed it, but evidently, that's not the problem.\n\nFor the deep dive, NumPy uses a library called OpenBLAS, which is an implementation of the BLAS library. BLAS stands for Basic Linear Algebra Subprograms, an interface definition for doing linear algebra. It defines functions for vector and matrix operations, and there are different implementations. This is one that NumPy uses underneath. The slowdown here is a side effect of what NumPy and OpenBLAS are doing.\n\nThe single-threaded program that I mentioned, well, Mr. started to debug the problem and discovered that it actually had 20 threads. The thread pool version had 43 threads, and the multi-processing version had 401 because OpenBLAS itself is creating thread pools, hence the title of the article. Python threading is fighting with the OpenBLAS threading, causing unpredictable performance problems in the threaded version. Essentially, the thread pool and the OpenBLAS thread pool are both creating queues. With a single Python thread, it feeds OpenBLAS's queue, and OpenBLAS goes and does its work. With multiple Python threads, each thread ends up feeding the same OpenBLAS queue, starting to fight to feed that queue. OpenBLAS has its own queues, slowing the program down. The multi-processing version is a little more complicated because you should end up with a single queue in that version, but Idamar suspects that the memory caching starts getting overwritten, giving the single-threaded version a performance advantage.\n\nWhat can you learn from this? Concurrent programming is hard. In the OpenBLAS case, at least there is an environment variable you can set to control how it threads. This can give you fine-grained control on where the threading is happening. You can decide to do it in your code or in the library. This solution might not be available with other libraries where similar conflicts can occur. You can still gain some speed advantages by deciding where your parallelism happens, essentially avoiding that fight. You could do data loading or pre-processing concurrently as long as when you call the library in question, you design a bottleneck. You need a join place before you hand it off to avoid the fight.\n\nIt's a great article showing the hairiness of concurrency and how sometimes you have to understand what's going on under the hood to get performant code. Even though throwing more threads at it doesn't solve the problem, it's often the challenge. The assumption that the hardware is going to solve everything for you is also dangerous.\n\nMy next one is a nice short read by Pete Feisen on Medium, published in a blog called \"Towards Dev.\" Titled \"A Crash Course in Python Comprehensions and Generators,\" the subtitle is \"Master them in 20 minutes, use them every day.\" If you're not familiar with list comprehensions, here's a great secret for you to save effort and writing, with some neat tricks inside Python for you.And then also along the way to learn about the concepts of generators, he does a really simple introduction to them. So I've also included some links if you would like to dive deeper into generators. But comprehensions take what could be like five lines of Python and combine it into a single line. The idea very often of creating a list and then appending items into it is something that is kind of doing automatically for you. The hardest part of a list comprehension is sort of remembering stylistically how they're written, and he has a whole area of the article where he talks about that and why to practice them and get in the habit of writing them.\n\nI liked something that was in one of our articles about the idea of list comprehensions where you have say the name new list at the beginning of the line that you're creating as an object, and then you're assigning with the equal sign inside of a pair of square brackets, the usual list notation things. It starts with an expression, and that expression could just be the item that you want to get out of say an iterable, so it could be I or something like that. And then you start a for loop right after that, so you say for member in iterable. If you can kind of remember the style and it helps to look at the article and get an idea of it, but it's very much like a for loop that's been folded together out of a couple lines. There's no indentation, there's no colons, you don't have to create the whole empty list. It's very pythonic, clean, and ready to go.\n\nA generator changes the square brackets into the regular parentheses rounded brackets that everybody's used to seeing on normal speech. So it looks a little more like you're setting aside an expression or something like that, but it's the same format. What's cool about generators is that they have this really great trick where they're lazy, so they basically don't evaluate what's inside them until they're actually needed. It can improve speed of your code, minimize memory use, and allow you to do lots of interesting things, especially if you're working with big files or large chunks of data. But they look identical, they just change the outer brackets on them. He also talks about set comprehensions, in that case, you're using the curly braces, and if you're not familiar with the set, basically you don't have any repeating elements inside of a set.\n\nThe last area he gets into is he talks a little bit about dictionary comprehensions. The difference is that the front expression you'll see will have that sort of dictionary style of key colon value before the for statement in it. He talks about some common things like you might see as a common interview question, the idea of flattening out values that are in a nested comprehension. He talks about how to do that, it looks a little kind of crazy inside a nested list comprehension, but he has a nice graphic to show what's happening inside there. I liked how he did that, he talks about this idea of eggs inside of nests inside of trees, which I think is not a bad way of explaining it. He has this little graphic to take you through it.\n\nThe last thing he talks about is this idea that if you want to take an expression in this case, say a list comprehension, if you would like to have it be filtered, you can have that conditional statement at the very end of what's happening. So you'd have expression for member in iterable, and then if conditional all in a line there. He has some nice notes at the very end talking about testing your mastery and he adds a few challenges for you. So again, a quick 20 minutes, you can dive in and learn some of these concepts and then come back and practice them. If you want some more detail, I'll include links for deeper articles on Real Python about how to use generators and yield inside of Python.\n\nI had a great conversation in episode 39 where I talked to Reuben Lerner and we had a long conversation about how generators work and the concept of coroutines and his style of learning Python through exercises. It might be a nice way to dive in a little deeper on the topic. Also, speaking of that, I find if you're thinking of picking up some of the asyncio stuff, because it uses similar structures, I find that generators, at least for me, were easier to understand than some of the asyncio pieces. So if you were gonna dig in, you might find value in going and learning a bit about the generators and getting comfortable with the yield in a single-threaded application before you go and make it complicated by multi-threading.\n\nThis really is just this real initial talking about how they're written. It doesn't really give as many good examples of where do you use this and how is this useful to you. So I thought I would include the context for that. For sure, because it becomes a little more vital. The other aspect I don't think gets into it in the article, but comprehensions 90% of the time are faster than the equivalent for loop.Because the intermediate variables in the for loop aren't needed, the process of loading them into the stack and manipulating them gets eliminated. This generally makes the process faster, but it can also lead to code that is unreadable. \n\nI love the analogy for nested comprehensions, but my gut reaction is to avoid it as it quickly becomes hard to read. Two for loops are much easier to read, especially when dealing with lists inside of lists that need to be flattened. It's a common interview question, but presenting it as a fancy list comprehension might be confusing. \n\nI generally find that if a comprehension can be kept on one line, it should be a comprehension. If it starts to span two lines, it's better to use a for loop to maintain readability. \n\nContinuing on the theme of concurrency, the article \"Multi-Processing Race Conditions in Python\" by Jason Brownlee discusses the definition of a race condition in concurrent applications. It highlights how shared data and timing issues can lead to incorrect results in multi-threaded or multi-processed applications. The article provides examples and solutions to avoid race conditions in Python. \n\nThe article delves into both thread and multi-processing challenges, showing how to use process locks, process managers, and custom classes to handle concurrency issues. It also introduces the condition class from the multi-processing library for communication across processes. \n\nOverall, it's a comprehensive guide to understanding and fixing race conditions in multi-processing applications. Jason Brownlee's article on superfastpython.com is a valuable resource for those looking to deepen their knowledge of concurrency in Python.This week, I want to shine a spotlight on another Real Python video course. It goes along with another one of the articles this week titled \"Understanding Python List Comprehensions.\" The course is based on a Real Python article by James Timmons, and in the video course, Rich Bibby takes you through how to rewrite loops and map calls as list comprehensions in Python. Choose between comprehensions, loops, and map calls. Supercharge comprehensions with conditional logic and learn how to use comprehensions to replace filter. I think it's a worthy investment of your time to learn one of Python's most distinctive features and how you can use them to create powerful functionality within a single line of code.\n\nReal Python video courses are broken into easily consumable sections and, where needed, include code examples for the techniques shown. All our video lessons have a transcript, including closed captions. Check out the video course; you can find a link in the show notes or use the search tool on realpython.com.\n\nThat takes us into our discussion. The discussion this week is from Twitter, and hopefully, it'll be alive when you come to check it out. There's a delay between recording and release, and there's been some weird stuff happening in the meantime. It's from Bob the Builder boss, and he works on Pie Bites. He wrote a very short tweet basically asking a simple question of how do you use imports in Python. He uses pathlib as an example. So, he asks, is the statement just import pathlib where you would still need to type pathlib.path to use the different methods and things that are inside that? Or do you type it out as from pathlib import just path, maybe you just need path out of pathlib, and that way you can just write path and use it. He asks why and got pretty good answers from some of our usual friends. One being Diva Group Hetta, who answered, almost always import the module to have separate namespaces. This is a theme that I keep seeing often in here. Namespaces are one honking great idea, which is from the Zen of Python. If you haven't done import this, there are a few examples of people from the data science space that use an alias, so saying import pandas as PD or import numpy as NP. If you're going to use that module quite a bit, it's nice to have the namespacing, but it's also sometimes nice to have an abbreviated name for that namespace. There's just a whole bunch of different things in here, and I thought we could discuss it. Chris had found this thread, and I was like, okay, it also kind of brings in and I have some additional resources. One of the ones actually quite a bit is a site called Python Anti-Patterns, and it has a bunch of reasons why you shouldn't do them. One common one is the from pathlib import Star, which imports everything and dumps it into the namespace, and why that's bad. So, anyway, we can discuss a bit. What were some of the things that you wanted to talk about?\n\nWell, the import Star, I don't do. I don't think I've ever done it in Python. I think that was beat out of me in my Java days because it has a similar structure, and that was a common thing at the same time. Do not have all that extra stuff in memory, don't do it. So, that one I've never done. I started to kind of think about it when you asked the question, and I realized I think I'm consistent, but I don't know if someone who wasn't me looked at my code would agree that I was consistent. I'm consistent to myself. There's a pattern like I'm not changing my mind. A lot of it depends on, for me, it's a Clarity thing. For example, pathlib I use all the time, so I'm not going to namespace that. If I see capital P path in my code, I know what it is, so I'm not going to bother namespacing it. I'm going to bolt the path object in directly, and that's not a super common collision. No, and I guess that's where there's always exceptions. If there are places where there are going to be collisions, then I move towards using the namespacing. I think if I were to go through and list out, I don't know how I could create a style guide based on what I do, it would be horrible. But like third-party libraries that I don't use as often probably get namespaced because then when I'm reading my code, it's like, \"Oh, where did this come from?\" Even in the standard library, if I'm doing something in math, I probably import math rather than just import sine or cosine, for example.But then some of it is context based. We've talked before about doing a bunch of stuff with Django Ninja. Usually, when coding something like that, which is a REST API library, most of the code ends up in one file in Django, usually called api.py. So why do I need the extra namespacing? I just grab what I need from Ninja because it's all ever going to be in there.\n\nOn the flip side, in Django, when you register your routes, you have to bring in the views. Due to the way Django is structured, all the views tend to be in a file called views.py. They're in different modules but all called views.py. When bringing those in, it gets really confusing. That's where aliasing comes in. I frequently do things like importing views as book_views, for example. Okay, I suspect if I ever go back to coding with large teams, I'm going to be violating code formatting norms and getting yelled at. But, you'll get some notes for my own little open-source libraries and projects. It's like, alright, fine. I do what makes me happy. How about you? Do you have habits? Are you consistent?\n\nI learned Python on the fly at a job and followed lots of tutorials. I saw the anti-pattern of importing Star a lot and had to think to myself. This was one of the first courses I did for real Python on importing modules, and it really helped to see the wreckage created in namespaces by using the command dir. You can quickly see how a simple import can pollute the namespace with different things.\n\nProgramming ends up doing common things, and that's why modules probably shouldn't all be named utils. If you're importing utils from different places, it can get crazy. I learned this early on and did a lot of aliasing with pandas, matplotlib, and numpy. PD and NP are really common, probably because typing them out can be funky.\n\nKeeping namespaces clean is important. Importing individual components or aliasing can be a stylistic choice, but paying attention to what you're doing is good. It's not a bad habit to import the whole module or alias it.\n\nOnto projects. My project is following along in the future of web assembly and Python, called Jupiter Lite. It's a Jupiter lab distribution that runs entirely in the browser, built from the ground up using Jupiter lab components and extensions. It's currently being developed by core developers from the Jupiter team, but is still an unofficial project. There's a neat demo site to try out and I really like the logo, which is a little light bulb.Jupiter light with a kind of as the wires and the cursive thing. I was able to play inside of it. The idea is that you could set up a site for yourself very easily because it's very much like setting up a static website, which is pretty cool. You could do it locally or with a static web host. You could embed it in a larger application. It doesn't require a dedicated application server, containers, or Docker.\n\nThere are lots of services that do Jupiter stuff, but it's cool that you could own it and have control over it. This would have been handy in the intranet I was working with at the bank or a law firm where everything was very closed down. If I wanted to show something interactive, this tool would have been really handy.\n\nThere are deployment options for deploying to GitHub Pages, read the docs, GitLab Pages, Binder, versal, and netlify. They have a nice set of visualizations running at the bottom of the main GitHub page. They show Jupiter interactive widgets running matplotlib, Altair, and plotly out of the box.\n\nIt's a cool project with nice documentation and examples. It's one of the latest webassembly projects that could be a handy tool for self-hosting Jupiter stuff without needing a lot of infrastructure.\n\nThis is not quite a project, but a collection of Easter eggs and hidden jokes in and around Python. The list includes import Dunder hello, import this, import Dunder future, and more. It's a fun and light way to start the year with some humor.\n\nOne of my favorites is from Dunder future import braces, which responds with a syntax error and the explanation \"not a chance.\" Overall, there are 15 items in the list for some entertainment. Check it out for some fun.There are a few other ones I'd never heard of, so there's a little more hiding in there than you thought. Board programmers with too much time on their hands. Yes, well that brings us to the end of an episode. Thanks for bringing in all these articles, projects, and discussion ideas. It's my pleasure. Just before we close out, if you've written something interesting, there is a way to submit your content to the newsletter. Yes, we don't include everything, so don't take it personally that we don't get all sorts of stuff. But if you want a chance at it, feel free to submit stuff for us. Yeah, and we'll include a link to the forum in the notes. I will definitely. It's a good way to start the year, get your projects and other things out there, and we'll see what we can include. Thanks again, Christopher. Always a pleasure. See you in a couple weeks. Okay.\n\nForeign easy to start and scale InfluxDB time series platform is available in the cloud, on premises, or locally. Get started for free today at influxdata.com. I want to thank Christopher Trudeau for coming on the show again this week. And I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey and look forward to talking to you soon.",
    "vLYCKWFeC3k": "Welcome to the Real Python Podcast. This is episode 140. How can you get more performance from your existing data science infrastructure? What if a data frame library could take advantage of your machine's available cores and provide built-in methods for handling larger than RAM data sets? This week on the show, Liam Branigan is here to discuss Polars. Liam is an experienced data scientist working in finance, technology, and environmental analysis. He's recently started contributing to the documentation for Polars and developing a training course for the library. \n\nWe talk about the library's overall speed and lack of additional dependencies. Liam explains the advantage of lazy versus eager mode and which to choose when performing data exploration or attempting to load a data set larger than your RAM. We also discuss potential barriers to switching to Polars from a Pandas workflow. Across our conversation, we explore several other libraries and technologies including Apache Arrow, DuckDB, query optimization, and the rustification of Python. \n\nOn Tools, this episode is sponsored by Anaconda Nucleus. With nothing to install and nothing to configure, Anaconda Notebooks is a fully loaded data science environment entirely in your browser. Start coding in the cloud on anaconda.cloud today. \n\nAlright, let's get started. [Music] \n\nThe podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. \n\nHey Liam, welcome to the show. Hey Christopher, thanks for having me on. You had reached out to me earlier in the fall, and sorry for the delay on getting you on the show, but I am very interested in this topic. I've heard about Polars a little bit, and I've definitely heard about Apache Arrow having talked about it a little bit in previous podcasts with Christopher, kind of covering some of the changes and updates in the data science world. \n\nSo I'm very excited to talk about both these things. Maybe you can give me a little background about you and your involvement with Polars. Sure, my background is actually as an environmental scientist. I did my PhD in physical oceanography in Oxford, finished up a few years ago. Then I was a postdoc for a few years and got a bit tired of academic instability. So I became a data scientist at a Belfast-based startup here in Northern Ireland called Analytics Engines. I became the lead data scientist there, and then last year I started my own company to do data science consultancy and also training. \n\nI was doing a training workshop for some oceanographers in Ireland with the Marine Institute, and I was training them how to use Pandas. I was finding that I was having to teach them all these little tricks that you need to do with Pandas to make it run a lot faster than the defaults. And then I started to show them there are some other options out there. There's things like DocDB, and then there's this Polars library. I showed them Polars and how fast it was, and then somebody was like, \"Why don't we just use Polars if it works fast rather than learning all these different tricks you've told us about using Pandas?\" \n\nSo then I thought, \"Yeah, well, that's a pretty good idea.\" I wonder about that too. Are there things, I guess, that will kind of be some of the focus that we get into here? Are there things that get in the way of just switching out to a whole new library? Is it partly just how much of the data science community is currently using Pandas only? Is it easy to switch something like that? I wonder what hurdles are there. \n\nYeah, so I've been thinking about this recently, about what are the barriers and the push factors for adoption of a new data frame library. There are little barriers like the syntax is a little bit different, you have things like using expressions in Polars, which is the way you build out your queries, and that's a little bit of unfamiliarity. But once I started using it six months ago, I basically stopped using Pandas overnight because I found that the way you write things in Polars just maps much more to how things sit in my brain. \n\nIt's doing the same for mine. I really got a chance to dig in yesterday, I was telling you right before we started, and I'm like, \"Oh, these are making so much more sense to me, just the grouping.\" And I think I've mentioned multiple times how I'm a fan of R and how it's laid out, and I'm thinking there's some weird concessions that went into creating Pandas and it is a legacy thing, I think, for certain elements of it, which make it kind of interesting. \n\nSo I think the thing about Pandas is that it was really the trailblazer. It really got things going and had to solve all these problems for the first time. And I feel like for the new generation of things coming through, that if you're starting with a blank sheet of paper, you have a chance to take in all the great things that Pandas have done, but also learn some of the lessons and start without having that legacy hold over.You're working hard on getting people up to speed with it. You have a lot of resources on your blog and even a nice cheat sheet which I always enjoy not having to dig through an entire article to find things I'm looking for. Someone got in touch, there's a Discord server for Polaris if you want to get in touch and talk about ideas about how the library works or some of the concepts that underlie it. Someone sent me a message saying hey, I'm always looking for a cheat sheet and I know you like to write about Polaris, so why not do that? I thought wow, that's a great idea. I can see from my analytics that people are definitely looking for that, it's handy for them, they're popular.\n\nYou do a bunch of content on YouTube, and we'll definitely include links to that. The other major thing you've been working on is a course. I've released the course on Udemy, I got so excited by this over the summer. It was just fun, everything was just... I guess the first project I started using Polars on was a large CSV that I was doing some exploratory data analysis on. I needed to load the whole data set and be able to randomly sample it and check out what's happening in the data. The first day I started using Polars, I loaded in the CSV just by calling read CSV. Normally in pandas, it took about a minute for that CSV to load, so I would get distracted and open up Twitter. With Polars, after just a couple of seconds, it was already loaded. I realized that it was fast, I guess I don't get my little bit of distraction time, but it keeps your flow, you're not having all these little one or two-minute gaps. If you have something that works fast, you can keep up your flow by taking all those little gaps and getting rid of them because the computer is working more efficiently on your query.\n\nI noticed little minor speed improvements that were noticeable. As a musician, I often use tools that allow me to continually have the music application or digital audio workstation play while I'm editing and modifying things. It's not a constant stop, go back to the beginning, where do I want to start from, just let it loop and keep going around. Sometimes that's how data scientists are working on things, and if they can stay in that flow, especially with bigger data sets that normally require coffee breaks in between, that's really cool.\n\nOne of the key parts of the API is that there's no index in Polars. When I have to go back and write some pandas code, I spend a lot of time managing that index. Once you realize you don't need it, you wonder why it's your job to deal with all that. Why can't the library just take care of it for you? They make a strong statement on their page, indexes are not needed! Not having them makes things easier, convince us otherwise, very \"come at me bro\" kind of thing there. I agree that indexes are literally a whole part of teaching pandas and managing them. When Polars was coming out and I was getting used to it, there was a guy who's a real Python and Pandas expert who released a two-hour YouTube video talking about how to manage indexes. I thought, this is the peak of pandas, that you need a couple of hours just to think about managing the index when you can use something else where that skill disappears.\n\nI tweeted right around that time, I was excited about the way things were going, I could see the intern shaming the lead senior data scientists because they're using these new things. All this knowledge you've built up on how to manage indexes just disappears overnight, and your intern is using a faster tool without needing all the experience you've gained through hard work.But tools change. One of the things that you have on your site is a set of predictions, sort of core predictions, as a particular post for core technologies and data science ecosystem. The first one you had was that Polars and DuckDB would replace Pandas as core tools for tabular data. That would be your first prediction. How do you see it going so far? Like, I don't even know the age of Polars. I haven't really dug into DuckDB in my little background research. I spent more time with Arrow.\n\nYeah, so DuckDB is another great library. I think DuckDB started around 2018 or 2019 and came out of, so I was tweeting about this a few months ago actually, that there's DuckDB and Polars, and they both come out of either personal or academic projects in the Netherlands. When we think of all the billions of dollars folded into data analytics, the two most exciting tools are really coming out of this kind of Open Source world. Polars was created by a guy called Richie, who's really the driving force behind the project. My understanding is that he was really interested in Arrow and he was a Rust developer doing some data engineering. He just wanted a Rust data frame library. That's kind of one of the key things to understand. I kind of think of Pandas as being like a Python library with C extensions, where there's a core bit of logic and a good bit of that is in Python, and then it calls C for the computationally expensive bit. But if you go into the Polars source code, you see that the Python aspect is more like an Econ API. A typical Python function in Polars will maybe parse the arguments a little bit, but very quickly it's passed down into the Rust layer to do all the core logic there.\n\nSo, like percentage-wise, the division is more like 10 to 90, versus what in Pandas is a lot more initial Python. If you ever have Pandas and you type in the wrong kind of column name, and it gives you an error, and you're debugging it, you go through different layers of the stack before you can. But with Polars, that doesn't really happen. Maybe you get one or two calls in Python, but pretty often you're just going straight into Rust.\n\nYou've done a little bit of work contributing to Polars. What's been your involvement with that?\n\nYeah, so I've done a little bit of work. When I started getting involved and I have no background in Rust, so as I'm saying, it's not a library where if you have a lot of Python experience, you're going to write any of the core logic because all that sits in Rust. I was like, this library is great, but what it needs is more documentation. I think all libraries struggle with getting people to write documentation, but for me, it was like, well, I can't actually write the Rust, so let's see what I can do. It's been really helpful for me because I've been writing this course and I basically have to go through the library function by function and be like, what does this function do? Okay, and I write some examples. My aim is to make sure that every function in there, if you look in the doc strings, has an example in Python. It's been an amazing learning experience because I've used Pandas for years, but if you're busy, working on projects, working on deadlines, you don't always have time to stand back and keep learning. This has been an amazing learning experience that almost every single time I've done a dive through those functions, I find some functionality that I never knew before. Then it's straight onto my blog or onto Twitter or LinkedIn to be like, hey guys, this is cool, I never knew you could do this. That's a fun way to share and contribute.\n\nWe've talked about that so many times on the show, that if you want to contribute to open source documentation, just even getting started with it is great. Learning how to teach something to somebody else makes you learn so much faster. Having the people involved in the project being able to say, hey, I'm working on your documentation and I have a question about this, that must be nice too. As a teacher, you don't always get that ability to loop that person in. That's really nice. There's an interesting question there, if you're producing this kind of material, how do you decide? Okay.What am I going to do basically for free and put into the repo and what do you kind of need to have in your course and the philosophy that I've been trying to follow is that what you have in the course it's not about having all this juicy stuff that isn't available for free, it's about having it set out nicely in a coherent format with exercises. That's why I've been able to write so many blog posts because I don't need to worry about keeping all these secrets to myself. That's not what I'm aiming for. I want to drive adoption of the library and show how amazing it is, which is great for my course. So that's why I'm focused on making sure that I'm not just working on my stuff but also helping the library.\n\nMy current project is writing a quick start guide for my course, like lesson number one with the four big ideas. I'm trying to get that merged into the library's user guide so it'll be a quick introduction for everyone. Maybe we should discuss some of those ideas now and dig in. One of the first things that harnesses speed are these modes that allow you to work in either eager mode or lazy mode. Eager mode runs code line by line, while lazy mode builds a graph of operations. Lazy mode allows for query optimization, reducing memory usage.\n\nLazy mode is beneficial because it optimizes queries automatically, saving memory and improving performance. It's a concept that is essential to understand when working with data sets and complex operations. It's often overlooked but can greatly improve efficiency in data processing.So it's great to have all that built in, just take the pressure off your left computer to do some of that stuff. I know that the statements for reading and say CSV in this case, scanning a CSV requires an extra step at the bottom, which feels very async IO in naming. It's a collect server command. What's that doing? \n\nCollect tells polarized, \"Okay, now it's time to take your optimized query graph and actually run it and give it the output.\" How's that different from Fetch? Fetch is the equivalent of a limit statement in SQL, so fetch is saying, \"Okay, we only need like three rows of the airport.\" Imagine if you got a group buy and you finish it with a Fetch and fetch of three rows instead of collect, it will basically parse the CSV until it's found three distinct group by keys and then it'll just run it from there. \n\nThat's more like a debugging and development tool, like a data tool where you're trying to learn about your data set. \n\nDo you want to learn Python in just three hours? You can get on-demand access to Anaconda's data science experts. Join Anaconda Learning to learn machine learning, data visualizations, data analytics, and so much more. No matter your experience level, learn through Hands-On experimentation and you'll be predicting the future with machine learning models in no time. Make a nucleus account at anaconda.cloud today to get started with Anaconda Learning. \n\nOne of the things that it does is it harnesses Apache Arrow and I was very confused as to what Apache Arrow was initially, partly because there's a lot of stuff happening in the data science space, which is great. There's a lot of interest and energy coming into this industry. I got mixed up with what parquet does versus what Apache Arrow does, maybe clarify that for us a little bit. \n\nYeah, so I think one of the challenges with Apache Arrow is that it's not necessarily written to be the public-facing part of everything. There's not the same emphasis on documentation, I think, and it's very much for data engineering kind of experts. One of the great things Polaris does is hide a lot of that behind the scenes. \n\nWith Arrow, the key thing to know is that it's really two things. On one hand, it's a specification for how you store tabular data in memory, so it tells you how to arrange and pack your bits to be optimized for modern CPUs and caches. On the other hand, it's a set of libraries that implement that format. If you meet the specification, then you can say that this is an Arrow memory format. \n\nThe key point to note is that you can create your own library in one of those languages and if it meets the specification, then you can also say, \"Okay, well this is also an Arrow library.\" The Arrow library that Polaris is built on is based on that, some of the most Arrow people felt that the official implementation wasn't optimized for their needs and started their own Arrow repo that Polaris is built on to optimize it more for rust. \n\nThe key idea is that it's not a file format, it's more of a format for how data is held in memory. It sets up sensible things like how numerical data is stored to read through the cache efficiently and has a more unified plan for handling missing data. \n\nArrow objects are read into memory, they're immutable. Is that different from how Pandas would handle it normally? I think in general, Arrow data is immutable, but there are cases in rust where that doesn't always hold. Check your local rust vendor for more information. These comments were mainly from the Arrow pages, trumpeting the idea that it's possible to use them in multi-threaded scenarios without worrying about synchronization of that data frame because it is immutable.Yeah, I find that I've never had any issues with that. Okay, it's also the idea that Apache Arrow is kind of like a Rosetta Stone. It implements the idea of zero copy, which means that processes happening in different processes can read into the same objects. So, if you think about Polars, it has parallelization, but it uses multi-threading. Different threads can work off the same memory formats, and you can pass things off to something happening in Python, R, or C++ without copying the data into that process.\n\nOne demonstration I've been doing is with Polars. If you have something like DuckDB, which can also support Arrow, you can call DuckDB for an operation and continue with Polars without copying data over.\n\nDuckDB's tagline is \"SQLite for analytics.\" It stores data column-oriented, making it faster for analytics compared to traditional row-oriented databases like MySQL or SQL Server. It's a single binary that can be deployed without needing a server.\n\nThe interaction between Arrow and Parquet is interesting. Arrow, started by Wes McKinney, the creator of pandas, aims to improve on the limitations of numpy for tabular data. Parquet files are compressed representations of data on disk, while Arrow represents data as a tabular data frame uncompressed.\n\nCSVs are text-based, while Parquet and Arrow use binary representations. They have columns with distinct data types and names, making them more efficient for storage and retrieval.\n\nArrow is being added to pandas, showing its potential to become a core technology in the data science ecosystem. In the tabular data science ecosystem, Arrow is gaining traction alongside numpy arrays for tasks like computer vision, NLP, and time series analysis.I think there's more of a distinction between numpy and pandas. Numpy is really good at some things, but it's hard to adapt to some of the tabular problems. For tabular data, pandas is the default representation, while numpy is more specialized in numerical computing.\n\nIn tutorials, numpy is still a great tool for generating data or creating examples. It has many methods ready to use. When it comes to linear algebra, pandas, pytorch, and tensorflow all use a data format that resembles a numpy array because it's essential for scientific computing.\n\nMany Python developers are interested in learning Rust. The attraction lies in the tooling and ecosystem that Rust provides, similar to pip for managing crates. It's a safer and more efficient way to work with C and C++.\n\nPython's history with packaging has been a struggle, unlike Rust, which has built on the experiences of other languages. The Python community thrives on collaboration and development, unlike Matlab, where there was little community engagement.\n\nThe rust community is still in its early stages, especially in terms of machine learning libraries. Projects like Polars, written in both Python and Rust, could serve as anchor points for building data science infrastructure. Polars also has APIs for other languages like Node and is working towards a WebAssembly API.\n\nThe core logic of Polars is relatively thin, making it easier to add new language APIs. Overall, the interest in Rust among Python developers stems from its tooling, ecosystem, and potential for collaboration in the community.That's going to save a lot of effort if somebody's done that heavy lifting for you, that's great. Where else are you seeing rustification? I think it's almost an exciting bit for me about that is that occasionally when I'm working with clients, there'll be some kind of nasty algorithm that they want me to implement, and that's where things often get slow. If you're reduced down to writing loops in Python, you can do things like write number and stuff to speed it up. But what I think the attraction is, and I see this a lot on the Discord of Polaris, is that people who are writing in Python but they want to just write that one bottleneck function in Rust, and then it's actually very easy to then just call that in your Python code.\n\nAt various points in my PhD, I was thinking, \"oh, you know this, I've got a bottleneck here, I might write this like C or C++ extension,\" and you look into it and people are basically saying don't do this on a blog post unless you really have to because it was such a not a simple process. Whereas to write a Rust extension is much more about just learning how to write that better Rust code. It's pretty easy to actually bring that into your Python code comparatively to diving into C and figuring out how to integrate all of that.\n\nI keep hearing it and I definitely see it on the horizon myself. I'm interested in kind of learning some of it. I don't have a project in mind, but you know I've talked to I don't know how many people now and they've all got little projects where they're trying to figure out ways to do that. I think that's great. I mean I think it's sort of a form of abstraction in a way, letting Python still be Python.\n\nI'm seeing a bunch of people actually use Polaris as their excuse to kind of try out something in Rust because the API is so similar between Python and Rust, and the Python API is better documented. So you can look at that and look at some Rust examples, and then it's again a safe space to get into do something and kind of work with the kind of data you're familiar with working with.\n\nThis week I want to shine a spotlight on another Real Python video course. It's tangentially related to this week's conversation about working with data frames and showcases the data visualization library with a unique approach. It's titled \"Graph Your Data with Python and ggplot.\" The course is based on a Real Python tutorial by Miguel Garcia, and in the video lessons, previous guest and core team member Martin Broyce shows you how to install the library plot 9 and Jupyter Notebook, use plot 9 to create visualizations in an efficient and consistent way, combine the different elements of the Grammar of Graphics which involve several layers including a data layer, aesthetics layer, geometric objects layer, and several additional layers within that grammar. You'll learn how to perform statistical transformations, how to implement a visual style with themes, and export your data visualization to files. Data visualization is a crucial step towards sharing your results and findings, and I think this course is a worthy investment of your time. Real Python video courses are broken into easily consumable sections and where needed include code examples for the technique shown. All lessons have a transcript including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the enhanced search tool on realpython.com.\n\nOne of the other questions you have on your predictions is not a prediction but sort of a question, and it's what do you think about GPUs? That's been kind of a rallying cry for a long time here is \"oh, we'll just throw GPUs at the problem in the data science community.\" Do you feel that that's slightly different if we have new libraries and new tools because I always think about that like, you know, what are the solutions for somebody who just has a home computer or a laptop? Yes, because I interact with some people on Twitter and they're like, you know, Polaris is pretty fast but if you use one of the GPU libraries it is faster. It's not actually kind of enormous difference but it is faster to use GPUs. But I think from my experience of having worked at deployed kind of machine learning projects, that it's not just the fact you have to go out and buy the GPU and then you need to be utilizing it. It's even from a deployment perspective, it's like okay, does that mean we can't just run everything on this one kind of EC2 instance, we now have to provision this separate expensive GPU instance and do all this extra kind of stuff. Like you just end up with this organizational complexity to having to manage GPUs in some of these production scenarios that are even more so if you're going into work on premises for a client and they're like \"oh God, we just bought this new server, don't come and say like we now we need to go and buy a bunch of GPUs for thousands of pounds or dollars whatever it does right\" and just make it work with the CPUs. I think it's just if everything if every laptop came with a good kind of GPU.Then I think that process would be much more advanced, but I feel like GPUs will still be very dominant at the high end of the market. But for the broad spectrum, it's still going to be cost-effective on a total cost basis to push for GPUs, especially with these new libraries making better use of the whole range of CPUs. Being able to do things like the lazy mode to take advantage of a lot of the libraries that are not even really doing multi-processing or using a lot of this stuff. Getting that efficiency there because I've worked on problems where I've needed a lot of memory. So, I've gotten a big EC2 instance on AWS to run something that needs a lot of memory, but I was embarrassed looking at the CPU utilization with Pandas because I was just using one CPU coming with 30 odd virtual CPUs and barely anything is actually running. I think you get a different cost rate once you're actually using all those CPUs as well as the memory.\n\nThis is a very specific question, but I'm in the Apple ecosystem and they've been building some very interesting new ARM style chips with unique GPUs that I think have to be written library-wise to take advantage of them. Do you know anything about Polars and how it runs on the M1 series or even the M2s now?\n\nThat's a good question. I'm going to put that out to the community because I've seen people say it runs, but that's about as far as I know. I'd like to see it taking advantage of those cores, but it requires knowledge beyond mine to get into that stuff. It's interesting because we don't have all your high-end workstations. I made a YouTube video last week trying to show the streaming capabilities of Polars, working with larger memory datasets. Processing data in small batches, even if it's a big dataset. I have a MacBook Pro with 32 gigabytes of RAM, but it's hard to run out of memory with Polars. One of my clients gave me a Windows laptop with 8 gigabytes of RAM, a much more typical Corporation laptop, and we showed that it could process tens of gigabytes of data in a couple of minutes without running out of steam using the lazy mode.\n\nThe core idea is that to implement this kind of thing, you have to adapt your algorithm on an algorithm level. For example, if you're doing group by a column and taking the mean of another column, you have to adapt your algorithm for each batch. Richie Wink made Polars streaming in about six weeks, implementing core algorithms to run huge datasets, which is really remarkable. I've tried other experiments with that.So everything I've worked on has tried. You can do these huge joins if you go to a big cross joint or something like that. It really doesn't matter because it's just gonna see how many threats, how many kind of CPUs you have, and then just set the number of batches. Then it'll run things through like that. It kind of takes a lot of pressure away. Think about how cost-effective that would be if you're paying on the cloud, especially for your maximum memory usage. You can say, \"Okay, let's take a bit more of cheap CPU time and a lot less expensive memory.\" Then that becomes quite attractive.\n\nAs a data scientist, you might be surprised by a project like you're initially going into it and you're like, \"Oh, wow, okay, I suddenly have this huge amount of data I wasn't prepared for.\" The idea of having to source something online or whatever, you may say, \"Oh, that's just trivial. I'll just do whatever.\" I don't know how you are with AWS, but all that seems to take a certain amount of time that is a little frustrating because it's not your skill set per se. The idea to be able to just continue running it on the machine that you have is great. Even the other story I hear a lot is that not necessarily you have to go through the cloud, but that your pan things just go too big for pandas. So people are like, \"Oh, we had to start using Spark.\" There was all this infrastructure complexity that's what you really want is a tool that you can use for tiny data sets. Then as that data grows and accumulates, you can then just be like, \"Okay, let's run it in the bigger mode.\" \n\nExamples of that where you're starting to eclipse what pandas was able to do and they were moving into Spark. From my own experience in my PhD in oceanography, I combined observational work with computer simulations running a climate model to see what happened in certain scenarios. I thought it was going to be a combination of both, but on my first research cruise in the North Atlantic, 37 days, by day two, I was like, \"Oh my God, this is not the life for me.\" That's a pretty intense way to spend. You see some beautiful stuff out there, Dolphins popping by at lunchtime. But yeah, that's a pretty intense way to spend. \n\nI kind of tell people that you have to be into that life. If you think of those weeks of work that seem like they're going forever, that was like a 37-day week of work, four years work for like 16 hours a day, maybe sleeping four hours a night, being wrapped around on your bed for that time. Then I came back off the ship and I was like, I'll focus on the simulations. In that case, you start with a low-resolution model working on a coarse grid. As your results start coming through, you start increasing the resolution, the scope of what you're doing. Each time you do that, suddenly your data is increasing by a factor of eight. Do that two or three times, and suddenly your nice little problem at the start has now become a data engineering problem by the end. \n\nIt's nice to have something that might be more elastic in that way, let it expand a little bit so you don't have to quite jump into that. That's a hard part for a lot of people. Even just having this conversation with you, here are a bunch of new tools. Primarily though, we've mentioned them to get into polars. You don't necessarily need to know all of what's happening with Apache Arrow, that's really under the hood and you can still be working with CSVs. If you're storing them yourself, you may want to look at something like parquet. Even just pip installing it was faster, it was like one line. But that's not a coincidence. \n\nOne thing that you've kind of radically are working with Richie and seeing how he thinks is that keeping the binary small is one of the goals of the library. The size of the package, because people come along to the Discord and they're like, \"Oh, it'd be nice if you add this advice.\" It's saying, \"Well, you can do that, it's maybe two commands at the moment and your thing would add one. Each of these things adds a bit more code on, and that just becomes a sort of bloated binary over time.So I think part of that is that it's nice to have a small binary and also thinking about things like WebAssembly. If you're running things in the browser and you've got like a 100 megabyte binary, that's going to slow things down a lot worse than if you've got a 10 megabyte binary. That's going to be a much nicer user experience. Did you hear the recent news that they've basically distilled MicroPython to run in WebAssembly? Oh nice, it's like 300 kilobytes, much smaller. I'll have to look up that number for sure, but it's beyond what it was before. This philosophy has been SQL Lite successful for 20 years, having a focus on efficiency and keeping your binary tight, which has a lot of benefits.\n\nIt seems like he subscribes to that. Are there points that I have missed that you want to focus on? I was going to talk about the interaction with the development of ecosystems. We briefly touched on that, but I've been surprised how well it fits into the ecosystem. Using something like MapLib, I was thinking, is that really like a NumPy kind of ecosystem thing? What's it going to think if I pass a column from a Polars data frame? Isn't it integrated in some ways with Pandas, talking about the size of its library?\n\nWhat I found is that we don't actually need that integration because what MapLib wants is just something you can iterate over. It just wants a sequence, so if it's a column in a Polars data frame, that's what it gets and it's happy with that. Same with Plotly, if you pass it a column from a data frame, it'll go and plot it and it's quite happy to do that. So there's an exciting kind of development happening called interoperability API, where all the data frame libraries will have methods that can work all happily together.\n\nThere's a similar project happening for arrays, the Array APIs, so that you could apply the same operations on all of them just using the same API. It sounds like it's very forward-thinking and needs to play well with others. It's great that Pandas was one of the first to adopt it, and as the dominant library, everyone else can do it as well and know that it's a good investment of their time to improve interoperability.\n\nAnother thing I see arriving this year is support from machine learning libraries. XGBoost now accepts Arrow tables, so you can pass an Arrow table directly into XGBoost and TensorFlow for tabular problems. If people want to get involved, my recommendations would be to install Builders content store and play around with it. Check out the official documents and user guides. If you get stuck, ask questions on Stack Overflow, as the community monitors it closely and you often get an answer within a few hours. Building that out as a support mechanism for the community is essential.Yeah, you can join the Discord to get talking about the kind of concepts and use cases. We'd love to see what people are using it for and hear about that. If you find a bug, feel free to raise an issue and provide a minimal example of what's going on. We'll think about how it works. If you want to go beyond that, write some documentation and do a pull request.\n\nOne thing I noticed is that we've talked a lot about pandas lately and how people like Matt Harrison and others have been using it. He was a previous guest on the show, and we were talking about chaining. Based on the examples I saw, both in the documentation and the ones you were creating, chaining seems to be pretty common in Polars as well. It's a bit chaining first because of the API development. You can't create new columns the same way you do in pandas. You use a chaining method. Also, being in lazy mode, I found that I start thinking about my queries as an end-to-end integrated process. The chaining method makes more sense that way, thinking of all the steps in sequence.\n\nThere are some other niceties built-in, like when you print a data frame, it automatically provides a nice grid with column names, data types, and more. It's easy to adjust settings with pl.config to explore different options.\n\nI'm excited to start playing with it more on different projects. People can follow me on LinkedIn or Twitter, where I post frequently about Polars. I also plan to make more YouTube videos to spread the word.\n\nI'm liking Jupitax at the moment for creating books from my course's Jupyter notebooks. It's great for version control and synchronizing notebooks with accompanying scripts or markdown files. These things don't have the outputs in them.And they're much easier to integrate. So the philosophy is actually that you don't commit to a notebook anymore, you just connect these synchronized files. Oh, cool. And then you can do nice steps on them and see what's happening. Yeah, it all works really nicely. There's a lot of cool things happening in that Jupiter ecosystem. I'm finding. Yeah, I have, I've kind of had my eye not focused on it lately. I haven't been doing too many stories about Jupiter lately. But man, it's a train that just keeps going. So what's the name again, is G-J-U-P-Y text? Yeah, okay, nice. That sounds like a great tool. I almost was thinking you were talking about actual printing, but it's much more of an intermediate format than to allow what you were just mentioning. Yeah, yeah. And then what's something that you want to learn next? This doesn't have to be Python specific, any kind of data analytics stuff. It's working with cloud storage more effectively because what I'm finding out with Polars is that the actual 1cr stops in memory and it's running that bit really heavily optimized. A lot of the bottleneck is now the interaction with your blob storage or S3 or whatever on the cloud. And then what I'm really hoping to see in Polars is that it can kind of take care of that. So if you've got a bunch of CSVs in the cloud, that you can just write your query and point it to the S3 bucket and then it'll hopefully be able to push as many optimizations as possible into the cloud and minimize the amount of data transfer. I think that kind of will remove the bottlenecks for a lot of people. Yeah, that sounds cool. Well, Liam, thanks so much for coming on the show. It's been really fantastic to talk to you. Yeah, it's been really fun. I really enjoyed it.\n\n[Music]\n\nAnd don't forget, for all your data science needs, join Anaconda Nucleus, your home for data science and Python. Join at anaconda.cloud to power up skills, innovate, collaborate, and find the perfect Python package.\n\nI want to thank Liam Branigan for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "2kaPDVD1Qr8": "Welcome to the Real Python Podcast. This is episode 141. Have you used the Python REPL (Read-Eval-Print Loop) toIt definitely shows part of teaching where it automatically highlights your code the way an IDE would. Having that in a repo session is really nice. Syntax highlighting indicates to the user that the highlighted thing is potentially different from another. Things like operators, comments, variable names, function definitions, and literal values like strings, numbers, or booleans are all highlighted and colored differently. It helps you quickly identify what's going on, especially for beginners. \n\nAlong with syntax highlighting and coloring, it has many other nice features that make it similar to working in an IDE. Python users often switch from an IDE to a standard Python prompt and lose all the advantages. This tool allows you to continue in the same mode as you drop back into a repo session outside of the IDE. It prevents context switching, as Bartosh points out, which is a good point. \n\nAnother teaching feature that I like is that it shows function signatures or doc strings as you type. It offers autocomplete options as you type, and you can tab through them or use Tab to auto-complete. This is helpful for students to understand how things work and what options are available. \n\nThe tool also has bracket matching features, suggestions, completions, automatic indentation, and a history feature that remembers multiple steps. It can rewind back and forth multiple steps, similar to a deeper undo. As a teacher, I occasionally need to clear the saved file to avoid auto-completing with unwanted suggestions. \n\nThe saved file is stored centrally as a hidden file. It's handy for teaching purposes to clear it out and keep the focus on the current learning concepts. \n\nOverall, the tool dives deep into Python configuration, debugging with pdb, quirks, and contributing to the project. It's a useful tool that many learners ask about and find helpful.So it was one of the most requested things as a tool that could enhance exploring and learning Python as you work. Do you use anything like this? No, I still use the old vanilla Rebel. Every time I go to do something complicated in it, I think I was going to do some research on these because there are competing tools out there.\n\nAbout 10 or 15 years ago, one of my developers set it up as default in one of our environments. At the time, our machines weren't fast enough, and it didn't feel responsive enough to me. It drove me nuts, so I was like, get rid of that. I got off you can do whatever you want in your own environment, just don't make it the default for the rest of us to use. I was always hesitant about going back, but processors have caught up, and it's a much better situation now.\n\nWith Rebel, I often write a little mini function, test something, break something in the middle of it, and then have to do up Arrow five times, once for each line in that function. But B Python deals with that kind of stuff a little better.\n\nIt's on my to-do list, and I'm looking forward to getting into this article in detail. I think more alternatives may be coming, which is something to look forward to.\n\nI wanted to talk about some alternatives on the show, like IPython, which is popular in the data science world. It feels like working in a Jupyter environment. Many of these tools have macro mechanisms, like magic words, to handle common tasks.\n\nFor Windows users, PT Python is a similar tool to check out. What's your first one? I'm going to talk about PEP 701, which is titled \"A Syntactic Formalization of F-strings.\" F strings were introduced in Python 3.6, but PEP 701 aims to create a grammar for the F string format to simplify code and remove limitations on fstrings.\n\nThe current parser for fstrings doesn't allow comments or nested expressions inside fstrings, but with the new grammar, these limitations will be removed. Elevating F strings into their own tokens in the parsers will resolve issues like error messaging inside fstrings and allow for better hints in Python 3.10 and 3.11.I don't know how quickly they will actually start adding some of the features. By moving it to the grammar, it allows them to do that in the future. This pep went through really quickly - it was created in November and it's already slated for Python 3.12. We've talked a few times on the show about how we both love the new error messaging. I'm looking forward to seeing these F strings augmenting with that kind of information. I think it's a big win. The other things like the comments and certain kinds of nested pieces, I'm indifferent. It's great if it's there, it'll make the F string more like Python the language. But the error processing was the thing that made me smile.\n\nPablo is definitely involved in it - he is the top name on the author for the 701. Being so involved in the error messages and kind of tying in nicely.\n\nAre you building real-time applications? Check out InfluxDB Time Series platform. InfluxDB is optimized for developer productivity, so developers can build IoT analytics and cloud applications quickly and at scale. With its data collectors and scripting languages, a common API across the entire platform, and highly performant time series engine and storage, InfluxDB makes it easy to build once and deploy across multiple products and environments at the edge, on-prem, or in the cloud. Check it out and start for free at influxdata.com.\n\nMy next one is from a previous guest, Brett Cannon. He's been on a few different times and if you don't remember, Brett's sort of background, he's a core Dev and a member of the Python Steering Council. But he also works for Microsoft. He works on the dev experience side for VS Code and is involved in the Python extension for VS Code.\n\nHe's Canadian, but he'll be honest - snarky Canadian as his website says. He was on a while ago and had talked about a project he has called the Python Launcher for Unix. He's been working on that for a while. I think I mentioned also that something I noticed about him was multiple years ago I said, \"Why do you like to do polls?\" In a time, he was doing most of that on Twitter and now he is only on Mastodon. So he's been kind of repeating that sort of trend of like, \"I like to pull the followers.\" These are mostly Python people following him, and he'll ask questions of them to think about decisions he's making as far as software and so forth.\n\nThe article on his blog is called \"Classifying Python Virtual Environment Workflows.\" He's got like a handful of different questions he wanted to figure out. It's all really diving deep into the idea of how do people use this tool of virtual environments. The article really focuses on standard Python virtual environments and not using the Conda environments, which is very popular in the data science world.\n\nOne first question was, in your setup, who or what manages the virtual environments? Could it be a tool that you're using like Pipenv, which will automatically create the virtual environment and then decide the location of where it's going to store it? There are tools like Poetry and a couple of others that try to help with that experience also and might do the same thing where there's a central repository somewhere in your machine maybe kind of obfuscated.\n\nThere's a tool called Virtualenvwrapper or Pyenv virtualenv, and these two are just assistance. They kind of maybe walk you through a script in the process of creating a virtual environment, but they don't hide or move the thing to a special location. They just sort of want other information and kind of walk you through the process. The other way is to create it manually - you, the end user, are deciding. You type venv, Python -m venv, and then you're giving the virtual environment a name and potentially a location, but you are the one deciding where and what to call it.\n\nI might ask you a survey, Chris, as we go - which of those are you typically using? So I still use Virtualenv, and more out of habit than anything else. It was one of the superior ones when I got started. The problems those solve aren't problems I've run into because the Python I write isn't hundreds of thousands of lines of code, and so I'm usually able to manage things without getting crazy.\n\nOkay, so you're the one managing it usually with the tool. I'm usually the one managing it, and part of that is also I don't really use an IDE - I'm old school, I use Vim.I tend towards command line stuff in the first place because of that. One thing I do have that is a modification is a function defined in my bash script that is the ACT command. My ACT command knows where I keep my virtual environments. So, if I say ACT RP, it will go into the place where I keep my virtual environments and run the source on the directory called RP, going into bin source and activating it. Essentially, I don't have to go into my virtual environment to activate them anywhere. That's the one compromise I have to manage the fact that they're centrally located.\n\nOne of the things mentioned in the article, which I think is why I still lean towards centralization, is that there are a bunch of places where my virtual environment is not connected to my project. For example, I have two or three different real python virtual environments with all my teaching stuff and recent library pieces, but I don't want to set up one for every single course. Contrast that to when I'm writing some code, I'll create its own library. The idea of the VMS being local makes me cranky from that perspective.\n\nI have lived in multiple worlds with this concept, and maybe I'm spoiling some of the later stuff, but the next question is really talking about where the virtual environments are kept. Maybe it's a central directory or you're doing it locally. For example, having a singular virtual environment for a cross-section of projects or doing it locally within the project.\n\nWhen I was working in an office, I was very often doing the thing with the central installation of Python and keep adding things to that based on that install. Because I was doing the same kind of work repeatedly, it made sense, and it was very script-based and not project-based. But when I moved to real python, it made sense to have a virtual environment for each project I was reviewing, even though it meant several steps to get going each time.\n\nThe article discusses how many virtual environments are needed, with options ranging from a single version centrally located to multiple virtual environments per version of Python installed. I've been using multiple environments for differing dependencies, with nothing tying them together, which is a small percentage of people.\n\nThe author also mentions the idea of additional virtual environments set up by tools like testing tools, such as Nox or Tox, for running tests. He talks about the importance of tools recognizing virtual environments and where they are coming from, especially in an IDE for code completion.\n\nOne question I have is about naming conventions for virtual environments. Do you use the hidden naming convention with a dot in front of your virtual environments, or is it not an issue because they're centrally located? I have a directory creatively named Pi_VR_.Ms. I think it is okay and there are a whole bunch of virtual environments now. I usually put the name of the virtual environment in my prompt string, which is really common practice. So my virtual environments tend to be really short obscure acronyms. One of the things I've also started doing is I will often, inside of the virtual environment directory, put a soft link to the project. Inside of the project, I usually put a file which is dot p y vrms and inside of it, it just has the acronym. So that if I come back to a project like three years later, I'm like okay, what environment goes with this? Where is it going? What is bqr? What was that for? I don't know what that is.\n\nYou were talking about he kind of skipped past the talk stuff. But it's kind of funny because I end up in both places. I have centralized virtual environments for my primary build, but I use talks for my testing. Talks has project-based virtual environments. And because I'm using talks to test multiple versions, I end up with technically virtual environments in the project and virtual environments outside of the project. The stuff outside is where I usually am doing my coding, and the stuff inside of talks is really just the hey did I break anything in three seven kind of thing. Just making sure that stuff works.\n\nIt's again, it's an interesting methodology. I like that it goes out to sort of, you know, there's stuff that you do that you kind of sometimes will assume based upon how you've been brought up and taught how to do this stuff and followed things that you go, well, this is what people do. And it's like, well, maybe not. You know, and if not that it's quite connected, it's more connected to the packaging stuff. But I fought tooth and nail using the SRC directory. I don't know. I shouldn't exist. There's no need for it to exist. We don't need it. But now all the modern tools want it there. And I finally just gave up and I'm like, fine, fine. I will stop trying to figure out how to tell you where to put the code, and I will put it in SRC so you can find it automatically. \n\nSometimes knowing what most people are doing and bending to that, you know, black is the same thing, right? I don't entirely like black's formatting, right? But aesthetically, aesthetically, yeah. But everybody's using it, and it's one less argument to have. So sometimes being compliant with the majority makes it easier to code, even if it bristles against you a little bit. And if you're making a tool that needs to kind of yes, make the best guesses, it becomes that much more important. \n\nSo that's kind of the idea. I thought about having to come on the show again. I'll see if I can reach out just to talk about that. And then he's been working kind of, you know, we talked a lot about he completed that series on his blog about the sort of syntactic sugar and the unraveling series that he did of like going through all the different pieces and kind of thinking about what is the core of Python. And part of that was to tie into, well, you know what's happened now with the web assembly and now that that's kind of come to light with things like Pi script. They've also figured out a way to make that small enough to fit on something like micropython. And so he was on a recent like Talk Python episode talking about that. So I thought maybe that'd be good to have him come back and discuss some of this. \n\nSo we'll see what's your next one. So this is a real Python, some real Python content, and we're going back to diving down the ego Avenue here. And it's one of my courses.\n\nYes, it is. It's on context managers, and it's based on the original article by Leo Donna Ramos. I just like saying his name, it's fun. The course and the article are called context managers and Python's with statement. If you haven't played with them before, context managers are what you call the thing after a with statement. And if you haven't used the with statement before, the most common example is when you're opening a file. So you write with open brackets file name as handle, and all the code underneath that block has access to the open file through the named handle. Context managers are one of my favorite features of Python. Python is not my first programming language.I have spent a lot of time in other languages ensuring that my open file statements were matched with corresponding closed file statements. Bugs can happen and messiness ensues whenever using any sort of resource files, network connections, or database connections. The beauty of a context manager is that it automatically handles the closing for you, making the code cleaner and more automatic, which is great.\n\nA context manager works by having an enter and exit method attached to them. When you instantiate a context manager using a with statement, the enter method is called when the block is entered, and the exit method is called when the block is exited, either normally or due to an exception. For example, in the case of an open file, the enter method opens the file, and the exit method closes it.\n\nPython sees the whole world as an object, so it's not surprising that context managers are classes. Python comes with a variety of context managers, but you can also write your own by implementing the enter and exit methods. The Dunder enter and Dunder exit methods have specific signatures that allow a class to be used as a context manager.\n\nThe course goes through different examples of context managers in the Python standard library, how to write a class-based context manager, and using a decorator in contextlib to build context managers out of functions using the yield keyword. This reduces the amount of code you have to write.\n\nI recently used a context manager in one of my open-source libraries for unit testing purposes. By creating a new context manager that wraps the assert raises context manager, I was able to add more context to error messages in unit tests, making debugging easier. This allows variables from loops or other parts of the block to be included in the error message.\n\nOverall, I enjoyed the course as it delved deeper into the creation and implementation of context managers, exploring the special methods and magic behind them. It was informative and provided a better understanding of how context managers work.Yeah, we have it marked as an intermediate tool. I wouldn't start out with this if you're new to Python. Use the magic, take advantage of the magic. But if you're ready to progress to the next level and you're comfortable with the basic language features, this is a powerful tool.\n\nThis week, I want to shine a spotlight on another Real Python video course. Christopher shared this course earlier in the episode. It's titled \"Context Managers and Python's With Statement.\" It's based on a Real Python tutorial by previous guest Leodanus Pozo Ramos. In the course, my co-host Christopher Trudeau takes you through how context managers work, what the Python with statement is for, and how to use it to manage resources. It covers common usages within the Python standard library, how to work with the special methods of enter and exit, and examples of how to implement your own context manager.\n\nIf you've ever wondered what the with statement does at the front of a block of code, how it operates, or how to implement it within your own code or classes, this course will be a valuable investment of your time. Real Python video courses are broken into easily consumable sections and include code examples for the techniques shown. All lessons have a transcript, including closed captions. Check out the video course, you can find the link in the show notes or you can find it using the enhanced search tool on realpython.com. [Music]\n\nSo, this next one, we had marked it as a bit of a discussion, but it sounds like you did a deeper dive. I will add my commentary as we go, as I've been asking you questions. My favorite kind of discussion, the one where I do all the talking. Yeah.\n\nThis is based on an article published by Hillel Wayne called \"Micro Features I'd Like to See in More Languages.\" Hillel has outlined three levels of features in programming languages. Level one is a feature that the language is designed around and these can't usually be easily ported to another language. The example he uses here is Rust's Borrow Checker. Level two features heavily define how the language is used, such as particular data types and how async code works. Level three, which is what the article is actually about, is the fluffy stuff that pretty much any language could borrow. The example he gives is a Python one, which is Chained evaluators. In Python, you can say if 2 is less than or equal to X, which is less than 10, you can do all of that in one statement instead of using an \"and\". The language obviously has to support it, but there's no reason other languages couldn't build this in and steal the idea.\n\nDo you feel like that last one, the quality of life feature, kind of comparing the two like two and three? Two he mentions like pattern matching being one of those things and it was more work involved and changes to the language that make it a little harder to do. Similarly, the quality of life might be something like that new pep that traveled through really quickly for f-strings. I don't know if that's quite the same. There might be other things there.\n\nAgain, the whole premise of the article is really just about these little things. This guy must have some deep language experience or likes to play with it because there are multiple languages in here where I'm like, I don't know what that is. Okay, yeah, totally. And the first feature he uses as an example of this kind of thing is something that's in Python. I remember being really happy when I discovered that this works. In fact, I was just teaching a Python course a few weeks ago and I showed the students this, and they went, \"Oh, that's cool.\" The idea here is if I say to you 1000000, you're gonna go, \"Was that a hundred thousand, a million, or ten million?\" And of course, when you see that in the code, you have the same problem. How many zeros are there as your eyes cross? In Python, you can put underscores anywhere in the number, and the most common place to do it is to put them where North Americans put commas in those numbers so that it's easier to read, say the thousands grouping. Now, that's actually culturally specific, and different people group them different ways, but it's essentially another tool to make it easier to read these kinds of numbers. This is one of the features that's in a bunch of different languages, Python supports it, there are some variations on it for other kinds of numbers as well, and this was one of the things that he thinks should be stolen.\n\nNow, let's move on to some things we might be able to argue about. The first one I kind of like, I don't think it'll ever happen, but I like it.Lua supports multi-line strings using paired double square brackets. The reasoning behind this is it makes nesting things easy because the opening and closing tokens for the multi-line are different. This allows you to stick square brackets inside of it, and because they just need to match, the parser can deal with it. There's a lot less escaping going on, and the only thing that you really have to escape is if you need an unpaired set of closing squared brackets inside of your closing square brackets. That's pretty uncommon, unlike quotation marks.\n\nStrings are one of those things where Python has both single and double quotes, as well as triple quotes, which is helpful. However, when it comes to multi-line strings, I saw Lua's implementation and thought, \"Yes, I want that in Python.\" It would be great if someone in Python could add this feature. Additionally, it would be helpful to have a way to automatically remove the indentation in multi-line strings to align them with the code. Unfortunately, this is not possible with string literals, as it would require a function call to achieve this.\n\nSome languages, like Ruby, allow you to indicate to the parser to remove all leading indentation in strings. This is another feature that I would love to see implemented in Python. Moving on to a language I've never heard of, NewLisp has a feature called \"function equals,\" which I find a little hard to parse. It allows you to replace the plus operator with any function, making the code shorter but harder to read.\n\nAnother interesting feature is found in Chapel, where declaring a variable as \"config\" automatically makes it available as a command line flag. While this integration with command line argument management is neat, it may be challenging to adapt to Python's library-based approach. Similarly, the Frank programming language supports dates as a built-in type, simplifying code but posing compatibility issues with Python's date objects in libraries.\n\nHillel, a proponent of Kebab case in variable names, finds it more readable but acknowledges it may not work in most languages due to parsing issues. This naming convention, using hyphens instead of underscores, is not favored by many, including myself. The distinction between Kebab case, camel case, and snake case can be confusing, especially when used in HTML.\n\nIn conclusion, exploring different language features, such as Chapel's automatic command line flag declaration and Frank's built-in date type, offers insights into potential improvements in Python. While some ideas like Kebab case may not be widely adopted due to parsing challenges, it's interesting to consider how different languages approach common programming practices.Somebody's getting creative with just two quick ones. Ruby has a special data type called a symbol denoted with a leading colon. The most common use of this is inside dictionary keys, which allows the parser to differentiate between a dictionary key and a string, making the parser's life easier and preventing certain bugs. There are other places where it can be used as well, and I think JavaScript is trying to go down that path with the JSON keys not requiring strings around it. I'm not sure how much of a difference it would make, but there are some edge cases that make it more interesting. Another feature I like is in the D language, which supports unit test blocks on functions. There's a syntax keyword for unit testing built into the language, so when you declare the function, you can also declare the unit test that goes with it. This means the unit test isn't in a separate file, which I love because anything that makes testing easier and more connected to the code is a good idea in my book. \n\nI added my comments as I went, and I can see the advantage of not having to deal with separate files connected to the code. I can't think of any other strong features, but I've seen uses of ellipsis for range operations and other nice features. It's fascinating to learn about all these different languages. The article mentioned other data science-specific uses, such as using an ellipsis for mathematical series. It's interesting to explore these different languages and their unique features. \n\nProjects can be a great way to explore new concepts and languages. I recently tried a project called \"pie pod\" by Misha Bersky, which is an audio player that mainly plays WAV files. It uses a textual user interface and has a simple graphical interface. I had to install PortAudio to get it to work, but it was a fun project to dive into. \n\nIt's important to explore different languages and projects to broaden your understanding of programming concepts. By trying out different languages like Lisp or Haskell, you can become more comfortable with functional concepts that can enhance your primary language skills. Projects like \"pie pod\" can be a fun way to explore new technologies and learn new skills in programming.So this is by Ian Bicking and if I'm reading his blog post correctly, it's based on an idea he saw on Twitter from him. The idea is to make a string or List classes that automatically use GPT3 in the case of an index error. \n\nIan's posting starts with some ideas that are dumb enough you just have to try them. In that spirit, he wrote an infinite AI array so the library declares two classes - an array and a dick. The new classes overload the index error and key error exceptions, calling GPT using both the current data and the object context to predict the next item in the array or the dictionary. \n\nYep, bottomless arrays and bottomless dicks, you'll never see an index error ever again. Ian has a great sense of humor and the readme includes statements such as \"But copy and pasting is too much work. How can I make my programs more dangerously unpredictable?\" \n\nOne of the examples he shows in the blog is a list of his favorite books - Dune, Perdido Street Station, Red Mars. He puts that in an array and the array's got three items in it. Then he slices it for eight items and GPT adds Hitchhiker's Guide, 1984, Lord of the Rings, Handmaid's Tale, and The Martian Chronicles. \n\nIf this is not crazy enough, the library also has a class called Magic. By calling a function on Magic, it then uses the name and the arguments for the function to call GPT to make the function up. \n\nThere's even a prompt to use a third-party library. For example, Magic.fetch Wikipedia Source prompts to install the necessary libraries. It uses both the name of the function and any named parameters. \n\nIan is very upfront that all of this is meant as a joke, but it's fun to play with. The library has tools inside so you can see what code got generated for Magic. \n\nIt's fun to play with and if you want a quick intro on how to programmatically call GPT, then this is a small enough library that it's easy to digest as an example. \n\nThanks again for bringing all that Pi coders goodness this week and we'll see you in a couple weeks, Christopher. Looking forward to it. \n\nAnd don't forget, the easy to start and scale InfluxDB time series platform is available in the cloud, on premises, or locally. Get started for free today at influxdata.com. \n\nI want to thank Christopher Trudeau for coming on the show again this week and I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. \n\nWhile you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey and look forward to talking to you soon.",
    "8HIBxJM-GBE": "Welcome to the Real Python Podcast. This is episode 143. Would you like to add data quickly to a map with Python? Have you wanted to create beautiful interactive maps and export them as a standalone static web page? This week on the show, Christopher Trudeau is here, bringing another batch of PyCoder's weekly articles and projects. We share a recent Real Python tutorial about using Python Folium to create geospatial data visualizations.\n\nFolium harnesses the power of the JavaScript library Leaflet. The project shares how to combine this graphical power with Python's data wrangling strength. Christopher shares a recent Python Enhancement Proposal about the Global Interpreter Lock in CPython. The proposal suggests a change to the build process that implements a flag for optionally building a GIL-less interpreter. \n\nWe share several other articles and projects from the Python community, including a news update, a YAML document from Hell, a set of logging practices to follow, a discussion about the discourse surrounding the recent Python Packaging User Survey, a modern Python UI Library based on Decanter, and a lightweight toolkit for bounding boxes.\n\nThe InfluxDB time series platform empowers developers and organizations to build real-time IoT analytics and cloud applications with timestamp data. Learn more and start for free at influxdata.com.\n\nAlright, let's get started. The Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Christopher, welcome back. Good to hear your voice. I'm excited to dive in this week. We've got a lot of interesting things and a really in-depth discussion that's been all over the Internet. We're gonna add our two cents. Exactly, yeah, four cents. That's worth a lot. You did have one small news item, is that right? \n\nYes, something that just popped up recently. There's a library that's been kicking around for a long time, which is Bleach. It's an HTML sanitizing library. They have just announced that the 6.0 release is out and they're officially deprecating the library. It's dependent on HTML5 lib, which is no longer maintained. Because Bleach is meant as a security library, they were nervous about being based on something that wasn't maintained anymore. \n\nThe amount of effort involved in porting it to something else was too high. For the next year, you'll get bug fixes, and then after that, maybe you should use something else. It'll be an interesting conversation at some point as to what the alternatives are. I think the de facto answer is don't allow your people to input HTML ever. Use something like Markdown instead, and then you don't have this problem and it's far safer. \n\nI think that's probably the right answer, but maybe somebody else will pick up the torch. Have you used this as a tool in some of your Django projects? It's a common thing on the web, like if you've got blogging, anywhere where you can allow the user to input, they might put in a JavaScript tag and that can do horrible things if you just post it regularly on the site. So you want to clean the HTML. \n\nIt has become like a lot of the TinyMCE editor and those kinds of equivalents where you allow people to input structured text. All support some sort of Markdown now, so increasingly the answer to the question is don't support anything that could break your site, and that fixes it. But yeah, I've used Bleach a fair amount over the years. That's good to hear. The community of writers that I know are mostly comfortable with Markdown. \n\nIt was definitely an introduction to me when I joined Real Python that our whole world is Markdown of sorts. Getting used to it, even using it for generating slides and other things like that. It's interesting to see that other people, contributors and such, would probably be comfortable with it too. And I guess just seeing as we're talking about it, a big thanks to Will Con Green and others who have been maintaining this library for the better part of a decade. Go work on the next interesting project. \n\nThat gets us into our articles and tutorials this week. Mine is a Real Python one from core team member and previous guest, Martin Boyce. It's almost a step-by-step. It really feels very close to that.But it's a tutorial about a tool called Python Folium. Folium is using a tool that I had heard about several years before I got into Python for doing mapping called Leaflet, which is a very popular JavaScript library. Folium ties it together with a nice Python API. Probably the greatest thing about it is that once you've created this fairly short script of creating and designing everything, what you output is a geographic visualization that can be shared as a website. It just outputs an HTML file that can be interactive, and you can control different components in it. So, it really shows off Folium.\n\nIn the process of it, you're gonna walk through setting up your environment, pip installing, and getting all that stuff going. Within three lines of a Python file, you've run it and it outputs that single HTML file, which you just open up in a browser and see the results. The default map tiles for the library are all from OpenStreetMap, which has pluses and minuses to it. Sometimes you're going to want something that looks different or has a different sort of styling. So, Martin takes you through a tool called Positron. There's this Cardo DB and Stamen Design Group that has made nicer base maps that can be imported and used in it.\n\nHe quickly adds geolocation stuff to it, and you can add the default zoom level and all these kinds of little commands pretty quickly with Folium through a few keyword arguments. You get to practice some of that. And then he uses a tool called GeoJson to describe the map a little bit more specifically for this purpose. You're going to look at it with political country boundaries that would then align with database information, so you can get your data. In the end, he's creating a choropleth map, which is basically a colorful way of indicating levels. In this case, it's ecological footprint per capita information. He talks about binding that GeoJson layer to generate the choropleth map and how to style it.\n\nOne nice thing that you can do with this since it's an HTML file is that you can work with this in Jupiter and get even more interactivity. He provides files for that, provides the CSV data for working with this particular project, coming from a Wikipedia article talking about ecological footprints that different countries have. Our two countries are not the best as far as our ecological footprints, but he talks about reading that information. He also talks about finding the keys within GeoJson data, which was a nice little aside that he had in there.\n\nHe ends up wrapping up, doing much more data visualization types of stuff, like controlling how many bins you have and adjusting where the colors show. Sometimes you apply something and it isn't quite giving you the story that you're wanting to try to share, so he does a little bit of adjustments there, doing custom data binning and adding the ability to control the layers. It's a nice tour of this tool to get you going with Folium, and I was impressed with how quick and breezy it was. If you're looking for a nice tutorial to get you going and you thought about adding maps to your data visualizations, this is a nice library to do that. You can download all the code, the CSV, and the Jupiter notebook to play with interactively. They also added a quiz, which is nice that you can try out. \n\nHave you done much data visualization stuff or played with mapping in that way? No, it's not a place I've entered into. I've worked with departments that did it, and yeah, sort of bow to the Wizardry. I do know it's something as simple as what title are you going to put on that landmass is a tricky question sometimes, so yeah, I'm happy to have stayed out of it. The political boundaries were an interesting wrinkle in this particular tutorial. When I worked at a law firm in Hawaii, there was a lot of that sort of geographic and other interesting data in the whole mapping area. Also, working in environmental science, it was pretty common to look at what tools are available. It's nice to see Leaflet being embraced in this way and getting into Python.\n\nWhat's your first article? Well, you know, the only thing I think Python developers like talking about more than how the transition from Python 2 to Python 3 caused famine, plague, and the dissolution of society as we know it is how the GIL is the only thing standing in the way of us using Python as a programming language. Yeah.Silliness aside, there have been many proposals and lots of work over the years to make Python faster and handle parallelism better. The latest is Pep 703, which is titled \"Making the Global Interpreter Lock Optional in C Python.\" In case you're new to Python or have had the good fortune to avoid writing code in parallel, the Global Interpreter Lock, known as the GIL, is a mechanism that prevents parallel code from accessing certain assets at the same time, causing problems when coding in parallel. There's a single lock throughout the interpreter, affecting extension packages written in C, for example.\n\nThere has been much talk over the years of a \"galectomy,\" that's what the cool kids call it, about removing the GIL from C Python. The challenge to removing the GIL isn't just C Python, the interpreter itself, but its extensions. As soon as you start to touch these things, you're going to impact how the C extensions work and whether or not the interpreter is backwardly compatible with those C extensions. The community doesn't want to create a big chasm of incompatibility just to fix the GIL, so Pep 703 proposes an interesting solution.\n\nThey're going to add a build flag to the interpreter that turns the GIL off. Essentially, the idea is to recognize that there's a subset of the Python community that's okay with a lack of backward compatibility and who could take advantage of the increased parallelism by removing the GIL. Instead of getting rid of it completely and creating compatibility problems, they're giving users the option to compile their own version of the interpreter without it.\n\nIn order to do this, they have to rearrange some of the interpreter's internals, such as the reference counting mechanism. If you build an interpreter with this new disabled GIL flag, it would not be binary compatible with the regular interpreter. Extensions that work with this new build become responsible for some of their own locking, meaning changes may need to be made to those extensions. The Pep is already marked as Python 3.12, so this should be showing up in the fall.\n\nFor developers doing data-intensive computation where parallelism is important or aren't particularly dependent on existing extensions, this could make a difference. Key players in the extension space like pandas and numpy might release compatible libraries that could take advantage of this new feature. It's an interesting development and a step towards addressing the GIL debate without completely getting rid of it.\n\nIt sounds like if you're interested in this, there will be some legwork on your end to make it happen. It essentially gives users the option to remove the GIL but at the cost of some compatibility issues. It's an interesting solution that allows for increased parallelism without creating major compatibility problems.\n\nThere have been various proposals and discussions around this topic, including sub-interpreters, which is still in the background. The prototype available with the Pep shows that this is more than just an idea, there's actual code to commit. If you're interested in this space, check out the Pep and the connected documents for more information.\n\nInfluxDB is a time series platform optimized for developer productivity, allowing developers to build IoT analytics and cloud applications quickly and at scale. With data collectors, scripting languages, and a common API across the platform, InfluxDB makes it easy to build and deploy applications across multiple environments. Check it out and start for free at influxdata.com. \n\nThe conversation then transitions to discussing different market markdown languages and the popularity of certain platforms.But it's definitely a tool that is in use across a variety of systems. It's something that you run into from time to time. I have had the experience of working with YAML, even though YAML is not specifically Python. It is a tool that you, as someone who is configuring tools or working with other people's projects, may have encountered.\n\nThe title is \"The YAML document from Hell.\" It's a blog post from Rude Van Acellbunk that covers an interesting set of hazards, potential pitfalls, or as my co-host Chris likes to call them, \"foot guns\" of YAML. The article starts with a nice introduction into how complex YAML is. It compares YAML with the JSON spec. There is a link to a YouTube video where Douglas Crawford claimed to discover JSON because it was so obvious and not invented. Many of us have used JSON and understand its functionality. YAML has strange edge cases, especially with the concept that it doesn't require strings to have quotation marks around them.\n\nThe article delves into different examples where YAML can cause unexpected results. One example is with port mapping where a number below 60 can be converted into a different number due to an arcane feature in YAML 1.1 that was silently removed in 1.2. This can lead to unexpected errors and confusion when working with YAML files.\n\nThe article also mentions how different parsers and versions of YAML can lead to varying results, making it challenging to work with YAML consistently. It warns against loading untrusted YAML documents due to potential safety concerns. One notable issue is the \"Norway problem,\" where the abbreviation for Norway in a list gets translated to \"false\" in YAML 1.1, leading to unexpected results.\n\nIn conclusion, working with YAML can be tricky due to its quirks and inconsistencies across different versions and parsers. It's important to be cautious when handling YAML documents to avoid unexpected errors and vulnerabilities.Yes and Y are true in that case also, so it's really kind of confusing that no would be translated to false. I'm not sure what other languages actually do that. I think it was meant that the original purpose of YAML was supposed to be more human-readable and not just for developers. So yes, no is sort of an obvious, and again, on-off has the same problem that I live in Ontario, which the two-letter Province code for that is \"ON\". Heaven help you if there's an Ontario, Norway because you're in trouble.\n\nAll right, no, yeah, too crazy anyway. So it continues and gets into non-string keys. Going back to our friends ON or NO or things like that, if that's potentially an abbreviation or something that again trying to be human-readable would make sense as a value, and that is that it could be translated into Boolean, and then that may not work as a key.\n\nThen one other thing that I wasn't totally assured on, but basically leaving strings encoded can lead to unintentional numbers that you're getting in there. So I'm wondering if that whole kind of version number thing where stuff gets rounded or ordered differently potentially because it's again numbers without quotation marks around it that they're intended to be strings. It's very intriguing, like all these different kinds of things that are in there.\n\nThe other one that I really enjoyed thinking about is a lot of people say, \"Well, I'll solve my own problem here by I'll just create a template and always use that and work inside of it.\" But that can be a terrible idea because whitespace is significant. So if you've laid out a template and you're maybe pasting values in or something, you may suddenly have adjusted your indentation and your whitespace, and suddenly you can't figure out what's going on as far as what the errors are. So copying and pasting and templating could be a really terrible idea.\n\nHe had a nice meme that he tied to there, which is a video of three people trying to find a duck while blindfolded as a kind of a contest, and the duck's just sort of wandering in between them. It's the idea of you trying to figure out where does the whitespace start and end here, these different things.\n\nThen he gives up some suggestions as far as alternative configuration formats. TAML, which we've talked about on the show a few times, is similar in many ways. Probably the biggest one is that strings are always quoted, and it is embraced by Python in kind of an interesting way. It's now even in the Python standard library. I'll include some links to a recent article by Garano about that, also includes a link to a fairly recent article about YAML from Bartaj about this. He covers some of the potential foot guns and so forth, but it isn't quite as convenient as some of the things that are coming now with Python and TOML becoming better friends.\n\nSo yeah, it's interesting to think about all these potential ways that you could get yourself in a bad situation just with a configuration file. And as YAML aims to be a more human-friendly alternative to JSON, in his conclusion, he's saying with all of its features, it became such a complex format with so many bizarre unexpected behaviors that it is difficult for humans to predict how a given YAML document will parse. I haven't had these kinds of levels of problems, I think I've had problems with the indentation, whitespace stuff, but not as many with the values. Have you run into issues with YAML yourself at the spacing all the time we use it as the feeder format for the Pi Coders newsletter, and I tend to have to do a lot of copying and pasting from little bits of snippets of templates and things that we have to do to add an event or something along those lines. And I'd say, I don't know, once every week or two, I'm getting a failure on line 432, and it's like, what's wrong with that? Oh, wait, there's a space missing. Yeah, so it's kind of wild all the other ones that there's been the document that they wrote is really intense as far as creating the specifications and comparing it to something like the JSON spec. If you've got a choice, I would suggest nowadays, if you're writing something new, use TOML. Avoid YAML if you don't have a choice, well then, you know, good luck.\n\nYeah, totally. What's your next one? So this one is General Development Advice article from Elrond Tourism called Logging Practices I Follow. As the title implies, this is advice about how to structure your logs. The first part poses a great question: should you even log it? Elrond breaks that down into sub-questions: is the thing you're logging a big object? If so, can you log only part of it, maybe like its length or some of its attributes? Is the info logged elsewhere, particularly in complex systems? You see the microservices all the time where it's like the first service logs it, and then the second service logs it, another third service logs it.So do you need that redundancy? The key question to ask yourself as you're writing the log statement is, does the information actually help me debug or understand what's happening, particularly in production? After covering whether to log, he goes on to talk about how to log.\n\nThe advice section starts with being consistent, which is great advice. Most logging tools will let you set up some sort of template that can help you with things like starting the message with the module or service name, and then the function - the name of the function or method that the log statement is inside of. Having that consistency can make it much easier to find things. \n\nNext, he talks about the logging level. Most log systems support error, warning, info, and debug. Being too verbose can turn into a cost, as some systems charge per gigabyte of logs. Each log call should be unique to avoid confusion. \n\nOverall, the article provides good advice on logging, regardless of the programming language you are using. It emphasizes the importance of being frugal with logging to avoid generating excessive logs and potential security risks. \n\nIn the Python community, there has been a lot of discussion around packaging tools and the state of the packaging ecosystem. This discussion has been sparked by a recent survey from the Python packaging community on how developers feel about the current state of packaging tools. Numerous articles and threads have emerged in response to this, leading to a flurry of discussions on the topic. \n\nIt's ironic that one of the complaints is that there are too many articles and threads discussing the abundance of packaging tools. Despite the overwhelming amount of information, the discussions aim to address the challenges and improvements needed in the packaging ecosystem.And then we'll start chatting about some of the vitriol that's been going back and forth in the discussion communities. I will start off with a really long but very descriptive title and article. The title is \"How to Improve Python Packaging or Why 14 Tools are at Least 12 Too Many.\" Unfortunately, the article is by someone named Chris, so I'm going to refer to him by his last name, Warwick, just to keep it clean. Warwick has written a really in-depth article that includes a survey of the current state of the packaging ecosystem, a comparison to how other languages do it, and some thoughts on that packaging survey that I was just talking about. \n\nHe starts out by giving a little bit of a history lesson, talking about the original distutils and setup.py. This evolved over time because requiring code execution for packaging is asking for trouble. And then, of course, we had the addition of virtual environments and all that, and then came wheels. He talks about each one of these and how the new tools came about, and different metaphors and all those things. And then, of course, there's the sideways answer to these things, like, \"Okay, use conda instead.\" \n\nThe heart of the article, or at least my favorite part, is he's got this big beautiful table in the middle that lists 14 different tools and the capabilities each provides. Some of these tools overlap with each other, and some are standalone. For example, if you're using conda, you're not going to be using pip because those things don't work together. Some of them are supersets, so like pipenv is meant to be a replacement for pip and virtualenv. What really blew my mind, I honestly didn't know that much about the folks who built these things, so I'd always kind of had the assumption that the reason we have so many is because everybody's come along and said, \"I will fix that.\" \n\nWhat blew my mind was there's not as much independence as I thought. A significant percentage of them come out of or are blessed by the Python Packaging Authority. Nine of the 14 are officially part of the authority. So I always figured the reason we had so many was because there wasn't a recommended thing. Well, it turns out our recommender is producing a lot of the tools and making the confusion worse. It kind of reminds me of that XKCD comic about standards. \n\nWorks article finishes up by summarizing the results from the packaging survey. The short version is most people agree that this is too complicated, and although that seems to be a given, nobody's in agreement as to what to do about that. A lot of the packaging thread that comes out of the authority's conversation they were having was concentrating on things like some of the more complex stuff like binary management. And that's a tough problem, and it kind of goes back to that sort of backward compatibility and, you know, kind of similar to that Guild thing we were talking about. \n\nRight, like what are you willing to break? And the question Warwick raises, and I agree with them a bit on this, is where should we be focusing and can we solve the 80 problem or make it easier.This week I want to shine a spotlight on another Real Python video course related to this week's discussion topic. It's titled \"Everyday Project Packaging with PyProject.toml.\" In this code conversation, you'll follow a chat between Ian Curry and Garana Hiala, demonstrating the relatively new officially sanctioned way of setting up your Python projects using a PyProject.toml file and installing your package with Pip. This technique has a good set of benefits, such as being able to call your project from anywhere, playing on the same team as the import system, and allowing for consistent imports. Along with having one file that will work for many build systems. Along the way, you'll learn about structuring files and folders in your project, understanding different ways to run your script, exploring how the import system works, and exploring the Python packaging world. You'll write a Python PyProject.toml file to configure your package and learn how to install that package with Pip. You'll also dive into various rabbit holes as Ian and Garana talk about the aspects of the process.\n\nReal Python video courses are broken into easily consumable sections and, where needed, include code examples for the technique shown. All lessons have a transcript, including closed captions. Check out the video course; you can find a link in the show notes or use the enhanced search tool on realpython.com.\n\nHow about your guy? Would he say this one is from Pratyang, and it's titled \"Thoughts on the Python Packaging Ecosystem\"? It's a response to a discussion topic that was spawned out of the original packaging survey. I'll include a link to the Python Packaging User Survey conducted from September through October of 2022, and the analysis was put out in November. The conversation kind of started then, and there's a thread to the discussion on it, which is interesting. A lot of players familiar to the show have been talking about this. Pratyang's overall thoughts and his response to what's going on have a very deep background and have worked in packaging, worked on Pip, and are very involved in what's going on at the core level and know many of the main players. He has a TL;DR section, and I'll hit the key points.\n\nThe Python packaging ecosystem unintentionally became the competitive space that it is today. The community needs to make an explicit decision if it should continue operating under the model that led to the status quo. Picking from different tools that do end different things is a good model. Picking from equivalent choices is a really bad user experience. Picking a default doesn't make other approaches illegal. Communication about the Python packaging ecosystem is fragmented, and we should improve that.\n\nOne of the core things I'm getting out of different conversations is that the communication provided is very fragmented, and coming from an organization considered an authority, that seems a little weird. Key points from his article talk about Python users not being software engineers, and Thea Flowers has a quote stating that the reason there are so many tools for managing Python dependencies is because Python is not a monoculture. Users expect a default workflow, and when comparing ecosystems like npm or cargo in Rust, where there is a single tool, it's nice that it worked out that way. This has been one of those things where I scratch my head about packaging.I've had many conversations about it. People are working hard to get the standards together. There are a couple of key points: flexibility leads to complexity. Packaging in Python has had a reputation of being a bumpy ride, mostly due to Python's versatility. \n\nThere's a discussion about the community spectrum: caring, collaborative, cordial, competitive, and combative. Unfortunately, we seem to be in the competitive area, with many people trying to accomplish the same goal. \n\nTools like conda, poetry, PDM, hatch, etc., are in the competitive model, competing for users, being the best solution, and even for contributors. \n\nPIP is the tool most Python users have used, positioned uniquely in the packaging ecosystem. It comes with everything and is widely used. \n\nThere's a fragmentation in the back-end part of the build process, with many tools available. The plethora of tools doesn't bother me, as it shows innovation and different ideas. \n\nThere are discussions about setup.cfg, pyproject.toml, twine, and other tools, with questions about their necessity and integration. \n\nPoetry seems to be an answer to the existing tools and processes, providing a different solution. There's a need for better communication and clarity in the packaging ecosystem.We could definitely clean up the default. I think some of it too is I'd like to better understand, and maybe this is just my own ignorance, but I'd like to better understand where the boundaries are. If particular tools are supposed to solve specific problems, I'd like to know which problems they solve and which problems they don't. If you're dealing with binaries, therefore, you need this other thing, that's great. There seems to be a large amount of overlap and it's messy, which is the problem. One of the key areas he talks about, and I touched on it briefly, is looking at using pip, which is a core tool for installing Python and adding packages. At some point, pip needs to make a firm decision on whether it's a development workflow tool or just an installer.\n\nThere's no single place where users can go to get information about the Python packaging ecosystem, either on how it's evolving or what the functional best practices are today. There's a bit of a vacuum. The steering Community Committee saying this is the community's thing, but a whole bunch of it's packaged with The Interpreter. Warwick's article mentions pep 582, which is being included in Python 3.12, and it's closer to how node does things. It will not completely eliminate the need for virtual environments, but it does address some problems.\n\nCommunication could help if there were a roadmap somewhere, and some of the conversations were about the goals. This could just be my ignorance. There are so many packaging tools that I haven't explored. The history of it is somewhat messy. There's fighting inside of it, and it's all volunteer work. Should there be paid involvement to make it more authoritative? Working with the Python core team and the steering Council could help.\n\nI invited him on the show right about the time he was trying to get this pep proposed about lock files and standardizing that stuff, but it was shot down. There's still a lot of community voting for things, and it can be messy. As someone teaching new users how to use Python, it's an area that can be challenging. Am I giving the best solution to this person?And it's compounded by the fact that the default behavior is something that can get you in a lot of trouble. Because if you don't use a virtual amp, you are going to do a cross your entire operating system install, and it will cause you problems eventually. Those who are new to the system, like one of the things, I was teaching a python course for a client a couple of months back, and the people who were asking for the course were not python people. One of the things they asked for was like, what is a template of a programming file that does nothing. I'm like, oh, you're Java people, aren't you? You have to import this, you have to do a class, you've got to get these brace brackets. You want hello world, it's print hello world, like there's nothing else to do here. The thing you're asking for doesn't exist. The challenge with that structure is something they really like. The challenge with trying to teach that is the bare minimum shouldn't be don't install a package so you understand what the virtual amp is because it's going to hurt you months from now. Some of it goes away because we do things like use Visual Studio or use PyCharm, and of course, they handle a lot of that in the background. But you want that first experience to be that hello world experience, not to be dangerous. The fact that we have to use virtual M's to solve a problem that's there because of the history of the language, I understand why it's there. Maybe this pet will help it go away, but you're into this place where very quickly, it's like, oh, you're in the shallow end. Here's the print, here's whatever. It's not a gentle slope to the deep end. It's a 30-foot cliff, and you step too far that way, and you're drowning. I think that frustration makes it that much harder for new students to the language. Particularly, as you said upfront, so many of the folks in the Python community are not software engineers. They may want to share their code, and they should be able to do the simple things and solve the problems they need. Because there isn't that gentle slope, they may not know how close to the edge they're standing. I am arguing that maybe it should be a gentle slope. How do we get closer to a gentle slope? I wonder if something like Pi script or other tools like that mature, if that could help somewhat. I keep thinking about other potential ways of making the slope a little easier. We have our tried and true methods that we're using at Real Python, but I still feel like often people can easily get around those guard rails and be in deep water. Let's talk about something with the projects this week. You're telling me we haven't solved it? Sorry, 25 minutes later and we're still like, yeah. These people have been talking about it for gosh, it came out in November, yes. Maybe we should include just a little bit before, and if you don't want to hear this, skip ahead by many minutes. I got chapter markers, click to the next chapter. Spoiler alert, we have not solved the problem. Go ahead and click to the next chapter. There's plenty to read and get familiar with what's happening. I'll include all the different threads, and it's as heated as it sometimes seems. I agree that it's at least not a combative landscape. It's competitive, and maybe that's the trick, trying to get back from that a little bit to kind of go back to his scale of communities there. The call to action is maybe a few more folks volunteer into some of this stuff, and we'll see it cleaned up a little better. Or somebody provides funding in a way to help us move in that direction. My project this week builds on an existing UI library that comes with Python, depending on your installation, it's tkinter. You've probably heard us talk about it a little bit here. This is a project by Tom Shamansky and he has a few other contributors on it. It's called Custom Decanter altogether. It imports directly to tkinter but provides a set of new, more modern, customizable widgets ready for you to go. It adapts to system appearance, meaning that if you have light and dark modes that are part of your OS like in MacOS or in Windows 11, it also supports High DPI, which is one of my favorite things about it. I've worked with a few other libraries where that was a bit of a chore to work around.Well, how do I get the fonts in and so forth? This seems to have the scaling ready to go in. It allows you to have buttons with images, which is kind of a nice little thing that I dig as far as getting buttons to look a little more interesting. It can integrate going back to maps, it can integrate with enter map view. If you have played around a little bit with Decanter, I feel like this is a nice little add-on that can quickly get you ready to go building up on top of it. Just pip install custom skinter in that sense and their suggestion right now is to use the --upgrade flag fairly often because they've been working on it pretty intensely. There is a nice set of examples, one, the complex_example.py, I thought looked really good on Mac OS and showed off many of those features. Based on the screenshots on the GitHub page, it had a very similar look on Windows 11. So, if you would like help to make things look a little bit more modern in your GUI interface, this takes Kinter up another level.\n\nSo, what's your project this week, Christopher? We're going to close out with a project called Pi boxes by Devram Cavus. If you've ever played with any graphic toolkits, you may have noticed that something as simple as drawing a rectangle isn't always simple. Different toolkits use different coordinate systems, so the location of zero zero is not always the same. If that's not bad enough, you can specify a rectangle either by using two coordinates or by a coordinate and a width and a height. That's where Pi boxes comes in. It's a library that helps you translate between these different systems. The names of the systems he's used in the library are based on some other libraries that use those coordinate systems. A couple of them I hadn't heard of, but there's things like Almendations 51 and Coco. Essentially, it's just how those systems work. In addition to doing conversion between the formats, the library also supports common bounding box operations like Union and area intersections. If you're in the graphics space and you're having to deal with this kind of translation, it's a small library, but it could be really helpful.\n\nAlright, well, you're taking a nice little break here over the next week. I'm excited for your travels. Yeah, a little bit of sunshine. Canadian winters, the answer is to get away from them. Alright, I'll talk to you in a couple of weeks. Thanks, cheers. \n\nDon't forget, easy to start and scale InfluxDB time series platform is available in the cloud, on premises, or locally. Get started for free today at influxdata.com. I want to thank Christopher Trudeau for coming on the show again this week, and I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey, I look forward to talking to you soon.",
    "_rkL7jYKdxw": "Welcome to the Real Python Podcast. This is episode 144. Can you describe your business processes with flowcharts? What if you could define the steps in a standard notation and implement the workflows in pure Python? This week on the show, Dan Funk from Sartography is here to discuss Spiff Workflow. Spiff Workflow is a Python tool for translating business process model and notation diagrams into a workflow engine. You can manipulate this visual chain of events to suit your team's business requirements. Individual events in the workflow can contain blocks or scripts of Python code to be executed. We discussed the concept of low code software tools. Dan also talks about how Spiff Workflow aims at getting non-developers within an organization involved in development.\n\nThis episode is brought to you by Telemetry Hub. Get real-time insights with Telemetry Hub, the full stack monitoring solution. Monitor web apps, databases, servers, and cloud infrastructure with ease. Customizable alerts make it the go-to choice.\n\nAlright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Dan, welcome to the podcast.\n\nHey, thanks so much for having me. I'm excited to talk to you. I have worked in the world of small businesses and I know you're a listener of the show, and so you've heard me talk about it a little bit. When you mentioned this set of tools and this idea of workflows, I got kind of excited about having you on the show. We've been going back and forth kind of coming up with how we can present it. Maybe we should start off talking about what this tool called Spiff Workflow is. It's an open-source library for executing diagrams. The best way to think about it is like a flowchart. If you visualize a flowchart, that's kind of what the editor and experience looks like for authoring stuff. You just draw out a particular process and then this flow can execute that process. It's based upon a thing called BPMN. I actually ran it and it's based upon a thing called BPMN. I actually ran it and kind of sent BPMN out to a few of my coworkers and friends in Canada and Europe who knew about it. It seems to be maybe a little more popular in places outside of the U.S. I don't know why. There are definitely organizations here in the U.S. that use it, but I think they also have a lot of connection to Europe and I'm not sure. We've asked a bunch of people, even organizations here in the U.S. if they use it, and there's not a clear answer.\n\nWhat is BPMN?\n\nBPMN stands for Business Process Model and Notation. It doesn't even flow off the tongue very well. It's definitely a very enterprisey thing out there, traditionally used in a lot of historically very tightly connected with Java. But what's interesting about it is it's a very clean, rigorously defined standard for how you draw these flow charts, what the rules are, and how the flowchart can actually be executed. They've thought through almost like a complete way. They've thought about how to make every single component work and behave consistently. What we've done is kind of followed that standard but implemented it in Python.\n\nWas this a thing that you saw in use and designed some of what Spiff Workflow as a way to encapsulate it as a tool?\n\nI guess we picked it up for a different project. We were just looking for a good workflow system, how do we automate all these complex workflows for a university? In all of our searches, we came across BPMN that sounded really cool. But then we looked at what it took to use these BPMN tools and Java, and it was just such a headache. We spent a full week, and we just never really got something running that made any sense to us. Then we started looking for, let's find something in a language that we really like, does Python do this? And we found Spiff Workflow, which sort of did it at the time. It was kind of good following and definitely could execute the diagram. That's where we started playing around with it, and it grew from there.\n\nSo that's how you got involved in the project that existed before?\n\nYeah, Samuel Ables found it in 2010, and we didn't pick it up until 2018. But we really hit it hard. We picked it up for this project for the University of Virginia for their medical research center, really rigorous things that have to go on for you to do a medical research study at a university. There's lots of what you're about to do to people.Yeah, think about not only flow charts but checklists and things that all have to be meticulously reviewed by multiple parties. The cancer center, the X-ray group, various boards - everyone needs to review it. We encountered some challenges while trying to make everything work, and ended up updating and enhancing the system significantly.\n\nWe made numerous contributions to the point where Samuel handed over the repository to us, and we have been maintaining it ever since for the past three or four years. There's a core team in our consulting company consisting of five members who were already implementing Python within the workflow and wanted to build on top of it.\n\nInitially, it was an experiment on how to build a good workflow system in Python, but then additional support for bpmn was added. However, it wasn't widely used, so we tried to make it more user-friendly for individuals without Python development experience.\n\nBpmn diagrams start with a simple open circle as the start event, followed by various tasks represented by rectangles. Tasks can be user tasks, service tasks, or script tasks, allowing for data manipulation and integration with external systems.\n\nEach task box can contain Python code that can be executed, similar to writing a script. It provides structure and simplifies complex programming tasks, such as building forms or making API calls to services like AWS.\n\nThere's a connector proxy in place to facilitate communication with external services, allowing for easy integration of new functionalities. Overall, the system aims to streamline workflow processes and make it accessible to users with varying levels of technical expertise.I want to be able to send messages out over email to our private email server or whatever else you want to stand up in there so you can configure that completely separately all your integration points. \n\nI had a recent conversation with Calvin from six feet up and he was talking about working with a tool called Apache airflow and the differences between these sound way more like that thing is just automated and is told what to do by a programmer, and this one is going to be more interactive and allow lots of user input but also have some nice automation functions in it. It seems like I'm on a theme lately here in the show which is cool. \n\nI like airflow a lot, in fact, we patterned this connector proxy idea we've got entirely based on airflow because airflow nails it, it's gorgeous and highly extendable. In the future, it would really be creative if they just kind of came together so all the connectors that airflow offers, we could offer as well and they would all just work the same way. \n\nYou're going to dive into the next elements on the flow chart. You had talked about the squares initially, the tasks. Squares are tasks, circles are events. Airflow handles long-running things so you could inject timers that will interrupt things. \n\nThere are diamonds that handle parallel additional stuff. The one question we get frequently is how do you handle parallel approval processes on the kids' footwork go do that and yeah, it totally can. \n\nLanes are another aspect, they look like swim lanes if you've drawn other diagrams with swim lanes on them. These diagrams can kind of use that so if the arrow goes from a task in one lane to another, it's transitioning from one person to another. \n\nThere are a few good examples if you go to spiffworkflow.org, there's an example right there on the homepage that hits these major components and shows you how they work. There are videos online to cover more complex stuff like multi-user permissions and parallel approval processes. \n\nBPM is a standard that's based out there and there's a link to a book from Bruce Silver on the spiff workflow read the docs site. It's an ISO standard that exists out there, very rigorously defined, much more than just the things that I've mentioned, very deep and can handle a lot of situations. \n\nYou mentioned the popularity of BPM across various parts of the world, what are the types of industries outside of university and medical research approval processes that BPM is being used?And then we could talk about potentially some of the people using your tool. Right now, what we're seeing in the community is that it is heavily used in the banking industry and telecommunications equipment. It seems that these organizations use it a lot. It's focused in Europe, with major companies like BPMN now Flowable, Kamunda, which are huge contributors to open-source tools like the BPMN editor we use. These companies are based in Germany or Switzerland. There is also a lot of academic traffic around BPMN, with about 16,000 articles published since 2019.\n\nThere's nothing stopping a small business or organization from using this, right? That's where we're heading, trying to establish a simple software as a service so any organization can build their own diagrams and automate parts of their processes or integrate the system into existing tools.\n\nFor our clients, the University of Virginia remains a client, and we are working with a company called Status, a web 3 company that believes in openness, transparency, and contributing back. They have funded efforts to make Spiff Workflow easier to use. The project we've been working on with them is called Spiff Arena, which wraps the Python library and makes it accessible to anyone. There's documentation on spiffworkflow.org for getting started.\n\nWe also have an article in IEEE Software magazine, where we talk about our work at the University of Virginia and the lessons we've learned in building our own BPMN engine. We cover a lot of information on what it takes to train an organization and the principles applied. The Insights column in IEEE Software features our work.\n\nDMN is a companion standard to BPMN, presented as a spreadsheet for conditional logic and listing business rules. It simplifies decision-making based on input and output. For example, in a pizza place scenario, input could be toppings and pizza size, and the output would be the cost. It simplifies complex decisions in a format that is easy to maintain.\n\nThe article is behind a paywall, but I will include a link for those interested.I'm guessing there may be some people subscribed to IEEE software, but it definitely seems like a good guide for it if people were interested in checking it out. One of the things that you talk about not only in that article but also in the documentation is how this fits into what people might consider a low code system. What does that mean? What is a low code system? I've always kind of wondered too. It's like a code, right? Yeah, no code is a thing too that I also don't really understand. Okay, but I've thought about it a lot.\n\nIf you're writing software, code is involved, right? What are you gonna do? Yeah, but yeah, a low code system, like the definition that seems to be most consistent out there, is a tool that lets people create software visually. I think under that moniker, we definitely fall. We want to make things more transparent and easier for people to understand. It should be easier for a business rule to get laid out in a way that resonates with people. You can sit in a meeting and draw this thing out, and everybody agrees, \"Yes, that's the way it should be, this is the process that should be followed.\"\n\nI also think there's the low code movement and the organizations and companies that attach themselves to that moniker that I haven't found a lot of love for. But if you look at it, we always try to make software easier to use, and there are some really good visual tools for creating software that don't call themselves that. Two of them that I encountered were watching my son grow up and play with computers. The first one that he did was MIT's Scratch program. It's delightful, it looks like Legos, but you can grab things and drag them onto the screen, and it gets basic programming concepts across in a beautiful way.\n\nIt's a neat overall learning tool to help visual learners and show how code glues together in the right order for the right results. Blender is another low code thing that I watched my son learn. Applying shaders or behaviors in Blender is very low code oriented, dragging and dropping properties or connecting wires in an intuitive way. I recently got a 3D printer and have been learning how to use it with open-source free software. Blender appeals to me in that sense, even though it can be challenging for specific tasks like making holes with Boolean operators.Stick it into the body of this box to have and then with a Boolean thing saying remove that so right where these intersect it should disappear, which is very interesting and definitely feels very programming. There's a lot of Python stuff hiding underneath Blender, which is interesting.\n\nI'm still going to keep digging with it, but it seems like maybe for building these project boxes and things that I'm kind of encasing, I'm not sure if it's the perfect tool for it, but I am intrigued by it. There's a tool called OpenSCAD, it's super nerdy, you write code to generate the 3D shapes. They're perfect 3D shapes for printing, but it generates these excellent solids that you can send to a slicer right away and they work fantastic. I'll have to look at that. As you write the code, you see the shape forming. It's really fun and delightful.\n\nThe stuff I'm making is usually just tools for electronic music and other stuff like that, trying to encase it. The funnest thing I built was for my dogs, some clips to build jumps out of PVC pipe for agility.\n\nLow code is a weird definition, but the concept of it is that someone within an organization could create a structured workflow with all the teams involved. They could lay it out visually and programmatically handle what goes in the squares by someone comfortable with Python or scripting in Python.\n\nIf someone was interested in contributing to the library, everything is on GitHub. Search GitHub for Spiff Workflow and you'll find all the libraries. The Spiff Workflow Library itself is just a Python GitHub repo. Spiff Arena is a mono repo with a front end and a back end. Contributions are welcome, and the mono repo pulls all the pieces together to make it easier for someone to grab and run.\n\nFor hosting solutions, everything is dockerized, and there's a Docker compose script in the getting started guidance on spiff.org. My consulting company, Sword Sartography, can stand up an instance for you and let you play around with it. We hope people are interested and willing to give it a try.\n\nThere's also a YouTube video on the website for standing it up, you can follow along and watch.Honestly, after 10 attempts of trying to record the video, I finally got the last one where I did it flawlessly and made it look easy. It's pretty straightforward.\n\nThis week, I want to shine a spotlight on another Real Python video course about the latest release of Python titled \"Cool New Features in Python 3.11.\" The video course, which is the companion of a tutorial by previous guest Guerana Hiela and my frequent co-host Christopher Trudeau, takes you through the new features and improvements in Python 3.11. These include better error messages with more informative tracebacks, faster code execution due to efforts in the Faster CPython project, task and exception groups that simplify working with asynchronous code, several new typing features improving Python's static typing support, and native TOML support for working with configuration files. I think it's a worthy investment of your time to learn how to take advantage of the latest version of Python, which continues to get faster and more user-friendly. Like all the video courses on Real Python, the course is broken into easily consumable sections, and you get additional resources and code examples for the techniques shown. All of our course lessons have a transcript, including closed captions. Check out the video course using the link in the show notes or by using the enhanced search tool on realpython.com.\n\nAs you've worked on this project, what are some of the things that you've learned regarding working on a project like this in terms of Python skills and programming skills? Well, like in a recent podcast with Benji Weinberger where you talked about his project \"Pants,\" a lot of what his project does is really help enforce good software development practices. It got me thinking that a lot of what we're doing as we've implemented this workflow is to figure out how to make it easy to draw these diagrams and write the software. We keep falling back to the same way you write good software in any other language. There are best practices and good rules to follow to implement software. One of the top ones right now is good encapsulation. One thing you can do with a task in these diagrams is call another diagram and execute it, creating some encapsulation. The other diagram can define its inputs and outputs, allowing you to pass variables over to that workflow process. This helps in breaking things up and reusing diagrams, eliminating spaghetti code that could occur if things are not well-contained. Figuring out the core elements to be reusable goes back to the idea of building blocks.\n\nTesting is another practice we've learned as we went along. Kevin and Jason came up with a great idea recently of building in a built-in tester for all your scripts. When you write a short Python script in the Script Task editor, you can now pull up an interface to write a unit test for that script task. You can define inputs and outputs and write as many tests as you want, ensuring they all work and keeping you honest. Version control is another important practice. All the BPMN diagrams in Spiff Arena store changes in a repository, allowing you to track changes and move them between environments. This provides the tooling needed to roll out changes from staging to production, essential for any coding environment.\n\nSoftware development layers, like in modern web development, with front end and back end, are another big consideration. Organizations need to have best practices working to ensure smooth operations.Yeah, which naturally evolved from the fact that in the front end, you have to write in JavaScript, and on the back end, that's the last language you want to try and use, or at least I've always felt it. Node people, but there are many reasons to separate the front and the back end and create these divisions of layers. It's a real division of concerns. When you're writing that front end code, you're concerned about user experience. When you're writing that back-end code, you're concerned with logic, integration, and ensuring that rules work and the database functions correctly.\n\nNot having to think about all of those things all at once is a real benefit. So, one of the things I've always said is that spiff workflow really represents a framework for this other layer. It's not front end, it's not back end, it's the business end. Different teams of people would use it and deploy on their own independent cycles to release changes they need to make. It could function somewhat independently of those other two layers.\n\nThere are all these different parties with their own specific interests, and as a developer, you often have to combine all those layers together. Initially, it's about what the business and the customer are trying to accomplish, and overall, what the system is supposed to try to accomplish. Flow charts are very nice for that. It's a nice way to think about it and it certainly talks to the right people in the right way to keep communications open.\n\nWhen you mentioned that there were tools, at least some tools, out there doing BPM and that were more from the Java realm, did you look at some of the code for those? We tried those initial weeks many years ago, and I haven't gone back. I've watched many videos over time trying to figure out a concept. If we're trying to add some new BPMN aspect to our code, the first thing we do is stop and look at what these other companies did and how they handled it.\n\nFrom a distance, it seems like professional Java developers are building these diagrams with the purpose of making their business logic more accessible to the company. I understand that methodology, but I don't think that's the direction we're trying to go. We're really trying to empower more of the organization to do these diagrams and not force Python developers into this framework to use it on a daily basis. It's a way for them to reach out and offer greater control and power to other people in the organization or their end users.\n\nIf they're able to touch it, look at it, and see the actual wiring of what's happening, does that provide better buy-in? I'm hoping so. In an ideal world, instead of walking into a board meeting as a software developer carrying your laptop, determined to hide behind the screen, you can work on something until the meeting ends. Hopefully, with clear and clean diagrams, when that board meeting happens, it's a touchpoint where you bring up the diagram and address any conflicts or issues before they arise later on.So wouldn't it be great if you could rise that back up to the top and people could say, \"Oh, you're right, we've got like these other four campaigns running. How do we want to fit this new campaign into this?\" Well, let's think about it critically. We can make a decision with the sales team in the meeting about what you want to do. Do you want to end that campaign or start a new one? Where is this going to fall? I was wondering about the idea of the meeting and showing the workflow, and kind of showing the diagram as it goes through. But even maybe the concept of drilling in with the programmer there and bringing up \"the script\" in them seeing Python initially. That might be like a lot for a non-programmer, but again, do you feel like because Python is fairly readable, that if a programmer is there, sort of highlighting the things, do you think that they can kind of get the point across of even things that are happening within? Is that an advantage in some ways?\n\nYeah, I think Python is a wonderful language to learn and you're seeing it everywhere. At least, I am. When I'm working at the University with grad students on projects, they all know Python. They could get in and make these changes, and so they're not that's not their focus. They certainly don't want to sit down and work through all the complexities of those problems day after day. I mean, they've got dissertations to write, much bigger problems in their mind. But it would be nice to hand them a little bit of power so that when they do want to fix something or change the way something behaves, they can just go do it and feel empowered to make it happen. \n\nMost of my questions were there. Are there other things that you wanted to highlight?\n\nOh, it's my whole world. It's been my whole world for four years. So much in my head. I think there's a lot of thank yous right. I'm definitely a poor contributor and making changes, but so much that's happened is thanks to the team like Alex, Elizabeth, Jason, Kevin, Mike, and John. Cool. Maybe we could talk about where you see your developments over the next six months or a year. What are the things you're working on? We are talking to a few new clients. I think certainly one of the more exciting things would be doing more with the web 3 stuff. What if there's these things called DAOs, these autonomous organizations, being able to drive those with a diagram would be kind of nifty. So I'm pretty excited about that, expanding this out and seeing it from the perspective of some other organizations and seeing can we do all three of them at once, right? Can we really satisfy the needs of these very different people? \n\nIf people want to learn more about it, where would you say they should start? Definitely hit the spiffworkflow.org. It's a good jumping-off point. There are links there that will get you to our Discord Channel. We're on YouTube, so I'm posting videos regularly there that are also linked off of spiffworkflow.org. Just go to spiffworkflow.org. It's got a lot of connections there for more support.\n\nOkay, cool. So I have these weekly questions that I like to ask everybody, and the very first one is: What are you excited about in the world of Python right now? Over this last three or four days, I've been trying to refactor error messages down before it flow. They're just a little wonky, and what'll happen is, it's a complicated enough system, there's so many different things going on that the errors end up kind of recirculating back through. Each time I catch it, I was previously kind of wrapping it, so just get like I wasn't adding, I was creating a deeper stack of error messages that nobody wants to look at. Python 3.11 recently introduced this thing where any exception, you can add a note function, and you can just add notes to an error and then rethrow it. We need to support things earlier than 3.11, so I just created my own top-level SpiffWorkflow exception and added this feature into it that will get rid of when 3.11 really is all we need to support. \n\nBeing able to add those notes and just append a little bit more information, like that's a good example. Some error happens in a script task, so you need to explain that error happened on line three. It looks like this variable X is not defined, and then I need to explain when it bounces back up.Oh this happened in a dmn table is where the split was actually getting called. Oh and the name of that dmn table is this, and then oh that got called from this other bpmn diagram, and that's this. So I can just add all those notes so when it finally hits the dpmn author, I can tell them exactly where to go and how to get there and what circuitous route led to this problem. Yeah, Pablo has been working really hard on error handling and adding those functions with the core team there, and they've the whole core team has added a lot in that world, which is really neat. Yeah, I'm excited about that. I think we've talked about it almost ad nauseam over the last year and a half from 310 and 311, just all that stuff, but just yeah for a beginner to know what an error is doing compared to just like a syntax error, you know, like right just generally. All that whole world and then being able to go three or four steps beyond like you know whatever that stopping block was to like you know do some inspection of what's actually you know the cause is really handy.\n\nWhat's something that you want to learn next? This doesn't have to be about programming or Python specifically. So one of the things I do as a hobby is I put ships in bottles. I've always kind of dug that problem and I just do it for other people like when somebody does something really special for me there's no other good way to thank them enough. I hope building a ship in a bottle and give it to him, but I don't know whether that really helps them out, that's just what I do. I've always wanted to learn to do something else like putting an airplane, particularly like a Wright Brothers plane, it's something that I could pull a string and it would just fold the wings out and they would decompress into this full thing that looks really fun. Or like the Brooklyn Bridge and now you have some suspension bridge that would hinge out and look really beautiful. Where do you even learn those skills? Is that like a YouTube thing or books or I have no idea where someone would even start. The original build that was really tricky, I had to end up ordering this weird book from England that was out of print that was fantastic. Although all of its techniques were very good, like it would just you know could you even find those materials, right? No, no, yeah, like it tells you how to build all your own tools to like work inside the bottle which was kind of nifty.\n\nSo what are some of the modern resources if you found other things that is there like a community around doing this stuff? No, not today, not that I really found. I do have a maker space here in my hometown, which is located in Stanton, Virginia, like a 25-30,000 people in the Shenandoah Valley of Virginia. We started this thing up about eight years ago, it just had a 3D printer and an empty building, we just started calling it a maker space and people kept believing us. We kept adding more things to it like somebody came along Rick and had just gave us a whole woodworking shop one day and Aaron came and donated all of his garage tools so we had hand saws and stuff and yeah it just kind of grew from there. I mean we got everything now we have a whole pottery studio, a metal working shop, laser cutters and the whole bank of 3D printers and that. It's been a really fun thing to watch. When I moved here to Colorado Springs I joined the Pikes Peak maker space for a little while and I learned a little bit about 3D printing so it wasn't like a complete noob when I finally got my own and at least kind of you know conceptually and you know core concept stuff which was really handy, you know the like big CNC machines and like you said a wood shop a little bit of areas for like electronics and things like that. I've been meaning to meet up with them again I haven't but they do like little you know sir class sort of stuff so I thought about doing like circuit python with them or something like that, oh that would be good, yeah we've got one part problem that python would help out a lot with which is like restricting access to certain equipment until somebody's cleared, yeah right that's why somebody will slip in there and just you gotta go through that class, yes yeah.Like especially a CNC machine can break that in two minutes. There's a laser cutter, and it's just gone. It's a thousand bucks, it's gone. So, something locking the power outlet or something like that. Some other maker spaces have built these and have all the details out there for Raspberry Pi's and the python code to lock the equipment down. You just run it through this outlet or put it in the cord that runs the piece of equipment. You gotta swipe your phone to unlock it.\n\nHow can people follow what you do online? We've got a Twitter feed that I keep putting stuff into. It would be great if people listened to it. Joining that would be a motivator for me to post more stuff. YouTube is a good place to subscribe, and I'll be putting lots of videos there. There's no other good way to describe diagrams to people than showing you what it's like to move the stuff around. You already mentioned spiffworkflow.org. \n\nYou also mentioned the Discord, and the best way to get connected to that is through spiffworkflow.org. There's a link on the website that'll take you and invite you into the Discord Channel. Dan, thanks for coming on the show. It's been fun talking to you. This is a blast, I think I was a little uptight at the beginning, but I loosened up along the way. I really enjoyed talking to you today. \n\nAnd don't forget to experience the power of full stack monitoring with Telemetry hub. Try it today and transform your monitoring strategy. Thank you, Dan, for coming on the show this week, and thank you for listening to the Real Python podcast. Make sure to click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python podcast is free. If you like the show, please leave us a review. Show notes with links to all the topics discussed can be found in your podcast player or at realpython.com/podcast. Leave us a question or a topic idea while you're there. I've been your host, Christopher Bailey, and I look forward to talking to you soon.",
    "jOtsfv2cLdQ": "Welcome to the Real Python Podcast. This is Episode 145. Would you like to practice your Python skills while building a challenging word game? Have you wanted to learn more about creating command line interfaces and how to make them colorful and interactive? This week on the show, Christopher Trudeau is here, bringing another batch of PyCoder's Weekly articles and projects.\n\nWe share a recent Real Python step-by-step project about creating a clone of Wordle. In the project, you'll practice building a terminal application, validating user input, and refactoring code into functions. Christopher shares an article that compares the two popular testing tools, Nox and Tox. He discusses how each framework approaches test environment configuration and why the author leans toward using Nox's Python decorator-based format.\n\nWe share several other articles and projects from the Python community, including a news update on trying out code and ideas quickly with the Python REPL, a PEP about requiring virtual environments by default, a discussion about things learned in 20 years as a software engineer, a project for a spreadsheet GUI inside Jupiter Lab notebooks, and adding C-style for loops to Python.\n\nThis episode is brought to you by Anaconda. With more than 30 million users, Anaconda is the world's most popular data science platform, making tomorrow's innovations possible. Alright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Christopher, welcome back. Hello, I'm excited to dive in this week. Got some kind of fun things I'm intrigued about and thrilled to talk about. It's a real mix of stuff, so we have some news to start, is that right? Yeah, for sure. First one is for you Django programmers out there. There's a security fix that has been issued, bringing us to 4.1.6, 4.0.9, and 3.2.17. The fix addresses a potential denial of service attack through the use of corrupted accept language headers. So, go patch stuff.\n\nThe second bit of news is the Python Software Foundation is hiring a security developer in residence. This is a full-time position to help formalize the existing security practices and to contribute to the security of CPython and PyPI. Resumes are being accepted until March 3rd, and there's an online forum where you can submit your CV. It does have a CAPTCHA there, so AI need not apply, I guess.\n\nYeah, you know, chat GPT's taking all the jobs, might as well do the security stuff. It's interesting who's funding that one there? Oh, who's that? I didn't notice that. It's called the Open SSF Alpha Omega project has made this work possible. So, the Open Software Security Alpha Omega. That sounds like a bad villain from an 80s movie. Potentially, yeah. Alpha and Omega, yes. Great, cool.\n\nAnd the final little thing here is it's Python maintenance release time. So, Python 3.11.2, 3.10.10, and 3.12 Alpha 5 are now available. Get them while they're hot. Wow, moving fast. Yep, alright.\n\nWell, my first article, I guess in this case a step-by-step project, is a Real Python one by Grana Hiala, a frequent guest on the show. I don't know if he's done many step-by-steps, but this one's great. I'm really excited about it, and it has a very low barrier to entry as far as like what you need to know to get in and play with it.\n\nIt's called \"Build a Wordle Clone with Python and Rich.\" If you're not familiar with Wordle, I don't know where you've been, but it's a word game created by Josh Wardle, launched in October of 2021. It got so popular online, everybody's sharing screenshots of it everywhere. It got bought by the New York Times, and so this is sort of a clone of it. It's missing a couple features, but it is a great way for you to practice your Python skills and create a command-line interface kind of game that's rather fun and challenging, and something that you could definitely share with other people.\n\nI found this great, and it looks pretty through using the Rich library that Will McGugan has created. I had not played with Rich very much up to now, and wow, it really does make a difference. It really showcases the kinds of things that you can create, this nice console, and colorizing the output and so forth really can make quite the difference to making something look a little refreshed and kind of fun.\n\nYou start out this whole project building a prototype, just the idea of how can you guess a secret word and giving you feedback of what letters were correct, or maybe they were in the word but not in the right position, or they weren't part of the word at all. So, you kind of build that initial functionality and practice that. And then, one of the key things you need to do is have a list of words for the game to randomly choose from, and you build this kind of cool parsing mechanism that can grab any text that you want and separate it into a word list for you.\n\nHe gives some examples that you can go on to Project Gutenberg, I haven't read the article, but is that what you're trying to say? Exactly, yeah.Project Gutenberg offers public domain books like Alice in Wonderland that can be used for text analysis. You can also choose works of Shakespeare for more interesting words. The program parses the text file and helps in learning about different functionalities and text encoding.\n\nThe article emphasizes building a prototype and then transitioning into creating functions, like a main loop, for better maintainability and testability. It guides step by step and introduces Rich for console printing functionality.\n\nThe program also focuses on handling edge cases like empty word lists and weird punctuation. It leaves room for improvements like verifying word length and dictionary word validation.\n\nOverall, the program is enjoyable and accessible for developers at all levels. It covers various aspects of coding and offers suggestions for further enhancements. It's a fun and engaging learning experience.What's your first one? This is an opinion piece by a gentleman named Heinek Schlawach entitled \"Why I like Nox.\" The article is a comparison piece between Tox and Nox, and why Heinek prefers the latter. Both Tox and Nox may sound like nonsense words, but they are testing tools. Tox has been around for a while and its main purpose is multi-environment testing. I use it with open source libraries. I typically write and test my code in the most recent version of Python, then use Tox to do backward compatibility testing against older versions of Python. Tox automatically creates and populates virtual environments for you for each setup you've defined in a config file and then runs your test suite in each one of those environments. \n\nNox is essentially an alternative to Tox. It handles the same kinds of problems, and its main claim to fame is how you configure it. Instead of using a text-based config file, you write actual Python scripts. Heinek's article starts out by praising Tox. He explains that it's a great tool and he's glad that it's out there. He doesn't really want to say anything negative about it but prefers how Nox handles certain things. Since the article is a compare and contrast format, it inevitably has to tell you about Tox as well. He was very conscious of not coming across as negative. \n\nThe big chunk of the article discusses the difference between how you configure the two tools. Tox uses an INI file format. The Tox config has sections and key-value pairs. For example, you set a value named \"envlist\" to specify which Python environments you want to use, and Tox sets things up accordingly. In contrast, Nox's approach is to write code instead of using a config file. You write a noxfile.py where you import Nox and use decorators to specify which environments run on which tests. This doesn't get embedded in your test suite; it actually wraps around it. A typical Nox function has two calls: `session.install` to specify what packages to install and `session.run` to give the command that actually runs the tests using Python's unit test, pytest, or another test runner. \n\nHeinek's preference is based on the idea that as a Python programmer, you don't have to learn Tox's language. An example he gives is the dependency handling magic that Tox does under the covers. Config files used in the past don't always work with the newest version, but with Nox, you're in control. It's your program, so as long as you haven't broken anything, you should be good. \n\nAt the heart of it is a difference in structural philosophy. Tox uses a subclassing model for sharing, where you override attributes, whereas Nox uses a function-based approach for reuse. Heinek finds Nox's approach more intuitive. He goes into more details in the article, and Nox has always been on his to-do list to check out. This article reinforced that for him. He was very involved in creating Nox and hadn't done a deep dive into both tools, so this comparison helped him understand better. \n\nIf your headspace is in Python all day long, it's easier to parse and understand the differences quickly. Heinek agrees that whitespace matters in configuration files and having something more parsable and checkable, like Python code, could be really useful. He appreciates the comparison between Tox and Nox, and while he uses Tox a lot for simple setups, he can see the potential benefits of Nox for more complex projects.He has an example where he runs coverage tests only on certain versions, like the oldest and newest versions. It's next to impossible to do trickier stuff like that. You can decorate the line with this and put in an if statement, and you're done. Knox's advantage probably comes when you start trying to do more challenging things in your test suites.\n\nThe examples also include different environments, like versions of Python or potentially other dependencies installed in that environment. When testing Django libraries, you need to test them in multiple Django and Python versions. Talks takes care of setting all that up, but it starts to feel like Blackmagic. It sets variables for you, and if something goes wrong, you might not know what it's doing.\n\nAnaconda notebooks is a lightweight, fully loaded data science environment in your browser. You can start coding with Anaconda entirely in the cloud on anaconda.cloud.\n\nMy next topic is about a new pep, pep 704, which proposes requiring virtual environments by default for package installers in Python. We are fans of virtual environments and have discussed them in previous episodes. The author of the pep is Pradian Gadam, and it was created on January 16th, accepting people's thoughts. The motivation is to prevent mistakes for new users and avoid pollution of system installations.\n\nThe pep recommends that package installers, like pip, require a virtual environment by default in Python 3.13. This change would prevent potential mistakes and guide users to create virtual environments to avoid pollution of system installations. It's important to consider this change early on as it's a significant change that could impact users who are not familiar with virtual environments.You're right. I need to activate my virtual environment as a reminder, so it kind of dives into that a little bit further. I won't read every detail of it. If you haven't looked at PEPs before, this is a good guide. This is a fairly short one, it covers potential issues with backwards compatibility. In this case, it's saying it would be incompatible with workflows where users are using installers outside of virtual environments. That actually brings up a big thing I'll mention here in the commentary that's been happening in the conversation behind the scenes. It doesn't have any security implications. \n\nI think a very interesting section that they have in the PEPs is this thing called \"how to teach this.\" The PEP requires that new users create and use a virtual environment to get started using Python packages. However, best practices are demonstrated in the case they have the link then to how to create virtual environments, which is on the Python packaging user guide. There's a reference implementation of how they want to do it and then a little section about how they would detect if an active virtual environment is there.\n\nIt's been a fairly hotly debated thing, so I kind of went into the discussion area. It's interesting, and I would argue that just my cursory reviewing and looking through this thing is that it's kind of leaning negative. I feel like a lot of people in the community feel like they already have these solutions. Of course, people that are on a Python discussion board, like python.org, are more likely to be long-time Python users, so they may not feel like it's needed. This is really a conversation geared toward total beginners or people that accidentally do this often. \n\nSome people don't really like the idea of how it would be enforced or it being enforced at all. A common issue that came into the conversation later, probably over the last 10-12 days, is the issue with Pip and Conda. Conda is another virtual environment/installer for Python packaging. The unfriendliness between Pip and Conda has been there a long time. It's something that I dealt with back a long time ago, and it was one of those things that had to be enforced in-house rules. \n\nI like the idea. I've blown off some toes myself by accidentally forgetting to activate my virtual environment every once in a while. I like the idea. I do understand though that anytime you've got a breaking change, it's going to make people uncomfortable. I don't know how often this kind of thing gets scripted, but if it did, that's the problem. As soon as you upgrade, now you have to go and edit all your scripts to add a command line value or an environment variable to say yes, no, I really mean to do this. \n\nThat might be one way of handling it. But even then, you're back to needing Dash yes or whatever for scripted versions. The condo stuff is a red herring. It has so many other things, it's its own environment, and everybody brings Conda up as in, well, what about Conda? I'm like, well, let Conda exist. Nobody's saying it isn't its own thing. \n\nThis PEP says installers, so everyone sort of goes, well, how do we make Conda do it? Maybe the answer is no, not installers. Maybe it's just, you know what, Pip's gonna behave this way, which comes with Python installed. So start there and then go, hey, we recommend other installers also behave this way and leave it there. Anytime you talk packaging or virtual environments, there's some depth there. There are features and things that I don't use, so I can't really pretend to say.Oh well, it definitely has to be done this way. I understand that there's a whole bunch of edge cases that I'm basically ignorant of. So, on the surface, I like the idea, but it wouldn't surprise me if it doesn't happen, and I would understand. \n\nI think it is a good conversation to have, and we talk about this within Real Python often. Like, how can we get people comfortable with starting with Python and best practices, steering people in that direction. I think that part of it is good. I'm glad that PEPs are not the end-all-be-all kinds of things. They can be accepted or not accepted, or they can remain as a conversation point for quite a while as ideas, proposals. I found that interesting, the last couple of PEPs we've talked about. I'm like, wait a second, this is like four weeks old and it's approved and it's in this spot. That's not what I'm used to. I'm used to, \"Hey, this has been in draft for years.\" \n\nIt's interesting, the paths that they can travel, huh? So, what's your next article? This is a Real Python article from Leo Donna Ramos, and it's called \"The Python Standard REPL: Try Out Code and Ideas Quickly.\" As a bit of a segue from what we were talking about, this is more aimed at folks who are new to Python. It's an introduction to the REPL. I live in the REPL, I'm in there mucking around all the time. Some of that might be because I don't use a standard IDE. I'm a VI guy. We'll get back to that in a minute. \n\nSo, when I'm teaching, I often go to it. I'm like, \"Here, you can play with it, you can try this out.\" I frequently find students who have done their own self-taught thing haven't come across it and they're locked into their IDE. I love the fact that this article exists. It's like, \"Hey, you've got this, the beauty of an interpreted language is you can have this little interactive playground, so go play.\" \n\nLike most of Adonis's articles, this is pretty comprehensive if you're just getting started with Python. It teaches you why you might want to use the REPL and how to get into it, including some of the command line options we talked about a couple of episodes back. One that was a relatively recent discovery for me, which is the `-i` which allows you to run a script and then dumps you into the REPL after it's executed, which is great for seeing the state and helping you debug. \n\nHe talks about that and a couple of other command line pieces. Then he goes on to talk about how to do multi-line code segments and things like line continuation and how error handling is done, essentially the basics of how to use these kinds of environments. He then starts talking about the special variable underscore. This is one of those things that I always forget is there. I come across it, I'm like, \"Hey, I knew that,\" and I never remembered that it's in here. This is a variable, a special variable in the REPL that gets the value of the last statement executed. So, if I'm testing a Django query and I forget to store the result in a variable, I just type the query out, and then I'm like, \"Oh crap, I got to do that again and put it in a variable.\" Well, the last value got put in underscore, you can just go variable equals underscore.So it's a nice little shortcut. One of the challenges you run into with the built-in Rebel is that importing is done once. So if you import some code from a file and then change the file, re-importing doesn't work. There is a workaround though, and this isn't so much a Rebel feature as a Python feature, but it's a good one to know if you're using the Rebel a lot. The import lib library has a function called reload, and it takes a reference to a module which then reloads it. This is a handy little thing to remember.\n\nThe next couple of sections in the article talk about how you write, edit, and re-execute chunks of code, as well as some info on how to get help and inspect the code you've written. This includes things like keyboard shortcuts, most of which map to the Emacs standard. If you're old enough to know what an Emacs is, for the record, it's a full operating system that includes an editor. Sorry, like I mentioned, I'm a VI guy and just had to get the jab in. Old grunge battles are the best to win. Anyways, if you're not new to the Rebel, the next couple of sections might still have stuff that is useful to you. The Rebel is actually configurable and has more depth than I realized. You can set up an environment variable called python startup and point that to a file, and it will load and execute that script when the Rebel starts. A couple of examples of doing this were the reload function that I just talked about. If you're using it a lot or something like pretty print that you're using a lot, you can stick this in the startup file, and then it'll get run every time you run the Rebel. This way, no more importing those exactly. You don't have to keep typing them over and over again. So that was a handy little thing I hadn't come across before.\n\nThe other thing near the end he talks about is you can actually integrate it with Rich. As you were talking about before, Rich is this command line text formatting kind of thing, and you can pull it into your Rebel and make your errors and tracebacks colorized. If you want to do that all the time, you could stick that inside your startup. Finally, the article finishes off with a description of what's missing and what to do about it. Mr. Bailey here mentioned the B Python REPL alternative in episode 141. This article talks about it and others, giving you a quick overview of their features. So if you're new to the REPL, this is a great introduction. And if, like me, it's kind of old hat, there's still some value in a quick skim. There are a few little gems in here that you might not be familiar with that could make your Rebel experience better. Yeah, there's some really good stuff in there, and he always is deep on the research. I'm excited to dig a little bit deeper into it because I was like, \"Oh yeah, I know this,\" and it's like, \"Well wait, hold on, go look through the expanded table of contents at the top of the article, and you could see some things that you maybe aren't as familiar with or it could be areas for you to research.\" I find there's always value in some of these longer articles because like I said with the underscore, there are things that you know, but if you don't use often, you forget. I just came back from vacation recently and I've got a nice camera, but I don't use it often enough to always remember how to use it. I'm always like, \"I know it does this, but I don't remember how to do it.\" Every once in a while, I'm back into the manual going, \"How do I do this and where is that button and which one is this?\" This kind of article is sort of the same thing, right? Even if you know it, if you're not using it frequently, the little items of, \"Wait, oh yeah, that's right, I can do this and it'll make my life easier,\" there's value in that.This week, I want to shine a spotlight on another Real Python video course. If you've worked in a language like Java or C plus, then you're probably used to writing getter and setter methods for every attribute in your classes. These methods allow you to access and mutate private attributes while maintaining encapsulation. In Python, things are different, and this course covers the details. It's titled \"Getters and Setters in Python\" and is based on a Real Python tutorial by previous guest Laodon Esposo Ramos. In the course, Darren Jones takes you through how to write getter and setter methods in your classes, replace getter and setter methods with properties, explore other tools to replace getter and setter methods within Python, and decide when setter and getter methods can be the right tool for the job.\n\nTo get the most out of this course, you should have the fundamentals of object-oriented programming in Python under your belt, and we've got you covered there with OOP courses and a learning path ready to go. Real Python video courses are broken into easily consumable sections and, where needed, include code examples for the technique shown. All lessons have a transcript, including closed captions. Check out the video course; you can find a link in the show notes or you can find it using the enhanced search tool on realpython.com.\n\nThat gets us into our discussion this week. This is based on a slightly older article, but it seemed to have come up in some discussion areas, and that's how you kind of found it this week and included it in PyCoders. It's titled \"20 Things I've Learned in My 20 Years as a Software Engineer\" by Justin Etheridge. It's on a site for a company called Simple Thread, and they have a team of developers with a really nice blog. If you read through their blog, you can see that they have lots of deep thoughts about different things like UX design, engineering, DevOps, and so forth. This article focuses on a lot of core concepts and opinions.\n\nOne point I definitely agree with is that I still don't know very much. The trick with software or technology is that it's constantly changing and growing in different directions. You look at one particular language, like JavaScript, for example, and it's constantly evolving with different front-end frameworks and tools. It's important not to be upset that you don't know everything because there's hardly any way to know everything that's out there. You need to specialize in what you can learn but, most importantly, be open and be a lifelong learner.\n\nBeing a teacher is one of my favorite ways to learn because you have to thoroughly understand the topic to explain it to others. That's why I took on the Real Python gig in the first place. I wanted to learn more about Python and share my knowledge with others through teaching and podcasting. It's essential to ask questions and not be afraid to do so. It's more impressive when someone is willing to ask questions rather than sitting silently without understanding.\n\nOne of the things I really liked about how this blog started is that without understanding context, advice is meaningless.He's starting from a humble place, sharing his thoughts that may or may not apply, and talking about his context with smaller teams, shipping focus, and productivity. This shift in focus changes how you interact and think about things, leading to different advice. Working at different companies during his university co-op program helped him see different styles and fit in better in the real world.\n\nComing from a background in music and service industry jobs, transitioning to banking or law firms was a shock in how problems were approached. Older engineers often talk about the best code being no code and the importance of removing unnecessary code. Productivity is not measured by lines of code written, and every system eventually deteriorates.\n\nDiscovering Dylan Beatty's musical parodies on YouTube made him think about the inevitability of systems breaking down over time. Knowing when to make changes and when to leave things alone is crucial for productivity. Sometimes you have to stop over-preparing and start building, avoiding getting stuck in tutorial hell.\n\nThe myth of the 10x developer is debunked, as he believes in negative productivity and the impact of team dynamics. Some people can hinder progress more than they contribute. Focus on getting started and diving deep into projects, like exploring Circuit Python. Avoid getting caught up in over-preparing and instead focus on getting things done.I definitely want to figure out in my hiring how to avoid those negative folks. That ties to something else he said, which I really agree with. Interviews are almost worthless for telling you how good of a team member someone will be. Smart and knowledgeable is not a good indicator. Obviously, you want people who are smart and knowledgeable, but the anti-patterns like unreliability, abusiveness, pompousness, none of that shows up in an interview.\n\nI get a real sense from his comments that he's very keen on teams that know how to work well together. There's a huge productivity difference when that gelling happens with a small team. Small versus large organizations, if you've only got five or ten folks, one or two negative contributors make a huge difference. When you've got a hundred thousand, it's a bump in the road and it's nothing.\n\nHe went much deeper because that was the common refrain in the comments at the bottom of this article. He wrote a separate whole article on it to explain what he meant. He describes all these different types, which I thought was a good read too. I'll include a link for that. In the comment section of that, a person added this interesting idea about having a person on your team who isn't necessarily a 10 times programmer but is able to help the other programmers within the organization.\n\nThey likened it to a term used in video games like Destiny or World of Warcraft called a \"carry.\" A person who can help new people joining a big event and guide them through the experience. If you can find a developer who likes to help and carry others, they're such an asset to your team.\n\nI would take somebody with strong mentoring skills and solid coding skills over so-called Superstars any day of the week. The vast majority of people who consider themselves Superstars were also difficult to work with. I'd much rather have a group of B players who get along and work together than trying to herd the cats of the programmer you see in movies.\n\nSoftware Engineers should write regularly, having a blog or journal sharpens communication skills. It's a good guide for things to look at and good discussion points that could be brought up with a team.\n\nMy project is called Mito, a spreadsheet inside your Jupiter lab notebooks. It's an interesting tool for people transitioning and interested in Excel.She often asks me, \"What is Python?\" I reply, \"I have 144 episodes of a show you can listen to.\" In the end, Python is a tool that someone familiar with or knowledgeable about guideposts can use to accomplish tasks. It can help someone transition from Excel to automation and other tools without needing to learn more complex Microsoft tools and languages. Python is more readable and user-friendly. \n\nTo start using Python, you can install it with pip in your virtual environment. When you launch it, a graphical user interface opens with familiar drop-down menus. You can import files like CSV and instantly see a data frame with graphical options to filter and manipulate data. The Jupiter notebook below shows the Python code as you work, making tasks like creating pivot tables easier. \n\nThe tool includes links to libraries like matplotlib, plotly, and pandas. It's a great tool for teaching and getting people excited about Python coding. One downside is the marketing aspect, as it asks for your email address when you open it. Despite this, it could be a useful tool for beginners. \n\nMy project this week is called \"Cursed 4\" by Tashara Sadwani. Similar to the previous project I discussed, it involves implementing a C-like loop in Python. Python's for loop is based on an iterator mechanism, unlike the C-style for loop. Tashara's approach uses a context manager to loop through blocks of code, mimicking a C-like loop. \n\nYou can install \"Cursed 4\" to experiment with this concept. Tashara's clever approach utilizes block syntax and proper variable comparisons to make it work in Python. The challenge lies in making the loop evaluate variables and comparisons correctly, as Python handles this differently than C.So what he does is he creates a custom class called VAR which you use in the assignment portion of the loop. He then takes advantage of the Walreceptor operator, so instead of saying \"I equals zero\" like you would in C, you say \"I colon equals VAR\" and then pass in the zero to VAR. That's pretty close to what the C style looks like. The reason he does this is it solves the comparison and increment portions. \n\nIf I just do X is less than 10, Python tries to evaluate that. But because I'm doing it on the VAR object, the dunder comparison methods get triggered. Since this is an object, \"I less than 10\" invokes Thunder less than, and he overloads that to change the state of the class, essentially controlling the loop. He does a similar thing with Dunder add to solve the increment problem.\n\nThe final bit, which was kind of tricky, is you want the actual context manager block to be looped over. He does this by getting really funky with the AST module, a parsing module built into Python. He uses the AST node Transformer class to find instances of the cursed 4 and then muck with their blocks so that you can do the looping. He actually talks about an alternative implementation using a custom codec instead, inspired by an equally evil library. \n\nThe project is a neat little idea and something to play with. The article, on the other hand, is more interesting than the project itself. He goes through in detail how he worked all this out, some of his dead ends, attempted things that worked, things that didn't work. It's a master class in doing some very questionable things, but you learn a whole bunch about some of the more esoteric corners of Python while doing it.\n\nWe've talked about context managers several times over the last couple of episodes, abstract syntax trees, and special methods. This project uses all that stuff, showing the underlying fundamentals of Python. It's fascinating, but I wouldn't want to use it. It's self-contained, making it digestible for learning purposes. It's a small project that uses these concepts and very little else, making it a great resource for understanding and applying these concepts to your own projects.\n\nMost languages in the C family have something like this, where there is a for-in loop or something similar. Python could have called the for loop something like that to avoid confusion for new users. But it's too late for that advice for Guido now.Well, thanks for bringing all these articles, topics, and discussion points. This has been fun. See you again in a couple of weeks. Talk to you soon.\n\nDon't forget, you can code in a fully loaded data science environment entirely in your browser for free with Anaconda notebooks. Start coding with Anaconda entirely in the cloud on anaconda.cloud. \n\nI want to thank Christopher Trudeau for coming on the show again this week, and I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. \n\nYou can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "t8_f5DMC3Vw": "Welcome to the Real Python Podcast. This is episode 148. Are you interested in deploying your Python project everywhere? This week on the show, Russell Keith McGee, founder and maintainer of the Beware project, returns. Russell shares recent updates to Briefcase, a tool that converts a Python application into native installers on Mac OS, Windows, Linux, and mobile devices. We cover how Anaconda hired him last year to work full time on the Beware project. He shares how this has helped him focus his efforts and move the project forward. We also discussed his recent talk at DjangoCon US 2022 titled \"How to Turn Your Website into an App and Why Maybe You Shouldn't.\" Russell details the problems of converting from the web onto a mobile platform. We also contrast WebAssembly System Interface (WASI) to the tools his team works on.\n\nThis episode is brought to you by InfluxData. The InfluxDB time series platform empowers developers and organizations to build real-time IoT analytics and Cloud applications with timestamped data. Learn more at influxdata.com.\n\nAlright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Russell, welcome back to the show. Thank you for having me. Yeah, I had to go back into my archive and dig it out. But you were on episode 22, it was really fantastic talking to you early on in the show and I feel there's been a lot going on not only in the Python community and things happening there but with Beware itself. Maybe we could talk a little bit about how the Beware project is going. Absolutely, it has been an eventful couple of years in every conceivable sense of the worst.\n\nWe talked a little bit about Open Source funding and it sounds like maybe that situation has changed a little bit even more recently, right? Yes, my, well, it's better just shy every year. Beware had a very big change in terms of its funding. It's a little bit of a weird way of putting it, but like the way in which the sausage gets made, I guess. Okay, so a little that's going to start off March last year, I accepted a full-time position to work at Anaconda. It's a company behind what puts a lot of work into the Conda package manager and Anaconda Navigator and that suite of commercially available tools. Anaconda has an open-source division whose mandate is to do the open-source things, make this ecosystem healthy, do the things that are needed in Scientific Python and whatever else, you know, numerical Python and whatnot to make this ecosystem healthy. They took a round of funding, I think a year like the start of 2021, I think, don't quote me on that one, but essentially on the basis of we need to, we want to grow, we want to expand, we think this is a huge market that is available, and Anaconda wants to be the company of Python in open-source Python in data science. And part of that is a couple of strategic long plays in terms of ensuring the long-term health of the Python ecosystem. In some regards, this is kind of Peter Wang and to the c-suite at Anaconda taking the bait of what I teased at my the keynote that I gave at PyCon US in 2019 that if we don't care about the platforms where people are using computers, then Python as a language is going to sunset because people aren't using desktop machines anymore. So having Python available on your phone, having Python available on tablets, having Python available in the web browser, these are what the emerging platforms where things are happening and one way or the other we need to have a Python story. And so to that end, Anaconda has put resources into Beware primarily because of the website, remember because of the mobile device getting on iPhone, getting on Android, and so on. They are also independently putting a lot of work into PyScript, which is the web assembly and making web assembly a user-accessible layer that can be played with there. Yeah, that's essentially what the big change has happened for Beware. Beware is still an open-source project, it is still independent. I work full-time at Anaconda, I work on Beware full-time. I do have a manager who asks what I'm doing on a weekly basis, but essentially the mandate was very clear that Beware is not an Anaconda product, okay? Beware is just something that Anaconda is funding because we think it is important or we think it is a valuable play and it opens up a bunch of doors let down the road for Anaconda as a company. Anaconda's business is selling to the Fortune 500 end of town, primarily large commercial support contracts around Python. The more people that use Python, the more people that need commercial support contracts. They've also got a bunch of things. So like and so it's like if all of a sudden the company that's currently just got a bunch of data walks in the back room doing data science mining of whatever data's coming in all of a sudden our building iOS apps and Android apps as well.Then that's another whole bunch of people that need site licenses for Anaconda. So it's in their interest and as a benefit, it just happens to be good for the entire Python ecosystem as well. Yeah, very much a rising tide lifts all boats kind of thing. Exactly. And it's not just the big end of town as well. Anaconda wants data science for everyone. They want everyone to be able to do computing, analyze their data, process their data, and use their computers as devices that can empower them to change the world the way they want to change it. Part of that is being on the devices where people are actually using their computers or doing their computing. So yeah, definitely.\n\nI guess we could talk briefly about beware and briefcase. Though a lot of people can reference episode 22 because we went into detail there. The goal is to get Python on all these end-user devices and be a deployment tool in a way. I don't know if you have your quickest elevator pitch for it.\n\nDeployment tool is probably the best way of putting it. It gets into some interesting territory in terms of nomenclature about you. Is it deployment, packaging, or delivery? There isn't a good consensus on what that word is. But whatever it is, you have something that you want to deliver as an app that the end-user can use. Most importantly, the end-user doesn't have to care that it's written in Python. If you are using Python to write that app, Briefcase is a tool that will let you take the code you have written and deliver it to an end-user so that they can run it without having to teach them about virtual environments, installing a Python interpreter, setting up their Python path, or pulling down packages from PyPI. It's just a delivered Python install that works. The extension of that is Briefcase lets you build user interfaces that are native using the API, and that's where Toga, as a user interface toolkit, kicks in as well.\n\nWe talked quite a bit about Toga and how crucial it is in tying in support and help to ensure that you can get that graphical user interface across all platforms. It required a lot of internal support with your team trying to figure out how to access those layers to create buttons and different types of interfaces.\n\nThat task has not gotten any smaller with time. We are still looking for assistance. We spent most of the last year solidifying the Briefcase base to ensure that running Python everywhere is a viable proposition. We needed to add support for M1 devices and improve packaging on Linux, Windows, and iOS. There's still a lot to be done, but we've made huge inroads over the last year due to working on this full-time. Anaconda has also been paying for another person, Malcolm Smith, to work on this as well. When you have two people working full-time on a project, you can make a lot of progress in a relatively short amount of time.Yeah, we were talking about that before. How you were only able to invest when you could, it wasn't something that you were able to invest in full-time at two and a half years ago. So that's great.\n\nThe flexibility to sit down and say, \"I'm going to spend the next three weeks trying to work out how to get a build system that can support both Mac on x86, Mac on M1, iPhone simulator on x86, iPhone on all these platforms inside the same ecosystem.\" You could do it over weekends, but just the spooling up of context every Saturday for six months is a bit of a headache. That's the context switching.\n\nThat's been the last year. We still have some work to go, but that's been the last year. The last couple of months of that year have been back on the toga situation, mostly trying to get the testing situation sorted out because one of the biggest gaps in toga has always been, \"Okay, you can build apps with it, but how do you prove that the toolkit is not regressing over time?\" It's trivially easy to make a change in one layer that makes MacOS widgets have a background color the way you expect and accidentally break the way that text labels work on GTK because you haven't got an automated test suite that validates the visual aspects of what is going on. That's what we're currently in the process of building up, a set of automated tests to make sure that the visual aspects of toga remain consistent over time. We can validate that they remain consistent over time and in the process go through and audit all the widgets to make sure that the API makes sense, that the API is fully tested programmatically, and that we have consistent naming of properties everywhere and all the things that drift when you're only working on it for four hours on a Saturday morning when you've got some spare energy.\n\nYou were talking a little bit about some deeper layer kind of stuff, talking about things like with data science, the C layer almost of these deeper layers, and making sure that works across into this platform. I wondered about that. I've been talking to a handful of developers that are crossing into this sort of rustification of some of the Python stuff and I wonder if that is a similar hurdle or an easier hurdle or if you've had to address any of that in some of the things you're working on.\n\nYes, I have, and it is all co-mingled. It is weird in that it is a situation where it is slowly getting better, but legacy is the thing that kicks you every time. Essentially, this all comes down to Pep 517 packaging type issues. Go back two or three years, setup tools is kind of where everything was. Setup tools worked, it lets you build binary packages but had some interesting quirks and like 20 years of rusted-on legacy and weirdness that's kind of baked into that. Pep 517 has been fantastic in that it now specifies an interface by which you build your package. The downside is that now you need to support every possible way of building a package, and so numpy now has a mizon back in. So now we need to teach Meson how to do cross-platform and multiply that by every other build backend that's currently being maintained and every other build system that's being maintained, and yeah, you get to something like Rust. You want this Rust package to build on iOS, that means I've got to work out how to drive a Rust compiler to spit out iOS content and all solvable problems like at the end of the day iOS is a Unix as long as you've squint at it enough so it can be done, you've just got to work out how to drive it.\n\nA lot of the time, the biggest hiccup, the biggest hurdle that we consistently hit is that the Python ecosystem broadly has an expectation that the platform on which you run pip is the platform where you'll be using the code. That is true almost everywhere except mobile devices because you are on MacOS building for iOS and you can't link the MacOS libraries or use the MacOS compiler to get to iOS. It's actually gotten marginally worse as a result of the M1 transition because previously you had an x86 laptop and an M1 or an iPhone, you would compile on your laptop, push the binary, and it would say, \"Nope, sorry, it can't do it, it's an x86 binary.\" And you go, \"Oh crap, I've linked in the wrong thing here.\" But now you've got an M1 laptop, it's the same CPU architecture and it's very easy to fall into a place where you think it's working but you push it to the device and it doesn't. Even though the binary is the same architecture, it's not compatible at an ABI level because you've linked the MacOS libraries and not the iOS libraries and variations of that kind of center problem.Yeah, it is complicated. Essentially, build systems are complicated. Hey, who would have thought? There's still a lot of work to be done. The upside is that there are one or two things that have changed recently that have made this a lot easier.\n\nPet 517 is kind of part of that. The second is the introduction of WebAssembly (wasm) as an officially supported target inside CPython. As a part of doing that, CPython has had to reckon with this in an official capacity because you can't run a C compiler in the browser. Well, I say that, you probably could, but you shouldn't run a C compiler in the browser. It's not suggested. I hesitate to say it can't be done because you can do some weird stuff with wasm, but the average user is going to be on their Mac laptop building a wasm binary which they ship to the browser. That is the same problem that iOS has, just with a different API target and a different set of libraries you need to link against. So, it is a problem that is now not just my problem, it is a problem that the broader wasm community has and a problem that CPython now actually has a stake in because wasm is an official target.\n\nThat's very interesting. I've had lots of these conversations touching on wasm. Two years ago, it was so exciting because it's going to change things. I talked to Brett Cannon about the idea of what's the core of Python, how can we package Python in a way that it could fit on not only smaller devices but potentially inside the browser. Now it's very much here in these initial states and the introduction of PyScript at PyCon was very interesting. I kind of held off on talking about it a whole lot on the show because I was like, let's wait and see what's happening with it. I'm very intrigued by it and to see how people are going to use it and what's going to happen with it. Also, like what you're saying, the tooling and preparing stuff for it is really intriguing to me.\n\nI wonder, it sounds like there was a version as a deliverable briefcase that was for the web previously. Or was it not? So, if you cast back, I gave a demo at PyCon Australia 2017. I demonstrated deploying to the browser, so historically it worked. Then it kind of stopped working and I never really got back to fixing it. At that time, we weren't using wasm, it existed but it wasn't a mainstream thing yet. It was based around a tool called Batavia, which was essentially taking Python bytecode interpreter written in JavaScript. You would push your pyc file to the browser and the browser would interpret that pyc the same way it would have if it was on the desktop. It worked well enough as a proof of concept, but the downside is that it gives you CPython the language but none of the standard library. You need to reimplement all the operations you can do on integers in JavaScript, but JavaScript doesn't have an integer type. It's complicated. So, what ended up happening is we ended up with a whole bunch of JavaScript tooling that just ended up in all the packaging hell that large JavaScript projects end up with. What started as 10 kilobytes of compressed JavaScript became 10 megabytes of compressed JavaScript, and it really wasn't viable as an approach. It worked but was a pain to maintain and it wasn't obvious that it was going to be a good way forward. So, I put that on hold and focused on platforms we know work, holding off on wasm until it's ready.\n\nAs you mentioned, Peter gave the presentation again at the PyCon keynote and announced PyScript last year, opening up the door. Peter's CEO of Anaconda and I'm at Anaconda, so I had prior warning that announcement was coming. I figured, let's just proof of concept, can we get the web backend working again? It took about a week, but managed to get a Toga backend for web back and working again. Later in the year, around October just before DjangoCon US, I sat down and said, \"Let's just proof of concept, can we get the web backend working again?\" It took about a week, but managed to get a Toga backend for web back and working again. Later in the year, around October just before DjangoCon US, I sat down and said.Okay, well, can we get a briefcase deploying to our website? So you just sort of say, \"Here's my app. My app will deploy to a Mac OS app. It'll deploy to an iPhone. Can I say briefcase deploy to the web and get a website?\" And yeah, we'll again, about another week, and we had a working proof of concept where you could take your hello world demonstrator Fahrenheit Celsius converter and spit out a single-page web app that loads price grip. So, it uses all the stuff that Anaconda has developed in the Python script. \n\nTo get a working Python interpreter in the browser, package up your app's code and your app's dependencies, and push those into the browser as well. Then load them and run them, essentially a single-page app. But it's a single-page app that you've written entirely in Python, rather than writing it in JavaScript or variations thereof.\n\nForeign developers love the InfluxDB time series platform because it handles large time series datasets and provides low-latency SQL queries, which helps them build real-time applications and provides insights that they otherwise miss. InfluxDB Cloud is a performant, elastic, serverless time series platform that can ingest billions of data points such as metrics, events, and traces in real-time with unbounded cardinality and store, analyze, and act on that data all in a single database. Check it out and start for free at influxdata.com. Thank you.\n\nI'm guessing that's about the time that you did your talk at DjangoCon US 2022. The talk is up on YouTube titled \"How to Turn Your Website into an App,\" and I like the subtitle, \"Why Maybe You Shouldn't.\" You spent quite a bit of time talking about this to an audience of Django developers, who are mostly comfortable with creating websites and deploying them using Python. The core idea was that you wanted to approach clients who often ask for both a website and an app.\n\nI haven't done a huge amount of client web developer experience; my life has been startups and app platforms. That said, I have built mobile apps. If I cast my mind way back, I was on the team that developed the very first app for Myspace. There are legitimate reasons to build apps, but common everyday experience shows that many apps really shouldn't exist and it shows in the user experience they provide.\n\nPushing back against clients who think they need an app is important. Sometimes a website is actually the right answer, especially for documents that need to be shared, rapidly updating information, or information that needs to be deep linked. Pushing back and teaching clients the best way to serve their users is essential.\n\nIn some cases, you do need an app, like the origin story of Beware. Building an app was necessary for data capture in the field, which needed geolocation and photo integration, things that apps do well. Web pages can sometimes do it, but not as efficiently, especially in maintaining context and continuity.\n\nOverall, professionals in this space should push back against unnecessary apps and focus on serving users in the best way possible.So I ended up needing a website. I had a website that was great. I needed an app, and we ended up using Cordova or PhoneGap to build it. I hated every second of working on that thing because it was this weird JavaScript hybrid pretending to be an app, except that it really wasn't. You got all the downsides of an app and a web app without any benefits. Hooray success! \n\nExactly. So we turned into, \"How hard would it be to do this in Python?\" Seven or eight years later, here we are. It turns out it was moderately difficult. Who would have thought? But we're now getting to a place where you could start thinking about building that app in iOS and actually have a legitimate application written in Python, sharing business logic with your backend. If you've got backend logic on a front end written in Python, you can use the same validation logic or client API access logic.\n\nYou actually have a native application at the end of the day sitting in your hand. You talked about the ability to access fantastic features of a phone like the camera, GPS, and entering information from contacts. Usually, there's a cascade of permission asking, but I'm wondering if you have tools in the tooling you created in Beware that can access those devices. Is that right? Yes, the bridging libraries vary from platform to platform. On iOS, we use a library called Rubicon, which exposes Objective-C as the native language on the device in Python.\n\nYou can access Objective-C classes and treat them as Python classes. The interesting thing about Objective-C is that it is a message passing language where messages are determined at runtime. You can access it through Python using FFI or C types. You can wrap all the underlying runtime methods in Python and use Python's magic to interact with Objective-C runtime APIs. It's like writing Python code that interacts with Objective-C behind the scenes.\n\nIt's definitely some black magic, but it's cool because as an end user, you're only writing Python code. There are memory management issues, but from an end user's perspective, you're only writing Python. Toga works by wrapping native UI classes provided by iOS and MacOS in a more pythonic layer, allowing you to share the same API between different platforms. Toga handles interactions like button presses and scrolls for touch interfaces seamlessly.Yeah, we can do that. An abstraction layer talks to whatever the native API happens to be. On Android, it's a very similar story. There's an abstraction layer we use called Chaka Pi. One of the benefits of having Malco on the team is that he's been maintaining this commercial toolkit for a long time. As part of coming on board with Anaconda, he's open-sourced that entire set of tools. So, we now have this battle-tested collection of Android integration and Java integration. You can essentially do the same thing with Java classes. We had a version of it with Rubicon Java Jacket Partners, but it turns out to be a lot better. It's dug into a lot more of the weeds. Essentially, the same thing is true.\n\nI was wondering about the type of background of working with phonegap or other tools to learn how those interactions and communications work. Where did you get the experience to learn it? Were you seeing it in other implementations of this type of thing, where you're translating from Python into Objective C or Swift, or what have you? Was that a background that you found in another language or another tool?\n\nNo, part of it is being 100 years old and having worked in the industry for far too long. I learned to program originally in BASIC, and C was my second language in 1988. Over time, you pick up little bits of this. I've had enough commercial engagements dealing with system integration, getting two systems that aren't meant to talk together and working out how to get them to talk together. Twenty-something years ago, the state of the art was a library called Swick, which still exists and uses some of the same tricks. Wrapping APIs, working out how to wrap one language in another language and build bindings to talk between them. One thing that got me from \"hey, wouldn't this be nice\" to \"hey, is this possible\" was looking at the sources for a Pygame because Pygame does this with Python talking to native system APIs. It's doing what Rubicon is doing through PyObjectiveC, which is maintained by the same person who does a lot of the CPython MacOS stuff. It's a lot richer in terms of what it does for MacOS but doesn't have support for iOS. It's also a lot larger as a library because it carries over a lot of officially published classes. It's an abstraction layer that lets you put a sprite on the screen, implemented by making calls to Objective C, gtk, and the win32 API.\n\nIs that a potential avenue if someone wanted to make a high-end performance video game on iOS? Could they create something in Pygame and package it through Briefcase? At present, Pygame isn't supported on iOS. However, there's no fundamental reason that it couldn't be. Beware as a stack is separated into layers, with the support layer getting Python on the device, Rubicon for talking to the iOS runtime, Briefcase for getting tools onto the physical device, and Toga for using UI libraries to build buttons and sliders.But there's no fundamental reason that you couldn't package any other toolkit to do the same thing, including Pygame. The catch is you've just got to write that iOS backend. You've got to do the conversion into the iOS Sprite biding libraries and figure out how to interpret keyboard inputs on an iPhone and resolve those problems. So, at this point, without, it's Pygame's problem, not Beware's problem essentially. At this point, the tools are there, right? You could do it if someone was motivated to do it. And at some point, I might take the bait and put something together to prove it can be done. It is complicated but not complex. There is a lot to be done. I want to understand there is a lot that needs to be done but it is all doable. It is just a matter of someone cranking the wheel and making the sausage come out.\n\nYou talked about that in our last conversation about Windows was one of the things you were working on Toga pretty hard at the time. You were like it's not this super complex thing, it just has lots of components. You're just kind of repeating yourself to like okay, well, how do I attach it to this? And once you learn how to attach one, you're kind of like learning the process of cranking through all of it. Exactly. A lot of it is working out where does Windows storage documentation for WinForms, what are its conventions for, when I need to know how do I attach to a button click, do they call that an action, do they call that an interaction, do they call that a signal, a callback? Where do they put that documentation, what do they call it, and then how do I interact with it? Once you've solved that for like, once you've got button sorted out and you understand how button works, the rest of the toolkit is basically just there for you. It's an implementation, like it's a to-do list of things to do. It's not a technical issue of can this be done at all? There are things like the WinForms implementation of tree doesn't have natively a concept of multiple columns of content whereas on GTK and macOS does. So, you then need to work out like how am I going to render a tree in WinForms, can I hack together something that looks like multiple columns, or do I need to make a compromise and say that tree only ever has one column? How do I build a complex widget out of a series of other widgets? How do I build a multi-column tree using the WinForms API? And at that point, you then essentially are becoming a WinForms programmer.\n\nYou're just coming at it with a very specific set of requirements. Okay, yeah, you're just going to pick up a \"How to Program WinForms\" tutorial and work your way through it. The same is true of GTK and iOS and Android and every other platform. You then get familiar with the APIs on that platform and how that platform structures things and then work out the rest of the L for one of.\n\nI thought about kind of going back to the web as a potential target and this I keep seeing mentions of Wazi or WASI and versus WebAssembly and this sort of crossover point there. I feel like this conversation kind of touches on that a little bit, and I don't know if that's a concern that you're thinking about at all with integrating that and also kind of I'm guessing it has to do a lot with the concept of a lot of websites. They're sort of a sandbox that they're designed to be interacted with in this one realm, and if you wanted to actually integrate into the hardware of the device, then it gets to this really interesting set of questions and problems. Wazi is an interesting case, and it's in some.Regarding it's kind of aiming at the same target as what beware is doing but coming at it from a different angle. I'm sort of aware of it, okay, and strategically ignoring it because I only have so many hours in the day. Does that stand for Web Assembly System Integration or Interface, something like that? Yeah, I will absolutely say correct. It's one of those ones where I know the acronym but I keep forgetting what it stands for. \n\nThe idea there is that instead of trying to get a Python interpreter to run on every platform and then moving your Python there, you get a Wazzy interpreter on every platform and get Python to run in Wazzy. Okay, and then at least in principle, the binaries are cross-platform because they're all just JavaScript running in a JavaScript virtual machine, so your binaries are then cross-platform. Kind of what Java was promising to be 25 years ago where you would have write once run everywhere except that now you actually do get to run it everywhere rather than, you know, it's a different runtime but as a runtime everyone actually has now because it's JavaScript rather than Java. \n\nTrying to convince people to swallow that elephant in one sitting and you can target any language at Wazzy because it's a binary format like an LLVM Clang targeted binary platform, so your C code can run in Wazzy and that makes it a lot more portable because any existing library can be compiled to LLVM which means it can be compiled to ASM. You then just hit this system layer of okay, well now I need access to a network stack or files or anything. Yeah, how do I get access to the system outside of this sandbox? \n\nThat is the set of problems that ecosystem is now challenged and trying to work out. In some regards, it's a bit like Node in some regards that you know the idea of Node was well we've got this web browser and every web browser has JavaScript by definition right and we have to build all this complex front-end logic for the web browser so can't we use that front-end web logic on the server as well? Let's write Node which lets us write our server in JavaScript and sort out the little bits that we need to actually get us a server on the server side like an actual HTTP server and then share the logic between front end and back end. \n\nThis is the same idea except that we're now doing it with Wasm. The thing we're bringing back so that the thing that we deploy in the browser and runs natively also runs natively on the desktop. In terms of the mobile story, there is another universe in which what beware is doing is not the way that we go forward. What you do is you write an application, you compile it to Wazzy, and you have a Wazzy interpreter on your phone that knows how to run this Wazzy binary and it's the same binary that runs on your macOS machine except that on macOS it's the macOS version of the Wazzy interpreter. \n\nWhich of these approaches are going to work, which is going to win, I don't know. Like I said, I have hitched my wagon at least in principle to getting Python everywhere and making it native on the platform you land on. Will that win, who knows, watch this space. There's certainly a lot of interest and a lot of activity going on in the Wazzy space. Yeah, yeah, I keep seeing it and just kind of wondering about that interconnection and things were kind of filling me in so much and some of the guys can actually coexist, like there's no reason the two can't coexist where you have the places where Wazzy are particularly interested is, and like this is probably the reason why you see you hear people like Brett Cannon getting so excited is that if you've got Visual Studio you need to write a plugin, right? You want that plugin to be available everywhere and for that reason all the plugins for Visual Studio are essentially JavaScript plugins but I want to write my plugin in Python because I want to have Python parsers and be able to use a Python interpreter and everything. \n\nIf I can compile my Python code to Wazzy then it's a JavaScript plugin all of a sudden and you can just use it on this other platform. That is the set of things where Wazzy as an idea really shines because it's I want to use Python but I don't actually care that at runtime it's Python. I just need to be able to use Python syntax to make the computer do things, and that's like an interesting ecosystem. It's absolutely a valid use case for where's your type stuff. Yeah, it's definitely going to be a watch the space thing. Yeah, oh yeah, last year has been crazy in that way.I really enjoyed the talk. I thought you hit some really interesting stuff. Not only the idea of why are you doing this and pushing back potentially on a client and saying, do you need an app and what's the cross purposes that you're trying to hit here. I like the idea that you kind of hit on a bunch of things like the idea that you need to be able to sync your data and keep things consistent across there. The other big issue is the versioning issue on mobile devices. I definitely like a lot of things you're hitting there.\n\nThe problems are framed in terms of an app, but many of them are not new problems. Versioning of APIs and having data consistency between your front end and back end are not new problems. There are existing solutions for them, and in some cases, the solutions are analogs of problems we've had elsewhere, like CAP theorem, database consistency between multiple sources.\n\nCAP theorem is the idea that you can have consistency, availability, or partitioning. You can have two of them but not all three. So, the solutions people came up with to deal with NoSQL databases are effectively microcosms of what you need when you have client-side data in an app. You essentially have a small database on your phone that needs to be consistent with the data on the server.\n\nIf you treat your phone as a second node of your database, you have to deal with transactional locking, updating, and guaranteeing availability and consistency. Partitioning is enforced by definition, and it's a known problem with existing bodies of knowledge on how to deal with it. What's missing is an ORM wrapper to make it easier.\n\nThere is space for an extension to the Django ORM or a completely new ORM that manages multiple database consistency when you don't have direct control over your other database. How do you manage consistency and transactions across multiple data sources when handing off ownership of data? It's a different thing because a certain amount of data can be held independently on the phone.Like Django has multiple database support. I wrote it, so it has multiple databases. But the catch is that when you ask for a transaction, I can ask for a transaction and know that I have it over all of my servers. Currently, I can't ask for a transaction lock on your phone. So you kind of have to mock that up, and there are ways to do it. But I need to treat your phone as something where I can only interact with it over an API that is potentially unreliable. There are known compromises that you can take, but you need to implement it and care about it in the first instance. Over time, I certainly hope that it becomes easier to manage so that as an end-user, I can just say, \"Well, I have my user data model and my bank account data model. This bank account data model is annotated as shared, which means it will be on a database, and this is the locking mechanism we're applying over these fields so that only one user is updating it at a time, for example.\"\n\nWe're getting close to an hour, and I thought maybe we could talk a little bit about if someone's coming to Beware and is interested in this idea of creating something to ship to Windows users and potentially phone users. How has your getting started situation evolved over the last two years? I would say it has evolved and become more robust with time as more people have tested it. The tutorial, at this point, has been used by many people, and the classic problems we're having are getting more esoteric. We recently closed out a hairy issue related to Windows App Store Python and its interactions with the home folder. Through better debug logging support in Briefcase, we can now pinpoint issues and resolve them more effectively. The tutorial will take you from knowing how Python works to having an app running on your phone with just a few commands.\n\nIt has become more reliable over time, but the biggest impediment is the need to download a two-gigabyte Android developer kit if you want to deploy to Android. We manage the download for you, but it can be a hurdle for those with slow internet connections or in classroom settings. Toga is another hurdle for projects using Beware.\n\nThere aren't specific projects I can shout out, but many people are building their first apps with Beware. We are interested in those doing big and fancy things with Beware.There's a lot of work that still needs to be done, particularly on the mobile platforms. There are a couple of basic navigation things that are missing on our roadmap. We will be looking at these over the next 12 months, ensuring widget layout is consistent across all platforms and enabling navigation to multiple tabs in an app with a simple widget drop in.\n\nThe apps we see are typically long-tail, as if you have the budget to build an app, you would do it natively with a development team. We are seeing demos of specific tools like a dice bag auditing tool for a Dungeons and Dragons campaign, which are solving specific itches and working on phones for easy sharing.\n\nThe progression beyond this is making the process even smoother, simplifying app deployment and submission stories, and potentially allowing app development directly on devices like iPhones. The goal is to make the process as seamless as possible for users.\n\nFor those interested in contributing, the first step is to do the tutorial and see if it works for you. Build something of your own and if you encounter any missing features, try to build them yourself. It may seem daunting at first, but it's a valuable skill to have and the Python path makes it relatively easy to get started.\n\nThere is still a lot to be done, and contributors are greatly welcomed. The project is moving faster now, and pull requests can be reviewed promptly. Maintaining the community is essential, and all contributions are appreciated.\n\nIf you're interested in joining the project, feel free to join the Discord for further discussions.And I think people can find all those links at the bottom of the Beware pages. That's right. So we've got a Discord, a mailing list which is mostly just announcements, a blog which is essentially a mirror of the mailing list, GitHub, discussion forums, tickets, and pull requests through there. You can reach me through Mastodon. Beware doesn't have a Mastodon presence yet, but I do. So yeah, I'm around and eager to talk about the bees. I'm enjoying being on Mastodon. I think we mentioned that right before we even started, and that's how I reached out to you this time. So yeah, it's a nice community there.\n\nMy favorite thing is that when I make a comment now, I see feedback and things are happening. I never quite got to that level on Twitter. It seemed like everything I would say would just go into a void and not exist. Now it's kind of a hellscape, so I'm excited to be on a different platform. We'll definitely include that. Likewise, did I miss anything that you wanted to hit? Contributions are welcome. We've made a lot of progress, and it's genuinely amazing what funding can do for open source. It's unsurprising but very real now.\n\nWe've had a year and a half of full-time F-key equivalent progress on Beware. Even when I've had a week like this one, where I've been beating my head against bug after bug, if I go back and look at my notes, we have made a lot of progress in 12 months. The next 12 months will be even bigger. From the perspective of end users, it's going to look like things have been changing. We're actually going to get to the point where the GUI widgets are built out, and we'll have native API access to hardware services.\n\nAre you doing any conference talks upcoming? I will be at Everything Open in Melbourne in just over a month, and then I will be speaking at PyCon US as well. I'm excited for the conference thing. For those who don't know, I live in Perth, Western Australia, which likes to claim the title of the most isolated capital city in the world. When the pandemic hit, that was a good thing because we just put up the moat and nobody came in. A month after the pandemic started, it was basically over in Perth. We did not have COVID in person.\n\nWe've since opened the borders, but the downside is I haven't been to a conference in three years. I miss seeing actual humans and getting feedback on projects. What's something you're interested in learning next? One of the interesting adjustments I've had to make as a function of doing open source full-time is not working on weekends to avoid burnout. I have to be almost pathologically aggressive to not do open source on weekends. I don't completely keep that up.I'm very judicious about what I eat to pick up on weekends. It's mostly stuff that's not on my critical path or a fun experiment that I want to play around with, rather than community maintenance or the project I was working on Friday that I can't let go of. \n\nDuring the pandemic, we moved house, so I've been doing a lot of home maintenance type stuff and getting on top of that. I've been doing a lot of woodwork and home crafty stuff. I did woodwork all through high school, so I'm resurrecting those skills and relearning a lot of them. It's been a lot of fun getting back into it.\n\nI have a garage with cars that I could move out of and tools that I could move into place on wheels, but I wouldn't go so far as to call it a shop. I have enough tools to be dangerous. I bought an adaptive cut system that folds up and looks like a dolly for moving furniture. It has a plunge saw and a track, so I can do some basics.\n\nI bought a cheap table saw, possibly too cheap, and I hope I won't lose any fingers working on open source projects. One of the first projects was putting it on a rollie stand so I can push it under the rest of the bench.\n\nIf you're interested in staying up to date with what I'm doing online, you can join our Discord at beware. We're also on GitHub with a stream of repositories, issues, pull requests, and discussion forums. Our website, beware.org, has a blog and newsletter you can sign up for. You can also reach me personally on Mastodon at fruitboy3742@cloudisland.nz.\n\nThanks for having me on the show again. I hope to see you at a conference soon. Don't forget that companies like IBM, Cisco, and Red Hat rely heavily on InfluxDB. Check out why they chose InfluxDB and get started for free at influxdata.com. Thanks for listening to the Real Python Podcast. Remember to click the follow button and leave a review if you enjoy the show. Visit realpython.com/podcast for show notes and to leave us a question or topic idea. I'm your host, Christopher Bailey, and I look forward to talking to you soon.",
    "UWzizzIxavg": "Welcome to the Real Python Podcast. This is episode 151.\n\nHave you ever installed a Python package without knowing anything about it? What best practices should you employ to ensure the quality of your next package installation? Christopher Trudeau is back this week, bringing another batch of PyCoders WeeklyThere are also potential languages that it may be using, like Rust or C, under the hood. You can also look at the license and the development status, which is something that is focused on a little bit. Under that, you can see the current status - is it under production, stable, inactive, in planning, or in an alpha stage. There are a couple of resources right in PyPI.\n\nOnce you've clicked on the package and get to the actual Details page, there's quite a bit of information there. The project description gives you some main details, links to the GitHub repo, GitHub statistics, documentation or home page links, maintainers, and other metadata. By looking at the documentation, you can quickly tell what's happening with the package and see a bit about the release history.\n\nThere is a tool mentioned that hasn't been used in this particular vein before. Usually, PyPI or the site's main pages or GitHub are used. The site mentioned is called libraries.io. It has a great stats page for the package that includes all the dependent packages, release information, additional contributors, and more.\n\nThe library's site is not specific to Python. It shows a JavaScript library called Purdy and provides a separate ranking system for packages based on different metrics. The GitHub repository is always a great place to look for information about a package.\n\nThe focus is also on the license, which gives an idea of the permissions, conditions, and limitations of the code. It is advised to use a virtual environment when installing these packages to avoid potential risks like typo-squatting.\n\nIt's a good resource for those new to Python and evaluating packages. It's important to consider the source code link on the PyPI page and the licensing when using code. Using a virtual environment and tracking installed packages can help with experimentation. There are tools available to clean up unnecessary dependencies in the virtual environment.I find it far easier to track the three packages I actually used by wiping the virtual environment and doing a clean install from the requirements file. This way, I know I'm getting exactly what I need after experimenting. \n\nYes, I narrowed down my requirements file to just those elements. It's a quick and easy way to play around, though there are better tools out there that do a better job, like Poetry for locking dependencies.\n\nI have a short post from Will McGugan, one of the creators of Textual, a text-based application framework that uses CSS for widget layout. He did an optimization experiment on one of his programs with thousands of widgets, focusing on the overhead of Python async IO tasks.\n\nWill created an experiment with do-nothing tasks and a tight loop to measure the performance of async IO tasks. Async IO proved to be more performant than threads, handling a quarter of a million tasks per second. This data helped him optimize his code further.\n\nBrett Cannon, from his blog \"tall snarky Canadian,\" discussed various topics at the recent pie Cascades event in Vancouver. His blog is a great resource, and I plan to have him on to discuss his recent posts.If you're not familiar with him, he's a long-time core Dev and also a long-time member of the Python steering Council. This particular one is titled \"How Virtual Environments Work.\" It's not so much about how to use virtual environments, but literally what happens when a virtual environment is created, what it does on your machine, and then how Python uses that structure. It was very interesting, and I got a lot out of it looking at what's going on. \n\nAt the end, he explains why he did this and delves into all of this to kind of look at it. It starts with a bit of history; Python didn't have virtual environments at the start. Scripts were the main thing that people were doing with Python, and it wasn't necessarily set up to do this thing with environments. As packages grew, the needs for isolated environments for specific tasks or projects grew as well, and that's when virtual environments became such a useful tool. \n\nInstalling globally used to mean that there was no isolation between your projects, leading to conflicts and versions as you work on different projects with different needs. Virtual environments came along to provide isolation and separation, only installing the things that you need or potentially packaging only the things that you need. \n\nHe also talks about the difference with conda environments and then goes into the actual structure of virtual environments, discussing how Python uses them and how packages are installed there. \n\nThe main reason he looked into this is his main job at Microsoft, where he works on the Python experience for VS Code. He noticed a problem with versions of Ubuntu and Debian-based distros that removed venv from the default Python install. He created something called microvenv, a fallback mechanism to help with this situation. \n\nHe also discusses why people don't just use Virtual EV, an older style tool for creating virtual environments, and compares it to microvenv, which is much smaller in size. It's a nice way to learn about what's happening behind the scenes and some of the tools involved. \n\nOverall, it's a tour of creating a virtual environment and leaving pip out, showing how instantaneous the process is with just creating folders and symbolic links. It's a valuable learning experience to understand the inner workings of these tools.I was having a conversation with Christopher before it got a little clunky without Pip. It is a way to create the structure of the virtual environment. You can learn a lot by digging into virtual environments and understanding what is being created on your machine. I'm thinking of including more articles on the usage of virtual environments and getting started with them on Real Python. This might address any questions you have about what the environment is doing.\n\nDid you use other tools before or have you always used Virtual M before it became venv? I still use Virtual M. I'm one of those who prefer to have all virtual environments in a standard location rather than under the project. It's people like me that challenge packaging conventions. Whenever I install a new Python, I first install Virtual M in the primary location to manage it.\n\nAs for typing, I've always been able to type quickly. I learned on a manual typewriter and played piano for many years, so my tendons are in good shape. I don't have any repetitive stress injuries. \n\nI'm highlighting a new Real Python course called \"Documenting Python Projects with Sphinx and Read the Docs.\" I'm obsessive about documentation due to a past experience where I had to fix a bug in my code after someone else wrote it. Documentation is key to helping my future self understand my code. Sphinx is a great choice for this purpose as it turns restructured text files into documents, commonly HTML.\n\nRead the Docs is a free site hosting over 80,000 projects and serving 55 million pages a month. It integrates nicely with Sphinx and repositories like GitHub. The course covers how to use Sphinx, its features, command line tools, and the autodoc plugin that reads Python comments for documentation.So if you've been a good little programmer and you've been writing comments on your functions and classes, Auto Doc will produce a document for you. One of my favorite uses for this is in the testing world. If your corporation insists on having a test document to go along with your test code, a great way of doing that is to put the comments in your test suite. Then you run Sphinx on it, it extracts it, gives you a PDF. When they ask where's your testing document, you can say here it is. You're not maintaining two different things, which is very useful. You only update one place, keeping it all in one place. As you update, it stays in sync and satisfies your corporate requirements.\n\nThere's a bit of extra work involved as you have to use the right tags inside your comments, but you can get decent results. It supports cross-linking so you can tag the name of another class or function, and the output will include links to the docs for those objects. It's really handy. Sphinx supports different themes, with one of the more popular ones being the read the docs theme, which produces HTML output that matches the rest of the documentation on read the docs. It takes care of the look and feel for you.\n\nAfter covering all the documentation stuff, the course gives you a quick walkthrough of the read the docs site, how to hook your repo up, get all the auto-generation stuff happening, and how it all works. There are references to fireflies scattered throughout. If you want to learn about Sphinx and getting better documentation out of your Python, this course is great.\n\nMoving on to projects, there's a quick one called duckargs, a code generator for argparse boilerplate. If you've used argparse to create CLIs in Python and want to avoid repetitive typing, this tool from Eric Nyquist is helpful. After installing it, you can type out the arguments, flags, default values, and it will generate the code for you. It speeds up the process of using argparse to create a CLI. It's a simple yet handy project that I'm looking forward to trying out.Yeah Eric has a couple of other cool projects. Check out his GitHub, he's got some other interesting things. He mentions he's a software developer specializing in C for embedded systems and Python. A lot of the projects he's sharing are all Python ones. He's got one about generating audio tones which I'm going to check out. That's pure Python so that'll be fun.\n\nThis week, I want to shine a spotlight on another Real Python video course. It just so happens to be the course Christopher was discussing earlier in the episode. This week it's titled \"Documenting Python Projects with Sphinx and Read the Docs.\" The course was written and presented by Christopher Trudeau and as the course instructor, he takes you through how to write your documentation with Sphinx, how to structure and style your document with restructured text syntax, incorporate your code comments and docstrings into your documentation automatically using the pdoc plugin, how to host your documentation on Read the Docs, and how updates to the project's GitHub page can also update your docs.\n\nThe course includes additional resources for you to learn even more about documenting your project with Sphinx and Read the Docs, including a cheat sheet for using RST syntax for Sphinx. Real Python video courses are broken into easily consumable sections and where needed include code examples for the technique shown. All lessons have a transcript including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the enhanced search tool on realpython.com.\n\nWhat's your project this week? Oh, I've got a two-for this week. It's both a project and an article by Jason Ross. The article is entitled \"Are Those Numbers Realistic or Fake? Try Using Benford's Law.\" So besides having a bit of a mouthful of a title, the article is about a phenomenon that I find fascinating. Oddly enough, Benford's Law isn't named after its discoverer, Simon Newcomb. Newcomb noticed a pattern in his logarithm tables books in the 1880s, where the number one shows up as a first digit almost six times more frequently than the number nine in a lot of situations. Newcomb published a paper about this, and then 50 years later, Frank Benford rediscovered the same thing and published his own paper. Now it's Benford's Law. It's the same reason the Americas aren't named after a Norwegian. Not everything adheres to Benford's Law, but enough things that this can be useful in the real world. It has been used to detect fraud in financial situations, for example with expense claims. They tend to match Benford's Law, so if they don't and they're more evenly distributed, there's a chance your expenses are fraudulent.\n\nSo that's the article and it relates to a project called \"Randalyze,\" spelled r-a-n-d-a-l-y-z-e. It's a random number generator that fits a specific distribution. For now, the only distribution it supports is Benford, but he's structured it so that others can be added later. You can use this little command-line tool, and it'll output in text, CSV, or JSON, and it essentially lets you create random numbers that fit the Benford curve. The next time you want to create fraudulent expense statements...no wait, was that out loud? Maybe we should wrap it up there before a grand jury convenes. It's a neat little mathematical phenomenon that shows up in a whole bunch of places like the lengths of rivers. It's a cool little tool to play with, something worth checking out if this kind of math stuff floats your boat.\n\nThanks for bringing all these articles and projects this week, and I'll see you in a couple of weeks. Cheers.\n\nUp next, I talked to Deb Nicholson, Executive Director of the Python Software Foundation, about PyCon US 2023.\n\nHi Deb, welcome to the Real Python podcast.\n\nHey, it's great to be here. Thanks for having me.\n\nYou are the Executive Director of the Python Software Foundation, and through that, you do many things. What I thought we could talk about briefly is how did you get involved with the conference and the PSF?\n\nThe PSF sort of came into being as there was a need for an entity to run the conference and once you get to a certain size, you don't want to be paying for hotels out of your personal checking account. The reason that I got here, I've been the Executive Director for almost a year, but I started in Python as a volunteer organizer for the Boston Python Meetup, which is where I live. We were doing Open Hatch workshops for folks who were just learning Python for the first time. We would do these day and a half long events and then hopefully get people to stick around and become part of the regular Meetup group.\n\nThat's awesome. You're really involved locally and it grew from there.Well, I have been working in free and open source software for about 15 years. I have been at various organizations in our space, mostly nonprofits. Most recently, I was involved with the Open Source Initiative and Software Freedom Conservancy. I also helped run a small conference in Seattle called the Seattle Junior Linux Fest, where I am a founding member. I have been involved in open source for a while, but it's nice to focus on Python because I believe it's one of the best communities.\n\nI just returned from Podcastades and had a great time there. It's a very welcoming community. As the executive director of the conference, my role involves handling all the out-of-band or unexpected issues that may arise. I also work on convening different Sprints, Summits, and conversations, aiming to support the Python community better and connect people together.\n\nThe conference this year will be held in Salt Lake City at the Salt Palace Convention Center from the 19th to the 23rd of April, with Sprints continuing until the 27th. It will be a hybrid conference, combining online and in-person experiences. Tickets are still available for both options, and discounts are available for students.\n\nOne unique aspect of PyCon US is the tutorials held on Wednesday and Thursday, separate from the main conference. There is a separate fee to join a tutorial, but it provides an opportunity to learn from experts in person. The Education Summit is typically held for one day during the conference, led by educators like Sean Tibor and Kelly Paredes.\n\nOverall, PyCon US offers a range of opportunities for learning, networking, and engaging with the Python community. It's a great event to be a part of, whether online or in person.And then there's a few sort of things happening around the language specifically that are kind of independent but interesting to watch. The Python Language Summit sort of happens around the same time. Yeah, the Python Language Summit is invite-only, but there's a whole typing summit the next day. People have a lot of opportunities to talk with the core developers, most of whom attend PyCon and give talks on Saturday morning about what's going on with all the different PEPs. It's a great opportunity to find out what other people are thinking about in Python and what kinds of improvements are hot topics in the community right now. Maybe talking with folks that would be affected by similar work can help you envision what you would like to see be part of Python. \n\nIt's awesome, and there's also a sponsor presentation on Thursday that's part of your main ticket. The sponsored presentations are not extra; they are part of your ticket. You also have quite a few keynotes, one almost at the top and end of each day with a variety of speakers. Ned Batchelder from the Boston Python Meetup is speaking, and Carol Willing, a long-time Pythonista, is also speaking. James Powell and Margaret Mitchell are also speaking about exciting things with Python. \n\nOne area I'm interested in is the lightning talks. It's a great way to start a conversation and gauge interest in a topic. Lightning talks are only five minutes, so anything you can talk about for five minutes is welcome. It's a unique way to identify others interested in the same topic. \n\nLast year, I didn't quite understand the idea of posters. It's borrowed from the academic world, where researchers show their work on a physical poster and engage in one-on-one conversations about their projects. It offers a different energy than live talks.\n\nThere's also a job fair happening on Sunday, which is timely for those looking for job opportunities. Make sure to swing by if you're a Pythonista looking for job opportunities. Marietta, this year's PyCon US chair, is celebrating an anniversary with PyCon US.Right, we sure are. It's the 20th Yukon. So, sorry to everyone who now feels old because you came to the first one. It's been 20 years. I always feel like that every time they share the war games or the hackers anniversary. I'm like, \"Oh Jesus, when did that happen, stop.\"\n\nBut it's a good thing. Mariana and she's working with Georgie Care on this to collect people's historical pictures, remembrances, any kind of snippet or a story about how your first PyCon went, or how one that was really pivotal. Like if you have a story about maybe you met your lifetime partner or got the job of your dreams at PyCon, we want to hear about it and share that in the 20th-anniversary celebration. So, that'll be put together in kind of a swanky little sizzle reel, I think, so people can kind of just mainline the experience of PyCon in a couple of minutes. I'm going to include a link to it, but it will be the last day of submission. I'm just noticing you got to get them in by March 31st, which is the day this show will come out. So, make sure you, if you hear this and you're interested in submitting your story and you didn't catch it up to, you know, if you don't have much time to wait, definitely submit your story. \n\nOr if you write and say, \"I have a story, can I have one more day?\" We'll see. I don't want to sign me out of Jordy up to be too lax, but if it's a really good one, I bet they'll make it. One thing that I've learned about through having other guests on the show to talk about their conferences and talking to people who've gone to speak at other conferences is that if you're interested in speaking at PyCon, you have some really amazing guidelines and resources. There's a whole, if you want to propose a tutorial or you want to propose a talk, what you also get is 20 years of resources that go much further. It's kind of a neat resource. I've definitely had people say, \"Definitely check out the website if you're interested in doing a talk at PyCon. The resources are amazing.\"\n\nYeah, we try to make it really low friction for newer speakers to apply, and there are a lot of community members that put themselves out there as someone who's willing to help with your proposal. You can join our slack if you want to. The general slack is also a place where you can find folks that want to help with proposals. So, yeah, that'll definitely all be in effect for our conference next year in Pittsburgh too. We already have chosen speakers for this year. \n\nBut, yeah, how soon before the conference does the call for proposal? It should be out, like, you'll have several months, so it should probably be out.\n\nOkay, so that's the common time, but we'll see. I think Pittsburgh is a couple of weeks later in the year than Salt Lake, just every venue is a little bit different. So basically, you should sign up for the PyCon newsletter so that you get notes about all the deadlines well in advance of them. \n\nAnd one thing that I didn't know as much about, I've heard of this from other conferences that there often can be help with your talk and getting going. But in some cases at PyCon, you can be assigned a mentor, somebody who's done a talk before. \n\nYeah, we do that, and you know, that is definitely something folks can do. I would also say too, like most of our speakers are completely happy to talk with people about, especially if it's in your area of expertise, about how they wrote their talk and what they think the program committee likes to see. That's all good. Everyone's very friendly here. Everyone wants to help you succeed. \n\nI said before we started that maybe you could choose a couple of talks that you're interested in talking about, and then you're like, \"Oh no, I don't want to have to do that. I have to pick from my favorite children.\"\n\nSo maybe I'll do it for you. Wow, because I would love to hear what your favorite topic. I mean, I did already mention Ned and then we were talking about newcomers. I know there's going to be a great tutorial for newcomers to Python by Trey Hunter on Wednesday. Oh, awesome, yeah.\n\nWell, there's a handful of people that have been guests on the show that are doing conferences, so if you've heard their voices on here, Brett Cannon, Calvin Hendricks Parker, Jody Birchall, Bruce Eckel, Pablo Belinda Salgado, and Al Sweigert, and a bunch of others. And then there's other people that I'm very interested in hearing from, Mark Shannon and Will Shazatka. Tell me about the newcomers orientation. Is that kind of what you were mentioning there, or is that something separate?\n\nYeah, there is a newcomers, well so there's a newcomers tutorial for learning Python, so that's like a four-hour thing. And then on right before the Expo floor opens on Thursday night, there's a newcomers orientation where you can meet with, I think it's Trey and Kojo.And maybe a couple of our board members, John and Debra, are kind of like, \"Hey, let's all meet each other. Here's kind of how it goes. Now we're all friends, so you have at least one or a couple of new friends here. You're not by yourself and like kind of where everything is around the convention center.\" \n\n\"Oh, awesome, yeah. And that's not extra, yeah. It's a big place. Oh yeah, the Salt Palace is huge. Next year's Pittsburgh event will be a little cozier, okay? Yeah, I enjoyed it, but I did put some miles on my shoes last year traveling to some of the back areas to get to the conference talks. So yeah, it's never a bad idea to bring your comfortable shoes to a conference.\"\n\n\"Oh, yeah, definitely. We've talked about quite a few of the events happening. I think one thing that we didn't mention is things that are happening. I guess it starts on Monday, the Mentored Sprints for Diverse Beginners.\"\n\n\"Yeah, so that one we're bringing back after we didn't do it last year, but we're bringing it back. So I haven't actually attempted those, but the idea is that if you haven't sprinted before but you're interested in giving it a try, you come by and someone will help you get set up and find a project. That's great! Sprints are very relaxed, so the whole conference days are like, 'Okay, we have like that ran over by three minutes. I have 11 minutes to get to the other end of the convention center.' But that Sprints are like, 'Hey, what's up?' Really mellow, like no clocks, no rules. I mean, there's still a code of conduct, but there's no rules about what to sprint on or how fast you're supposed to go or anything like that. Cool!\"\n\n\"And this year again, there is a, I guess it's pronounced Charlie's track going again, right?\"\n\n\"Yeah, I've heard people say Charlotte's. So that's the Spanish-speaking track, like all the sessions are given in Spanish. And it means that we're gonna actually have like a mirror of that on the Hulu, which is the virtual instance where there will be a Spanish chat room for people to watch Charlotte's track and then be able to chat about it in Spanish so that they kind of know where to go to find the other remote Spanish-speaking participants.\"\n\n\"Alright, so another expansion on the online stuff this year. Yeah, we're really excited about that because we're like, well, if we're gonna have sessions in Spanish, we should be able to have some hallway track in Spanish, right? Yeah, definitely, yeah, cool. And then one thing that we could mention is the, there's a PyLadies auction that is kind of an annual event, right?\"\n\n\"Yeah, that one's a big one. It is Saturday night. We are doing a slightly larger room than we did last year because we sold out last year, so I think the capacity is like 300. It's a classically kind of Conference Center banquet dinner. You're not really there for the food, but you're there for the company and the auction. There's some amazing, let's see, one of our board chair last year got a gold chain keyboard necklace, which I don't know if that's sounding as cool now that I'm saying it as it looked in the pictures, but yeah, that was a donation from Capital One and it was really amazing. We raised a ton of money for PyLadies. PyLadies, like the International network of PyLadies chapters, is a fiscal sponsee of the PSF so we helped them with their back office and their admin stuff and we helped them by hosting this auction during PyCon. It's great. It's one of our accounting team's favorite events because they get to bring in money in real time. So that's great.\"\n\n\"A couple other things to mention. We could talk a little bit about the COVID policies this year. They're basically similar to what it was last year, right?\"\n\n\"And well, people have a lot of opinions about that, but we pledged to have a masked event with vaccine verification. And we also pledged that we wouldn't roll back our health policy. We just felt like, regardless of what else is going on, we're bringing an international audience, people from like 50 different countries to one place in Utah. So it kind of doesn't matter if you could catch COVID at the Utah Supermarket. That's not what we're doing. We're bringing an international group of people together. And then it's also really important for our attendees to know that here's what the health and safety policy is. We're not going to change it right after you buy your plane ticket. Yeah, and so that was also really important to make sure that what we said we were going to do is what we kept. And it also, I would say, makes the event accessible to people with immune issues or people who share their house with folks that have immune issues. We're really into accessibility. We want everybody to be able to come to PyCon and have a good time and not have to worry about stuff that we can take off their plate if we can.\"That's great, that's most of the questions that I had. Am I missing anything that you wanted to speak about? The only thing I think was on the accessibility Tech. We are also doing live captioning for all the sessions again this year. Okay, so I think we've been doing that for a few years, and we have it for both of Charlotte's tracks and for the English tracks. Captioning for both, that's fantastic. And then those all end up on the videos that are posted later. Yeah, they do. Like last year, our English speaking captioners couldn't come in person, so we were able to use the technique that we use for our Spanish speaking captioners who are remote to get our English speaking stuff live remote captioned. Oh wow, it was okay. It was just like stuff changed about the travel rules, and anyway, it was okay. They're gonna join us in person this year, so that'll be nice. Great.\n\nI have a couple of weekly questions I like to ask. The first one is, what's something that you're excited about in the world of Python? That can be a book, package, editor, or other thing that's happening, or an event. Obviously, PyCon is a big one, but what else are you excited about right now? I'm always thinking about how this is the first year I've been the executive director. We're not quite a year, and what's just been exciting to me is hearing about all the things people do with Python. Like, every week I meet someone who's using Python to help cure cancer, or using Python to look at space and see galaxies thousands of light years away from us, or in digital humanities, biology, everyone's using Python in all these different ways. It's been really exciting because once you say you work at the Python Software Foundation, everyone wants to tell you what they use Python for. It's been a great year of learning about 100 new things that people do with Python.\n\nThe next question is, what do you want to learn next? It would be really handy to know a lot about how European policy gets made right now. I don't know if that's an exciting fun one to share, but we're definitely looking at the Cyber Resilience Act that's being considered in the European Union and what that means for Python as an open-source project. I don't consider us a commercial entity because we're a charitable nonprofit, but that's a US thing and this is EU law. I don't know if that's so much exciting as it would sure be handy to know lots about how European policy gets made. I've been hanging out with open-source lawyers for over a decade, so I have the right places to start. It's a lot like, if it was really easy to affect policy, everybody would do it, right?\n\nWhat's the best way that people can follow what's going on with PyCon US 2023? If you want to pay attention, we're on Twitter, we're on Mastodon. You can follow the PSF or PyCon US, and we also have a newsletter that we send out seasonally. We don't talk to you for a while, right after PyCon, and then once we have dates, hotel blocks, CFPs, and things, then we start talking to you again. Well, thanks so much for coming on the show, and I'm looking forward to hopefully seeing you there in Salt Lake City. That'll be fantastic. And don't forget to start sending relevant and timely product notifications for your web and mobile apps for free with courier.com. I want to thank Christopher Trudeau and Deb Nicholson for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. Show notes with links to all the topics we spoke about can be found inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "mt4LCmQ9A7Q": "Welcome to the Real Python Podcast. This is Episode 157. Would you like to speed up your Python machine learning code dramatically? What if you only had to change a few keywords and a couple of type hints on portions of your code? This week on the show, Christopher Trudeau is here bringing another batch of Pi Coders Weekly articles and projects.\n\nWe discuss a new programming language named Mojo, which is a superset of Python. It aims to fix Python's performance and deployment problems. The project has many interesting ideas and a leader who has helped to shape modern compiler technology.\n\nWe also share a pair of Real Python tutorials from Leodanus Bozo Ramos about object-oriented programming in Python. The first article is a deep dive into the creation of classes. It's an excellent refresher for anyone looking to hone their OOP skills in Python. The second tutorial covers the SOLID principles, which are five well-established standards for improving your object-oriented design. These principles guide you to create object-oriented code that's more maintainable, extensible, scalable, and testable.\n\nWe cover several other articles and projects from the Python community, including a news update showing warnings when running Django, tracking the progress of your Python program, and a markdown browser for your terminal.\n\nThis episode is brought to you by Koyeb. Koyeb is the fastest platform to build, deploy, and scale all your Python apps. Simply git push, and your app is live on high-performance servers around the world. Deploy for free at koyeb.com.\n\nAlright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey, Christopher, welcome back from all your travels this week. Oh yeah, been on many planes.\n\nAlright, so we have a bunch of topics to dive into this week, and one we're going to kind of add a discussion onto it, but you were going to start with a couple of news items, right? Yep, both are bits of PEP stuff. The first one is PEP 713 has been accepted. This one is entitled \"The Callable Modules.\" If you're not familiar with that vocab, I'm sure you're familiar with the idea. Take a function, for example. If you use it without the parentheses, you get a reference to it, whereas if you put the parentheses on the end, you call that function. This process applies to other things as well. You can make an object callable by implementing `__call__` on the class. And in fact, a dirty little secret, some of the things in the standard library that you think are functions are actually callable classes. So this is deep into the mechanics of Python. Back to the title, callable modules. What it's proposing doing is allowing you to use those parentheses semantics on a module as well as on a class and a function. The primary use of this is to make your code more readable. You've probably seen things like `from PPrint import`. That duplication kind of feels redundant, and this pattern of a function named the same thing in the module is rather common. Sometimes the function is the only thing in the module. So, by making the module callable, what you essentially do is you have the module, then you'll create a special function inside of it called `__call__`, and now the module itself would be callable. So instead of doing `from PPrint import PPrint`, you could just import PPrint and call it as if it was a function. Okay. So obviously, they're probably not going to do it to PPrint. I'm just using that as an example. This one is slated for Python 3.12, so we should see it in the fall release. Looking forward to that. Alright, get to play with it, let's see how it works. Yep, exactly. And then PEP 712 is a \"Let's try this converter parameter for data class field.\" What this is, data classes have been around since Python 3.7. If you haven't played with these, they're a special way of using classes where you can specify data attributes. They're pretty handy for defining things like objects that you want to deserialize some JSON into Python and bring a concept to the language. Kind of like pedantic or Django use these sort of mechanisms. They don't actually use data classes because they predate it, but it's the same kind of thing. It's that idea of creating an object that's dictionary-esque but inside of a class. Speaking of Django or pedantic, when you write a model class in those frameworks, you need to give extra information to the attribute in order to trigger side effects. So, for example, if I want to use an integer in Django, I might use a positive integer field which Django then maps to a column in the database. So, data classes support a class method called `field` that allows you to do something similar to a positive sort of integer field thing that I was just talking about. If you're putting it in the data class, it's a more complex way. If I just say `int`, I'm stuck with an `INT` and I can't do anything with it. So, instead, I use `field` and tell the `field` method that I want to do `int` and these other things, or I can construct something more complicated than it. This is how you can do side effects or create things that are more complicated. Yeah.Once you do this though, once you use that field method, you're losing the type info because it's no longer just a generic hint. What this pep does is add an additional parameter to the field method called converter, which allows you to specify the type, providing type check functionality back in this case where otherwise it would have been gone. Okay, now this pep is slated for Python 3.13 so you'll have to wait for 2024. That means that Garret will be covering it in our \"What's new in Python 3.13\" episode as I have a hard time getting through anything on typing without sounding like an old manual limited Cloud. So, it'll be his turn on that one, I'm sure. Well, you get a chance to talk about that more later, I'm sure. But we can argue it's a year and a bit off, so we'll get to that argument when we get there. Maybe I'll have seen the light and I'll be the type guy by then, and maybe I'll completely change my mind. That would be weird, stranger things have happened.\n\nAlright, so that dives us into topics, and we have a pair of really detailed and kind of amazing tutorials from Lay it on esposo Ramos. We should just turn \"leonis\" into a verb. This article is extremely detailed, and you learn lots. Yes, very much so. And he has taken on the challenge of explaining object-oriented programming in Python. This one is \"Python Classes: The Power of Object-Oriented Programming.\" I kind of feel like this is a different presentation of OOP. You know, this is just my opinion. It has two recognizable sections to it. The first part really diving into let's teach you OOP, and then let's teach you kind of advanced things. I wanted to present this since it's very long. I'm not going to do a summary of it because I feel like that's kind of missing the point of it here. I wanted to talk about who would be checking out this tutorial and do I think it would work for them or not. Would it work for a beginner?\n\nYeah, I think if you pace yourself and you practice the techniques that are shown, there are also a lot of reference additional tutorials if you want to get into that more advanced sections. There are lots of sort of off-ramps to go to other real python tutorials inside of it to dive into those details and let you marinate in them a little more. Because by the end of this, it's going to seem like maybe a lot for a beginner to kind of get into, but I feel like the explanations are good and thorough for the amount of time that a single tutorial on OOP is going to allow. I think it would work for a beginner, but the idea is that they should probably pace themselves and maybe come back and try it out. As someone who has learned OOP in Python as a first experience, this is me, I found it to be a really great refresher and it also added a lot of additional gems hiding along the way that you can kind of discover as you go, which is not uncommon and we've mentioned that multiple times in a Lay Adonis, right?\n\nIf you're coming from another language, I think this would also be an excellent tour of the OOP in this language and some of the uniqueness and the some of the gotchas and things you may want to be aware of, but also some of the breeziness of it comparatively to some languages that are a little stronger on structure and things like that. It's really detailed, and what I also was amazed by is that it never lost my interest. I really enjoyed going through it, and like I said, as someone who had studied OOP from a handful of other books and some other real Python stuff, I think this is the best version of it in the sense that it really explains some of these concepts in a way that, have you had that teacher before where they explain something to you in a fresh way and you suddenly know, ding, it clicked for you, you know, or that light bulb turned on, you're like, okay, I feel much more confident now. If I was to explain this to someone else.\n\nAs far as some of that and some of that the standout gems for me, the explanations of instances versus sort of class attributes and then later methods, the way that self and that sort of word is used and introduced, I think really helped me sort of cement the functionality between instances and class versions of things. And there were lots of these kind of other unique things which I'll mention as I kind of do like a summary of going through like some of the table of contents. He talks about something I hadn't heard of or hadn't run into directly, maybe I've seen it and just breezed over it, but there's a concept of using slots in object-oriented programming in Python, and it creates a lightweight class. I thought it was presented really well and was very interesting. The other info that I tried to search for out there on the wider internet, beyond real python, was kind of murky and very light on explanation, and I felt like this was a very good version of that.The tutorial did a thorough job of explaining why you might want to use Python as a multi-paradigm programming language. We've talked about this in previous episodes of the show. Many people come to Python with different goals, like a Choose Your Own Adventure book. You can do object-oriented programming in Python through classes.\n\nThe tutorial starts by defining a class, creating objects from it, and accessing attributes and methods. It then goes into more advanced topics like public vs. non-public members and naming conventions. The benefits of using classes are discussed, along with when to avoid them. Working with data and attaching data to classes and instances are also covered.\n\nThe tutorial then explores lightweight classes, slots, behaviors with methods, getter and setter methods, and properties. It delves into specialized classes in the standard library, data classes, enumerations, inheritance, and class hierarchies. Alternatives to inheritance like delegation and dependency injection are also discussed, along with abstract base classes and interfaces.\n\nUnlocking polymorphism with common interfaces is also touched upon. This tutorial covers many areas of object-oriented programming in Python and is recommended for experienced programmers coming from other languages. The pythonic approach is lighter weight than languages like Java, so it's important to understand the nuances of Python to avoid running into issues.I don't need that I need to know more of the language intricacies kinds of things because you might be coming to Python as a second or third language. This kind of article is great for developing and running Python apps, which is challenging. You need to handle everything from setting up automated builds to designing a scalable and resilient infrastructure. Koyeb makes it easy to deploy your full stack apps globally with a simple git push. Thousands of Python developers are already deploying with Koyeb. No Ops required. Enjoy simplicity, scalability, and stellar performance. Start deploying now for free at koyeb.com.\n\nI already hinted at it but there's something he didn't cover in the article. There's a companion article by Leonis called \"Solid Principles: Improve Object-Oriented Design in Python.\" The solid in the title is an acronym that helps with better object-oriented code. It's not Python-specific. The article guides through the design principles of SOLID. Each letter stands for something specific. The S is for Single Responsibility Principle, O for Open-Closed Principle, L for Liskov Substitution Principle, I for Interface Segregation Principle, and D for Dependency Inversion Principle. These principles help in designing objects and working together in Python.\n\nThe article steps through each principle with examples. The Single Responsibility Principle suggests that a class should only do one thing. For example, separating file management from zip file management. These principles are ways of thinking about designing objects and writing better object-oriented code. It's not a classification, but a guideline for writing better code. It's important to keep these principles in mind while writing code.\n\nI've come across these principles before, but I don't use them directly. It's more of a guideline for new developers in object-oriented design. In Django, where object-oriented design can get messy, these principles can help in structuring code and avoiding common mistakes. It's an architectural way of thinking about code design rather than strict rules. There are exceptions to these principles, but being aware of them can make you a better programmer.So, this next topic that we're going to dive into has a lot of buzz and excitement. It dives really deep into a very specific area of what Python can do. This makes it very interesting, and as this story develops, we'll have to learn where it goes. I've provided a lot of resources, and this is the one that you were able to find even more additional resources to include in Pi Coders. So, we could make this our discussion point.\n\nThe first thing I'm going to mention is an article on the fast.ai blog by Jeremy Howard. He works for Fast AI as an advisor to the company we're going to speak about, which is Modular. He's extremely excited about this thing called Mojo, which is a superset of Python. The full title is \"Mojo may be the biggest programming language advance in decades.\" A lot of stuff happens with that idea.\n\nChris Lattner, a key person involved in this project, has a storied history. During his PhD thesis, he started the development of LLVM (Low-Level Virtual Machine), which fundamentally changed how compilers are created. He also launched Clang, a C and C++ compiler that sits on top of LLVM. This forms the backbone for a lot of Google's performance code.\n\nAfter working with LLVM at Apple, he developed Swift, leveraging the power of LLVM. Then, he started to work at Google on a new thing called MLIR (Multi-Level Intermediate Representation). MLIR is a replacement for the LLVM IR for many core computing and AI workloads.\n\nHardware in computing has changed significantly, with GPUs and TPUs becoming more common. MLIR aims to create a multi-level version of the code that can be spread across all that hardware.\n\nBeyond that, there's an introduction by the company Modular called Mojo, which aims to avoid the two-language issue often discussed on the podcast.Well, in order for it to be faster, we'll work on compiling things in other languages that we can insert into Python. Maybe in NumPy it's doing things in C or Fortran, or we're talking about other modular pieces that we can add, compiled in Rust, to speed up those portions of code and send code down multiple paths with compiled libraries.\n\nThe idea with Mojo is that maybe we could do all of that within one language, with the ability to write in a Pythonic style and add sections of code that switch into faster mode. For example, instead of using \"def\" to define your function, you could use \"FN\" to go into that faster mode. The trick would be to declare the types of every variable in that mode for compilation.\n\nThere's also the idea of using structs to have attributes tightly packed into memory for use in other data structures, avoiding chasing pointers. The language aims to help with deployment by statically compiling applications for smaller and quicker launch programs that run efficiently across different hardware.\n\nThey're trying to address various aspects and will provide links to their keynote showcasing these features. The language is currently in an introductory phase, with a demo by Jeremy Howard inside the video showing the Jupiter notebook open on their modular platform. It's not yet open source but will be eventually.\n\nThe language is designed for machine learning and AI, focusing on speeding up Python. It can work with Python, import modules, and work with scientific libraries like Matplotlib. However, it's not complete and lacks features like tuple support, classes, keyword arguments in functions, async IO, comprehensions, etc. The language is a work in progress, with a roadmap highlighting its current limitations.\n\nIt's intriguing that they chose to showcase it now, possibly due to conference season and the involvement of Chris Lattner from Google at Modular AI. The language is still evolving, with room for improvement and development.I'm wondering if they want to make people aware of the explosion of AI stuff out there. Part of the discussion is about two threads we found on Hacker News. What's neat is that as people ask pointed questions, Chris Lattner and Jeremy are answering them, which is cool. They want to avoid bad impressions and falsehoods being spread. People were complaining about the Objective-C to Swift transition, and Chris acknowledged it wasn't great. He's trying to avoid similar issues with this new language based on past experiences.\n\nI like that Chris and Jeremy are active in responding to questions. They provide deep insights into compiler performance and type systems. People on the internet tend to criticize things like Swift and Python packaging, leading to unnecessary debates. Despite the hype, I'm optimistic about this new language potentially solving problems in a different way.\n\nThe team behind Mojo seems to have expertise in compilers and is introducing new concepts like multiple levels of representation. They spoke at a TensorFlow conference a few years ago, discussing their approach and the challenges they faced with rapidly growing models in AI and machine learning.\n\nThe hardware's pace of advancement hasn't kept up with the growth in AI models, leading to challenges in addressing the scalability of these models. It's interesting to see how they're tackling these issues and potentially making significant performance gains.So I can imagine that somebody who's working at that level, working on the compiler side, then also creates the language that can take advantage of those things. Some of the fun stuff that it can do programming, but it has some very interesting things where you can kind of have it gauge its own level of optimization. It could try out and tune itself, which I think is really neat, like having it auto-tune how this particular algorithm will work best with this many cores. That, I think, is really smart, and I haven't seen that in a language before.\n\nThe idea of being able to pick and choose where you want to add functionality is fascinating, and I appreciate that it's not a brand new language. It's still going to read the way that Python reads, which I think is really cool. I mean, I know that person didn't like white space because it's difficult to copy things and move them around, but that's always the same argument every single time. \"I can't copy and paste code.\" Okay, well, pay attention, you're doing it.\n\nJeremy touches on it in the article a little bit that because this is compiled, all the compilation stuff is happening on your local machine, which in theory fixes the distribution problem. You have a different distribution problem because now you have to target your platforms, but as in, I have to compile for Windows or I have to compile for Mac or I have to compile for Linux. They don't really cover any of that. Quite frankly, we kind of do that within the Python community anyways. A lot of libraries are available via compiled wheels.\n\nI think that's an easier problem to solve, but being a Mac user who is at the bottom of the totem pole on the targets, when somebody says, \"Yeah, this problem is solved,\" what I hear is, \"So there won't be a distribution for you.\" It'll be fine, you'll just have to brew something and then install the Brew thing. Yeah, so I was definitely having that problem with things like TensorFlow and some of these other larger models that I wanted to play with.\n\nThe versions we're using are several years before this version of the Mac came out, and I'm not sure how to set it up for it. There were explanations, but it was very convoluted. I'm hoping that will help with modernizing some of that too. It'd be interesting to see what comes out of it.\n\nThe second conversation was started by Chris Lattner, and the first post I see on there is titled \"Mojo: A New Programming Language for AI Developers.\" I don't know if it's going to answer the general purposeness of Python. I'm not sure if that is part of the targeting or not. There are lots of very specific problems that AI developers and ML developers have, so it'll be interesting to see what happens there.\n\nThe advantages of a closed beta somewhat solve the 1.0 2.0 problem in the fact that you're able to control who you're letting see it. If you have to make a big change, the people who are playing with it know that. The disadvantage is that you hype it, and then everyone goes, \"Well, does it do this?\" and you don't know. You're limiting where you're getting your feedback from. It's a bit of a pros and cons approach, and you're always sort of seeing things like the promise that says, \"Oh, we will open source this,\" and it's like, \"Let's talk about it when you do it.\"\n\nThat's kind of what happened with Swift. The idea was, \"Hey, we're going to open source this and this will be the thing for servers and this will be the thing for ML.\" Google and the community tried, but it never took off. Fundamentally, open sourcing means somebody can fork it. That doesn't mean there isn't a committee completely populated by one company in charge of the official release.\n\nSo there's always that balance. The difference with Java was far more out there before Oracle started trying to clamp down on things. The big companies to a certain extent kind of want their cake and eat it too.Sometimes that limits the reach of the language. It would be interesting to follow along. \n\nThis week, I want to shine a spotlight on another real Python video course. It provides a thorough introduction to one of the most famous machine learning algorithms. The course is titled \"Using K Nearest Neighbors in Python\" and is based on a real Python tutorial by Jose. The video course is presented by previous guest Kimberly Fessel, and she shows you how to explain the k nearest neighbors algorithm both intuitively and mathematically. She also shows how to implement k nearest neighbors in Python from scratch using numpy, create a model, make predictions with scikit-learn, randomly split data using scikit-learn's train test split, adjust hyperparameters, and score predictions. K nearest neighbors is a great place to get started on your Python machine learning algorithm journey, and this course is a worthy investment of your time. Like all the video courses on real Python, the course is broken into easily consumable sections, and additional resources and code examples are provided. All course lessons have a transcript, including closed captions. Check out the video course using the link in the show notes or the enhanced search tool on realpython.com.\n\nWhat's your next one? This is a quick little article called \"How to Have Python Show Warnings When Running Django\" by Joseph Victor Zemit. The advice is for Django, but it's really about command line options available to Python, which can be used when running Django's Dev server, for example. Python supports a command line flag, \"-W\", that controls the warning level. By passing in \"-Wd\", you get any warnings issued in the code the first time they're issued, so you don't keep seeing the same one repeatedly. You can also use \"-W ignore:DeprecationWarning\" to show all warnings except deprecation warnings. Another option is the \"Dev mode\", which can be activated with \"-x Dev\" or by setting the environment variable \"PYTHONDEVMODE=1\". These are different ways of controlling Python warnings to help you understand if your code needs adjustments.\n\nFor the Django-specific bit, there's a control script inside Django called \"manage.py\" used to run commands like the development server. You can add flags like \"-x Dev\" to the Python command when running \"manage.py\" to show deprecation warnings. This helps you fix and clean up your code to avoid issues when things change.\n\nMoving on to projects, I started playing with one called tqdm that you shared with me. It's a progress bar for Python programs that you can use within the console to track the progress of your code. It's easy to use - just import tqdm and wrap it around the iterable you want to monitor. For example, if you're using a for loop with range, you can do \"for i in tqdm(range())\" to see the progress as your code runs.And then as the thing is progressing, it just shows in the terminal the progress as it's walking by. It doesn't use up a lot of processing power. It will work in all standard terminals - Windows, Mac, Linux, or within the Jupiter notebook. It doesn't require any dependencies, not even curses. It's just Python in an environment that can support carriage return and line feed control characters. The article goes a little further than what's shown in the GitHub, showing how to customize it a little bit, how to change some of the animations, how to use different characters or colors or ASCII art to create some nice techniques of progress bars and seeing it progress as you go. If you have loops within loops, you can use it multiple times and it would show multiple progress bars as it completes one section to the next section. \n\nIt's a neat little project and if you ever needed a quick progress bar for your Python program, this might be a handy tool for you to add. The one caveat with it, which I think maybe goes without saying, is if you're piping something like generators through it, it has to turn it into an actual thing because you can't show progress unless you know how many items are in the progress. Otherwise, you need a spinner because you wouldn't know how big your generator is going to be and where the end is. \n\nWhat's your project this week? We're going to close up with something called Frog Mouth. It's from the folks at Textualize. Frog Mouth is a markdown viewer that uses the Textual toolkit. It's simultaneously a useful tool and a bit of a showcase for how you could use Textual. You can either use it as a tutorial for writing Textual stuff or just use it as a markdown viewer if you like. It's Python, so of course you pip install it and then once you've done that, you've got Frog Mouth available as a command line tool. You run it passing in either the name of a markdown file or a URL pointing to one. \n\nIt took me a minute to figure out that some of the menu interaction was mouse-based, but once I did that, everything else went smoothly. It does a really good job of rendering the file and distinguishing between the different kinds of tags inside the markdown, presenting the output nicely. It also supports a subcommand called GH, allowing you to directly load from a GitHub repository. For example, Frog Mouth GH Textualize/textual loads the readme file from the Textualize Textual repo. The first time I did this, it blew up with some sort of connectivity error. I think my network glitched and it had the prettiest stack trace I had ever seen. \n\nThe second time I ran it, it loaded fine. The feature is handy because what you're trying to do is look up the readme file of something in a repo somewhere, and now you've got this on the command line. My one complaint is they didn't use a flag for GH, like it's not --GH, it's just GH. So if your markdown file is named GH, they were smart enough to figure that out, but it's a weird kind of overloading that throws my OCD off. Will, if you're listening, this should be a flag. \n\nThat's my only complaint, and it's a nitpick. Otherwise, an interesting little library to check out. Did you mention the pipex thing with it? No, I didn't. Pipex is a tool that is pip plus execution, and it's kind of like setting up your terminal with a bunch of tools and creating your environment. It's neat because it's very easy to install and uninstall. It supports doing it with Frog Mouth as well. So if you've got common outside tools, it's basically a common outside tools environment so you're not having to run your virtual environment for it. You can use pipex with it as well.Cool, thanks again for bringing all these articles and projects this week, Christopher. Always fun.\n\nAnd don't forget, you can deploy your Python apps globally in minutes for free with Koyeb. Head over to koyeb.com and start deploying for free today. That's k-o-y-e-b.com.\n\nI want to thank Christopher Trudeau for coming on the show again this week. And I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review.\n\nYou can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "DReWGl1uqMA": "Welcome to the Real Python Podcast. This is Episode 158. Do you need a refresher on using Docker with Python? Would you like to learn how to configure a continuous integration pipeline with modern tools and Docker? This week on the show, Christopher Trudeau is here bringing another batch of PyCoder's weekly articles and projects.\n\nWe share a recent Real Python tutorial from Bartos Jacinski about building continuous integration with Docker. Docker provides consistent environments for configuring, testing, and delivering Python applications. This tutorial will help you get up to speed with current Docker and CI techniques.\n\nWe also speak with Bill Pollock from No Starch Press about Hacker Initiative. This public non-profit gives back to and strengthens the hacking community. The 2023 Grant cycle is currently open until August 15th, and we discuss the application process and projects from previous Grant recipients. We cover several other articles and projects from the Python community, including a news update implementing metaclasses in Python, creating time machine-style backups, and scanning your project for vulnerabilities.\n\nAlright, let's get started. [Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Hey, Christopher, welcome back.\n\nHey there. Alright, so this week we have a couple pieces of news and a little bit shorter on the topics in the middle because I have an interview with Bill Pollock talking about Hacker Initiative, which is a really great interview. I was really excited to talk to him and also a great opportunity for people who are interested in potentially getting funding for their projects. He has a charity that is looking for people to apply and do grants for. So please stay tuned and listen for that at the end of the show here. But today we're gonna start with some PyPi news, right?\n\nYeah, there's lots going on over at PyPi. I'm not sure if this is how funky things always were and now we just know about it because they have a blog. Yeah, the blog is new. Yeah, or whether somehow the blog is causing the universe to conspire to give them stuff to write about. I don't know how it's happening, but there's a bunch going on. First off, on May 20th, they actually had to shut things down for a little while. They suspended new account and new project registrations. We've talked multiple times about some of the malicious package naughtiness going on over there, and they were getting hit pretty hard. So they just decided to suspend the creation of new accounts and the creation of new projects. It lasted about 30 hours, and then they opened up for traffic.\n\nOkay, so this probably sucked for some people if that was the day you were gonna create a new account.\n\nGoing live today, but I'm kind of happy that they're doing it right. Like, this gives them another lever that they can use when the stupidity is going on.\n\nEspecially if it's automated, exactly.\n\nSo more power to them for doing this. I think it just shows responsibility, so that's great.\n\nGood. And the second bit, also from the PyPI blog, evidently back in March and April, they were subpoenaed for user information by the US Department of Justice. And because of how this stuff works, they're not allowed to say very much about it. They have written a lengthy posting about what kinds of information they have and could have been made to turn over. They're also promising to review their data retention policies so if this happens in the future, it will be clearer what they can and can't provide.\n\nWhich brings me to a very important question. Just what did you do, Mr. Bailey?\n\nIt wasn't me. I was just running that demo project from Gerana and that's it. Throw it under the bus.\n\nI don't know. It's really kind of interesting. I'm glad that there's this level of transparency, but it's also probably good to know what sort of things are you inserting in privacy-wise into these services and what's available if something got subpoenaed. Yeah, the posting is very honest about what their policies are and how they want to think about it, and they seem to take the privacy of your data very seriously. So they're gonna re-examine some of this for the future. One last little thing quickly, the beta preview of Python 3.12 came out on May 22nd, so we're getting closer and closer to that release in October. It's coming up. Try it out. Yeah, I think I saw builds for the Wazzy version being kind of posted also, which is kind of exciting and kind of harkens back to my conversation with Brett Cannon, so there's versions out there for those things too that people try out in the beta. Alright, well, that brings us into topics, and my first one is from Bartosz Jachinski, and this is a... Well, I don't say very.But it is an advanced tutorial on using Docker and going beyond that, also setting up continuous integration (CI) and using a bunch of tools. Bartos took on this massive task of looking at an older tutorial that was popular on the site but was kind of aging, partly because of all the different resources, tools, services, and things that it was using. It was from Michael Herman, before Dan got involved with Real Python, and the original article was \"Docker in Action: Fitter, Happier, More Productive.\"\n\nHe was looking at ways to update it and he added this note in the tutorial, which is saying, \"Hey, this is loosely based on that original. Unfortunately, many of the tools described in the original tutorial are no longer supported or available for free. In this updated tutorial, you get a chance to use the latest tools and technologies, such as things like GitHub Actions, which would be new comparatively to when the original was written.\n\nSo, I've thought about tackling these rather large tutorials in a different way. There isn't a great way to summarize them without kind of just listing everything that's in the table of contents. I might do a little bit of that later as we go because I want to give people an idea of, \"Hey, what's in this thing?\" I kind of almost want to do more of like, \"Hey, who is this for?\" It's really not geared for beginners or even kind of intermediate people that are looking to do pure Pythonic things. It's much more geared toward, \"Hey, you have this project and you've heard about using Docker. Potentially, you're thinking about other advanced things like continuous integration or even configuring properly something that you're going to put out there in the world and making sure that it has gone through all the steps of like, \"Hey, is this secure? What are the things I need to think about as far as preserving the integrity of this code and so forth as you do it?\"\n\nDocker is a really powerful tool and it's been around for a long time. So, one of the people I think of that this is maybe a good fit for as an advanced tutorial is someone who maybe used Docker three or four years ago and hasn't been keeping up with all the things that have changed about it. Maybe some of the services you used to use have changed and you'd like to really get a refresher on that and sink your teeth into something, really learn these tools in a very integrated way. I think this would be a great resource for you.\n\nIt uses a large number of different tools, a really disparate kind of things, and ties them all together. It does do Python, but it's mostly Flask, and you're setting up a basically a site counter kind of thing that can live online. And of course, you do the local development type of thing, which is a really common thing where you're setting it up on your own machine with Docker, and there's different versions of Docker, other ways that you can integrate it, but you do a lot of command line integration kind of stuff, the CLI tool from Docker.\n\nIf you haven't used Docker in a while, like I was saying, this intricate project is going to really help you sharpen up those skills and get more familiar with what's happening today with it. I personally found it very useful because of the ways that I use Docker very often are to simplify a Python tool, like we've talked about different ways that data science projects can be rather large and involve lots of different tools and sometimes they might be available for you to grab a Docker container for you to do the experimenting with.\n\nWe also at Real Python use a tool called Marpit, which is a slide-making tool, and the easiest way to do that project generally is to just grab a Docker container. I use that locally on my machine and then I just turn on Docker and run the commands for it. So again, I wasn't deploying lots of Docker containers of late. It was something I was doing more four or five years ago, so this was a good way to get back into it.\n\nThis is much more of that build, configure containers, get your hands dirty details of the ins and outs. You run a Reddit server and you're going to do that locally and kind of play around with it, setting it up and communicating with it, setting up ports and things like that. And then, like I mentioned, you create this dockerized Python web application using Flask. You work with Docker images, you play a little bit with pushing to the Docker Hub registry. It even gets into orchestrating with multiple containers and using something like Docker Compose. You learn again the sort of CI stuff, trying to figure out how do you create the workflow and then do all that with GitHub Actions. He has you really working with lots of configuration, you start initially setting up with TOML files and practicing some techniques with Pip, a couple things that I hadn't seen.\n\nAnd I actually have this question for you. I'm sure you've used requirements files, but have you used constraints files with Pip? No, I have not. Okay, so it's something that Pip does that is really interesting and it was kind of something that I was like.Oh, let me do a little more research and learn a bit more about it. I'll include some more links to it from the PIP documentation. The idea is to ensure that with this constraints text file, all your versions are using the same version number. You might think to yourself, what do requirements do that kind of does it in a different way? If there are multiple things that are looking to be installed, what I feel like it does is that it's saying if you're going to use, say, requests, then it should be this version. I've seen it in a few repos, and here you get to interact and play with it a little bit, so I thought that was kind of neat, new for me.\n\nYou configure YAML files, our favorite because Docker uses that. You work with Docker Hub, and I mentioned GitHub actions. There are lots of pitfalls shown, which I think is great. And then, of course, lots of tips and tricks for avoiding them. I know that Marta's invested a ton of time into this piece, and it really shows, so great work on it. I would read this mental section just real quick from the table of contents because it's just like so many details just under the subheading of \"dockerize your flask web application.\" You learn about understanding Docker terminology, the anatomy of a Docker file, choose the base Docker image, which involves how small can I get it with Linux distribution, what version of Python pre-installed, how to isolate the Docker image, caching your project dependencies, running tests, use Pytest, and this a lot specifies Docker commands to run in Docker containers.\n\nRecognize your Docker file for multi-stage builds, build and version your Docker image, push the image to a Docker registry, and then yay, run the Docker container. So that's just like in this one portion in the middle of this table of contents, so you can kind of see the amount of detail that you get into. It's definitely a DevOps kind of thing, but the intersection of Python and that is pretty common, especially if you're wanting to host or deploy things that are not using a pre-configured solution. This will help you with a lot of that stuff. Great job, I'm impressed with the amount of detail that went into this project.\n\nWhat's your first topic? So this is a course from a frequent Real Python contributor named Christopher Trudeau. I hope I'm saying that right. It's called metaclasses in Python. Metaclasses are one of those things most people never need to use, but learning about them teaches you more about how classes work in Python, so it can be fun. Let's start with the tricky stuff. Metaclasses are, well, meta. You've probably heard somebody, likely me, say everything in Python is an object, and even things like integers are objects, even though they're a fundamental data type, and in some other languages, they're not. In Python, they are. Now, when I say everything, I mean everything. Those classes that you write to define objects, yeah, those are also objects, and like the way a class is used to generate an object, a metaclass can be used to generate a class. So you can get a hint about how all this works by opening up a rebel and playing around with the type function.\n\nType returns information about the type of an object. For example, if I create a list called \"cats\" with some strings in it, when I run type parentheses cats, I get back class list because the type of a list is the class list. So makes sense so far, right? So then you move on and you're going to create a class called \"dog\" and an instance of that, say \"Fido.\" Like with the list case, if I do type Fido, I get back class dog. Makes sense. There's a little more information in there than that, but that's the essence, class dog. Now here's where it gets tricky. If I run type dog, that's asking the type of the class rather than the object instance. What you get back is a class type. The type of a class is type. In fact, the type type is as far up as you can go because the type of a type is also type. And this is where your brain melts, right? \n\nThe course starts out by running through you through all of this, along with a brief history lesson, as it hasn't always worked this way. This concept of the way types work here is based on inheritance, was added in Python 2.2, and both the old way and the new way, new meaning at least Python 2.2, were available at the same time. Python 3 killed the old way, so the not-so-new way, which is now the only way for backwards compatibility. The syntax of the so-called new way is also allowed in Python 3, so if you've ever seen a class inheriting from objects, that's the Python 2 style. It's allowed in Python 3, you can skip it in Python 3, but it all does the same thing. And that's the so-called new style, new as you know, 20 years ago, right? You should never name anything new because it dates very quickly. Anyway, so that's the background. Now to the actual metaclass stuff.\n\nThe first example in the course is a meta counter. This is a metaclass that counts how many classes have inherited from the metaclass, not particularly useful.It helps teach the concept with only a few lines of code to declare a counter meta inherited from a type, which causes it to be a meta class. A meta class can contain a Dunder new method just like classes can, and it's invoked when the meta class is created. Counter meta creates a counter and stores it inside of the meta class when Dunder new is invoked. To use a meta class, you use it as an argument as part of your inheritance.\n\nIf I were going to create a class called Pi and it uses counter meta, you would write class Pi parentheses meta class equals counter meta. Counter meta counts the class usage, not the instance usage. Creating the Pi class sets the counter meta's class counter to one, but you can create as many kinds of Pi as you like. Strawberry, apple, raspberry, even rhubarb. If you're evil, and counter meta's counter is still one because there's only one class using it, not the instances.\n\nSuperior to Pi is cake. I'll fight you. If you create a cake class that uses counter meta as a meta class, the world will be a better place. By creating the cake class, not instance objects, the counter meta count value gets incremented to two. So chocolate, vanilla, how many instances you want of cake, the class counter stays at two. That's the basic idea.\n\nThis is the class creation classes, the course runs you through some common uses of meta classes like Factory patterns, Singletons, and how magical Frameworks like Django and pedantic use them. It then does a rather deep dive into one of the standard libraries' meta classes, which is enum. There's an entire lesson devoted to walking you through how an enum is built, how it uses meta classes, and all the weird little edge cases involved.\n\nObviously, audio is the worst way of trying to describe code. So if all of that just sounded like yammering, maybe take a look at the course and see the visuals as you go along. Either way, I'll end off with a quote from Tim Peters that seems to show up anytime anyone mentions meta classes: \"If you wonder whether you need them, you don't. The people who actually need them know with certainty.\"\n\nSo, powerful little tool and interesting information about how the under bits of classes work in Python. Does it work with like an if you think you can't afford to do them, then I don't know, to a certain extent. Yes, if you have to ask how expensive, you probably can't afford it. It's a little bit that once you've learned them, there are problems where you go, \"Oh, that's how I do that.\" You're probably not going to drastically change your coding approach, but if you're doing some harder core stuff like writing out Frameworks, it can be a useful tool.\n\nWe had a deep conversation sort of discussion a few episodes back. I'll include a link for that too, where we kind of dove into some interesting stuff that's along these lines of talking about meta classes. The conversation before we were sort of talking about the idea that people complain about it being a dynamic language. Why are we spending the cost of that? Well, the ability to do this kind of stuff is why we're spending the cost of that. Things like Django, pedantic, and SQL Alchemy, and a lot of things like decorators are connected to these kinds of ideas, and the dynamicism gives you some power.\n\nAnd it comes at a cost. Depending on your work and what you're working on, that cost might be important or not. So I have a quick story. This was actually submitted as an email to me from Tom Bertucci, and he wrote, \"Hi Christopher, a long time listener, first time caller. I played every Real Python podcast episode at least once.\" So he had an idea for a short podcast segment that came to mind when his son texted him a question from college, \"Hey Dad, how do you pronounce SQL?\"\n\nSometimes I created videos to evangelize new technology, and I happened to be thinking about trying to get my employer's Mainframe programmers excited about Python by demonstrating how they could continue to think in SQL but write in an object-oriented manner by using SQL Alchemy. So I thought this would be a perfect time to start a video with the interesting story about how SQL got its name. In the first three minutes of his video, which I'll link, it's a YouTube video, he describes this history. I'll even summarize even more.\n\nTom takes you through the history of databases starting back in 1962. He's talking about the network model and it used this multiple cross-reference system which looked really convoluted as far as how data would be connected to each other. In 1970, Ted Codd created this thing called the relational model, which was a very early form of a query language.He was a mathematician, so the symbols and notation were cryptic for programmers to figure out how to write as programming. His colleagues were programmers and they got the gist of it and ran with the idea. A lot of this was happening inside IBM in 1973. The first attempt to create a query language was named Square. It was a weird acronym for specifying queries as relational expressions. It used subscripts to indicate tables and relations, which were hard to write in programming. The original needed to be better, so it was improved to SQL. SQL stood for Structured English Query Language, but it was pronounced as SQL. The controversy on how to pronounce SQL was hopefully resolved.\n\nI want to shine a spotlight on a Real Python video course about meta classes. Meta classes are a mysterious mechanism for instantiating classes in Python. You'll learn about how Python's metaclasses work within object-oriented programming. The course is titled \"Metaclasses in Python\" and presented by Christopher Trudeau. It shows how everything is an object in Python, including classes themselves. You'll work with special methods like Dunder call, Dunder new, and Dunder init. Meta classes allow you to do some magic and understand what happens behind the scenes when you instantiate a class.\n\nMy project this week is Pi scan, created by GitHub user as win. Pi scan reads a requirements.txt or a pyproject.toml file and looks up each item in the open source vulnerability database. The open source vulnerability database is a public database with vulnerabilities in packages. Pi scan uses the database's API to quickly scan your project's dependencies and print out the results. The project is written in Rust and is a neat little tool.\n\nAnother project is rsync time machine, which provides time machine style backups for rsync.And it's a Python Port of rsync Time Machine backup, which was much more like a script kind of tool written literally in Shell commands. So, it is translated into Python. It works on Linux, Mac OS, Windows via WSL, and it's very flexible. It can back up to and from any kind of file system, which I thought was pretty impressive. It states that it's fully tested, with no external dependencies; you just need to be greater than or equal to Python 3.7. It has a nice terminal output, explaining what it's doing, which I appreciated. I ran it and tried it out on some different directories, and it worked great. \n\nIt has a safety feature which I found pretty quickly; the backup will only happen to a destination that's been explicitly marked to be a backup destination. It very friendly says, \"hey, this isn't a designated place to back up to.\" It even gives you the script snippet to put back into the shell to run it again. It uses the latest symlink so that it will point to the latest successful backup. It has a couple of other nice advanced features, like exclusions, and you can use an exclusion .txt file that would basically say, \"hey, don't back up these folders.\" \n\nI just ran some basic tests on it. The project is by Baz Nicholod. I'll include links to it and then include links to the other former projects. It can do backups into and from SSH destinations. It has a resume feature which is really nice. As it does the backup, it will show a current date that would have the existence of everything you were backing up, and then it will have a managed version of those dates. \n\nIt's a neat project to kind of look at as far as the overall structure of it. Our sync time machine is cool. Every time Time Machine fails on me, I always go, \"I'm gonna have to find another way around this.\" It's something to check out. \n\nThanks again for coming on the show and bringing all these articles and projects, Christopher. Always fun talking to you. \n\nUp next, I'm going to talk to Bill Pollock from No Starch Press about Hacker Initiative and its 2023 Grant cycle. \n\nHey Bill, welcome to the show. Thank you for having me join your show. It was really fun meeting up with you at PyCon. I know Dan had met you last year, and I saw you come by the booth, but this year, we got to talk a little bit. You told me a bit about Hacker Initiative and how you were looking forward to getting the word out about getting people to apply for grants. \n\nI thought maybe we could start here. What would be your definition of a hacker or maybe the organization's definition of it? When I founded what was called the No Starch Press Foundation, but then we changed the name two years ago to Hacker Initiative, the idea was to support a broad range of hackers. The word hacker has come to mean all kinds of things, but we basically think about people who want to do something that a product wasn't originally designed for or they want to research a new idea or a new way to build hardware. \n\nSteve Jobs and Steve Wozniak are considered to be two of the earliest hackers. So, Hacker Initiative defines hackers very broadly as people with a hacker mindset, which is thinking about how to do something different and move the world forward in many different areas. \n\nYou said that you had started Hacker Initiative as a slightly different organization initially through No Starch Press, your existing company. It's the same organization, but I had never started it. Hacker Initiative is a public charity.Okay, never having been in the nonprofit world, I didn't actually understand what I was creating. I knew what I wanted to do, what I wanted to do was put a bunch of money aside. How much of that money came from early humble bundles, we mentioned that earlier. So, we've been humbled on those leading book publisher for years. I used to bundle close to a million dollars. I and the company made a lot of money from the bundles. I set a bunch of money aside and the idea was to have the Community Drive this. So, I tried to make it as open as possible. I'm a big open-source fan, but it turns out that public charities have tons and tons of rules. It's really hard to get the word out, to get people to give grants, and to fund and support it. But it's the same organization, it's just not in any way actually tied to No Starch Press, except that I created it, I funded it, and we used the logo initially. But it's a completely separate 501c3 public charity.\n\nSo, you started it in 2016. I officially created it. It sounds like that's been quite the journey of learning for yourself. Have there been lots of people helping you along the way? I'll address the first question first, which is yes, it's a constant journey learning and understanding how the nonprofit world works. It's not really my world. I've been very successful running a company for going on 30 years with no down years, which is pretty amazing in the book business. But the nonprofit world is very different. And yes, I have an attorney that works very closely with us to make sure that we stay on track. We basically, the public charity is, I guess if I were to, I think I'm correct in saying it's basically run by the IRS and the California Attorney General. But my role as chair is to follow the rules, which doesn't always sit well in the hacking community. But unfortunately, what we have to do, and if we don't do it, we can literally go to jail. Wow, that's a different experience for sure. It's different from saying, \"Okay, we're going in this direction,\" company. It's like, and that's where we're doing 10 minutes later. I can't change the way the mission statement is done. I don't want to. I mean, that's the intent, right? But there are a lot of rules that can make it difficult for us to fund certain projects. We have to really stay within the mission and there are numerous exclusions that we have to look out for to make sure that we don't violate those. And ultimately, we report to our donors, people give us money for a particular purpose.\n\nYour website, hackerinitiative.org, has examples of grants that you've given each year to recipients. That's correct. And I wanted to detail a little bit. You leave a very large umbrella of what a hacker can be, and I think that's fantastic. And there are lots of good examples that are inside that grant recipients. By your kind of menu, if you were going to shine the light on some of them just to give people an idea of the types of projects that have received grants in the past, what would be a couple that you might want to point out? The basic process is that we have a programming committee that's separate from the board, although we can have board members on the programming committee. I'm just a board member as the chair. The basic process is the programming committee reviews the grants, they make sure that they don't violate the exclusions, they make sure it's not a church or religious organization, and so on. People involved in hacking-type projects have often liked things that we can't fund as a public charity. But things that personally that I found interesting, like there's one kind of modern project. Well, one recent project was someone had the goal of creating basically a free 5G network. So say you have schools that are requiring remote learning, and maybe it's less of an issue today, but probably still an issue for schools, and you have a community that can't really afford the internet connection that's $70 a month, whatever. So, the idea was to build, and I know there are other projects doing this kind of thing, build the 5G stack that you could basically have people use to network machines without having to pay cable services. It's a great idea, but it's a lot harder to implement than it is to describe, right? We have another project in the works, which is one of many quantum computing research projects. Seems interesting. We like the idea, of course, as one board member said, like, \"What the hell is that?\" Or, you know, like, \"I mean, what is this a real thing?\" You know what I mean. But the reality is we don't need to, the project doesn't have to work for it to be successful. So the idea is because not everything that we try in life is going to work out well. Yeah, I think everybody has an example of that in your own life of trying out, and definitely programmers do so. Yeah.Right, we try it, we make an effort, we try to get it to work and sometimes we abandon the project if it doesn't work. But we tried. So, with Hacker Initiative, the project doesn't have to actually succeed as a project to be successful. This is true a lot in the FTC (First Tech Challenge) robotics. I just did a bunch of research on it based on learning a little bit about it. It sounds really cool and it sounds like your son was involved in that. Is that right?\n\nYeah, my son was actually one of the drivers, a primary driver for my creating this. This is a perfect example of the kinds of projects that we would love to fund. When he was in high school, he was programming, like many people, this thing called python at age 12. He actually did the tech review on python for kids when he was 15. He was in high school and they interviewed him for this robotics team. They used python and asked them some Edge case questions. He's like, \"I don't know, but I'll look it up,\" which is exactly the right answer.\n\nThe kid that was interviewing him was basically trying to show how smart he was. They didn't put him on the team, so this team, a bunch of friends through the friends, were frustrated with the management on the robotics team in this high school. So, they started their own team. This is exactly the hacker resource. It's like, \"Screw the adults, we're just gonna do it our way.\" So, they did it. The first year, they said, \"Yeah, we're gonna be first in the FTC championship World Championship.\" There are over 4,000 teams and all the parents were like, \"Yeah, yeah, yeah, you know, whatever.\" They used us as mentors only when they needed us, but we didn't tell them what to do. They would come to us when they needed something and basically end the call once they had literally one had what they needed. They learned everything on YouTube, used the tech shop at the time, and got some deal where they made beautiful parts and stuff.\n\nSo, the upset is these four high school students got together, brought on two or three other people as well. In their second year, they came in second in the world championships, second out of 4,100 teams. They were competing against teams that were like Google Engineers sponsoring them or Intel engineers and major money. I gave them, I think, five thousand dollars. But the point is, even though they should have come in first, they changed the robot in the finals which is also something that we learned. They did a fantastic job, they made an amazing robot, and the great thing was I had nothing to do with it and neither did the parents.\n\nWhat they all learned, and this is the kind of group that we want to support, they had the right motivation. They didn't have to come in second for this to be successful in their mind. If they didn't come in first, it wasn't successful, but that's not the point for us. We want to drive, we want to support that drive. When we build an application, I built an application using InstallShield years ago and people were like, \"If you could use InstallShield, you could write a program.\" I just did it because I had to and wanted to, right? But it took many hours and this is a classic thing in building any kind of application. But if it failed, it was still a learning experience. So, Hacker Initiative is not there to judge the merit of these projects, we're looking for impact and measurable results.\n\nIn the case of a robotics team, what's the impact? In that case, it would be like, are you working with the community, are you teaching kids in your community, maybe doing sessions at the library, having a YouTube channel where you show how you build stuff, and share how you learn how to build the Worm Drive. That has real impact, measurable results. That's a little more challenging, but we have one project we funded where they built the \"farm bot,\" it's basically a robotic arm out of a kit to maintain plants. The idea, the impact was they were growing food for an aging population in a community that didn't have a lot of money. The way they measured it, suggested by our attorney, was, \"Why don't you weigh the food?\" There you go, that's it. I never occurred to me, how would you measure impact? Well, weigh it. You're growing food, how much food did you grow, 10 pounds or a thousand pounds. That's impact and that is really the kind of thing that we're looking for, like take a step back and say, how can you do more with this information, what can you teach, just as you teach with real python.Right, like what do we give back to a community that has real impact too? There are lots of projects when you start thinking about it that could do this, but they're not commercial ventures. We're not funding startups, right? We're not looking for that. It's the kid or it's an adult who's like, \"Hey, I need 1200 bucks to get this thing,\" and here's my... In fact, I think you can do more sometimes with a thousand dollars than you can with a hundred thousand because the person who wants that thousand, they're so dedicated. For example, \"I want to take a Jura espresso machine, and they cost 2,000 bucks. I'm gonna hack them, and I want to make them into a blowtorch or something.\" I don't know, whatever. I mean, not... but yeah, like, okay, that sounds cool. And why would... what will the impact be? \"Oh well, basically, I'm trying to have people have home blowtorches so they can make creme brulee. You know, I'm making a random, nonsense right.\" But like, we would not approve that particular project. But like, someone wants to buy something, take it apart, and modify it, and basically destroy the equipment and appearance. Like, there's no way you're not going to buy, I don't know, a thousand dollar phone just to destroy it, right? But we'd say, \"Oh, that's cool. How much money do you need? What are you going to do with it?\" \"Well, I want to modify this so that I can make an open-source version of this, or have people modify it so that they can connect some nodes to some open network, or just add some explosive features on the board that they couldn't get to. And I want to teach them how to do it.\" Do you see what I mean? Yeah, yeah. So you're sharing kind of what you've created, and you're kind of able to either create a large impact through maybe the internet, but also maybe a local impact through having, you know, classes at a library or something like that, or some other kind of public thing. Okay, or YouTube. But, you know, here's what I did, and here's what you can do with it. Yeah. So, one part of hacking is like, here's what I did, do try it. Like, take a bunch of code, write this initial thing, and then you talk about ways that you can basically hack the code in it. I'm not talking about breaking things, I'm talking about making that into something that it wasn't before.\n\nYeah, and when we talked earlier, we kind of went down a little path where we were talking about that large non-profits typically are not interested in the small stuff to sponsor. Why was that? What were some of the reasons there? So, my understanding and from my conversations with other people in the non-profit world is that when you're giving out grants, and you can see this, let's say you're National Science Foundation, right? They don't want to talk to you if you want 500. They'll talk to you if you have, I think they have like a billion dollar funding, right? So they'll give you 10 million dollars, but if you say, \"I just need 1200,\" they're not going to pay attention to you because someone's going to have to put the time in to evaluate and they're looking for impact. So, if you go back to government oversight and say, \"Here's how we funded,\" you want to show impact and measurable results. This is what I learned about early on about grant writing. Like when you look at sites like Charity Navigator or similar that evaluate non-profits, there's a lot of nonsense that goes on in the non-profit world from what I've seen. And that's a lot of it is there are definitely large, very large non-profits where one gives to the other and they're showing... I don't know that there's a whole bunch of reporting that I let our attorney and accountant deal with. But there's a real lack of transparency when it comes to evaluating projects like we're designed to do. We want to do micro-granting. I firmly believe that that's a way to really make a difference because most people aren't writing requests for 10 million dollars. They're like, \"I just need a couple thousand bucks and I'll do this.\" Yeah, this is going to Kickstart our robot team, whatever. Yeah, yeah, right, exactly, sure. But like, with large non-profits, it's like they don't want to talk to you, not because they don't like your project, but they have to actually show to their donors and supporters, like, \"Here's how we used the 100 million dollars that we have. Here's where the money went.\" And they're not going to... If you think about the time investment in all these little projects, it's not worth it to them because they're not designed that way. Yeah. So, the idea here is to make it easy for people to reach out with projects where someone understands them and can say, \"Yeah, this is cool. You want to show how to convert a van to be totally solar-powered. You have a process for doing it. You're going to release the plans for free. You're going to show people the steps. And like, that's something we can support. And again, if it doesn't work, you know, then what we want to do is share... share what failed, teach us, right? What not to do.Yeah, totally. So part of why we wanted to get you on the show is because you were sort of almost like we talked to so many people doing conferences, this sort of call for proposals. You were saying, \"Hey, I'm looking for people to submit grants.\" Yes, absolutely. Our grant cycle is open. I think the closing date is in August. It's on the website. We need people to submit grants because we can't actually go and give money to an organization. People need to submit grants. It seems pretty straightforward. Some people might be nervous about it, but it's just like three steps, so not too bad.\n\nThere's a group on the other end tasked with looking at what comes in and mentoring the grant applicant. The programming committee's goal is to figure out which things meet the nonprofit's mission and mentor the grant applicant on how to use the money and document their project. There's a bunch of paperwork involved, but that's what the mentorship committee is meant to do.\n\nThe programming is more like programming a film festival and making sure everything works. The 2023 Grant cycle is currently open and closes on August 15th. I'll include links for all this stuff. The First Tech Challenge is an amazing initiative started by Dean Kamen, who created the Segway. It's a great way to teach people basic skills and how to run a project.\n\nGrowing up, I was the weirdo in high school who liked science. Many people around the world are misunderstood and don't have the resources they need to learn. It's not about money, but about connections and opportunities. I always think of the brain inside our head and how some people may not have the same support growing up.Oh, you don't want to do that. That's a waste of your time. Go ahead and play baseball. Right now, there's nothing wrong with baseball. I can't catch, I can't hit, but it's just not the way I was wired. So I'm gonna do something different. Maybe you want to redesign the baseball bat. And someone says to you, \"You can't do that, you're only 12.\" But maybe you have a great idea. Maybe you need 2500 bucks to get a machine so you can actually test your idea. \n\nWe have people in various situations where they don't have the support they could use. And part of what they need is money. We're not going to mentor you on how to do that with your baseball bat, right? But if someone's like, \"Here's this cool thing I want to do. Here's the impact it will have. Here's how I'm going to measure whether it works,\" that's a really cool project. We'll find it. I mean, well, it's not that simple, but the programming committee might then boost it to the board. And the board's like, \"Yeah, this is cool.\" \n\nIt can be people living in poorer communities, people without resources, but that's not the primary motivator. This is not how the nonprofit was formed. Yeah, but to reach out to people who don't have the support and give them some level of support that will allow them to fulfill a dream, to test something, to prove us all wrong about something, a quantum computer in their bathtub, you know?\n\nYeah, cool. That's awesome. I really appreciate you coming on the show to tell us about this. I'm looking forward to hearing about next year's grant proposals and I'm excited to see who comes out and wants to check it out. Thank you. You're a really good interviewer and I appreciate it. I appreciate the way you approach it.\n\nOh, thank you so much. I really appreciate the opportunity to share some of what we do. And I want to thank you for what you do for No Starch. I'm a huge fan. Thanks again. Yeah, thank you for allowing me to share this with you.\n\nI want to thank Bill Pollock and Christopher Trudeau for coming on the show this week. And I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. \n\nI've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "qmGpW1w3ENk": "Welcome to the Real Python Podcast. This is episode 159. Have you thought about getting more involved in the Python community? Are you interested in volunteering for an event or becoming an organizer? \n\nThis week on the show, we speak with organizers from this year's PyCascades conference about making connections, learning new skills, and managing your time. We have three guests to discuss working on PyCascades 2023 and how they got involved in volunteering. Conference chair Ben Berry, a site reliability engineer based in Seattle, is currently working on a private platform as a service. Diversity chair Madison Swain Bowden is a senior data engineer out of Seattle, currently working at Automatic on the OpenVerse team. Sponsorship chair Michael Vanderkamp is a back-end engineer at Coffee Meets Bagel. \n\nWe discuss finding other volunteers, maintaining motivation, and connecting with sponsors. Our guests also share their stories of overcoming challenges, finding their community, and what they found fulfilling about volunteering. \n\nThis episode is brought to you by Proxify. Proxify offers developers career growth opportunities with top companies in the US and Europe. Join Proxify, visit career.proxify.io. \n\nAlright, let's get started. \n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. \n\nI want to welcome everybody to the Real Python Podcast. It was really fun going to PyCascades this year. I was able to attend in person thanks to the generous support of my boss, Dan Vader. I'm excited to talk about going beyond not only what happened at the conference this year with all of you but also talk about organizing, volunteering, and being involved in a Python community in general. Maybe we'll go one by one and let you introduce yourselves a little bit. I'll start with Ben. Ben Berry, you're the conference chair this year for PyCascades. How did the conference go for you? \n\nThe conference looked great. I imagine being chair is a lot of work, so yeah, I think all the organizers were pretty tired by the end of it. But all the feedback we've heard made it sound super rewarding and a lot of fun seeing people in person again. \n\nYeah, a lot of fun. Was that your first conference in a while? \n\nYeah, this is my first in-person conference since PyCon Cleveland in 2019. \n\nHow did you get involved with PyCascades? \n\nI spoke at PyCascades in 2019. That year, I dragged Madison to come to PyCascades. She and I worked together at the time, and I wanted a friend there while I was speaking. \n\nThat sounds good. Not that I didn't already have friends in the Python community, but it's good to have a friendly face in the audience when you're speaking. \n\nExactly. And then last year for PyCascades 2022, Madison was actually chairing and asked me if I wanted to be a volunteer chair. So I did that, learned a lot, had a lot of fun with all the other organizers. Again, it was a lot of work, especially day of, but from there, you know, got into being the chair this year. \n\nAwesome. Since you've been mentioned, Madison, you were the diversity chair this year, which is probably a new role compared to what you were doing as an organizer the previous year. What were the types of things that you were involved with doing this year? \n\nI have been involved with PyCascades since 2021. I was the diversity chair in 2021 and then co-chair in 2022, and then back to diversity chair for this last year's conference. The role is centered on ensuring that the PyCascades conference was accessible and inclusive to all attendees. A lot of the work is making sure of accessibility, COVID policies, and ensuring a safe environment through the code of conduct committee. \n\nIt's great. I definitely want to talk more about the way PyCascades has been building the organization from within and the help from previous organizers. Michael, what's your role at PyCascades? \n\nI was the sponsorship chair this year. I got involved when a co-worker, Russell Duhon, reached out to me and connected me with Ben, asking if I would be interested in getting involved.And I said sure, and that's pretty much the whole story.\n\nIt sounds like a very interesting role. In kind of trying in the year that we're going into, I would imagine sponsorships have been a difficult area with the way technology and this sort of field has pulled back. Were those some of the challenges that you faced this year?\n\nOh, definitely, definitely. We've got a lot of cold shoulders, a lot of just no responses, a lot of sorry we can't this year. And to be fair, we also even got off to a slow start because I said yes I would join and pretty much immediately got COVID-19 and was out for three weeks. Oh no, that puts a kink into everything, yeah.\n\nSo that meant that we got some companies saying sorry, you know we just finished wrapping up our sponsorship plans for the next year and so that just added to the difficulties there.\n\nOkay, we might talk a little bit about that with other organizing. I can imagine that finding sponsors is kind of a very unique sort of skill set compared to maybe a lot of the other parts of organizing. But I definitely want to come back to it. I don't know if I'm necessarily the best at it either, this is my first time doing something like this. I certainly learned a lot I think, but yeah, it certainly requires a different skill set than being, let's say, a back-end engineer for instance.\n\nThat's very interesting that way. So I kind of thought about organizing our conversation into layers of volunteering and organizing. I thought maybe we could start small initially and then go back to the larger conference level type of thing that's much more public and is more regional or as large as something like PyCon US. Did anybody attend PyCon US this year also?\n\nYeah, I was there.\n\nOkay, Ben, you came, okay. Oh yeah, I was there, it was fun but it was a lot to do both back to back and I'm sure you experienced that on top of being an organizer and then going to. So yeah, I think it's kind of like conference seasons, sort of a spring conference season and then I think there's a fall conference season.\n\nYeah, we had PyCon, there was an open space of conference organizers. Okay, and it was my first time meeting a lot of the other organizers of other conferences and a lot of them refer to their timing as being based around PyCon, whether it was a little before or a little after or like six months shifted. But a lot of them kind of base it around the dates of PyCon for whatever strategy they're employing, whether they want to be as far away so they aren't trying to consume the same oxygen or whether they're trying to be really close to try and build some of the same momentum.\n\nSo, the factors could be just trying to coast a little bit with some of the momentum of another organization and looking at time off or people that are submitting talks potentially could be available at the same time. Were there other factors that they talked about during the open space? Those were the big ones that I heard, just I think one of the things, one of the reasons I don't know if this is originally one of the reasons we did this, but with one of the places we benefit with PyCon is a lot of people will try out their talks at PodcastAids before going to PyCon. I think that's both valuable to the speakers and the attendees, you get like the secret inside track, for instance, Brett Cannon's talk on syntactic sugar was previewed at PodcastAids and then ran again at PyCon, so that's one of the places we leverage it.\n\nI talked to him in between both of them and he's like, okay, I got a bunch of feedback and I'm changing the number of items and how to kind of organize this, that is kind of a neat way to develop a talk, I guess.\n\nSo, I thought again we could go small initially, how did you get involved in volunteering in the Python community generally? Maybe we could talk about individually different starting points, like if it was maybe a user group or some other kind of circumstances, and how did you find that community? Michael, would you want to start?\n\nSure, yeah, this was my introduction to the community.\n\nNice, I think I dove into the deep end.\n\nYeah, I explained to Ben right in the first meeting, you know, I haven't even been to one of these conferences before or really hardly any conferences at all, so I'm not really sure what to do. But you know, I have to say I didn't know that and I wouldn't have been able to tell either, you did a fantastic job.\n\nYeah, you did an amazing job, it sounds like from everybody here just kind of watching it. That's great, yeah, you held it well.\n\nThis was my introduction, I've been meaning to, I just moved to the West Coast last summer and I was meaning to get involved with the community out here and this just came up.My introduction was okay. Does it excite you about potentially joining other communities? Are you in Vancouver or Vancouver Island? I'm in Victoria. Are there any local communities that you could join there? I still have to find them. Maybe we'll get you some advice.\n\nHow did you get started in finding your python community? Wrangling me to come to that first PyCascades in 2018 was a pivotal and formative experience for me. I talked about it on the podcast stage last year because of how formative it was. It allowed me to build networking and connect with other people. Seeing the diversity in the PyCascades Community was important for my acceptance and seeing those talks in 2018 was pivotal for me. In 2019, I went and it was the first year after coming out as a trans woman. PyCascades was one of the biggest events I attended after coming out and it was a great experience.\n\nI was involved with Puget Sound Programmers of Python (PUPPY) in 2019-2020 but PyCascades has consumed more of my time. Through PyCascades, I got connected to PyLadies groups in Seattle and spoke for Women Who Code. There is overlap in the minority in Tech space with these groups, which is great for visibility.\n\nCross-pollination is happening between different organizations, which is interesting. How did you get started with PUPPY? I'm not officially a PUPPY volunteer, but I'm always at their events and help out when needed. I'm not officially in their organizing group, but I'm involved in their activities. I don't remember how I got involved with them.I think I heard about them at PyCon 2017 in Portland, which was the first Python event I attended. I think that's where I heard about them. But I also know a family member who is a software developer in the area, and it might have been him who referred me to Puppy. \n\nHow has your experience been with that organization, and what types of events have you attended? Puppy is still trying to come back from everything being closed down due to Covid. It's been hard on a lot of organizations. There's a lot of interest in people doing things in person again, but they're having a hard time finding spaces to do them.\n\nPrior to the pandemic, Puppy would have a long talk format meeting every month, usually with multiple speakers and sometimes lightning talks. They were usually hosted at a local office building. They also had special interest groups, but I don't remember the acronym they came up with. There were groups for preparing for interviews, Advanced Data Science topics, and programming nights.\n\nThey also had a public Slack that's really active. It's a good place to find me because I'm always checking it out. As a developer, how often do you feel the need to impact the world? Proxify offers opportunities with leading companies across various industries. They care about giving developers a supportive environment and opportunities for a successful career and a fulfilling personal life.\n\nIn Colorado, I joined a local Meetup called Pie Springs where we would meet in a co-working space. We would help beginners set up Python on their machines, do lightning talks, and share projects. When everything shut down, we tried Zoom meetings, which were interesting. They now do in-person events once a month and Zoom meetings once a month. It's hard to find time to get involved outside of work.\n\nHave you had experiences with internal groups or teams at your workplace like a Python group? At my previous employer, Technology Transformation Services, they had guilds for different areas like DevOps and security. They were very casual and run like coffee chats for talking about various topics.Yeah, I lied. It's not coffee Ops, coffee Ops is the Meetup that uses lean coffee, which is the term I was looking for. Lean coffee style is what the coffee Ops Meetup Group uses, a way of self-organizing around topics to talk about.\n\nIn person, you usually do it with sticky notes at the start of the meeting. There are piles of sticky notes and Sharpies around, and everyone writes down what they want to talk about on a sticky note. Then, you put all the sticky notes on a wall and group them if there are similar topics together. Everyone votes by putting a dot on the sticky note they like, and the topic with the most votes is discussed.\n\nYou usually set a timer for three to five minutes and talk about the topic for that duration. People are considerate enough to let whoever takes the floor have the floor. At the end of the three to five minutes, you vote on whether you want to keep talking with a thumbs up or thumbs down, like speed dating for topics.\n\nIf the majority still wants to talk about it, you add another minute or two on the timer. If not, you move on to the next highest voted topic and continue this through your time.\n\nWe also have experiences with guilds or other things in organizations, not guilds, but more like presentations at engineering meetings or lunch and learn sessions where someone presents something they've been working on.\n\nReal Python doesn't have something like this internally, and it would be interesting to have a learning platform for internal sharing. We do have organizational activities but not specifically for sharing knowledge.\n\nI've never worked at an organization where it made sense to have groups like this, or they just didn't exist. It could be due to the history of the organization or the size and team isolation factors.\n\nAt the first place where Ben and I worked together, I was one of the only data engineers at the research institute. I organized a mini airflow Meetup at pie Cascades to connect with others using the tool, which ultimately led to recommendations for my current job as a full-time data engineer with a team.\n\nI didn't have that kind of community at work, which is why other external communities were crucial for my growth and exposure. It provided me with opportunities that I wasn't getting at work.That makes sense to me. That's one of the reasons I've tried to talk about this topic a handful of times on the show. I come from a completely different world, as you can tell by my background. For those of you who are watching the video, I do a lot of music stuff, so almost every single job I've ever had was through referrals and connections. That's how many industries operate. However, I think sometimes in programming environments, people don't try to break the walls and meet other people to get involved in the community. But very often, that's how you make connections and build relationships that expand your horizons.\n\nI've always been kind of in between introvert and extrovert. I have those times. I met another organizer for PyCascades, Nina Zakaranako, and I think her term was \"Expovert,\" where she would be involved in conferences and could be an extrovert when needed. It's important to think about where you're going and how to make connections in different industries.\n\nMadison, it definitely sounds true. There's this lie that I was told in college that the world is a meritocracy and all you have to do is be good at something for all opportunities to be open to you. It's frustrating to realize that's not the case. Networking opportunities are crucial for career advancement, especially for minority individuals in tech.\n\nNetworking is not easy, but having different events and ways to participate can make a difference. For example, I met someone at a conference who pitched the idea of a conference at a roller rink where everyone roller skates around and listens to talks. It's about mixing up the space and building crucial connections.\n\nI find events like that interesting because I have a hard time sitting for a long time. Being an organizer at a conference is great because you have an excuse to be running around the whole time. Changing it up and moving around can be refreshing. Lightning talks in different spaces sound fun.\n\nWhen I got deeper into organizing for the next PyCascades, I was going to be a conference chair. The big challenge was defining the vision for PyCascades and finding volunteers. It's about maintaining the momentum of the event.That's thanks to a lot of great organizers in the past, like what it should look like. Knowing the next thing that needs to be worked on in the next thing to do is really hard. Remembering that you need to have policies in place or remembering that you need to do coffee service, or things like that. Guido's example from his retrospective of knowing not to order just the same sandwiches for every day of a conference because people don't like eating the same sandwich. Just the sort of self-direction of figuring out the next thing to do and doing it, especially on a long horizon, is I think the hardest part.\n\nFinding people is also difficult. I was thinking about the volunteering part, and it's gotta be difficult to find willing individuals that you can entrust this vision to. So far, I have had a very high level of trust in all of our volunteers and organizers, and that has never bitten me. I intend to keep being very trusting of all of our organizers and volunteers, but even with that high level of trust, just knowing who to reach out to to find more people I think is being especially hard post-COVID.\n\nPuppy hasn't really started spinning up lately, and that was one of our big sources of volunteers for PyCascades in the past. People have changed jobs, which was also a challenge when we were looking for sponsors. A lot of our contacts during COVID changed jobs, so now we had to find new contacts.\n\nWe have a bunch of information and a big spreadsheet and Notion that Kurt tries to keep track of all the companies we've reached out to and who we've spoken to. It sounds like it's very tricky. One of the things you mentioned is that you were able to have this pool of people that you could reach out to. Were there other communities that you shifted to to try to find your pool of volunteers if you weren't able to find them through something like Puppy?\n\nFor our day of volunteers, we got a lot of folks who signed up in response to our emails. We had a Google form for intake and posted on various platforms. Finding our core organizers is the harder part because it's asking for a recurring commitment. This year, we largely leveraged Alyssa's contacts as she seems to know everyone in Vancouver.\n\nWe still didn't fill all of the roles that we've had in previous years. We filled about half of the roles we've had in previous years. This year, we didn't have a single organizer who had ever organized an in-person conference before. Some of our organizers were here in previous years for our online iterations but nobody had done an in-person conference before.\n\nThere are unique challenges for both online and in-person events. Shifting back to in-person while keeping the virtual going means running two platforms at the same time. It seems challenging. What would be your pitch to a volunteer to say, \"Hey, this is what you would get out of doing this\"? This is like some of the neat things that you would get out of volunteering for an event like that.I volunteered for PyCon this year doing registration, and there was this wonderful way that my brain was broken afterwards. Every single person at the conference looked familiar, and I couldn't remember if it was because I had met them in a previous year or because I had met them 10 minutes ago going through registration. It's a great way to meet people. It's also one of the great things about PyCascades - it's small enough that it feels like you know every single person there by the end of the conference. By volunteering, you get to kickstart that and make a personal connection with just about everyone.\n\nInstant Icebreaker, yeah! I'm here to help you get checked in or whatever. If you work registration, you're almost guaranteed to make a connection. So if that's something you want to make sure you check off your bucket list at PyCascades next year, work the registration desk. Consistently, what I've found is being a volunteer at events has been a ticket to meeting some of the coolest people in the different spaces that I've been in. It is a fantastic way to meet people right out of a shared necessity of bringing about this event.\n\nThis touches on a point that I had mentioned earlier, but particularly for folks who are in minority groups within the tech space, there's also a sense of being able to help build welcoming and inclusive spaces. For me, seeing a trans woman on stage at a tech event was life-changing, and being able to perpetuate that and foster inclusivity was a powerful experience. Volunteering allows for connecting with minority groups, building spaces, and finding familiar faces in different spaces.\n\nWhat was your experience with volunteering, Michael? Maybe it's just me, but when attending a conference like this, I have a sense of what to do if I'm new to the community. I need to look like I have an important text coming through just to look busy. Meeting everyone and feeling like I'm contributing something useful to the community is important.\n\nIf you were going to sell volunteering to someone else, what would you say they would get out of it? For me, it's about meeting the community, getting involved, and contributing to something good. It's a wholesome feeling of contributing and learning new skills that you wouldn't in your day-to-day job. Crafting marketing emails, social media tweets, budgeting, and designing swag are all valuable skills gained through volunteering.\n\nI learned a ton about editing SVGs this time, editing logos for events, and updating designs for future conferences. It's an opportunity to engage in event planning activities that are different from your daily job. It's a chance to learn and grow while contributing to the community. Nice.I definitely would not have been able to figure that out in 10 minutes over dinner this time last year. Michael, what were you gonna say? I definitely agree with this about having things that are not normally done in your day-to-day job. This experience for me was like what I was doing, the skill set involved almost completely disjointed from my job and involved learning a lot of stuff and getting familiar even with just emails.\n\nIt sounds like something so simple, but then when you start having to write a lot of emails to a lot of different people outside of your organization, people that you haven't met before, it's a whole new world, it's a whole new skill set. And I think I learned a lot, figuring out what's effective definitely fast. I would imagine, or even just like how to use email tools effectively and how to add a signature.\n\nThis is so much more advanced than Slack requires other things. This week, I want to shine a spotlight on another Real Python video course. It uses a real-world project to help you hone your skills with wrangling data using Python. It's titled \"Using Pandas to Make a Grade Book in Python.\" The course is based on a step-by-step Real Python tutorial by Brian Weber, and in the course, instructor Caesar Aguilar takes you through how to load and merge data from multiple sources with Pandas, how to filter and group data in Pandas data frames, and then how to calculate and plot the grades. Along the way, you'll practice many of the skills you need to work effectively within Pandas, like working with CSV files, aggregating values, and how to assemble it all into a real-world project. Like all the video courses on Real Python, the course is broken into easily consumable sections, plus you get additional resources and code examples for the techniques shown. All our course lessons have a transcript, including closed captions. Check out the video course; you can find a link in the show notes or you can find it using the enhanced search tool on realpython.com.\n\nI kind of want to talk about the flip side of all of this and discuss how to avoid overdoing it and burning yourself out in the process of doing this and potentially burning bridges in that process. I don't know if you had that experience or how you avoided getting to that point. Anyone want to take that? I came really close to burning out on this one. I think there was a period where I was just like, I don't know if I'm the right person for this. I don't think I can be doing this. I don't think I'm contributing enough. I think we need somebody else, is what I felt like. Ben and Madison and the other organizers kind of pulled together and said, \"No, you're here, you're doing okay, it's fine, we're gonna be okay, you're doing a good job,\" and that kept me in it.\n\nIt sounds like you reached out then, that was part of your help with that was like, yeah, I'm struggling. Definitely, and then the thing that kind of at that point where I was like, okay, it's not just me, I'm not just in isolation, there's a team here. When I need help, I can just reach out, and I can also cut myself a bit of slack. I don't have to be burning. I think Michael got thrown into the very hardest job because we were behind schedule on sourcing sponsors even before we asked Michael to be our sponsorship chair.\n\nI think most of the reaching out was happening right as all of the terrifying recession news was starting and companies were doing layoffs. So Michael was emailing a sponsor, actually went through a contact who was doing our sponsorship, actually got laid off during this whole process. We had to start talking to a different company about giving us money as they're trying to cut headcount and be more in the black. Michael really got thrown to the wolves, and I hope our goal, Michael back, was more reassurance than strong-arming. It was reassurance.\n\nI remember seeing the message that Michael sent, thinking, \"No, wait, Michael, you're doing such a great job.\" I remember seeing that thinking, \"No, wait, Michael, you're doing such a great job.\" I need you to know that this is like everything else, it's not you, it's the world, it's the people.\n\nWe were knee-deep in an existing contract negotiation when Michael came back as well, and that was a whole thing. Definitely knowing that there's folks to share the load with and that you are capable. Do you have any other advice, Ben, to avoid burning out on it? I'll let you know when I figure it out. If you find the secret, please tell me.Because what I worry about is that you get to a point where you've done too much. I have this personality where I'm obliged to help people and do all sorts of things. Very often, that turns around and people start to load additional stuff on top of you. You're like, okay, I can only take so much more before I want to explode. That's never the great solution, but that's often what happens to people with that personality. They're just like, I've taken on too much.\n\nSo, I kind of think about ways that you can recharge after these events. It sounds like you took some time off, yeah. I took it kind of unofficially, deliberately doing less for a couple of weeks following PyCon US to try and breathe and have some time. Starting to spin things back up in the last week or so to get ready again for next year. Cool. Madison, were there other techniques that you used?\n\nThe pandemic hit interestingly right after I was coming out of a phase of burnout. It was a necessary space for me to sit and relax and not be doing things. That gave me space to recover and start getting into Pine Cascades and other organizing opportunities. Learning to say no is something that I continue to battle with. Having the conference as a priority in my mind helped me prioritize other things.\n\nAfter last year's podcastades, I wrote everything I had accomplished on note cards and stuck them on my fridge to remind myself of my achievements. It's hard for me to take time to relax because I'm always engaged in things, but recognizing my accomplishments helps me justify taking a break.\n\nIt's like a large-scale life Pomodoro Timer. I did this for this amount of time, now I'm going to take a break. What's something you're excited about in the world of Python right now?\n\nI'm still catching up on Python and excited about features like async IO and type hinting. I recently tried structural pattern matching for the first time, and it was really exciting. What's something you're excited about in the world of Python?\n\nI keep hearing about how great pedantic, fast API, SQL model are. I'm excited to convert a project from Go to fast API and see what all the hullabaloo is about. Ben, what's something you're excited about?\n\nLike Michael, I'm not on the bleeding edge of Python. The thing I'm working on at work right now had to be downgraded to Python 3.8.So I'm definitely not on the depleting edge of the language features. What's most exciting for me right now is all these events happening in person again. I'm excited to see them again and because of this long break, I think there's a lot of Changing of the Guard kind of stuff going on. It's really exciting to see new people running the same events again to bring new ideas, new faces, and new friends.\n\nMichael, what's something you want to learn next? This doesn't have to be about programming specifically. I am trying to learn plenty in the world of programming, not just in Python. I want to learn more about cloud computing, Kubernetes, containers, and get more comfortable with that whole ecosystem.\n\nMadison, what do you want to learn next? I want to learn Rust. Some folks gave talks about interactions with Rust at PyData that I was at a couple of weeks ago, and I keep hearing such good things about it and how exciting it is, especially the interoperability with Python.\n\nBen, I can relate to that. At PyCon US, multiple times throughout the conference, I was in the sponsor showcase and had the Rust book from No Starch Press in my hand, ready to buy it. I've been interested in starting to dabble in it. But my next thing that I want to learn is getting into film photography. I've been doing digital photography for a while and now getting into film. I've been using CircuitPython to do some stuff around that, like making a shutter timer with my CircuitPython Express.\n\nIf someone wanted to follow what you do online, what's a good way to do that, Michael? I'm a bit of a ghost online, to be honest. I'm on LinkedIn and have a GitHub account, but I mostly avoid social media.\n\nMadison, as an employee of Automatic, I'm contractually obligated to say you should follow me on Tumblr.com. My username in most places is AetherUnbound, and you can find me on GitHub and Mastodon as well.\n\nIf you're interested in Pi Cascades and following what Pi Cascades is doing, we have a newsletter you can subscribe to on our homepage, podcastcascades.com. You can also follow us on Mastodon, Twitter, and Instagram.\n\nI want to thank you all for coming on the show and talking to me about organizing and volunteering. It's been a fantastic talk. Thank you for having us.Thanks for having us.\nThanks.\nAnd don't forget to be more than just a developer. Enjoy The Best of Both Worlds: a successful career and the ultimate work-life balance. Join Proxify, visit career.proxify.io.\n\nI want to thank Ben Berry, Madison Swain Bowden, and Michael Vanderkamp for coming on the show this week.\n\nAnd I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review.\n\nYou can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "YjDlJhl3WDY": "Welcome to the Real Python Podcast. This is episode 160. What are the unique challenges of a large Python code base? What techniques can you implement to simplify the management of a big project? This week on the show, Christopher Trudeau is here bringing another batch of Pi Coders Weekly articles and projects. We discussed a recent thread on Hacker News about working with a large Python code base. Christopher advises configuring tests and using tools to keep your code consistent across an organization. He also answers several questions about code complexity, typing, and leveraging third-party libraries. \n\nWe cover several other articles and projects from the Python Community, including news from the Python Language Summit, using KIVI for GUI development, understanding the power of bit manipulation, removing unused import statements in your code, and adding reminders about links from a podcast using a Python-based iOS project. Alright, let's get started. \n\n[Music] \n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. \n\nHey, Christopher, welcome back to the show. \n\nHey there. So we were going to bypass the news segment, but it seems like some of the topics that you're putting together for this first grouping are kind of newsworthy. \n\nYeah, sure, why not? \n\nOkay, not news. However you want to do it. So right, end of the PyCon conference that just closed up a few weeks back, they had the Python Language Summit. This is an event for developers who are involved in writing Python implementations like CPython, PyPy, all that kind of good stuff. It's a full-day event with multiple conversations about the future of the language and sometimes they talk about upcoming PEPs and that kind of good thing. A bunch of blog posts and articles have been popping up that are kind of little snippets of things they talked about. \n\nWe've talked on some of these topics before, so I'm just going to summarize quickly, and if you want, you can dig more deeply into other things. Okay, the first one was a progress report on PEP 594. For those of you who don't have the PEP numbers memorized, PEP 594 is the dead batteries PEP. They marked a bunch of standard libraries for removal in 3.12 and 3.13. Nineteen modules were deprecated in 3.11, and now they've got inside the 3.13 branch that the removal has happened. Of course, 3.13 is still a ways off. \n\nWe don't even have 3.12 yet, but this is a work in progress. There's a good summary post on the Python discussion board from Victor Steiner, who's the coder who's actually doing the work. He talks about what got removed and what your choices are if you're using one of those things and you still need it. The next two bits are blog posts by Alex Weigood, who writes on the Python Software Foundation Blog. The first blog entry is around the continuing conversations about the GIL. \n\nThere's a lot of ongoing work connected to the Global Interpreter Lock, much of which we've talked about before. One project is PEP 703, which proposes to make the GIL optional in CPython. This is also slotted for Python 3.13. At the summit, Sam Gross, the author of the PEP, gave an update on the progress and the impact of the change. At the moment, the no-GIL implementation, which is the branch he's working on, is about six percent slower on a single-threaded core, which isn't too bad a hit considering the speed up that you'd get for multi-threaded code. \n\nSam thinks they may even be able to get lower than that. There were some conversations around the implementation, its impact, questions, that kind of stuff, and evidently, this makes debugging a little more complicated somehow. I wasn't clear how to me, but I'm sure you can dig into stuff in the PEPs to find that out a little more if you're curious. We'll link to the blog post and the PEP. \n\nI also came across today the discussion on the PEP inside of the Python discussion thread has resurfaced. There seems to be some bit of tense conversation going on, so it'll be interesting to see what comes out of all this. We'll link to that as well and see what gets settled out of that. The other blog post from the summit that I want to talk about is titled \"What is the Standard Library for?\" This kind of loops back to where I started here with PEP 594. \n\nThere's been a bunch of conversations in the last few years about what should be removed from the standard library, and at the summit, they talked about creating some guidelines for when to add something and when to remove something from the Standard Library. It's kind of a meta-conversation about having some rules about how to have future conversations, but that could actually make it simpler to make these kinds of decisions in the future. \n\nThere's lots going on at the language level, and I love that our community is so open about this. It's getting talked about, and sometimes you don't always want to know how the sausage gets made, but it's definitely interesting.We've talked about different parts of the overarching Python organization recently, especially before PyCon. There have been blogs posting about what's going on, including updates on Pi Pi a couple of weeks ago. Transparency is good, but sometimes interesting things come to light. It will be interesting to keep following and see that everything isn't happening behind closed doors. They are sharing after their Summit, which is good.\n\nFirst, there is a real Python tutorial by our friend Leodanas Pozo Ramos. It covers concepts like object-oriented programming, meta-programming, and creating callable instances using Python's Dunder call method. Functions, classes, and methods are examples of callable objects in Python. Custom classes can also produce callable instances, allowing you to call the object itself with parentheses.\n\nThe tutorial explains the different types of callable objects, including built-in functions, user-defined functions, constructors of custom classes, generators, closures, and more. It also delves into the differences between Dunder init and Dunder call, providing code examples to solve real-world problems using callable instances. \n\nYou can explore by using the `dir` command to list valid attributes for an object. The tutorial includes examples of creating callable instances, like building a power Factory class. It also demonstrates how instances of classes can retain state between calls and cache values from previous computations.\n\nAdditionally, the article covers writing class decorators and implementing the strategy design pattern. It clarifies the concept of how an instance can be called by itself and the benefits of simplifying method calls by using Dunder call. Overall, it provides useful insights for those looking to deepen their understanding of Python's capabilities.A class that's implemented the callable is an interesting feature of the language. As the user, you just call it without caring. This also ties back to some of the meta-class stuff discussed a couple of weeks ago, as it uses the same mechanism. \n\nAn article by Anurag Verma titled \"The Power of Bit Manipulation\" feels old school. Back in the old days, we carved bits directly into the hard drive with a chisel. Though I'm not that old, I had a boss who told a story about fixing a magnetic drum with a screwdriver. This story, whether hyperbole or not, is enjoyable as it feels just true enough to be interesting.\n\nIn languages like C, which are closer to hardware, you often need to be concerned about the bits that make up a byte. Bit manipulation is still useful in some situations, even in Python. Anurag's article covers the details well, starting with fundamental bit operators like AND, OR, XOR, NOT, and shifting. XOR is exclusive OR, and shifting involves moving bits left or right within the byte, equivalent to multiplying or dividing by two.\n\nThe article also discusses bit masking, which uses bits inside a byte to perform operations. By combining a byte with a bit mask, you can determine if a specific bit is on or off. Bit manipulation can be useful for graphics or working directly with hardware. The article covers counting, rotating, reversing, and swapping bits, as well as algorithms commonly used at the bit level, like bitmapping.\n\nIf you're heading into the graphics or gaming space, where these tools are common, or if you're interested in deeper networking stuff, bit manipulation is a useful skill to have. Overall, it's a good article with a nice introduction to the topic.\n\nI remember you did a course on binary, bytes, and bitwise operators, which covers similar topics. There's a video course available if you prefer that format. The next article I have is about KIVI by Francis Ali on the website pythongguys.com. It provides an overview of different GUI frameworks, including KIVI, which we might have discussed before.But I'll mention that what's nice about this tutorial is it's really an overview. Hey, get started kind of play with it. I mean, that's literally this title, \"Getting Started with KIVI for GUI Development.\" It has lots of little first steps to get you going. It takes you through writing a hello world and then lets you play and explore with some of the widgets and layout tools in KIVI. I didn't mention it yet, but KIVI is an open-source library designed in a slightly different way from other graphical user interface libraries. It's designed to be very cross-platform all the way to mobile devices. So, you can create not only for Windows, Mac, Linux, but also for iOS and Android. It even supports things like multi-touch and more.\n\nAfter the hello world and exploring some widgets and layout tools, they give you a listing of some typical GUI stuff. You have text inputs, labels, buttons, checkboxes, and unique things like progress bars, drop-down menus, and images. It has different layouts, including grids, page layouts, scatter layout, and stack layout. There are examples to practice with, like trying out button layouts and playing inside their canvas property, where you can draw lines, rectangles, ellipses, and more.\n\nThe library has its own styling language where you can set up prototypes for reuse. It uses its own KV Lang language, where you create a file using angle brackets and a dictionary style to name things. The file makes things reusable across multiple projects.\n\nThere are a few other features mentioned near the end, like a builder class and automatic widget loading. If you're looking for another tutorial, Real Python has one geared towards building a mobile application with the KIVI Python framework. It guides you through creating a calculator app, from basic logic to distribution on different platforms.\n\nKIVI is a powerful tool in the GUI world, and this tutorial is a good starting point. Have you written much with it? I've done technical reviews of the KIVI video course, which was Darren's. I liked working with it, especially the reusability part. The challenge is making it look native on each platform. I did some prototyping for mobile work years ago, and it worked well for quick and dirty prototyping, but didn't look like Android.\n\nA lot of these frameworks have a similar issue. B is trying to use native elements, so I'm intrigued to see developments, especially now that there's more funding for it. The project is moving faster and aims to be distributed everywhere.[Music]\n\nThis week, I want to shine a spotlight on another Real Python video course. It's about a topic we covered this week and is another resource for getting you up to speed building GUI interfaces for your Python applications. The course is titled \"Build Cross-Platform GUI Apps with KIVI.\" It's based on a Real Python tutorial by previous guest Mike Driscoll. The video course is presented by instructor Darren Jones. He shows you how to work with KIVI widgets, lay out the user interface, add events, use the KV language, and also how to create a calculator application. Then package your application for Windows, Linux, and Mac OS, and how to research the tools to package for iOS and Android.\n\nThis is an intermediate video course. You'll need to be familiar with object-oriented programming, but we've got you covered here at Real Python with multiple courses to get you up to speed. If you're interested in building cross-platform GUI interfaces, this is a worthy investment of your time. Like all the video courses on Real Python, the course is broken into easily consumable sections. Plus, you get additional resources and code examples for the techniques shown. All of our course lessons have a transcript, including closed captions. Check out the video course. You can find a link in the show notes or you can find it using the enhanced search tool on realpython.com.\n\nSo, we have a discussion this week. You found a topic that we were going to dig into. It's a Pecker News thread, right?\n\nYes, it's called \"How Do You Deal with a Large Python Code Base?\" The gentleman asking the question is working on a code base with, he says, somewhere between 10 and 100,000 lines of code. That's a big range.\n\nYeah, it's like 90,000 in that range, yes. Sort of just looking for tips and hints as to how to deal with that and what it looks like. It's interesting. I find to me with this kind of thing that most of the advice is almost language-independent. And one of the things I like to try and distinguish between is, you know, the larger the code base, the two things you need to start thinking about is how do I maintain the quality, and something that's kind of connected to that is a psychology thing.\n\nAt my peak when I was a very junior developer and I didn't have to attend any meetings and I was heads down and whatever, I was producing about 10,000 lines of code a month. So, what that means is when you start getting into large, depending on your definition of large, that's five or six months' worth of work or a year's worth of work, and you start forgetting what the pieces are. In all likelihood, in the industry, that's not how 100,000 lines get produced. How 100,000 lines get produced is you've got nine or ten or whatever people touching it, and the people who are touching it over time aren't necessarily the same people because people come and go, right?\n\nThe psychology of it starts to become not just what is the current quality, but how do we ensure that the future quality is up to snuff. One of those things that most developers find a very difficult concept to deal with is, on average, you're the average programmer, which means on average, half the team's going to be better than you and half the team's going to be worse than you. So, we start talking about a lot of things.\n\nSo, when people in Python start talking all about typing and all the rest of it, usually what they're really talking about is, \"I don't trust the other people on the team to write good code unless we enforce certain rules.\" Larger code bases start to become about what rules are we going to have and how do we make sure, preferably and as automated a fashion as possible, do we stay with those rules in order to maintain the code quality. That makes sense to me. And there's other aspects of it, which unfortunately are very hard to enforce at that level, which is things like architectural rules. Like, we're going to stay within our box, and this thing is not going to call that thing. That kind of code understanding knowledge tends to be a little harder.\n\nOne of the things I like to deal with when I'm working with teams around these topics is I want to try and get code knowledge, linting, Black, whatever those kinds of things are regimented on the teams. We're not going to argue about whether it's a single quote or a double quote. I hate the fact that it's a double quote in Black. I don't know why it bothers me, but it's easier to just say, \"Okay, we'll use Black, and we're not going to argue about it.\"Right, what kind of percentage of the arguments does that get off the table? A lot of them, like jokes about tabs versus spaces and things like that in other programming languages. Not only do you get the philosophical argument about it, one of the challenges with that is if it doesn't happen as often in Python because the spaces are important, so we've all become very attentive about how it works. But in a language like Java where it isn't, I can set my editor up so that it uses tabs, you set yours up for spaces, I read your file in, it converts it automatically, which means when I stick it in the repo, the repo sees that every single line in the file has changed, which is bad, right? Because now I can't tell what I touched and what I didn't touch because the editors touched everything. So it's all red lines, yeah, yeah. So there's a consistency thing there that can be really helpful. Having these tools in place means you're not having those fights, and you can start having the conversation about is this the right architecture? Should we concentrate on speeding this chunk up? And oftentimes, by standardizing something, you make the joke about black, I think it's like all good compromises, I don't think anyone's happy with it, right. But by standardizing on something like that, we don't have to have the argument about it, right? So it just alleviates it, and you set what those rules are.\n\nAnd then the other aspect of it, I think, is the whole real estate adage of \"location, location, location.\" Well, the programming equivalent is testing, testing, testing, and the larger the code base, if you're learning a large code base, having automated tests helps you learn it. If you don't have a lot of tests, then you have to figure out how to start putting them in. And one of the things that I find is kind of subtle is having a good set of tests that gives you good coverage across the board reduces the risk of refactoring. This means when you're dealing with things like technical debt or you want to try to put in a performance improvement, the long-term productivity of the team goes up if you've got these tests in place because they've got a safety net. You're not always doing the high wire act of can I touch this, should I touch this because you can touch it and then run the test and go, did I break it? Yeah. So testing is important no matter how big the code is, but the larger the system, the harder it is for you to keep all of it in your head at any given time, which means you might not understand the consequences of the thing you're changing. This is a tiny little thing, it'll do nothing and off it goes. I ran into this with some code I wrote the other day. I touched something and I'm like, oh, that'll make it easier and it'll make it faster, and I had the tests that were around it and they passed, and that's fantastic. And then the other tests started failing. I'm like, oh, there was an assumption there, there was a dependency there. Oh, crap. So you have to go in and touch the other code. This is the kind of stuff that the testing catches, and particularly because Python is dynamically typed, this becomes that much more important because if you're not using typing to its full extent, then you need the testing to help catch this stuff.\n\nThat makes me think about a couple quick things, like one is we've talked before, at least I've had a couple people on shows talking about this idea of really large functions and the idea of refactoring the code and so forth. Does adding the tests as you go or even after the fact tend to keep those sections organized under a specific thing that you can then test for? Like does that help avoid this? Anything that should be a single function doing a single function? In theory, test-driven development is supposed to address that, and that's the idea of writing the test first. The reason is because the longer the function, the more likely the more things it does. And if you have to write the tests first, that means you're going to have to write a lot of tests for it. So having to think, okay, I need to do these three things, that means I'm going to have to write these three tests. It does seem to make it, I think there's a psychological aspect of, I will keep it smaller so that the test that goes with it is smaller. So it can be helpful, and I would flip that on its head as well.If you're inheriting a large code base that has a lot of content, the first thing you do is write tests for it. You write automated tests for that function and get it working. Once you've got that, you can refactor it without introducing a regressive bug. This helps you ensure that you're doing things correctly.\n\nSome may question whether the dynamic nature of Python makes it harder or easier for a larger code base. It really depends on your approach and how you use it. The conversation often leads back to typing and the psychology of the team. Typing can catch bugs, but it may not make a significant difference if you're disciplined in your approach.\n\nTyping is a tool like any other. If you find yourself writing complex type information for a function, it may indicate that the function is too complicated. Simplifying your approach may be the right direction to take.\n\nUsing libraries like scipy in data science projects can be beneficial, as long as you understand how they work. It may add some overhead in terms of management, but leveraging well-developed libraries can save time and effort in the long run.\n\nOverall, relying on existing libraries and tools can make development more efficient and productive. Python's extensive library ecosystem allows developers to focus on solving problems rather than reinventing the wheel.There are going to be exceptions to that, but I would start from the assumption of can I take advantage of somebody else's code. Yeah, that makes sense.\n\nOn that same line, someone mentioned this particular project. I guess it's pronounced Odoo, O-D-O-O. It's a suite of web-based open-source business apps. It's a weird thing to just throw out to somebody to say, you know, the person didn't really mention any real specifics outside of code and some of the tools that they're using. They didn't really mention what the project does so much, like it's a web backend on top of a large database.\n\nI wonder about those kinds of tools, like large open-source business apps. Have you ever explored anything like that? Has something like that ever come up? I'll mention my own example with it. There's a project called Moodle. I don't know if you've ever heard of that. No, I haven't. So Moodle is an open-source learning platform. It's called an LMS, a learning management system, if you will. A lot of smaller universities and schools and so forth. Again, I worked at this school for recording engineers, and that was a project that we decided to take on and use. In that case, a lot of that code was complete for you. You were kind of not doing so much coding but working within the framework to build it out for your particular project.\n\nHave you ever invested in something like that or took time to look at those kinds of projects? I used to have to play with some of the Zope stuff, which is kind of next to that. The challenge in these situations is always how square is your peg and how round is the hole. There are cases where this fits very nicely and it can save you an awful lot of time and energy. There are cases where people end up bending over backward because it's what they know. Where it can get interesting is toolkits like this might get you 80% of the way there, but that 20% that you're trying to build may not fit into their model. So when you're trying to make architectural decisions about these kinds of tools, you want to have a decent idea of what your big picture is so that you can see whether these kinds of tools will actually help you get there. Some of it depends on how pluggable they are.\n\nThis comes back to things like the argument of Flask versus Gen. It's framework stuff. If you're going to be using an ORM and having Django's ORM is a huge advantage, but it's an ORM and there are things that aren't so easy with it. Yes, I can download the plugin that causes it to talk to a NoSQL database, but now I've got an octagonal-shaped peg and a pentagonal-shaped hole.\n\nSo, it's always the challenge. Similar to that when the article is asking questions about things like Scipio and LDL, the other challenge with this is the idea of data as code. Particularly when you're dealing with things like testing, you've got to be able to manage your data. I see it all the time with my clients. How do you test this? Well, we download the latest version of the production database, anonymize it, and run it through. I had one client where they were testing every single time, their BA's would have to find an order in the same state as what they were testing in the production database.\n\nIt's just insane. Some of these things, like order processing, take a lot of steps to build. So we started getting them to build tools where they could push a button and create a package that was in state number four so they could start testing from that point. Being able to manage your test data as if it's code and have your system in different states to test properly is really important, particularly with large code bases.\n\nThat makes sense. I think about the times I was working with real estate mortgage databases, very specific things that need to hit all these guidelines and crazy edge cases that you might better make in advance.Yeah, you might get in a situation where the current state of your test database doesn't have that situation in it. Then how do you test it, right? So, yeah. Well, I think that takes us into projects. Did you want to go first on that, or do you want me to? First, that's fine, yeah. Okay, so my project this week is a tool by Hakan Selik called \"unimport.\" It's a linter that specializes in dealing with unused imports. Like everything you pip install it and kind of like black, you point it at a directory and just say go. It goes through your target Python files and removes any unused imports that it finds. It gives you notifications and it's all pretty and colorized to tell you what files that it touched. From what I can tell, it seems to fairly robustly handle a lot of the weird little corner cases that can happen. There are situations with typing where you end up expressing the type in a string so the language doesn't necessarily see that it imports being used. Similarly with using Dunder all, it understands all this. They've figured out how to check for all these things. It's got pragmas for skipping things. They've got their own built one called \"onimport\" and then they use the \"no QA\" one, which is fairly common in other tools as well. Documentation was actually quite comprehensive. It includes things on like how to use it in a pre-commit hook, how to use it in Docker, how to use it in GitHub action. So, he's covered a lot of the major pieces. Personally, I've always ever done this with Pyflakes and it's a manual process. Pyflakes says it's unused and then I go and fix it manually. But this is my favorite kind of tool, the kind that just sort of does that one thing, does it well, and goes off and does it for you. As an aside, Hakan also wrote something called \"unexport,\" which helps you keep your Dunder all values up to date. So, if you're using that feature in the language, that might be worth checking out as well. Nice. I have a quick update on two weeks ago. I mentioned the rsync time machine bossing. He actually listened to the show or the fact that you linked him in our release of it, and he noted the stuff I had done, you know, talked about of excluding certain directories and that you had to kind of do a little research to learn how to set that up. He's updated rsync time machine to deal with that and it has it in the documentation now. Look at you. He's listed like I had done an actual pull request and I was like, well, I didn't do that, but it's nice that you mentioned it and then sent me an email about it, which was really cool. This is another kind of community thing that kind of hopped into our transom here, or under the transom, or how you say that. He has it listed as a small iOS app for iPhone that allows you to link to, you know, basically add links that you've heard in podcasts such as ours. I think Talk Python and Python Bites is also mentioned in there, and it will add those links into your Reminders app inside the iPhone. The fact that he says that it's an iOS app is a little misleading in there, but it's a project by Daniel Engvall and it's on GitHub, and again, I think I already said the name, but it's called memocast. If you were listening to this show right now and you wanted to select one of the links that we just mentioned such as this one and have it appear in your reminders so you can go and look at that later, this is the tool that's kind of doing it. What he's using to kind of leverage this whole deal is an iOS app that's called Pythonista, which allows you to run scripts, but you can also create actual other larger applications right on your phone. I'll talk a little more about Pythonista in a second because it's been around a few years and it's actually a pretty powerful tool. His project does a lot of really nice stuff of showing you if you wanted to learn how to do some of this stuff, a lot of the features and how you can kind of implement that with your phone. It shows you how to create what's called a share extension that would then run the Pythonista script and how then it could connect to the Reminders app inside there. He's using a very specific podcast player in this case, Google Podcast, so it's kind of wired for that. I personally use a different podcast player, but I downloaded it, tried it all out, and it totally worked fine.It was really cool. He also shows how, with a separate script, you can install a different script through a URL, which I think is neat to check out. Lots of good stuff demonstrated within this project on how, if you're interested in having your phone do something fancier, and your go-to tool is usually Python for organizing code, then I think this might be a neat way to get into that. Pythonista has been around for several years. It's always been under the radar as far as allowing things to systemize within your phone, and everyone thought it would get kicked off the platform, but it's still here. It's by Ole Zorn, OMZ Software. He publishes stuff under that name, and it's a ten-dollar one-time fee thing. I think I'm on version three currently. The scripting environment is in Python 3.10, and you can use it on iPhone, iPad, and other iOS devices. It's very much a batteries-included kind of thing, with popular third-party modules like requests, numpy, matplotlib, pandas, and lots of other tailor-made stuff ready to go for iOS. You can access sensor location data, the photo library, contacts, reminders, clipboard, and more, harnessing a lot of Python stuff within iOS, which is pretty neat. I've played around with it a bit, mostly as a learning tool. It has a full-featured code editor, syntax highlighting, code completion, and also supports graphics and multi-touch. They actually have some games and stuff that you can create. So, it's kind of two things in one: Pythonista being the platform used to work inside, and then his project, the memocast, which again has support for our show. Also, if you're not aware, we have really thorough show notes created every week with links and additional links available at realpython.com/podcasts. If you have a fancier player like Overcast, Google Podcasts, Apple Podcasts, or Spotify, the links are now in there. I also create chapters so you can navigate the episodes, clicking on different areas to replay a story or navigate to a different part of an episode you listened to a while ago, with all the links available for you to take advantage of this feature. I don't do this often, but I'd like to throw out a request: if you enjoy the show, which is free, can you help us out and leave a review? That would be great. You can do it on Apple Podcasts or any other platform you like. It really helps the show get exposure to other people, so spread the word if you like it. Please leave a positive review for us. Thanks again, Christopher, for bringing all these projects and topics this week. Always a pleasure. Alright, talk to you soon. Bye. \n\nI want to thank Christopher Trudeau for coming on the show again this week, and I want to thank you for listening to the Real Python Podcast. Make sure to click the follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. Show notes with links to all the topics we discussed can be found inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and I look forward to talking to you soon.",
    "OcrawlYJjQk": "Welcome to the Real Python Podcast. This is Episode 161. Are you looking to advance your Circuit Python projects? Would you like a collection of resources and tools to help you along your path? This week on the show, Todd Kurt is here to discuss building projects with Circuit Python. Todd has been working with embedded electronics for a long time and has been an active member of the Arduino Community. He recently started to build projects using Circuit Python, and it's become his preferred prototype method. He shares software resources, hardware tools, and advice about working with Circuit Python and embedded electronics. We discussed several of his music hardware projects and the libraries and modules for synthesis. He also shares a powerful online prototyping tool to plan your project before spending money or plugging in a soldering iron.\n\nAlright, let's get started.\n\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Todd, welcome to the show.\n\nHi, thanks for having me on.\n\nYeah, I was very excited to talk to you about Circuit Python and all the projects that you do. I have bought several of them.\n\nOh, thank you. I wanted to just kind of nerd out about Circuit Python but also get some advice for people that are maybe going beyond some of the basics. I've had a couple of people on in the past to talk about some of the fundamentals of getting started with Circuit Python, but I think of like what are the next level, what are some advanced projects and kind of fun things that you can do with it. A lot of the listeners already know that I'm really into music and you kind of have that bent in a lot of the projects you do. Anyway, maybe we could just briefly talk a little bit about yourself. You founded a company called ThingM, can you tell me a little bit about that?\n\nSure, so imagine a world before the Internet of Things. Around 2006 or 2007, my business partner Mike and I were trying to evangelize what we were calling ubiquitous computing, as a term of art at the time in academia. We were trying to get companies to think about designing products with internet connectivity. We imagined a world where previously dumb objects could be on the internet and could talk to each other. For example, an internet-connected toaster or dresser. We were trying to envision what they would say to each other. Nowadays, I've distanced myself from the Internet of Things concept because it has become more about devices being controlled by companies rather than the original vision of devices being citizens of your own house. The original premise of ThingM was to make devices smart, take previously dumb objects and make them smart to explore new use cases. One of the products that came out of our research was the BlinkM, a little I2C LED that became popular for controlling RGB LEDs with Arduino. I then made a USB version called Blink1, which is a USB-connected LED that can be controlled via your computer and store color patterns. This became popular as it could be hooked up to various internet services for notifications.\n\n[Music]Yeah, nowadays it's much harder to do because there's been a lockdown of a lot of the APIs out in the world. So the user level, like a normal person level use of the Blink One has contracted. The other main use of it is for people who own racks of servers and need to know what server 74 is doing. They can plug a Blink One into every server and write a script that checks the status. In addition to their normal monitoring, they can have ambient visual monitoring of the whole server rack. They can also turn the light on for remote hand support, like directing someone to the purple blinking server.\n\nIt's really just a one-product company right now, and it's really a one-person company. I'm the only one doing the design work, with a couple of assistants helping with logistics. We don't have employees or an office, just my garage. \n\nIt sounds like you've had an interesting background working with hardware, software, and firmware over the years. I was reading about the bootloader podcast with Paul Cutler, who has become a strong voice in the CircuitPython community. He created the CircuitPython podcast and suggested a weekly news podcast focusing on embedded computer topics like CircuitPython, Arduino, and 3D printers, which was a lot of fun.\n\nInitially, we wanted to do both audio and video podcasts, but towards the end of the year, Paul had to prioritize other work. Now, he's brought back the CircuitPython podcast in seasons, which seems like a sustainable practice. The content is evergreen, so it doesn't matter if it comes out this week or next month.\n\nI worry about the stories we cover and try to focus on projects and push people towards what they can do with Python. My background started with C, but I eventually got into playing with Python.Well, I'm a big fan of the Adafruit people. Adafruit are the ones who are currently financially sponsoring most of CircuitPython development. A good friend of mine, John Park, does these weekly live shows for Adafruit. About three or four years ago, he would occasionally ask me questions because he's a good programmer but doesn't come from a programming background like I do. I've been programming since I was 12, so a lot of these concepts just soaked in. A single word triggers the association of what they're talking about for me, whereas John Park doesn't have that background.\n\nHe would ask me simple questions about how Python would do something, and I would struggle to answer because my Python experience was mostly from contract jobs where I'd come in, do the work for a few months, and then leave. My Python code wasn't idiomatic at all. When I started looking into CircuitPython, I found it really interesting because it solves many initial chip configuration problems I encountered with Arduino projects of any complexity.\n\nFor example, if you have a project with a display, buttons, an SD card, and audio output, doing it in Arduino is a lot of work. In CircuitPython, because the drivers exist for those functions, it's much simpler. The drivers have good error messages, so if you use them incorrectly, it will tell you what's wrong, unlike in Arduino where it might just crash.\n\nI find it fascinating how Adafruit and the CircuitPython team quickly support new products by building libraries for them. This saves a lot of work for someone like me who has been doing embedded stuff for a long time. My current strategy for bringing up a new PCB idea is to start in CircuitPython to check if everything can work before moving to Arduino or lower-level C.\n\nIn old Arduino, the original chips had limited pins for specific functions like serial communication, PWM, and analog input. If you wired your circuit differently, it wouldn't work. But in CircuitPython, there is more flexibility in using modern chips, allowing for easier prototyping and testing before diving into lower-level programming.It's only allowed to be input and not output or exactly that exactly that. So the chips nowadays, it's like this next level up. They're based on arm cores usually, but every pin, like almost every pin, can be reconfigured to be a bunch of different things. Some chips, like the ESP32 series, almost every pin can do every function, which is nuts. The more common case is you have this crossbar switch idea inside the chip, and it can only make certain types of connections. While you could have, say, PWM on every pin, you can only have, say, serial transmit receive on pin zero and one, seven and eight, twelve and fourteen. There's also maybe a second serial port that can also be on some of those pins.\n\nIf you choose poorly, you can end up making that crossbar switch not do the thing you want. It's really hard to tell that in Arduino. But the way that Circuit Python's drivers are written, when you try to instantiate these high-level objects like the serial object or the pin object, it'll tell you if that thing's in use or you can't do that on those pins. It reminds me of interrupts on PCs 15 years ago. Like, \"Oh no, you can't put your sound card on that one because this one's using this for this board you bought already.\" It's very similar to that electrically.\n\nHaving Circuit Python help you do the design work of, \"Okay, I want to use a display, an audio output, buttons, and a knob. Where can I put that?\" You have the chip on your breadboard, wired up, and you try to do it in Circuit Python. It tells you where you can't put certain things, and you adjust accordingly. Then you can change your PCB, and when you get it back, it works first try.\n\nIt's interesting that you mentioned starting on something like Circuit Python for a project prototype and then maybe switching it to Arduino. What would be the purpose of switching there? Is it because it's running C or doing something different? \n\nOne of the things about Arduino that is powerful is that it presents a language that's like C plus but much friendlier. It's like C plus with training wheels, and many functions you call are actually C functions with simple C plus wrappers. Anything you do in Arduino is running at the full speed the chip can handle. For functions where you need to be faster, you can write them in Assembly Language and put them in your Arduino sketch. Arduino allows you to go down to the very bottom of the chip if needed.\n\nIn Circuit Python, you can't drop down to the low level stuff like in Arduino. Circuit Python has a floor that is Python, and the supervisor only lets you do things so fast. If you want to blink an LED quickly, you're limited to a for loop. This limitation becomes apparent when making a musical instrument, like a sequencer, where accurate timing is crucial. Circuit Python doesn't provide accurate timing mechanisms, making Arduino a better choice for such projects.Yeah, there are ways to sort of ameliorate it. You can purposely run the garbage collector yourself periodically. You can make sure you're doing things that preserve memory as much as possible and don't do a bunch of allocations to minimize the amount of garbage collection that gets done. But you're still going to have this plus or minus two or three millisecond wiggle in your timing, which doesn't sound like a lot. But if you think about it, a 16th note at 120 BPM is like seven or eight milliseconds. So it's already your time is gonna sound kind of wonky if you're doing a sequence of any kind of complexity.\n\nThat's basically why. Yeah, it makes sense. It sounds like it's one of those things I always liked about MIDI. Generally, it's kind of a similar thing where you can, as a protocol, tell it to do specific things. You're basically remotely controlling lots of things. I kind of think of MIDI as circuit Python kind of the same way. MIDI is too slow to do actual sound to come out of it. That was always a big problem I had with trying to teach the subject to my students. They just, you know, it's like MIDI is not actually sound.\n\nIt's a really hard concept to get across. Yeah, it's just allowing you to control it. So I wonder sometimes about, like, is there a way to bridge the two, the way that Python uses these additional libraries that are written in Rust or other things like that that can be sort of handed off the code into these optimized compiled sections? But maybe not on this level of embedded systems that you'd switch from one language to another after you've prototyped it. That's what you do to do everything interesting in circuit Python. You are doing that because there's the core libraries that exist in the flash of the circuit Python that's running on your chip.\n\nThat includes a bunch of functions for the medium to high level of chips that circuit Python runs on. It includes being able to access the file system that exists on the chip itself. That looks like a flash drive to your computer. That includes things like being able to read WAV files for audio playback. That includes things like being able to access a frame buffer to do display stuff, both on little LCD displays but also now on actual HDMI displays. This is on a little four dollar board. Writing circuit Python, you can write to an HDMI display and have it display things. It's amazing.\n\nI think I saw that project. I'm very interested in it. Like, I'm wondering about the visual synthesizer kind of thing that you could do with that. Would you need to, like, when I was looking at a project that you were kind of showcasing somewhere in Mastodon as a link or something like that, I was like, \"Oh, this looks cool.\" A friend of mine is like a visual synthesizer freak. He just loves that stuff. Oh, cool. He's a big fan of Yak, the coder guy from. He's done a lot of video game stuff, but he's created lots of visualizers over time. But that idea of being able to fire the HDMI at that point, you're saying it's using sort of an already written library to access aspects of it. But yeah, I was using circuit Python.\n\nSo one of the things Scott Shawcroft, the circuit Python lead, who you had on your show, like, I don't know, three years ago or something, which is a good episode everyone should go check out as well. He very early on made this core library called DisplayIO that is a pretty high level API to drawing onto displays. Instead of having pixels, like XY and the color of the pixel, XY, you instead have Sprite sheets where you say at this XY position and this width and height, I want you to draw this bitmap. And it takes care of drawing it for you. Within a few lines of code, you can make a little game because you're not doing this low level, how do I draw a circle, how do I draw a line? You're just like, \"Oh, this bitmap that I uploaded on the circuit Pi drive, draw it over there. And now draw the enemy bitmap over there.\" And so it's really easy.The HDMI stuff works by using display i/o with a different output device. You set it all up, and now your previous display i/o work on small displays can go onto computer monitors. That's cool. I'll try to include links to some of that stuff. I tried to order a board recently, the Adafruit Pico DVI feather, but it was out of stock. In a similar vein, we were talking about creating audio, and you've been focused on projects lately. One was mozzie, an Arduino library for synth stuff. Another is synthio, a new library for CircuitPython.\n\nCircuitPython has good audio output support with three technical ways to output audio. Depending on the chip capabilities, you have different choices. You can easily play WAV files with CircuitPython, making things like sample players quick to create. The mozzie library offers full synthesis, like an old 8-bit sound chip from a video game system. It has a fun Lo-Fi sound and can be used for making cool synthesizers.\n\nCircuitPython didn't have these features before, but now you can create modular synthesizers with code. You can experiment with oscillators, filters, LFOs, and more to make unique sounds. You can also create drum machines and play with different samples easily. It's been fun to explore these possibilities in CircuitPython.Well, sorry Jeff Eppler, his whole name is Jeff Eppler, but his handle is jepler. Somehow he found the time to work on what is now called Synthio, a synthesis library for CircuitPython. It's built-in and really cool. It doesn't follow the standard techniques and names that Mozzie does, but it can do things that other synthesis libraries can't. It uses single-cycle waveform oscillators as its basis and allows you to modify those waveforms in real-time as the oscillators are playing. This means you can do wave table synthesis, granular synthesis, and other things that were hard to do before. You can make crazy sounds with a small amount of work. It's fully repitchable and has amplitude envelopes, LFOs, and math blocks for combining LFOs and envelopes.\n\nThere's a PR for adding initial filters, like high pass, low pass, band pass, and notch filters. You can fake filter sweeps by modifying the waveform oscillator. This is an extra thing that seems wild to have in the core, but it's there.\n\nOne problem with CircuitPython is the inability to load native code that's not built into the firmware. Right now, there's a small subset of numpy functions available in CircuitPython, but no way to add more without sacrificing other features. It would be great to have a fully-featured numpy that could be loaded in for more functionality, but currently, it's not possible.\n\nThere's potentially a way to load native code in MicroPython, which could be ported to CircuitPython. However, writing C modules for CircuitPython is challenging and may not meet the core quality standards. It would be ideal to be able to experiment with personal code without impacting others or requiring them to recompile CircuitPython.\n\nThis week's spotlight is on the Real Python video course \"Python Basics: Reading and Writing Files.\" It covers the essential topic of working with text data and files in Python programs. The course is based on a section of Real Python's book \"Python Basics: A Practical Introduction to Python 3.\"The video course is presented by Real Python author Bartos Jacinski. He shows how to understand the difference between text and binary files. You'll learn about character encodings and line endings, work with file objects in Python, and read and write character data in various file modes. You'll also learn how to manipulate CSV data using the CSV module. Working with files is crucial for Python developers. This course is a worthy investment of your time. Like all video courses on Real Python, it's broken into easily consumable sections. You'll also get additional resources and code examples for the techniques shown. All course lessons have a transcript with closed captions. Check out the video course by following the link in the show notes or using the enhanced search tool on realpython.com.\n\nRegarding the \"Micro Lab\" or \"U Lab\" link you had in the bootloader, is that what you were talking about? For some reason, in CircuitPython, the package is called \"ulab.numpy.\" I think \"ulab\" stands for \"micro lab,\" but I'm not sure. There was maybe an envisioning that other scientific functions would go under the \"u-lab\" space. You can choose to add it or not have it, but there's only one entry in the \"ulab\" namespace, which is numpy. Everyone imports \"ulab.numpy\" as \"NP\" and performs standard numpy array operations.\n\nOne handy use of ulab.numpy is for Neopixels LEDs. You can light up LEDs randomly and fade the entire strip to black using numpy arrays, making animations look much better and run faster than pure Python solutions. By casting pixel data into a numpy array and using numpy functions, like numpy.add, animations become smoother and faster. This technique can enhance audio and video projects as well, like waveforms in Synthio being numpy arrays.\n\nSorry for the confusion.And so you can do a bunch of numpy math. One of the ways I was doing the fake filter is we have the numpy ffts. So one of the ways you can do a quickie filter is to do the fft of the waveform and then chop off the higher coefficients, set them to zero, and then do the inverse fft to convert it back into a waveform. That's one way of going from waveform to the frequency components of the wave, chop off the high-frequency components, and then make it a waveform again. Boom, you've just now low pass filtered your signal. You can't do that in real-time, of course, but if you need to convert a square wave to something less of a square wave, you can use that.\n\nI want to talk to you about one of the things I was thinking about was just for these types of projects, these more advanced things to get into. I could imagine that somebody might say, \"What types of tools, boards, or other kinds of things would be good places to go next?\" Maybe we could start with the board kind of thing. You do a lot of projects with the Raspberry Pi Pico where you've created two or three different things. Maybe we can mention briefly here, like your picotouch sort of touch keyboard, which I show everybody.\n\nI keep one of mine in my laptop bag all the time. It's really neat because I bought one of those cord touch things back in the day when they came along, and I'm like, \"Oh my God, I can build one of these for this much.\" All I got to do is hopefully properly solder a Raspberry Pi Pico on it and then order the Raspberry Pi Pico from somewhere like Digikey and get them in a plastic container that looks like Chiclet gum or something like that. It's crazy. I think of that board as a neat board. It is a Raspberry Pi with certain aspects of it. Well, it's a Raspberry Pi Pico, so one of the very frustrating things about Raspberry Pi is they made this very successful line of single board computers called Raspberry Pis. The company is called Raspberry Pi, and these things are computers that run an OS, they run Linux, they run full Python, they run Apache, anything you want. Plug in a monitor, plug in a keyboard, plug in a mouse, and it's a real computer. You can run Chrome, Audacity, whatever.\n\nBut then they came out with this amazing chip called the rp2040, and the first little board that carried that chip was called the Pico. But the full name of it was the Raspberry Pi Pico because it comes from the Raspberry Pi company. Confusion. The problem is that people hear Raspberry Pi Pico and they think it's a small version of a Raspberry Pi. It's not. This is a different board. It's totally different and so frustrating because it's a pretty good board. One of the things that make it really good is it's four dollars. That's one of the main reasons why I use them. They are easy to use, almost disposable boards. I feel like because they're four dollars, I can do some experiments with it that I maybe wouldn't feel comfortable doing on a more expensive board. If I damage this, I'm not going to feel too awful.\n\nBecause Circuit Python and Arduino work on so many of these boards and often a better board like the Feather DVI that also has an rp2040 chip in it, but that's a more expensive board, it has a lot of extra features. If I slipped with the wires and fried that board, I'd be sad because it's more expensive and a bit harder to come by. I can do most all the experiments I need to do on the Pico and then once I think I know what's going on, I can copy my code over to the Feather DVI board and maybe make a couple of changes at the top to say which pins to use because maybe I chose different pins.\n\nI love the Raspberry Pi Pico because it makes me feel less anxious about messing something up. You've done two or three projects. The other project I dig is the Pico step sequencer.I did that one last year, right before it was two weeks before Circuit Python Day, which is an annual event that Adafruit has created. John Park had found a source for these things called Step switches, which are cool 80s looking switches with a built-in LED. They're Big And Chunky and look straight out of the 80s. I thought, \"Oh man, the Raspberry Pi Pico, eight of these switches, a knob, a little display, and MIDI out. Okay, I can do this in two weeks.\"\n\nI whipped up a quick board because every pin on the Raspberry Pi Pico can do a bunch of stuff, making it easy to wire up. I worked on the software on the Adafruit Macro Pad, which has 12 buttons and a better display. I got most of the sequencer working, and when the board showed up, I quickly soldered it together. It was a pretty usable little MIDI step sequencer about the dimensions of a paperback book, costing around $30 in parts.\n\nIt was my first time playing around with Circuit Python and a display, which was interesting. My hardest part was the 3D printing and getting the height of the Eco correct. I ended up soldering it down at the board level instead of using standoffs. The little 3D printed case I made was a hack job, but it worked.\n\nThe project used the eighth-inch Jack version of MIDI, which was cool. If I were to start a project today, I would reach for the Raspberry Pi Pico. It's a common board to use, and there are options for solderless boards and sensors like SparkFun's Quick and Adafruit's Stemma QT.\n\nThese boards make it easy to hook up devices without soldering, using I squared C protocol. It's easy to start with Stemma QT stuff for quick prototyping. For more advanced projects, you can explore soldering your own stuff. I typically solder breadboard pins onto the Pico and use a solderless breadboard for quick prototyping.And then I'll run jumper wires between the Pico and the board, whatever board is like lately it's been a little audio output boards and pots and knobs and stuff so I can make little synthesizer toys. But yes, that's a very quick way to try stuff out. It's not very stable because all this stuff is kind of held together with spring-loaded bits of metal. So like if you shake it too much, it'll come undone. But it's good for trying stuff out.\n\nOne of the things that I was impressed with some of the projects that you've built, when I was watching your videos, is that most of these boards need power. It's like you're gonna need, if it has audio outputs or something like that, you can definitely connect there. But usually, the power is brought in by the USB connection. So you're using these almost ubiquitous things that you got at a conference or something like that. There's like the little battery charger to top off your phone battery. I ended up never using it for that because the phone batteries were fine, and I ended up with like 10 or 12 of these things laying around. I got a fantastic one from last year's PyCon AWS had this huge one that is coated in rubber, has suction cups on it, and has two outputs. So I can actually power my projects and I can actually, instead of having to like, because that's the one area that I've kind of failed at, I've been trying to get better at, is like, okay, well, I want to make a board that I can maybe do Bluetooth with. And so now it needs to be remote and have power. I think that might be the easiest way to get around it because the batteries are pretty massive in these things.\n\nThe strange paradox of these little phone charger bricks that were so common like 10 years ago is that nowadays our phone's batteries are so big that these little lipstick ones that we used to get at conferences will maybe add like two percent or five percent of charging a phone. They're useless for that because these little microcontroller projects draw like 20-30 milliamps, which is one hundredth of what a phone will pull. So you can run these little projects off of these normally junked USB power banks for hours.\n\nIt was kind of funny that this most recent video, I made earlier today, and I'd forgotten this little lipstick-shaped one that I've been using for months. I'd use it for like maybe half an hour, then put it away. It finally died on me today. I was in the middle of recording this video and it died. Do you have to charge it occasionally maybe before you record? Too funny. I was impressed with that as a technique. I'm like, oh, actually, I can power the little synthesizer and the sequencer at the same time. It's kind of nice, kind of a neat trick.\n\nSome of the other things that I've heard you talk about, not only on the bootloader, but just kind of seeing you mention otherwise, were kind of tools for the person who's getting a little further into CircuitPython. I think that you mentioned that you're not a big fan of IDE kind of stuff. What are resources you would use if you need to make sure that your projects, maybe you're trying to test out a sensor and see if it's receiving the right numbers and so forth? As far as coming in and out of the board, what are some of the resources you use there?\n\nSo yeah, I like to divide these up into two areas, software and hardware. For the software tools, the way I program is I'm an old school programmer. I program by having a text editor window and one or more terminal windows open. That's how I've been programming for decades. And so that's how I program CircuitPython. I have a terminal window open that I use a tool called Tio, but you can use any serial terminal program to connect to the virtual serial port that CircuitPython presents to you. In the other window, I have the code.py open that is on the CircuitPi drive of the CircuitPython device. My standard workflow is I make edits to the code.py, I save it, that causes a reload that I can see happen in the terminal REPL, and I can see how my code is working.And so that works great. It is also very transferable. You can do that on a Chromebook, you can do that on an iPad. I've even done it a little bit on an iPhone.\n\nYou're opening terminal windows that way. Yeah, there's a little terminal program that I've got for the iPhone that I found somewhere. Oh, awesome, cool. Even if you don't have that, you can still edit the code.pi and watch it run. Compared to how you had to install the Arduino IDE that only ran on certain computers, it's really cool that microcontrollers are becoming so powerful that they can become citizens of your computing space rather than just peripherals. That's how I work as a terminal and code editor.\n\nThen you're like, \"What is the equivalent of pip in the CircuitPython world?\" For a long time, there hasn't been one, but for years now, there's been this thing called Circup written by this guy named Nier. It's open source, you can get it on GitHub, it works on all platforms, and you can use it like pip. You just say, \"Hey, I want to install this library,\" and you say \"Circa install Library name,\" and it gets put onto your device for you. That is super handy because a lot of the hard work is done by these libraries.\n\nI was impressed with that. I didn't know that was available. Normally, you would have to go find a collection of additional libraries and physically move them into the appropriate directory on the CircuitPython device. Circup does that automatically. It knows the destination, and I thought that was a really handy tool.\n\nCircup is super powerful because one of the official ways to install libraries involves downloading a zip bundle, unzipping it, pulling out the library, and hand-dragging it over to the CircuitPython drive. In all those steps, there's a lot of room for error.\n\nAnother tool written by the same person is Disco Tool, which helps you find the drive name and serial port name of the CircuitPython device plugged into your system. This is really handy, especially on Linux and Windows where it can be difficult to find the serial devices and COM ports.\n\nDisco Tool helps with learning port numbers and finding where your device is on your computer. Circup is used to install libraries onto the device, and Disco Tool helps find where your device is in your computer.\n\nThen, you can use whatever text editor you prefer. I have a nice repository on my GitHub of CircuitPython tricks. It's like a little awesome list of techniques and things to remember how to do. One of the things I have is in my home directory, I have all these \"name of thing - hints.txt\" files that I've been editing for years. I started creating a similar one for CircuitPython.But then John Park kept asking me how to do this thing, and I quickly copied and pasted it to him. He asked me how I was so fast, thinking I must know Python well. I explained that I just did a search on the Circuit Python hints.txt file and copied and pasted it.\n\nHe convinced me to post it online, and much of the content of Circuit Pipeline Tricks is inspired by John Park's questions. I thanked John and provided the link to Github.com/circuitpythontricks.\n\nI got the name \"Todd Bot\" from my best friend in high school. I initially didn't like it but eventually used it as my domain name. I also have the handle \"Sound Orphan,\" given to me by the same friend.\n\nI recommended an online simulator for the Raspberry Pi Pico and other chips called \"Wokwi.\" It allows you to run Circuit Python on a virtual Raspberry Pi Pico in your browser and experiment with virtual LEDs and buttons.\n\nI mentioned using Eagle for creating circuit boards, but I am gradually learning KaiCAD, which I find to be better. Autodesk's acquisition of Eagle led to changes that may require me to switch to a different tool in the future.\n\nI also discussed Thea Flowers' work on a browser-based circuit design tool, which I find intriguing.It's a key CAD viewer. So if you come across a Kai CAD schematic or board layout on the web somewhere, you can just drop the URL into her viewer and see all the parts and how they're wired up. It's been super instructive to me, so a big thumbs up to that. Thank you, Thea.\n\nYeah, definitely cool. And if people are interested, include links not only to the specific repositories we talked about but also your GitHub, which has a ton of different projects. Some of the physical hardware ones are still available on Tindy, right?\n\nYeah, people have always been asking me, \"Hey, why don't you make this available to buy somewhere?\" And I'm like, \"I'm not really into that.\" It's not ready for prime time to be sold. But last year, I decided to start putting some stuff up on Tindy just to give people an answer when they ask if they can have one.\n\nWhen you get PCBs made, the minimum order is five, so I end up with extras. If I buy more, I can just put the extras on Tindy and it's been paying for some of my experiments lately. That's cool.\n\nIt's crazy how easy it is now to make boards. You can whip up a board in Kai CAD, export the Gerbers, and upload them to a board house for a low cost. OSH Park is really good for US-based orders.\n\nWe hit most of the stuff you wanted to talk about. One thing in the hardware tools area, a USB power meter is really handy to monitor power draw and prevent damage to your board.\n\nA little USB hub with switches is also useful for quickly turning on and off your board without having to physically unplug it.I'm not a fan of micro or which one is this one that's on almost all the boards. I can't wait for everything to be C but it's probably too expensive right now. The Raspberry Pi Pico used a micro b connector which is kind of insane but it's easy to wreck it if you're being a little too hardy with it. The fewer times you stress that connector, the better you'll be.\n\nI have these weekly questions I like to ask everybody. The first one is what's something that you're excited about that's happening in the world of Python? I want to learn more about the internals of CircuitPython. One of the really nice things about CircuitPython is that you get to see how Python thinks about things from the inside. It's like everything's an object, you know? I want to look into how the internals of CircuitPython numpy stuff works and see how some of the synthio stuff works.\n\nWhat's something that you want to learn next? I want to go back and relearn some of the Digital Signal Processing stuff from my original schooling. I've forgotten almost all of it so I want to see what the basics are and what certain filters actually do.\n\nYou can follow me on Mastodon at toddbod.mastodon.social or on my YouTube channel where I post videos of my projects. I usually post a GitHub gist and a video on YouTube for each project so you can see it in action. I also blog occasionally on toddbot.com/blog.\n\nIt's been fun talking to you. Thanks for coming on the show.I want to thank Todd Kurt for coming on the show this week. I also want to thank you for listening to the Real Python Podcast. Make sure to click the follow button in your podcast player. If you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey. I look forward to talking to you soon.",
    "_BaCPTssX7s": "Welcome to the Real Python Podcast. This is episode 162. What advice can you extract from the Zen of Python? How can these 19 guiding principles help you write more idiomatic Python? This week on the show, Christopher Trudeau is here bringing another batch of Pi Coders Weekly articles and projects. Christopher shares a Real Python article by Bartaj Zhichinski titled \"What's the Zen of Python.\" We talk about how to access the Zen within Python and the poem's origin. We also discuss how different sections provide contradictory advice for what makes good Python code. We cover recent posts by previous guest Matt Harrison about using Python and pandas for finance. Matt's article covers methods in the pandas library for aggregation, resampling, and rolling averages. We cover several other articles and projects from the Python community, including a news update, solving a Legend of Zelda puzzle with Python, avoiding simply providing advice, displaying better stack traces, and creating files with fake data.\n\nAlright, let's get started. Thank you.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Hey, Christopher, welcome back.\n\nHey there. So we've got a nice round of news this week, a whole bunch of items, right?\n\nYeah, lots of bits and pieces here. So first off, we've got a bit which is a little stale. It happened since our last podcast went out, but it was a while back. There were new point releases for Python 3.7, 3.8, 3.9, and 3.10, and 3.11, excuse me. And that same announcement spoke of 3.12 beta 2, but since then, 3.12 beta 2 has already been replaced with 3.12 beta 3. Lots of progress there on the release front.\n\nNext little bit has to do with PyPI. Their ongoing journey to implement two-factor authentication continues. A while back, they turned on 2FA for high volume accounts, and although they turned it on, they were still allowing password-only authentication to help ease the transition. Yeah, so that transition is done now, so if you've got 2FA turned on for your PyPI account, you don't have a choice. You have to use 2FA. That's part of their ongoing move towards getting better security going on there.\n\nAfter that, the faster CPython plan for Python 3.13 has been released. We've talked about most of the features on the roadmap before, including things like f669.554. We're not going to get into it, but if you want to see all the proposed changes in one place, there's a GitHub link if you want to take a look at that.\n\nOkay, and on top of that, PyPy, the alternative interpreter, has released a new version, that's 7.3.12. This version supports Python 2.7. They still support that, 3.9 and 3.10.\n\nAnd the last little bit is some news from Read the Docs. That's the open-source hosting site for documentation. A few years back, they added the ability to configure your documentation settings through a YAML file called `.readthedocs.yaml`. The format of this file has been updated to version two, and they're phasing out the use of version one. So if your docs don't currently have a config file or they use the old version, you're going to need to upgrade. You'll get an email about it. The final cutover date is September 25th, and there are some blackout windows in the meantime as they test the new systems.\n\nYeah, we've talked about this a few times about the versions of YAML, so that's probably going to be a nice change. That's the new standard, right? The primary piece here I have found is essentially they've been deprecating parts of the dashboard, things that you used to do through the dashboard. They started adding new features, and they didn't stick them in the dashboard, so you needed to use this config to get certain kinds of features on Read the Docs.\n\nOkay, and so essentially, like my old projects still use the dashboard, my newer projects have one of these YAML files. And so the note I got from them was basically like, these are things you haven't touched in a while. Not that's the way it was phrased, but that was the consequence. So yeah, right.\n\nAnd one last little thing, not quite news, but this morning I read that Twitch has updated its content classification rating system. So Mr. Bailey, as we intend to keep this podcast family-friendly, please no kissing or licking of the microphone. That's now considered adult content.\n\n[Laughter]\n\nThere goes our plan for the podcast. I guess so. Keep those cameras off. I have one little note I wanted to add because we've talked about PyCon US 2023 a couple of times and talked about PodcastAides 2023 a few times. I may have mentioned the videos being up already for PodcastAides, but just to make sure people are aware, yeah, the videos are up on YouTube for both of those conferences now, and I'll include links that you can go and check them out.\n\nAs we dive into topics this week, you have a Real Python one you wanted to start with.My first article is about the Zen of Python, written by frequent Real Python contributor Bartash Suzinski. If you're new to Python, you might not have come across the Zen before. It's sort of an Easter egg containing development philosophy, and you can see it by opening up a REPL and typing `import this`. It's kind of referred to as a poem, but that's a bit liberal if you ask me. The poem was written by Tim Peters, a long-standing C Python core developer. The article introduces you to the Zen, breaks down its different parts, and discusses how strictly you should adhere to it.\n\nThe article mentions a recent talk at PyCascades by Chris Negabauer about the limitations of the Zen, such as decorators and type hints possibly violating the guidelines. There's humor in both the Zen of Python and the talk, pointing out various ideas and concepts. The original posting of the Zen was not inside code but on a mailing list, with some humorous history behind it.\n\nThe article delves into the different aspects of the Zen, highlighting areas where interpretations may differ among developers. It includes examples like using Greek letters in code, which could be seen as adding unnecessary complexity. The article concludes with a section on the humor and history of the Zen, with inside jokes buried within.\n\nAnother article I enjoyed was \"Python for Finance: Pandas Resample, Groupby, and Rolling\" by Matt Harrison. It covers handy Pandas features and tips, with examples running on the Ponder platform. Ponder is a tool that can run Pandas inside your database, making it a unique way to work with data. Matt Harrison is an advisor to Ponder, and the article provides valuable insights into using Pandas for finance-related tasks.But you could access the data yourself. It uses an interesting data set, the FDIC Bank Find Suite, which I was not familiar with. Some data that you could play around with if you're not familiar with it. The FDIC, the Federal Deposit Insurance Corporation, has bank failure data and provides valuable insights into the underlying causes of these failures. It helps to develop effective risk management and regulatory compliance strategies. They kind of harken back to something I used to do. I used to be involved in risk management for a loan portion of a bank, so that was very interesting to see some of this data. \n\nThe data that he grabbed from this overall suite of information on the site is bank failure data from 1934 to 2023, with about 4,000 entries. It takes you through the real common data grooming kind of stuff that you might do, like renaming columns and fixing date formats so that they can be used more properly. He shares the whole data dictionary, explaining the abbreviations and codes used by the FDIC, like resolution types. He shows how they resolved this, and of course, that probably changed since the 30s. \n\nHe starts out by using the account feature to figure out how many failures per year. He uses the dot DT accessor to access them and then shows a couple of different plots. Defaults to showing a noisy bar graph where it's very hard to read every single year being printed at the bottom, so he shows the steps to make it a little more readable, making it a line plot. He shares a really nice feature that's a little bit hidden in pandas, called offset aliases for dates. By using the resample feature, he can convert the time series data into several time series data with different time intervals, so you can look at what was happening monthly with an overarching view of what was happening yearly. \n\nHe demonstrates Group by and creating plots with that, then shows how to do a feature that I haven't ever needed to use, but something that I could see in financial data that would be very handy, which is a 12-month rolling average using the dot rolling method. Overall, it's a really good demonstration of how to tackle one of these kinds of problems. He doesn't give you direct links to the data, but he does give you a link to the website where you could find the data to grab and go through some of these examples on your own. \n\nIt's a neat demonstration, and Matt's definitely an expert on the pandas stuff. If you're wanting to learn a little bit more, I'll include a link to our previous conversation on the podcast. I have a question for you, Chris. There are three big peaks in this data that you can see. There's one in the 30s, which would be the Great Depression and the banks then. There's one in the 80s in the beginning of the 90s, and then there's the housing crisis, more recent in 2007-2008. Which do you think is the tallest? \n\nI wouldn't even know how to guess. It's the Savings and Loans crisis that happened in the 80s and early 90s. It's crazy how many Savings and Loans failed in that time period. Of course, they were insured through the FDIC, so it seems like, you know, I remember hearing about it, but it just wasn't a focus of my life in the 80s to think about, and it didn't really affect me as much as the 2007-2008 stuff. I have vague memories of Black Monday and my father explaining he worked for IBM, and his only stock investment was the shares he got as part of working for IBM. \n\nThey crashed massively, and I remember him talking about how severe the drop was. Of course, as a kid, your first thing is like, will that affect us, and he's like, yeah, it might take me a couple more years to retire, but you know, that was sort of the thing. Yeah, I do remember it being catastrophic. Yeah, but yeah, I just pulled up the graph now, mentioning it. It's not even close. It's crazy. But I mean, the main difference is the consolidation that happened after that, so the monetary values were maybe similar with the 2007-2008, and it's just regulations may be good guys, whatever. \n\nYes, well, at risk of praising Canada, our banking system survived that quite greatly. Okay, so there might be an argument for having some rules. Yeah, whatever. All right, well, tell us about something fun.All right, my next article is by Gaz J and it's called \"Python and The Legend of Zelda.\" Long before Zelda was crying, there was an Oracle of Ages game on the Game Boy. Near the end of the game, there is a puzzle with a room full of colored tiles laid out in a 13 by nine grid. When you step on one of them, they switch colors. Your goal is to turn all the blue ones to red. Gaz, a programmer, was driven a little crazy by this puzzle. He wrote a program to figure out how to solve it, using a Brute Force search algorithm. The article walks you through the Python script he wrote to solve the problem.\n\nFrom one old man to the other, remember the days when you couldn't just look up the answer on the internet? You had to go down to the magazine stand and buy cheat hints on paper. I still have books for some Bethesda games like Oblivion and Skyrim.\n\nMy next topic is a blog called Byte Code, spelled b-i-t-e, which is a substack mailing list. The author, listed as \"Nobody has time for Python,\" shared a piece titled \"Why not tell people to simply use Pi M, Poetry, or Anaconda.\" It's a follow-up on relieving python packaging pain, focusing on sharing packages and programs effectively with end users. The goal is to provide advice to a large number of users in a reliable way.\n\nThe article emphasizes avoiding using the word \"simply\" when giving instructions, as it can make things seem easier than they actually are. By providing steps without justification, it can lead to confusion and frustration for users. It's important to help users effectively navigate their path without oversimplifying the process.I'll mention the list of specialty tools that he mentions to avoid using. Maybe avoid using Homebrew for installation of Python. I have to agree with that one. Homebrew is a wonderful tool, but it's a bit specific for Macintosh machines. There is a similar tool called Chocolaty for Windows, but it can be tricky to use. Another specialty tool to avoid is PiM for managing multiple Python installs. He also suggests avoiding Anaconda if you're not doing data science, and only using Poetry if necessary and comfortable with it. These tools are very specific and not simple to use.\n\nThe original article advises not to install the latest major version of Python. Libraries may not be up to date, and you may be on the bleeding edge of features. It's safer to hold back a bit depending on your needs. Use only python.org for installation on Windows and Mac, or official repositories on Linux. Installing or running anything outside of a virtual environment is not recommended. Stick to basics like pip and venv for creating virtual environments.\n\nEnsure to use the -m flag when running commands like python pip install to target specific installations. Be explicit about which Python version you use in your virtual environments. The Python community is diverse, so it's essential to provide advice that targets a broader audience rather than a specific group. Providing advice for the masses is crucial.\n\nThe tools mentioned to avoid are intended for specific use cases, and using them outside of those cases can cause issues. It's important to consider the intended use of the tools before using them. For example, PiM may not install a full version of Python, leading to missing components in the standard library. It's crucial to understand the tools you're using to avoid unnecessary complications.\n\nOverall, it's essential to be cautious when using specialty tools and to stick to reliable sources like python.org for installations. Virtual environments are recommended for running Python code safely. Avoiding unnecessary tools and focusing on the basics can help streamline the Python development process.Someone who is a client of your operating system that'll solve your problem. Yeah, someone who is told, \"Hey, you should use Python instead of Excel.\" And now they're going to learn a new OS and a terminal paradigm. And while you're using and while you're at it, use Emacs because it's better. Anaconda is kind of a similar thing like I experienced in my first days in an office using Python. It was a \"quote unquote\" Anaconda shop; this is what we're going to use. All the articles I would see would say pip install this, pip install that. Well, it's not great to mix using conda for their virtual environments and then using pip. It has its own package management stuff; stay in that realm, do it all there, and it's fine. But if you start mixing things and crossing things over, bad stuff will happen, and that's hard.\n\nIt's hard to learn until you've already kind of messed up your environment. It's not that it will solve all your problems, but it will make a big difference. They go through each little piece of advice, and I won't spoil it because it was a very good read. I really enjoyed it a lot and appreciated what they were putting in there. So, I'm looking forward to reading more from \"Nobody has time for Python\" and \"Byte code.\" I think it's a nice resource, and it was fun reading this. Just typical advice for beginners, these are a good set of six standards that will help most people get by. Edge cases will be edge cases, well, and I think it's important advice, not just for beginners, but for those of us who aren't beginners to remember what we're telling beginners.\n\n\"What is gravity?\" Well, if I'm answering the question to a five-year-old, we're going to talk about Newton and apples, not about bending space-time. You have to understand your audience. You're standing watch this movie from Nolan, that's right. You comment about the article starts out, \"Don't say simply.\" That's another one of those words that you're supposed to avoid. I had a prof who had, I think it was almost a vocal tick; he used the word \"obvious\" a lot, and the problem was the course was quantum mechanics; there's nothing obvious in that ever. Every time it came up, you could just hear the entire class sort of groan. It's like, \"Yeah, here's a third-rate differential equation, and we go from here to another level, and obviously no.\" After 30 years, it's now obvious to him. Yeah, you lost me three chalkboards ago; there's nothing obvious about this at all.\n\nI love those university chalkboards that can rotate up and down and move around. Anyway, I think that gets us to our discussion this week, and we're heading into a discussion on Hacker News called \"Is parallel programming hard?\" and if so, what can you do about it. We're looping in something that is kind of on the same topic, which is an opinion piece that everybody who's posted about this has modified his title slightly differently on Pi coders. I called it \"Async IO: Why I Hate It,\" and it's by Charles Lifer, who's the creator of Pee Wee ORM. The question being posed is sort of two parts: Is parallel programming hard, and what can you do about it?\n\nCould I pause you briefly? It's referencing a book by Paul E McKenney, and it's a free PDF that you can download. It's 662 pages, and it's about doing parallel programming in C, its most recent revision. It's interesting because the whole book's premise is about this question, and it's a very deep dive, more like a reference book than something you'd read from front to back.\n\nThe first part of that question, is parallel programming hard, if it was just that, we'd say yes, and there you go, we'd be done; it'd be a short conversation. The second part is where it gets interesting. The internet being the internet and Hacker News, sometimes you get nice stuff and sometimes you get the internet. The first good chunk of this article, almost half of it, is really just a drawn-out conversation about vocabulary where everyone assumes that the way they were taught was the one true way and everyone else is wrong. It gets into a deep semantic difference between the words parallel and concurrent when you talk about parallel and concurrent programming. Depending on how you were introduced to the space, these are either synonyms or subtly different.\n\nI'm not particularly interested in arguing over nouns. Personally, in my head, they are synonyms, but in all fairness, that could be because I'm misremembering the textbook definitions that I haven't read in 20 years.And so, if you're going to look at the discussion, you might want to scroll past the first little bit. Although there is some interest in where the semantics of it come from and where some of the confusion arises. This is always one of the things if you're talking to somebody about a topic that's new to you; understanding how they're using words and how it might be different than how you're using words can be rather revealing.\n\nThe two main concepts that drive these kinds of programs, whether you want to call them parallel and concurrent - I'm not going to get into that argument - are the idea of I/O bound work and CPU bound work. The first is the stuff that spends all of its time waiting on input or output, like data coming in over a network. The second is whatever pegs your CPU and the next thing getting done is waiting on the CPU becoming available. How you approach these two different problems is different.\n\nThreads work for I/O bound because even if you have a single CPU, one thread can be put asleep while it's waiting on some I/O and you switch off to another thread. So let's say you're writing a program that reads content from a bunch of different websites. The processing that you do on that content will likely be several orders of magnitude faster than the time it takes to fetch the content. So you can have many threads, each one fetching something, and then you wake up when it's been fetched and you do your processing.\n\nBy contrasting the CPU bound case, this doesn't work. If I'm trying to compute primes, I'm not waiting on I/O, I'm just doing math in the CPU. The only thing I can do in this case is add more CPUs. Independent of these two concepts is a separate idea, sometimes called trivially parallel or embarrassingly parallel work. This is a problem where the division of labor between the pieces is obvious and there's little to no interaction between the different parts.\n\nVery few problems are embarrassingly parallel, and even those that are, you end up in this part of the time is embarrassingly parallel but not all of it. So there's chunks that you can get speed up by throwing more threads or more CPUs at something, and then there's chunks that you don't. The challenge comes in when you have to deal with situations where threads are communicating with each other, leading to concepts like deadlock and race conditions.\n\nI did my grad work in this, and the joke I often make is the only thing I really learned is to try not to do it. In fact, one of the comments in the discussion thread is that you'd be amazed how much you can accomplish these days on a single thread with the right optimizations. Essentially, the argument is to not do parallel computing unless you really need to. It's that whole premature optimization thing that people fall into.\n\nIt also connects to how time-bound you are. If you're working on petabytes, you're going to have to do something along these lines. But if your processor takes a minute and 30 seconds instead of a minute and 29, you might just want to wait the extra second rather than garner the overhead. The complication and how all this comes back to the async IO article is that there are a whole bunch of different ways of doing threads and how threads behave, even just within Python let alone going out into other places.Charles' primary premise in his article is basically that he hates it, so don't use it. He talks about using things like threads and G event instead. His argument is that async IO is cooperative threading, which means the thread doesn't give up and get passed off to another thread until it willingly gives up. If you haven't written your code in a well-behaved fashion, the other threads will just sit there and starve. There's some real trickiness involved in this, so be careful diving into this particular pool.\n\nI wonder sometimes about the motivation behind writing some of these things. We talked at the beginning of the whole thread thing about battling over semantics and word choices. But I have to argue that I've talked to a handful of people already on the show about using async IO, and it's working great for them. Many of the new frameworks are doing a lot of that work for you. Part of his argument is that if you are using language features to support asynchronous mechanisms, it has to be all the way down the stack.\n\nIf your library is built on a library that's built on a library that doesn't support asynchronous mechanisms, your asynchronous call may get converted into a synchronous call, losing all the benefits. This is why you start seeing asynchronous-specific libraries. For example, if you're using the requests library, which is synchronous, you can use ahttp, an asynchronous version. It's not just about adding a new keyword; you have to figure out which libraries to use.\n\nI personally find it easier to wrap my head around threads than co-routines, but that may be due to my bias from writing threads in C 30 years ago. You need to ensure that the whole stack of libraries and imports follow the asynchronous model. The pace of adoption varies, as seen in larger libraries like Django versus Fast API, where Django is slowly introducing asynchronous features.\n\nRegarding the video course on speeding up Python with concurrency, it dives into explaining computers, latency, concurrency, threads, race conditions, async IO, and multi-processing. It's a good intro to the topic, including sample codes to try out. It will be our spotlight for this week.This week, I want to shine a spotlight on another Real Python video course. It covers the topic discussed this week and is an exploration of multiple forms of concurrency in Python. The video course is titled \"Speed up Python with Concurrency\" and is based on a Real Python tutorial by previous guest Jim Anderson. The video course is presented by my co-host Christopher Trudeau. \n\nIn the course, you'll learn the following:\n- How I/O bound programs are affected by latency\n- Which concurrent programming patterns to use\n- How race conditions complicate your concurrent program\n- The differences between I/O bound and CPU bound workloads\n- The differences between the Python concurrency libraries\n- How to write code that uses the threading, async IO, and multiprocessing libraries with code examples\n\nI think it's a worthy investment of your time to learn about the concurrency methods available in modern Python and the various ways it could speed up your programs.\n\nLike most video courses on Real Python, the course is broken into easily consumable sections. Each lesson includes a transcript with closed captions, and you'll have access to code samples for the techniques shown. Check out the video course by finding a link in the show notes or using the search tool on realpython.com.\n\nI think that brings us to projects, and I'll go first. My project is called \"pymg,\" a better display for stack traces. The project is by Muhammad (username: mimsai) and Amir Malik Yen on GitHub. It's a CLI tool that interprets your Python files by the Python interpreter, displaying error messages in a more readable and easier-to-understand way if an exception occurs. It's one of those prettifying tools that help you understand what's happening. \n\nThis tool requires Python 3.11 and utilizes the pi compile module and the Python interpreter to ensure the syntax of the Python file is correct. It uses the subprocess module to capture the output and a feature called a mirror file to imitate what's happening in the source. The tool adds a piece of code to your source to capture the data of the exception that occurred. It's a neat command-line tool that can be useful for teaching about stack traces.\n\nNow, for the project I have this week. It's a testing toolkit called Faker File by Arthur Barskine. This tool generates files for testing purposes, supporting a variety of file types including images, MP3, PDF, PowerPoint, Excel, and more. It also handles different storage mechanisms like writing to a file or S3. It has both a command-line interface and a programming interface, making it versatile for different use cases. I haven't had the chance to play with it yet, but it seems like a useful tool for generating test files.But it even integrates with Django. So if you've got an ORM that has a file field, you can poke it and say, \"I'm going to generate this kind of file for that and put it into your testing things.\" So I did run into a couple of rough spots. It comes in a collection of packages, so there's the base package and then common and others. For example, if you're not using Open Office, you don't have to install that sub-package.\n\nI went to use the CLI, and it requires a certain subset, and it didn't work because I did pip install. So if you want to use the command line, make sure you've got the right package. After running into this, I filed a bug, and Archer almost immediately replied back, pointing out it was in the documentation. So, my bad for not seeing that. We had a quick conversation, and now he's putting in a try-except wrapped in a print message like two hours later. So there was a quick fix in here, and now it'll at least tell you what went wrong, rather than just saying, \"I can't find this.\" It's always nice to see the maintainer be quick on their feet with this stuff.\n\nThe other little complication I ran into is probably a Mac-specific thing. The generated files go to Temp, and on Mac, that's this weird buried subdirectory that can be a little hard to find. Yeah, that's the odd place. Inside the script, the name was relative, so I couldn't figure out where it was putting it, but the command-line tool does show the full path. Once I knew where to look, it was like, \"Oh hey, look, there's all my other files that I generated.\" But like I said, I think that's a Mac-specific thing, and neither of those things are problematic once you figure them out.\n\nHaving the ability to feed test files to your software is pretty cool. In fact, one of the examples I was playing with was a ZIP file, which generates the internal so you can say, \"This is a ZIP file with text files and an Excel file inside of it.\" You can have a ZIP file with a nested ZIP or whatever your use case is. This is definitely worth checking out if you're playing around with software that is pulling files in as input and you want to include this as part of your testing.\n\nIt looks really handy. One thing I want to mention is that it uses square bracket notation for how you want to pip install it. One of the choices is Faker-File. Sometimes that is odd depending on your terminal. It may not like square brackets, so sometimes you need to put that whole string after pip install in quotes, and it usually works much better if it has that square bracket stuff. If you're getting some kind of strange error, there are examples of square brackets common, or you can go into this specific if you don't want to install too much.\n\nIf I remember correctly, if you use the common, that was what you needed for the CLI, was like the base one. This looks fun. Always need fake data. It's very painful to create on your own. Well, thanks again for bringing all these articles and projects this week, Christopher. Always fun. Talk to you soon. Bye.\n\n[Music]\n\nI want to thank Christopher Trudeau for coming on the show again this week, and I want to thank you for listening to the Real Python Podcast. Make sure to click the follow button in your podcast player. If you see a subscribe button, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "VsR7ckUIjYk": "Welcome to the Real Python Podcast. This is Episode 163. How much Python do you need to learn to start creating projects? What's a good balance of information and hands-on practice? This week on the show, Eric Mathis is here to discuss his book Python Crash Course. As a former high school science, math, and programming teacher, Eric saw something missing in the programming publishing landscape. We discussed the guiding questions that inspired the book's development and the title. Eric covers how the crash course takes readers through a fast-paced introduction to Python that culminates in three unique projects. We also discuss Eric's blog, Mostly Python, where he digs deeper into technical subjects. He also occasionally shares more topical posts and includes exercises with many. \n\nAll right, let's get started. [Music] The Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Hey Eric, welcome to the show. Hi Chris, thank you for having me. Yeah, it was really fun running into you and talking to you briefly at PyCon. I got a chance to meet the big fish from No Starch Press, as he likes to call himself on his business card. Yes, so we had a little interview recently about a hacker initiative, which was really kind of neat. And it was really cool talking to you. Yes, I enjoyed meeting you. So I wanted to have you come on and talk about the Third Edition of Python Crash Course, and we might also get into various other kind of topics and teaching in general as your background of being a teacher. But I wanted to start with a quick question, which is why Alaska? Why Alaska? That is a fun question. I grew up in New Hampshire in the 80s, and when all my friends started getting driver's licenses, I got my driver's license but I kept riding my bicycle. Hence, I have traveled by bicycle all my life. So in my 20s, I started riding across the US on a bicycle. I've crossed the US, I think, five times now. But I enjoyed those cross-country summer trips so much that I quit my job and lived for a year on my bicycle. Wow. And for that long trip, I rode from Seattle across to Maine, down to Florida, over to California, and up to Alaska. So that's pretty good sense. The first time I reached Alaska was by bicycle, and I went back to my home in New York City at the time and lasted three years before deciding to just move to Alaska for good. Okay. Charmed you completely when you went. It did. Well, cool, nice. Okay. So that was a choice as you're teaching that you have done in your background. Were you doing some of that in Alaska at the time? Yeah, I studied physics in undergrad, and originally I was going to be a particle physicist, but I didn't want to be a student until my 30s. So I tried teaching for a while, and I found that the intellectual challenge of trying to reach everybody in the classroom was as hard and as satisfying as hard science. And so I just stayed in teaching. Yeah, it is the challenge. I taught at a school for recording engineers, and so these are kind of just outside of high school, kind of secondary education. And it is a challenge to keep people engaged. And I always called it like infotainment that I would have to do to keep people engaged. You almost have to add all the jokes and comedy routines and whatever to keep people engaged. And I think this is, you know, there's always a nice personal way to start conversations, but it also informs everything I do in teaching and then writing a book. One of the clearest things for reaching everybody is about relevance, making what you're doing relevant. Yeah, that makes sense. Yeah. So I started teaching in middle school in New York City, did that for seven years, and then moved to Alaska and I taught another 20-ish years here. At some point, you just started saying \"ish\" by decades. Sure. Yeah. Was Python a big part of that at all in your teaching? So my programming background, my dad is a software engineer in the 70s and 80s. So my first programming experience was learning to write a short number guessing game in BASIC on a kit computer that we had in our unfinished basement in the late 70s, early 80s. I loved it. And through the undergrad work in physics, I had some exposure to a bunch of different programming languages through high school and college. So I got the classic 80s kid of BASIC, Logo, C, Pascal, Fortran, probably some others. And then in the early 2000s, I was mostly Java work and some JavaScript. And then somebody said, \"You should try Python.\" And they did. Just as a kind of a general question, what do you like about Python? So that was 2006, I believe. Okay, that's early Python. Yeah, still kind of, yeah, it is. And so at that time, I was writing my programs in Java. And for people unfamiliar, Java is a statically typed language. So you have to declare all your variables before you use them. There's a lot of boilerplate to use for every single program.And so somebody told me that I should try Python. Your programs would be about a third as long as they are in Java. That was a really bold claim but also fascinating. Yeah, and I tried it and my Python programs looked weird with the whole white space thing, but it was exactly as that person described. That was just kind of mind-blowing. Yeah, and as people say, it was just fun. There's something about Python that just fundamentally made it more fun. Yeah, have the things that you like about Python changed over time?\n\nAbsolutely, and I think I'll hold off on that for a moment because this kind of gets into the book and then come back to what's changed. Yeah, okay, what I like about Python has changed a bit. Yeah, that makes sense. Yeah, cool. Was there a deciding factor for you to become an author?\n\nYes, and it comes back to, you know, was I teaching Python? So most of my teaching career has been in Math and Science, but because I was always a hobbyist programmer, I would try to sneak in programming classes whenever I could fit them into the curriculum. Okay, so I taught a bunch of intro programming classes over the years. One of the most enjoyable experiences was when I first came to Alaska, or actually when I returned to a teaching job after taking some time off. We had 30 Windows computers in our school and 27 of them did not work. Oh man, so that was 2008, and I had this as my first exposure to No Charge Press as well. I had just read Ubuntu for non-geeks that summer as my intro to Linux. Okay, and so that funneled into teaching students to install Linux on those 27 computers and got them working. Yeah, the students maintained our fleet of computers for two years, which is fantastic. Wow, that's pretty cool.\n\nAnd so eventually, the district reinvested in infrastructure and we got new computers, and the students were no longer administrators. But it was a really good experience. Yeah, just kind of quickly thinking about the book, who's the intended Python developer for it?\n\nVery good question, very fun question. And it kind of comes back to your question of, you know, was I always thinking of writing a book? How did that come about? So yeah, you know, I choose that times how kind of blunt and open to be about this, but one of the real impetuses for this was my father dying because my father died in 2011. And my mom asked me to go through his computer and tell her what was worth keeping, was there anything that she should know on his computer as a programmer. So that was a really profound experience and really humbling. And I saw these projects that would never see the light of day. To clarifying that my father grew up in a time where like you kind of had to make software perfect before you released it because releasing meant writing to physical media, distributing all over the country or all over the world. You're not going to be able to put updates to that disk that's way off in another country. I realized that if you took my computer and looked through it the same way, you'd find all kinds of projects I would never. So I realized that I had spent a good part of my life becoming a reasonably competent programmer, and I was looking for something to apply my programming skills to. At that point, I had never done any professional programming work. It was all hobbyist, but I had started to use it to address the inefficiencies in education.\n\nSo I went to PyCon in 2012 with the goal of finding out if there was any role for me in the programming world. Okay, and I was really intimidated to go because I didn't think of myself as a programmer, and people described the Python community as welcoming, and I sure saw that the first night at the hotel in PyCon. Oh, cool. I ended up in conversations with a few people, and I found that immediately found that half the clothes running into were really good programmers looking for what to do with their skills. And half of the people were people with specific domain interests looking for how they could use programming to do their own work more efficiently and better. And was Python the fit right for that? So my goal coming to PyCon was to get more grounded in using programming to address inequities in education. And so I was going to write kind of infrastructural software for educators, a good quick way to say that is to this day most teachers write their lesson plans in Word.\n\nYeah, it would be like writing all of our code still to this day in Notepad with no programming support, right? And so what they're, okay, you know, it's easy to think like, okay, teachers can't work quite as efficiently, but what it really does is if you write three years of lessons in Microsoft Word and then you learn how to teach better, but that teaching better requires slightly a slight restructuring of your lessons, there's no way to go back and restructure all the work that you've already done for curriculum development. And so what that really does is it holds people back from implementing better teaching strategies, and so there's all kinds of foundational things that we have figured out as programmers because we can build whatever tools we want.Yeah, it feels like education, nobody has voted out that balance of profit motive making tools that sell well but aren't great versus open tools that aren't developed to the degree of policy they need for widespread use.\n\nI had an experience using a learning management system, Moodle, probably 15 years ago. It was a very interesting experience.\n\nI'm not sure how it's advanced since then, but I talked about it on a recent episode about tools that come out and try to be a one-size-fits-all thing, and it is very awkward. To bring it to the book, I gave a lightning talk at PyCon 2013 about all this. It was intimidating as a teacher to speak to 1500 people at a programming conference when they're all looking at their laptops and phones. I wanted to say, \"Put those away.\" It's very different, but everybody looked up because I said a few things about how proprietary software would never address issues in education. If you have 1500 programmers, as a whole, people have initiative. People have figured out how they learn, found teachers that work for them, or found resources that work. If we don't have a way to start getting things done, a lot of those people have chips on their shoulder about things that were done to them in their educational experience. After I gave that talk about how we could improve education by taking some ideas from the programming world and bringing them to the education world, not just resources but how we do the work, about 20 people lined up to say, \"Here's my educational trauma story, here's how a teacher treated me poorly, and I hope you build what you're talking about because it should improve education.\" One of those people was Bill Pollock, the founder of No Starch, and he said, \"I like what you're doing, what you're talking about. I hope you build it, and if you want to write a book, here's my card.\"\n\nI didn't want to write a book, I wanted to go back and build an education infrastructure. But I went back to my classroom and had a poster on my wall titled, \"What's the least you need to know about programming in order to do your own projects?\" It was a list of topics like variables, lists, dictionaries, and a few common kinds of projects people tend to be interested in. I realized that's the table of contents for the book I wish I could teach from. That was 2013, and at that time, all the programming books available made too many assumptions about what people new to programming knew. They were either for kids or made assumptions that didn't work for people, so I wanted to write a book for anybody old enough to not want.\n\nIt's quite a wide audience, not designed for a common type of book where people have more background in programming languages. It's designed to start from the raw fundamentals and talk about programs. It's interesting to trace the history of programming books back to when there were no books, just manuals, then programming books by programmers for programmers, and now more pedagogical grounding for programming books in the last 10 to 15 years.I would agree that it's definitely reaching newer sets of authors and opening it up. Also, it's easier to write a book, but not necessarily easier to sell one. The bar has been pushed higher, as just dumping technical information into a book format is no longer enough. You have to follow through and ensure that you are teaching and reaching your audience.\n\nAs I look at the table of contents and the topics covered, I wonder about concerns regarding covering a large number of topics in a single book or including three sets of projects. There are two things to consider: projects and coverage. It all comes back to the purpose of teaching and giving people the ability to understand themselves and the world around them.\n\nWhen teaching programming classes, I always start by discussing projects to give purpose to what students are learning. This inspires motivation and provides context for applying the information. The exercises in the book are intentionally designed to set people up for success, even if they may seem repetitive at first. It's important to practice and put in the work to truly learn programming.\n\nIt's like exercising your body - you need to start somewhere and build up your skills. Jumping straight to advanced concepts may be overwhelming, so it's important to start from the basics and work your way up. This approach may receive pushback from those looking for more challenging exercises, but the goal is to ensure that everyone can succeed in learning programming.I can see why it's important from my own experience trying to get people to do things in the video courses that I create. It's important to type and follow along and get the keyboard under your hands. I recently started getting piano lessons. My wife got me three piano lessons for Valentine's Day this year, which was perfect. My teacher has helped me choose a harder piece that's my goal. I can play individual measures, but my real joy is the starting exercises that I can try to play well. People familiar with playing instruments can relate to the idea of having bigger performance pieces and smaller exercises to learn specific skills.\n\nOne of my problems with music teaching has been that they often have you play songs that may be boring or not popular music. It's similar to the exercises you do. Are you creating something you want to show others? I wonder if this is similar in programming, where you want to be doing something of interest, not just an exercise. Good teachers separate themselves by telling people when to expect their skills to be good enough to interact with their visions in the field.\n\nMusic has shorter, simpler pieces that can sound good if played well. For people learning programming, there's a myth that you can read an intro programming book and get a high-paying job. Including projects in the book helps people go from knowing nothing to building a functioning web app they can share with others. It's different from just learning coding skills and then finding a project to apply them to.\n\nBuilding a web app, a Space Invaders clone, and data visualizations are projects in the book. The goal is to go from knowing nothing about programming to having a complete product to show others. Keeping the project section up to date is a challenge due to the changing world. The title \"Python Crash Course\" is a format that No Starch Press uses. Other books in the series use the same format, and it has become a signature style for the publisher.I'm gonna be a little hazy on some of the history of this idea of two books in one really did come back to that experience of walking back into my classroom after being invited to write a book and seeing a poster on the wall that had a list of things you need to know and project you could consider. When I put the proposal for the book together, I don't think \"Python Crash Course\" was the working title for the proposal. I think that was kind of workshopped from interactions with No Starch Press, and I think Bill might have come up with that title. I do remember being asked at one point as the book expanded from the anticipated 250 pages to 550, \"Are you sure this is still a crash course?\" Yeah, but it was ambitious. So, sometimes I shake my head and think, \"Oh, this whole idea could have flopped. People could have looked at this book and said, 'This is way too much.' But I think the scaffolding really does work.\"\n\nOne of the things I was going to mention earlier is in the development of programming books in the 90s, programming books were like two to three hundred pages. And into the early 2000s, some of those books literally grew to 1500 pages. That's a heavy book, and it's not really a book at that point, it's a reference. So, there were authors who started their writing in the late 80s into the 90s where programmers couldn't necessarily rely on an internet connection. And if they had an internet connection, they might not have access to full reference materials for a language. So, some of those really massive books really grew out of an over commitment to that idea of documenting everything in a language in a book.\n\nThis week I want to shine a spotlight on another Real Python video course. It covers a topic that we touched on briefly on the show: creating visualizations with your data. It's titled \"Plot with Pandas: Python Data Visualization Basics.\" The course is based on an article by previous guest Reka Horvath, and in the course, Darren Jones takes you through the different types of pandas plots and when to use them, how to get an overview of your data set using a histogram, how to discover correlation with a scatter plot, and how to analyze different categories along with their ratios. Whether you're just getting to know a data set, preparing to publish your findings, or making a presentation, creating visualizations is essential.\n\nThat kind of brings me to a question I have about some of the techniques of how you reveal things as you go. The example I had was, do you stress about showing ideas early in the book and then explaining them later? An example would be you show this concept of multiple assignment that's done through this Tuple syntax on page 28, and then you don't get to explaining what a tuple actually is until like page 65. I wonder if there are people that could look at that and go, \"You're not even naming that thing,\" and if that is a complaint or if it is advantageous to do it in this way.\n\nEverybody who would look at that passage and say, \"Hey, you didn't name that thing,\" is somebody who already knows the name of that thing. So, when you know the name of that thing, you can look at all the other stuff being introduced, ignore that because you already know it, and just focus on this thing that's not being named. If you try to name and explain everything as it comes up, you're going to overwhelm the person learning. Teaching programming is different than many other topics because people have access to immediate feedback. If something works, people can see that, and if something breaks, they see it right away. Python is even friendlier now about telling you what you did wrong, which is fantastic.\n\nI watched a presentation at one of the Ed Summit education Summits at Python a few years back where a classroom teacher shared the first code example that they show all of their students on the first day of class.It was something like a user class or a student class. It has an admit method, maybe a greet method, and several attributes like name, age, teacher, and whatnot. They would just show that .py file to their students and ask their students what they saw, starting with questions like what they think will happen when they run it. In a group setting like that, where you can facilitate the conversation, people can work out what might happen due to the readability of Python and the reasoning skills of students. This goes back to the material, the instructor, and the learner's approach to teaching.\n\nLearners have intuition, and some have more than others, with more access to their intuition. Seeing people unpacking early on without it being named, people can see they can define more than one variable on a line. They can either keep using it or name it, explain it, and keep using it. The balance of how much to explain is an interesting one for teaching. Functions and importing modules felt early to me, but it's important for students to know because they will see it in other people's work.\n\nThe guiding question for the book is about what's the least you need to know about programming to take on a project you care about. It gets you started doing things and allows you to fill in the blanks later if you want to go down the rabbit hole. Lists are the favorite thing to teach because you can take someone from printing \"Hello, World\" to understanding how to deal with more than one piece of information in a list in 20 minutes.\n\nYou need to know how to add items, take items away, access items, and loop over items in a list. Combining two lists is not necessary right away. The goal is to go deep, and that's what real Python does. The newsletter python.substack focuses on helping people understand the basics and getting into intermediate and advanced topics. Each series, like focusing on lists, leads to learning more about the internals and beyond.I don't know, maybe a third of the way in the book, I would argue that the difficulty starts to ramp up. You get the functions and then I mentioned importing there, and then boom, you're in classes, kind of learning some of the fundamentals of OOP, but not the crazy super intense deep dive, which is important. And then you're in files, which is combined with exceptions, and then you're in testing, which I think is also really interesting to add in this type of book.\n\nYeah, I was going to say, the guided question is what's the least you need to know in order to work on your own projects. So another guiding principle for me in choosing what to include and leave out is how easily can you learn this thing if I don't include it. Okay, so with lists, we have to show people how to add items, remove items, access items, but when you get to something like, do I need to show people how to combine two lists, can they easily look that up if I just Google \"python combine two lists\"? If the answer is a clear yes, then that's a strong candidate to leave out of an intro book.\n\nI think another reason for the success of \"Python Crash Course\" and the reason it works for so many people is because of that careful curation. It's almost like you could have that massive glossary of terms that would fall underneath each one of these sections. Like, okay, well, these are all the methods that they could learn about, and then are you just starring the most critical path? Yeah, I think that's what the Mark Lutz book was, \"Learning Python.\"\n\nIt's definitely an O'Reilly book, and Mark Lutz is the author with David Asher. It's like a 2003 book, the second edition, which I don't know if there's a high graph that'd be okay. I know where I was going with that. I graphed the page count for that book, which has helped me think about revising \"Python Crash Course\" each time it came to do a new edition.\n\nSo for the second and third editions, my goal was to not increase the page count of the book. I was going to ask you about things that you decided to change, and that's a guiding principle too, then. Yeah, which is interesting as Python grows more features. It's been interesting to go through each new feature that Python introduces and ask, is this something that my audience needs to know in their first exposure to Python?\n\nAs much as we like a lot of the new features, a lot of them I don't cover. Like I don't cover the walrus operator. I do cover things like pathlib, and it's really enjoyable to see changes. Yeah, it's a fun update and a fun update to my own workflows. Yeah, I just looked at the table of contents, and it goes on for I don't know how many pages for that book.\n\nYou brought up something interesting that I haven't really responded to, and that is the jump in difficulty that comes in the course of this intro material. I just wonder, like, is that something that people struggle with? Fun questions, I've long said that a book is a promise, especially a non-fiction instructional book. The book is a promise that if you start here with me, I will take you to this endpoint.\n\nThinking about what to include in the first half of an introductory book that's going to lead into projects is kind of defining what that promise is going to be. I would argue that if you want somebody to have a solid foundation as an independent programmer in Python, they actually need to know what functions are. They need to know how to use them, they need to know how to write them, and they need to be aware of some of the complexity of the different ways you can write arguments and parameters. Otherwise, it's not going to work right. They don't need to master that, especially arbitrary numbers of arguments in arbitrary keyword arguments. Those are kind of heady abstract concepts for someone who's new to programming. They should be aware of it.But they shouldn't expect Master it as far as working with modules goes. People do need to understand how to split a growing program over multiple files, right? So, I feel like when you start to use functions is a natural place to see that. Maybe you don't use it, I mean, it's interesting to watch people's workflows on brand new projects. Are you the kind of person who sets up multiple files and starts working in a nicely structured way right away, or are you somebody who tends to work all in one file and then split things out as they grow?\n\nThat's an interesting question for experienced programmers. I think about so many beginner books kind of approach it as, \"Let's just get you to be a scripter.\" Yeah, and I think that you're actually kind of teaching somebody to be, or at least introducing the concepts of like, \"Hey, this is how you can grow something so it's actually manageable, at least you have structure, and kind of see how things can interact with each other, and it's used everywhere else, you know, if you go outside the script world, you know?\"\n\nWhat I don't do is teach all the intricacies of the import system, right? But what I try to do is show people what's possible because some people will see a really long single file with a bunch of functions and then calling those functions, and that's perfectly fine to them. And if you try to split it up, it becomes more complex. There are some people who will see that same long file and it will look complex to them because there's so much in that one file. And if you split it up, it suddenly makes more sense to them. So, you kind of, as a teacher, you have to be ready to serve both of those kinds of learners, kinds of workers, yeah.\n\nYou already mentioned some of it, but like this is the third edition. I'm not sure when the first edition came out, but what were you excited about rewriting in this version of the book? Alright, so I'll use that as a segue to get at the testing question as well. Sure, so the testing chapter I think is about 11 or 12 pages. I did not learn about testing until I was about 20 years into my life as a programmer. I would say that's not uncommon, yeah. And so when I finally learned about testing, it was so much simpler than I thought it would be. Okay, a complex test suite is really complicated and hard to wrap your head around, but writing a single test function and then a small set of like three or four test functions is not really difficult.\n\nAnd I like sleep. I particularly like walking away from my computer and being confident that I'm not going to be surprised by bugs, new bugs, and errors, sure. And so testing is what gives you that comfort in that sleep, the ability to walk away from your computer for a while. And so my goal, and you can I think you can see this in that chapter, my goal is not to teach people much of the intricacies at all about testing, but just to show that it's possible, show what it does, and just plant that idea so that it's not a big scary thing that you've never seen before, okay?\n\nAnd again, like Pablo's work on error messages in Python just blows my mind to have a tool that makes testing simpler than it was in the standard library. Well, that's the thing that I feel people feel like they have to teach is the standard library way, and it's like just because it existed before this fantastic tool is here, is this really the best thing to show a beginner or somebody that you want to just get introduced to the concept? Or should we show them something that's going to make their life not as difficult, but it's just like it's kind of clunky, you know, in some ways. And you can show lots of, it's an interesting idea, you know, to say, \"Hey, let's just jump to this,\" yeah?\n\nSo, okay, you asked what I'm excited about updating. I was very excited to drop unit test and move to Pytest. Pytest just amazed me because it's one of these packages that is simple enough that it's appropriate to teach to people as their first experience testing, yeah, but complex enough that organizations should use Pytest for their tests. That's a strong testament to how well-designed that package is, yeah.\n\nBut the first edition came out in 2015. I started writing in 2013. I naively thought I could draft it in the summer and then revise it during the school year, and it turned into two and a half years of early mornings and late nights, but at that point there was no established single third-party library for testing. It was kind of tossed up between nose and Pytest. I stuck with the standard library unit test at that point, but Pytest has clearly emerged as the go-to third-party testing library. So that was kind of a nice thing that you were excited about maybe rewriting. And yeah.And it also the nice thing about that is everybody's experience of installing a third-party package in the first half of the book, right? Because when people finish the first half, they can then go on to the video game project, the data visualization, or the web app project. All of those require third-party packages. So, it's kind of awkward to say if you haven't installed a package, go look at this. But if everybody's done that with Pi tests, you can just use the same PiV install that they already used. Yeah, that's good too. I mean, get them up to speed in that process. I think it's interesting. I wonder if you had doubt in your mind as you were assembling these things, that you're like, \"Is this going to work? Is this enough information for them to get there?\" Was there some questioning, or did that get worked out during the review process of the book? That is an interesting question.\n\nYou know, when I revised it, everybody who touched the book was free to tear it apart because it had not been tested by end-users. With the second edition, I just took a step back and said, \"You know, one of the things I'm proud of is I have responded to just about every single email anybody has ever sent me about the book.\" And I told Bill that at one point, and he kind of laughed at me with the mindset like, \"You don't have to do that.\" And I said, \"I know when I put those two and a half years into writing the book initially, my goal was to have a book that would be one of the stable Python learning books for 10 years. It's kind of hard to imagine putting that much work into a book and then maintaining it, sure.\"\n\nI'm a teacher at heart. I spend my whole life teaching, and so in some sense, I just plain enjoy hearing from people learning from my work. There's another aspect of it where, as I respond to people, I'm looking for patterns in the questions they're asking. Yeah, and so if somebody has a one-off question about something nobody's ever asked before, I just answer that. But if I start to see patterns, then I make notes about how to change what's explained in the book in a way that will alleviate those questions. So, I do that all the time in the courses that we have, the video courses. It's like The Sixth Sense movie, like I see questions, I see comments coming, and I would like to avoid that, you know, like if it's possible. If I can help you as the reviewer of your work, you know?\n\nAnd if you do that well enough, then the questions remain interesting because people aren't asking the same questions over time. They're new, and my unique questions are interesting. So, when it came to writing the second edition, writing the Third Edition, particularly by the Third Edition, there were things that would come up. Chapter eight is about functions, and if a reviewer suggested changing some, I had an experience where one of the reviewers suggested changing pretty significantly one of the passages, and my response was literally millions of people have learned about functions from this page. I have to weigh the points you're bringing up against a million people not asking me a question about that one page.\n\nI say that very objectively. I have appreciated the staff and everybody who has worked on the book coming at the project with an open mind of being critical. But it's interesting as a book ages to start to weigh individual questions against that collective experience that everybody has read it. Yeah, I guess we could talk about the changes maybe of what has happened with the projects. Have they changed across versions?\n\nIt was interesting. The Space Invaders clone is called Alien Invasion, and it uses Pygame. Pygame is another library that I'm so impressed with. It just remains so stable over the years, and it's still good. It's such a good experience for people to use what they've learned about Python. So, people are not writing modern 3D games in Pygame, but you probably shouldn't start by trying to write a modern 3D game. There's so much you learn about how code defines interactions in a game by focusing on a simple 2D game.\n\nI would never go to a machine and play a Space Invaders clone these days, but if it's code that I wrote, I'll play it for an hour. There's something about playing a game that you wrote the code for. So, when I first wrote it, it was function-based. Everything was a function, and by the end, there were like 10 arguments in some of the function calls. So, a bunch of my emails were like, \"Ah, this isn't working. Oh, you got that order of your arguments wrong.\" So, in the second edition, the game became class-based. It's a little more showing objects, yeah. The whole game is an object, so all the functions become methods, and there's just very few arguments passed around. The drawback is it's a little more complicated.So I do get questions from people initially like I don't understand the first couple pages of the game project. But the payoff is huge, so I just tell people, \"Here's an online explanation that goes a little bit further.\" But for the most part, trust it, start to work with it, and you'll start to see how pieces interact. It's been quite satisfying, that's good.\n\nIt seems like the graphing one, you've chosen a variety of libraries over time because things have changed. Yeah, I saw pie gal as the one that you were using for a little while. I don't know if that's the second version or whatever, which I talked about that maybe two years ago on the show. I think it's mostly matplotlib and plotly. Yeah, it is. I enjoyed pie gal, that was the first edition, has stayed in because it is the foundation of so much graphical work in Python. So there are other libraries you should probably consider for professional projects, but most of those are built on top of matplotlib. Having an understanding about how it is really beneficial for making sense of whatever library you choose.\n\nI like that you show styling, that's something that I feel like doesn't get covered enough. People want to make things look nice and make it look their own. Something as simple as choosing that is huge to me. It's hard to teach because I feel like good programming teaching should include references to documentation. You should start to onboard your learners onto the library documentation, but that documentation is so vast. How do you choose the right places to dump people into? It's hard, what city are you sending them on off-ramp to? I thought a good video course would be a guided tour of documentation of some different packages.\n\nYou kind of like during the graphing, person going through it gets to work initially with just some sort of fundamental data, and then you work with CSVs, and then you work with APIs. Were there changes there over time as far as things that you would choose to ramp up the budding data scientists? No, I really described that well. The first chapter of the data project uses computer-generated data, which is nice because you're generating all the data so there's no stability issues. The next part is using CSV files and it's focused on weather data and earthquake data. I set it up so people can download those files from my resources so if those original data sources disappear or change, it doesn't affect the book. The API section is harder, we use the GitHub API and I kind of cross my fingers it stays open.\n\nI went to a conference once, it was for a totally different tool called FileMaker. This person was showing how to integrate APIs into this FileMaker tool and format, and so forth. I raised the question and everybody just stared at me. My question was, \"What do you do if they change the API on you or the API goes away? What kind of things can you set up to make this fail well?\" It was stuff that was in my mind even as a beginner in this platform trying to integrate this stuff. The idea like you have of adding testing in this early book is always kind of the sort of thing. I think APIs are that other thing, like I don't even know, that was like maybe nine years ago or something like that that I went to this conference and they just sort of looked at me like, \"Oh, that's just always going to be there.\" I'm like, \"I don't think so, that's naive.\" That was the vibe I got, you know. It was a strange experience I had where everybody just turned and looked at me like I was the weirdo messing up his presentation. I'm like, \"Well, I'm trying to help other people here by asking this question too.\"\n\nCosmic crash course sells consistently enough that I get to update it. I get to do incremental updates whenever it goes to a new print. And those really should be minimal, but if like the GitHub API disappeared, I could propose a more significant change and have something that works. It is interesting though if you said the last project is a Django web app and I include deployment because the natural question once you have a working web app on your local system is, \"How do I share this with my friends?\" So if you can walk people through deployment, it's just infinitely more satisfying. The first edition came out in 2015, and that was for rookies' heyday.And so it used Heroku. There's a part of me that didn't sleep well for the rest of my life wondering when the deployment process would break. It finally did, and we had the Heroku migration. The Third Edition uses platform.sh, but I have the same questions about stability.\n\nI'm actually working on a project called Django Simple Deploy. Are you familiar with Django? A couple of years ago, I wrote a custom Heroku build pack that, before you push your project with Capo Heroku, you would run a Heroku set build pack and specify this custom build pack. If you then did Heroku main dash dash automate all, it would do everything for you - write your profile, modify your settings, do all that boilerplate stuff, and magically work. It felt like the magic of Heroku, but it was unsatisfying because it felt like doing Heroku's work for them and only worked for Heroku.\n\nMy shower thought was, how could I do that in Django's world instead of Heroku's world? The answer was to write a management command that you give the platform name and it modifies your project configuration for that platform. That's how Django Simple Deploy was born. You install Django Simple Deploy, add it to your installed apps, and run a single command - python manage.py simple deploy --platform. You can name Heroku, flyio, or platform.sh, and if you automate all, your project appears in a new browser window.\n\nYou have to have that platform CLI installed, but you don't have to go to that platform's docs or pre-provision an app. You just make your account, download their CLI, run this command, and your project appears. It's helpful to beginners and authors, as anyone who wants to cover deployment can use this tool instead of teaching platform-specific deployment processes.\n\nThe Simple Deploy project becomes a boundary layer between the teaching resource and the platforms that change all the time. That's cool. It was a big change for this edition. I don't use it in the book yet, but my goal is to have that project stable enough to use for the fourth edition.\n\nI wanted to touch on a couple of quick things - providing additional resources, code, and cheat sheets. I thought that was really cool. Is that something that you've developed through battle-tested classroom experience? The cheat sheets have been downloaded more times than the book is in print, about three million times. They're inspired by Python Crash Course but useful for anyone working through an intro Python resource.\n\nThe goal is to help people feel more confident about the code they're writing. Learning programming is not about memorizing, so you should expect to have to look at what you've been learning in order to write your own code. The cheat sheets are a segue out of always flipping through the book, so you can look at one sheet as you're doing exercises and start to feel more confident about the code you're writing.I made a fill in the blank version of a cheat sheet where I taught the class and asked them what should be filled in. They created their own cheat sheet and if they made the effort in my class, they would have a useful tool. If they didn't bother filling it all in, it would be useless. This is battle-tested information that I have gathered over six years of teaching. These are the areas where people usually struggle, and by writing it down, you solidify your learning.\n\nI haven't implemented this idea for programming yet, but taking notes or using other tools to help solidify your learning is important. I was asked about my flashcards book, and I decided to create flashcards for Python after the success of my book. The goal of the flashcards is to provide a portable set of learning resources that are not bound to a screen. You can pull out the relevant flashcards and test yourself on the information.\n\nI am excited about attending conferences again, especially Python conferences like PyCon and DjangoCon. These events are great for my well-being, especially living in a small town without other programmers around. I plan on attending DjangoCon this fall and participating in sprints for various projects.\n\nI am currently focused on learning more about testing in Python, specifically with pandas. I want to become more fluent in using pandas for analyzing complex data sets. I am also interested in learning about the latest version of pandas (pandas 2.0) and hope to discuss it soon.\n\nTo follow my work online, you can check out the online resources for Python Crash Course at ehmathis.github.io/PCC_3E. These resources are helpful for working through the book and gaining a better understanding of Python.I'll include the links for that in the show notes. I'm writing weekly about Python, mostly Python all one word Substack. The focus for my writing each week is overtime helping people move from a beginner Python mindset to intermediate and into advanced topics, especially around a deeper understanding of Python fundamentals and how we apply it to a variety of projects.\n\nHow long have you been doing this now? I started that in December. I was looking for a way to write more consistently in real time, and it's a lot of work but I'm loving it. It just lets me do deep dives into a bunch of little topics that have some longer running threads as well. We do this Pi coders version of the show that is more about articles and so forth, so I want to make sure that he's aware of it because there's a lot of interesting stuff happening on that Substack. I like what you're writing about.\n\nThank you. Well, Eric, thanks so much for coming on the show. It's been really fun to talk to you. I've benefited from Real Python so much over the years. It's a pleasure to talk with you.\n\n[Music]\n\nI want to thank Eric Mathis for coming on the show this week, and I want to thank you for listening to the Real Python podcast. Make sure that you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "4XKPs64KSgs": "Welcome to the Real Python Podcast. This is episode 164. What principles should be considered when designing a Python library? How do you construct a library API that is understandable and easy to use? This week on the show, Christopher Trudeau is here bringing another batch of Pi Coders Weekly articles and projects. We share an article about building Python library APIs. The piece provides advice for packet structure, naming, error handling, and more. The author guides you toward Pythonic principles by comparing clunky versus elegant design examples.\n\nChristopher discusses his recent video course on Jinja templating. The course covers creating text files with programmatic content and employing Rich templates to structure the front end of Python web applications. We cover several other articles and projects from the Python community, including several news updates: why membership tests are fast for the range function, CLI tools hidden in the Python standard library, a thread about the right way to install Python, recipes for using the Polders library, and a project for feature flags within Django.\n\nThis episode is brought to you by Sneak. Sneak helps Python developers stay secure without slowing down by providing real-time code scanning and actionable fixed advice right from their IDE.\n\nAll right, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Hey, Christopher, welcome back.\n\nHey there. We got a big bundle of news this week. You'd think with it being summertime there'd be less going on, but yeah, we've got a whole bunch.\n\nGreat. So I guess we'll just dig right in.\n\nSo PyLadies has announced that they're planning a conference for December. It's still in early stages, and they're looking for volunteers. So if you're interested in helping them organize and think about these kinds of things, then reach out, and we'll send you a link for where you can do that. Cool.\n\nThe next three items are all from the Python Software Foundation. First, they just recently had their board election and they've announced their five new members. We'll link to the list of that, and I think a couple of them don't you?\n\nYeah, actually, I met Denny Perez, and Denny is actually Real Python's own Andres Panetta's wife who's our community manager. She's very much a community organizer manager and met her when she was volunteering at Podcast.Case. I know she volunteered at PyCon, so definitely a mover and shaker, and I could see why she got some votes there to get involved. And if you're interested and you don't recognize the names or not familiar with those people and want to learn a little bit more about why these people wanted to be on the board, there was a set of interviews that Jay Miller did. He does a podcast YouTube thing called Python Community News, and I'll include a link that is basically a playlist with everybody who's nominated so you can check them out and see what you think. Yeah, good luck to them all. Well, that's a big job and helps the community keep going, so that's fantastic.\n\nSo what else from the PSF? Next, two different job things. First, you may remember there was a posting a while back for a security developer in residence. Well, they've made the hire. His name's Seth Larson, and he's got a great post introducing himself, talking about what the job entails and what he hopes to accomplish. So, again, we'll link to that. And then on the job topic as well, they've opened up a new position to go along with the developer in residence. They're adding a deputy developer in residence. So if this is something that interests you, the applications are being accepted until July 26th. Yeah, you'll be working alongside with, so that should be pretty interesting. And in fact, I think that was one of the first posts I saw was Will McGugan posting, \"Who wouldn't want to work with Lucas?\" So, yeah, there you go, go work with Lucas.\n\nOkay, a couple non-PSF items. Django has released a security fix for their major supported versions. It modifies a potential denial of service vulnerability in the email validator. And finally, PyPI is deprecating eggs. This doesn't really affect too many people as the world has more or less moved on to Wheels. But if you've been coding for a while and you remember the egg format, well, it's going away. Existing projects with eggs will continue to be downloadable. They're not going to kick things off, but new uploads will stop allowing the egg format as of August 1st. And as a side note, any idea why they're called eggs? I dug, I couldn't find it. So Wheels are because of cheese wheels or references, yeah, that makes more sense, which was the original name of PyPI, which is a Monty Python sketch. But yeah, I couldn't find anything that said, \"Hey, all I could ever find was egg is to Python is jar is to Java.\" And I'm like, that doesn't help me, it doesn't explain where you came up with the idea. So yeah, anyways, when I saw that packaging solution of Hatch and Hatchling, I thought that had something to do with it kind of retroactively, but I guess not either. Anyway, but yeah.I'm not sure. So that gets us into topics. I have a real Python one to start with. It's actually kind of a shorter one from Gerardo. I don't know what's happening here. Gerardo has been on the show several times, and he has a new article called \"Why are membership tests so fast for range in Python?\" What he's talking about here is looking for a particular item using the `in` operator to see if a particular value is within a range, as opposed to maybe some other iterable like a list or something else.\n\nI guess it's really an exploration of range in a lot of ways. He does a lot of interesting experiments playing around with similarities and differences and how you can work with them. So, if you like these kind of deep dives into intermediate data structure topics, this is definitely for you. Range is most commonly used by programmers in for loops to iterate over an unknown range of numbers. There may be some other interesting uses for it. \n\nThe big thing he's showing here that's interesting is that you can pick out elements of a range or check whether a given number belongs within that range. He also shows some other similarities. For example, you can actually use indexes on a range. If you did a conversion, like creating a range of 0 to 10 million and then converting that to a list, you could do different things like indexing on them, checking the length, or looking for a certain element using the `in` operator.\n\nHe shows that if you were to time that using `timeit` and they both look for something that isn't existent in that range, there's a significant difference. It takes like 4.6 microseconds in his test to see that it's not there, whereas it takes like 5.7 seconds. The main reason for that is that it's more of a formula as opposed to looking through all the different values in it. \n\nA range has a start, a stop, and potentially a step that it moves at. The step is where you could see a big performance difference. It becomes an interesting optimization. If you're checking whether or not it's a power of every three or something like that, it starts to become messier. The formula that is looking for it would take the element you're searching for, the start and stop of the range, and the step value. \n\nHe goes through and says, \"Well hey, let's talk about this a little bit further. How does Python implement a range?\" By default, range is actually implemented in C, which is partly why it's much faster. He thinks about how you could implement it in Python, and takes you through that process. Range may look like a function because you call it, but if you dig deeper, it's actually a class. Its constructor is when you call `range` and put the different parameters within it. \n\nThe article goes into creating a custom class that works in a really similar way to range, and he implements the different special methods that you would need.[Music]\n\nDunder contains what we were just talking about. So if you call in on that, it would recreate the formula from before.\n\nThe rest of the article talks about whether a range is better than a list. Of course, that's always going to depend on what you're trying to accomplish. Lists can have different objects within them, they aren't ordered or sorted by default. There are also comparisons with sets and dictionaries, so it's a real exploration of ranges and how they're structured. The overarching question is how determining membership inside a Python range would work. It's a fun exploration and I'm looking forward to what Gariana writes this coming fall as we are approaching 312 pretty fast.\n\nThe first article I have is by Simon Willison and it's called \"CLI Tools Hidden in the Python Standard Library.\" There are some runnable tools in the standard library that you can use directly from Python. The two I use most are the Json tool, which pretty prints Json, and the HTTP server. If you're new to this idea, you can run `python -m json.tool` with a file name containing Json to pretty print it. Likewise, you can run `python -m http.server` to host a web server from the local directory. I have a couple of projects where I use these tools fairly frequently.\n\nSimon decided to go spelunking through the standard library to see what else was there. He found over 90 answers, which was quite a surprise. The article talks about his searching process, what he found useful, and highlights some key tools. One tool I hadn't seen before was `python -m site`, which outputs information about Python's dispatch configuration and variables for package locations. Another tool I used recently was `python -m base64` to base64 encode a file. There are also tools for compiler geeks, such as `python -m tokenize` and `python -m ast`.\n\nOne interesting tool mentioned is `python -m calendar`, which outputs a calendar. It allows for different arguments to show specific time frames. Overall, there are some neat tools in the standard library for CLI projects.\n\nThat sounds like a fun little CLI project for people looking to create something quickly. Go play around and see what's there.[Music]\n\nThere are a ton of ways for malicious actors to get into the systems you build, like SQL injection, arbitrary code execution, and out-of-bounds rights, just to name a few. Luckily, you don't have to be a security expert to keep your apps secure. Snyk is a developer security platform that helps you secure your applications from the start. Snyk does it all right from the existing tools and workflows you already use: IDEs, CLI, repos, pipelines, and more, so your work isn't interrupted. Start your free Snyk account at snyk.co/realpython.\n\n[Music]\n\nSo, my next one is from Ben Hoyt on his blog. Initially, I kind of just glossed over the name when I looked at it. \"Designing Pythonic APIs\" seemed interesting, but I missed the word \"library\" in there. So, \"Designing Pythonic Library APIs\" is going in a completely different area. People often think of APIs as web-based application interfaces, but this article is actually about designing your own library and how the end user will use it. How can you design it to be friendly, usable, understandable, and approachable? How do you get rid of boilerplate? It's a well-structured article with detailed insights.\n\nThis article describes principles useful for designing good Python library APIs, including structure, naming, error handling, type annotations, and more. It's a written version of a talk Ben gave in June 2023 at the Christchurch Python Meetup. The article is well-structured, likely because of the thought put into structuring the talk. Ben starts with an example of building an HTTP request using the standard library, urllib.request. The code is complex and hard to parse. He then contrasts it with the simplicity of using the \"requests\" library, which allows for a more straightforward approach to making HTTP requests.\n\nGood API design is crucial for the user. Ben showcases how the idea behind the \"requests\" library started with a clear outline from the very beginning. The first commit to the library is structured as an outline, defining classes and functions needed for HTTP requests. This structured approach leads to a more usable and understandable API for the end user.So it's something like an outline. There's a lot of work that needs to be done, but it gives you an idea. Names have been created, and the functionality should make sense to somebody looking at this in terms of what they're going to do. The takeaway here is when creating a library, start with a good base and then iterate from there. That's the theme, giving you solid examples of where good practices have been put.\n\nSpeaking of practices and talking about things pythonic, he brings up the Zen of Python, which has been a theme for us over the last couple of weeks. In this particular one, he focuses on two of the lines from the Zen. He focuses on two of the lines for this API stuff: \"explicit is better than implicit,\" and \"flat is better than nested.\" This goes to pick on the standard Library APIs, especially the flat is better than nested. He gives a couple of examples, like in the email package, where things seem very nested, and it's like why wasn't it just more straightforward.\n\nHe talks about the advice that he gets into from there about modules and package structure. He uses requests as an example, where the structure is implemented in a way that makes it straightforward to use without importing sub-modules. He goes through the code and shows how it's structured, making it ready to go, which is kind of nice. He then gives another example of how to structure a toy app, showing how to build the API file and the shop file with its class structure.\n\nHe also picks on some other examples of libraries that nest things, like Django. He talks about the historical reasons behind some of the nested structures and how history gets in the way. He mentions pep 713, which has been accepted into Python 312, and how it will help flatten things once people start taking advantage of it.So, it's really diving into this design idea of keeping things fairly simple. It, of course, then gets into naming, which is one of those memes - naming is difficult, finding that weird combination of nouns and verbs. He has some takeaway advice that I'll just summarize here: names should be short if they can, while still being clear. The request package itself gives you a pretty good name to begin with that you can then just tack on, request.get or request.response, and it kind of makes sense as far as noun and verb. \n\nHis feeling is that function names should be verbs and classes should be nouns, but you don't have to necessarily get hung up on it. A language that is a little over the top with this, that I've seen, is like Swift, where it's very much a jumbled set of words to indicate everything that's happening along the line. I'm trying to think of one that he gives as an example, where it's just like a crazy long type of name, like JavaBeans and things like that. It looks like it's all written in German, right, instead of being a sentence with a space in it. \n\nSo, it's just something to think about in that way. He gives some additional gems as you go through it - opinions about exceptions and how that should be done, his ideas on versioning, and then his ideas on type annotations. Generally, I felt like it was good advice. You know, not necessarily have to follow all of it, not unlike or as we've talked about with PEP 8 or PEP 20, the Zen of Python. I haven't seen an article like this where it really kind of delves into why do modules this way, why do this sort of stuff and structure this way, and I felt like it put a lot of these ideas in one good place. \n\nWhat do you got next? Well, it's been a few weeks since I've been all self-indulgent, so once again it's time to talk about one of my courses. Enough about me, Mr. Billy, what do you think about me? Anyways, this one is called Ginger Templating and it's based on a similar article by Philip Axani. If you're not familiar with Jinja or Jinja 2, if you want to be entirely pedantically correct, it's a templating tool. Think of it like mail merge in Word but on steroids. You give it a text file and a context, and it combines those into a result, filling in things like variables and doing conditional operations on the file. \n\nThe first example in the course is actually kind of like mail merge. You write an email template for some students who did well in a Python course that you're teaching, and then you run a script and it generates an individualized message for each student. When you write a program that uses Jinja, you typically are loading a template from a file and then rendering that template using a context dictionary. The dictionary contains information that the template engine uses to create the results. In that student example, the dictionary contains the student's name and the score they got on the test. The template is a text file that uses double curly braces to indicate variable replacement. These are also known as mustache variables, which is just fun to say. \n\nSo, double brace name closing double brace gets replaced with the value that corresponds to name as a key in your dictionary. The language goes far deeper than that and has all sorts of control structures, so you can do loops and conditional blocks, and you can even define your own macros. One of the most common uses of Jinja is to deal with HTML. HTML has a lot of repetition and boilerplate, so being able to treat that more like reusable code blocks has a lot of value. \n\nThe course gives you a quick intro to Flask, which is a web framework, and it integrates nicely with Jinja. You use Jinja to create the HTML templates, so you get sort of a two-for-one here - a quick little intro to Flask just to see how Jinja gets used in the real world. I mentioned that loop thing before - a common use of that is to build lists in HTML, so you take your context dictionary, say it has a list of things that you want to show on the page.And then use a Four tag to loop over the list and output the LI tags for each item in an unordered list. This allows you to write a lot less HTML and dynamically change what appears on the page by changing the context dictionary and the calling function. Flask allows you to map URLs to a function, and then the function renders the result, returning the HTML. This all glues together nicely. \n\nIn addition to providing a bunch of control tags, Jinja also allows you to write your own, which can be really powerful and lead to interesting reuse cases, like writing your own nav tag. You can get quite deep in this stuff. And of course, if you're like me and you're a Django person and you run into a case where you would go \"I want Django templating outside of Django,\" well, Jinja is your answer. Most of the base tags are very similar, as the libraries have been influencing each other for quite some time. So if you've already got Django skills, picking up Jinja is really pretty quick and fun to write. I hope folks find it useful. \n\nThe whole idea of the typical boilerplate that you would normally insert HTML is just so much nicer to build off of this base and add different things, like a nav bar or other sections of things. The block formatting and all that stuff is a smart way to go about it. \n\nThere's a tool called Markplates, written by a Real Python author for Real Python authors, but it's open source. It's essentially Jinja templating used to send custom tags. It's a smart way to manage text. \n\nFrank Eno's post is a discussion asking everyone to \"kill a developer in four words or less.\" Some interesting replies include \"off by one error,\" \"it's just programming,\" \"chat GPT,\" and \"kill -9 one.\" The conversation includes humorous and insightful responses.So, this mechanic, someone else is there or not. It wasn't the admin at the back. Don't stare at the man behind the curtain. But yeah, I've learned to be a little more careful when I issue kill commands when I'm logged in as root. This one would be related. You took down production. Yeah, pretty much. I like the client thinks yes. And then one that's common for anybody looking in startups is we take equity. Yes, yes. And then the most famous of all, push code on Friday. Yeah, let's deploy this Friday.\n\nI came up with a couple of my own that are Python-specific. Okay, so mutable default arguments, parentheses, and assert. So I'm doing well. These are three I'm sticking under four. Okay, trailing comma because that's one that bites me all the time. It wasn't meant to be a tuple. And then the last one, which actually is dead on four words, is edit list while iterating. But we're, I don't know if I was a little more talented, I probably could turn all four of those into a haiku. Maybe there's a Twitter thread we should start or a Limerick or something. Yes, yes.\n\nThis week, I want to shine a spotlight on another Real Python video course. It covers a topic that Christopher discussed this week and is an exploration of how to simplify working with HTML and web front ends with Python. The course is simply titled \"Jinja Templating.\" It's based on a Real Python tutorial by previous guest Philip Xeni, and the video course is presented by my co-host Christopher Trudeau. He shows you how to install the Jinja template engine, how to create your first Jinja template, and render the Jinja template in Flask. How to use for loops and conditional statements within Jinja, how nesting works within the Jinja templates, how to modify variables with filters, and how to use macros to add functionality to your front end.\n\nUsing templates is essential in full-stack web development, and with Jinja, you can build rich templates that power the front end of your Python web applications. Like most of the video courses on Real Python, the course is broken into easily consumable sections. Each lesson includes the transcript, including closed captions, and you'll have access to code samples for the techniques shown. Check out the video course, you can find a link in the show notes or you can find it using the search tool on realpython.com.\n\nThe other one that I threw in as far as a post to kind of discuss briefly, and this relates to a discussion that we had a couple of weeks ago also, this is from Chris Alban on Twitter. \"What is the right way to install Python on a new Mac M2 MacBook? And I assume it isn't the system Python 3, right? Maybe Homebrew.\" A big sigh. Number one, there is no system Python 3 in it. If you type Python on an M1 or M2 MacBook, it doesn't have a version of Python in it that you get from just typing Python. I didn't know that they got rid of it. Yeah, it's no longer there. So that confusion isn't there, but the naming scheme is still there as far as typing Python 3. So what was our advice? Our advice is to install from python.org. I got in a bit of a back-and-forth with somebody in that actual thread who had said, \"Oh, don't use the python.org one because it doesn't include Ticenter and then something else.\" They were saying it didn't include. I'm like, actually, that's incorrect. That's the one version that does. You might be thinking of something like PyM who does these abbreviated versions of installs and so forth. Oh, they didn't. It said it didn't include IDLE. And I'm like, no, both those things are there. It's just, in my opinion, now the problem is that it's the internet. And I think Chris Alban is known more in the data science community. So his responses that bubbled up very quickly were all kind of from data science people, and they were all like Conda or Miniconda and things like that. And that seems to be the winning as far as the internet voting on Twitter about it. There's a handful of people that started to chime in with Docker. I don't suggest you go that route. I just feel like if you're trying to just do Python, the python.org one is definitely going to be the simplest way to get you going. It includes all the standard built-in resources. But yeah, it's interesting to kind of read through it. And then I don't know what your opinions are, but I do not suggest using something like Homebrew because you're just adding something like that to it. So yeah, I've had a lot of challenges with Homebrew. It's saved my bacon a couple of times, and it's fried it almost as often. So I have a love-hate relationship with it. I always just use python.org. I'm surprised to hear anybody mention Docker and simply because it's known not to be performant on a Mac. The M2 Max or the M series Max is an emulation, so it's not working very well at all. I do wonder whether with the M2s being so fast that you don't notice it. I know.I can't run it on my old system as I have an older Intel system that brings it to a halt. I wonder if someone replied without trying it on a Mac. I've had the most luck with the python.org version, as I use Virtualenv. The only advanced thing I do is ensure aliases are built when it gets installed, with version number aliases. I tinker a bit by renaming folders in the library Frameworks. Otherwise, vanilla python.org has always been good to go.\n\nIt's interesting because it's fairly popular with two million views. I thought we were the last Mac users, with everyone switching to VR goggles. It has 111 quotes in it, lots of opinions. Everything is personal, but as an M1 Mac owner, I've installed three versions of Python on it for testing. I haven't tried the betas, but I can run all my projects on it.\n\nThe Python packaging problem hasn't been solved in the last two weeks. They're still working on it. Moving on to projects, I have a fork of the Pandas cookbook called the Polars cookbook. It uses Polars for similar tasks with different datasets provided. It covers various aspects of data manipulation and cleaning.\n\nA project I recommend is Django Waffle, a feature flag tool for Django. It allows for easy feature toggling in Django projects.The idea of a feature flag is to release features to a subset of users. It's a great way to beta test in production code. You can choose who can see something, and if it's not fully developed, you can open it up to friendly users. Google is a big fan of this mechanism. Most features in Chrome are released this way without staged releases. They just release the browser, and if you have the setting turned on, you can access the feature.\n\nLarge organizations use this method for beta testing without managing separate servers. Django waffle uses the ORM and database to set up flags. You can associate flags with different situations, such as super users, staff, Django User Groups, or manually selected users. There's also a rollout mode to incrementally expose a feature over time.\n\nIn your code, you import waffle to check the state of a flag using functions in an if block or decorators and mix-ins. Django waffle also provides template tags for HTML. In addition to flags, there are switches (on or off) and samples (random) for testing against random users.\n\nThe package has been around for a while and is well maintained with active adaptation to newer versions. It's useful for longer live Django projects with a larger number of contributors. The GitHub account is named Django waffle, and it's worth checking out for Django projects.\n\nI want to thank Christopher Trudeau for coming on the show again this week. Thank you for listening to the Real Python Podcast. Make sure to click the follow or subscribe button in your podcast player. Feel free to leave a review and visit realpython.com/podcast for show notes and to leave a question or topic idea. I've been your host, Christopher Bailey, and I look forward to talking to you soon. Cheers!",
    "Dne05raZ9zU": "Welcome to the Real Python Podcast. This is episode 165. Are you getting the most out of your Postgres database? What features could you leverage to improve your Python project? This week on the show, Craig Kirsten from Crunchy Data is here to discuss getting the most out of Postgres. Craig shares his years of PostgreSQL expertise with advice on getting more from the platform. We talk about rich data types for describing ranges, geospatial data, and JSON. Craig shares tools for accessing performance statistics from the command line and how to optimize your terminal settings for SQL searches. He discusses Postgres extensions for customizing the database to your needs. Craig also provides multiple resources for learning more and an online tool for practicing within a playground environment.\n\nAlright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Craig, welcome to the show. Thanks, glad to be here. I'm interested in talking to you. I mentioned in some of the emails back and forth that I have a lot of background in doing SQL stuff in the past. It's kind of interesting because I didn't really have a lot of deep access to doing more advanced stuff in SQL. But I'm intrigued to talk to you about Postgres because I feel like, and this is something we briefly talked about offline, it's something that a lot of developers in the Python world know about but maybe don't know why they should be using it. What are the advantages of using a tool like this? So I wanted to dive into Postgres and SQL with you. Yeah, that sounds super exciting. Cool.\n\nI mentioned to you that our audience is geared toward beginners and intermediate developers. Very often, those kind of people are making projects and want to be able to showcase their skills by standing something up and showing an application running. Data is always a big part of that. What are some of the reasons people would want to look at Postgres? I think, you know, we were talking about this a little bit beforehand, and I think in the Python world, if you ask people, they'll say, \"Use Postgres if you need the database.\" At risk of a huge detour, like we as developers think we're super practical and well-reasoned in all of our decisions. At the risk of alienating the entire audience, to me, I used to work at Heroku. I was a very early product manager there before they were multi-platform, multi-language. I got there and ended up launching the Python support. I remember all the Python developers at the time were kind of jealous of this Heroku platform thing because it was so easy to deploy. It's kind of like, well, Ruby and Python, they're really the same language. They have amazing communities. When you look at them, they are more similar languages than they are different. We're so well-reasoned, and hey, I think Python is much better. Yet, everyone in the Python world says Postgres. If you throw a rock, someone's going to say, \"What database?\" It's going to be Postgres. I was at a conference years ago, and at one of those speakers' dinners, they were talking about how as developers, we have these things that are just canon gospel, and we believe in them so strongly. But it's really just being a bandwagon fan. The speaker was like, \"Take, for example, Postgres. I don't know why I should use it. I mean, if you ask me, of course, I say Postgres, and you're crazy if you don't use it. But I can't actually tell you why.\" A lot of the audience knew me, or the rest of the table knew me, and just got quiet. It was very funny. Those people just got quiet, and five people turned around and stared at me. I just rattled off a list of reasons. So, I think it is a really good database, and it is the right choice. If you want to hang it, turn off the podcast in 60 seconds. It's transactional DDL, it's rich data types, bridge indexing types, it goes outside basic relational, it's full text search, it's one of the richest geospatial databases in the world. It competes head to head with ESRI, which is an expensive proprietary database. Rich JSON support, extensions which completely change what it can do. There's a laundry list of reasons. So, if you want to just end the podcast now, great, you've got the laundry list.But we can drill into a lot of those. I think it's really fascinating because Postgres, for the longest time, was not cool and sexy. It was reliable and safe for your data, which, as a database, is crazy to think about. Other databases didn't always prioritize reliability and safety like Postgres did. It started there and focused on that before adding in more advanced features like JSON that developers can take advantage of. \n\nFor beginners, I think it's good to embrace. I've talked to many application developers who are willing to learn new algorithms but shy away from their database for some reason. It seems scarier and more intimidating, but it doesn't have to be that way. Understanding what's in the box, like transactional DDL, and knowing where to find resources can help bridge the gap from basic usage to leveraging specific features like range types.\n\nThere has been a resurgence in the development world regarding Postgres. In the last 10-15 years, Postgres has matured and become more user-friendly and manageable. It's now easier to trust a managed service to handle database administration. Postgres has added features like JSON support and various index types over the years, making it a versatile and powerful database option.\n\nThe community has played a significant role in helping Postgres evolve and become more accessible. Postgres is now viewed as sexier and more advanced than it was a decade ago. Features like JSON support and different index types have been added over the years, making Postgres a competitive choice for developers. The shift towards managed services like Atlas has also made database management more accessible to a broader audience.Well, it can be inside both of these rows because it's a point inside of a shape, right? Then it got space partition gist and Brin indexes. It's kind of crazy that it's like, wait, here's a whole new index type just showing up in Postgres each year, right? So really, over the last 10 years, it's gotten really rich in terms of feature sets. I think it's okay to call a database sexy. Like, I don't know that a database is sexy, but that theme, right? It's like, oh, actually yeah, now Postgres is cool and sexy really in this last 10-year timeframe.\n\nA lot of core development is happening there and not standing still. One of the things you mentioned that I'm kind of intrigued by is this idea of different types of indexes. But one of the key elements that, going through the documentation, is seeing all these unique types of data types. What would be examples of those that would be advantageous to a Python developer going beyond simple data types that they might know?\n\nI think there's a lot. That's like the perfect softball. I'm so excited about talking about data types. I feel like we talk about them often on the show and in other ways. It's all about communicating back and forth between these systems, and typing is critical to have types. Absolutely, and it's... I'll get it out now so that then you know, my partner and I have a date night tonight. So that I'm us, and they're talking about types. Let me find one or two examples. Range types in Postgres are a type that is prominent too. Why would you store that as a range type in a database? If you think about a college scheduling application, you can build all this logic in Python to ensure things like not enrolling in two classes that overlap time-wise. Range types are enforced at the database level, allowing constraints like having only 30 students in a class at a time.\n\nIt's been a while since I've been in college, but I totally remember the rush to sign up for classes and the constraints on available seats. Enforcing such constraints at a database level in high volume systems matters. The fact that you have a data type in Postgres like range types, which can store time or numbers within one type with database constraints, is valuable. The Python world has started to embrace this, with Django and SQLAlchemy offering specific types for specific database drivers.\n\nRange types are one of those types that don't get as much attention. Json in Postgres gets quite a bit of attention. There's a Json type in Postgres, which wasn't real Json initially but evolved into a real Json field type later on. Postgres has continued to evolve with new types like Json, and the Python community has embraced these advancements.One of my colleagues jokes that the \"b\" stands for better. It's actually binary. I like better a lot. Better is like a binary representation of JSON on disk. With gin indexes, you can index on every key and value. You add one index and now it's a fully indexed JSON document inside a relational database with columns and rows. \n\nThese days, I think of Postgres as more of a platform. Range types, JSONB - probably most of you out there listening are not writing raw SQL and raw migrations. You're probably using an ORM, so check out the docs. There is a Postgres-specific section in the ORMs like SQLAlchemy and Django. Take advantage of it. \n\nI worked at a couple of different banks, and I got used to tying data together between separate tables. The idea of having a big blob of JSON in a single field is kind of wild to me, but it's a newer style of database storage. \n\nA lot of people ask me if I, as a database enthusiast, use JSON. For the last 15 years, everywhere I work, JSON has been there from day one. We run a managed database service, and we monitor databases with health checks that retrieve data in JSON. \n\nWe have different types of feelings for each database, and we pull it back in JSON. It makes sense to have high-moving and high-changing data in a JSON column. Not being too dogmatic about how things should work makes a lot of sense. \n\nAn example of where JSON would be useful is with metrics or events in a Django setup. Metrics and events are super common in apps. For example, a calendar scheduling application may track user interactions and events to improve user experience. \n\nThere are so many metrics that you can track, such as user clicks, confirmations, and time zone issues. Having different types of JSON for each metric can help with tracking and analysis. It's important not to overcomplicate things and to focus on efficiency.Metrics are advances Json are super super common. An interesting call out, if you want to have API traffic log data, like if you want to record the API log event so that you can replay it, my recommendation is don't do that as a Json B. Do that as a plain text Json because then we don't have to go back and forth in compression or indexing. It's like, hey, if you just want to persist Json exactly as it was, preserve the white space and everything. Use that Json, not the binary version. Otherwise, if you're querying on indexing or that sort of thing, you usually want to use the binary one.\n\nThis week, I want to shine a spotlight on another real python video course. It covers how to create interactive Geographic visualizations that you can share as a website. The course is based on a real Python tutorial by the previous guest Martin Royce. It's titled \"Creating Web Maps from Your Data with Python Folium\" and it's presented by the video instructor Kimberly Fessel. She shows you how to create an interactive map using folium and save it as an HTML file. How to choose from different web map tiles, how to anchor your map to a specific geolocation, and bind data to a geojson layer to create a choropleth map, and then how to style that choropleth map. She also shows you how to add points of interest and other features. Learning how to build interactive visualizations is a worthy investment of your time and sharing standalone web pages is a great way to get your users to understand and dig into the data. Like most of the video courses on real python, this course is broken into easily consumable sections. Each lesson has a transcript including closed captions and you'll have access to code samples for the technique shown. Check out the video course, you can find a link in the show notes or you can find it using the search tool on realpython.com. Thank you.\n\nOne of the other things that was mentioned is GIS being used in the platform. What are some of the things happening there? It's interesting, one of my colleagues is the primary contributor and maintainer of post GIS. I think I can make the statement it's the world's most advanced open-source geospatial database. Post GIS goes toe-to-toe with Oracle and even in some cases esri in terms of geospatial. Postgres has this notion of extensions, you can extend the postgres. Postgres was built with this extensibility idea in mind from the early days. Postgres name means post Ingress, which came out of UC Berkeley. Post GIS is an extension, probably one of the most advanced extensions out there. It adds new data types, new operators, it transforms postgres into this whole world of geospatial stuff.\n\nIn the Django world, GeoDjango is really great and exciting and kind of moves in this parallel pace. If you're doing anything with geospatial, take a look at post GIS. Even without post GIS, there's basic geospatial stuff like Earth distance within postgres.Extensions seem to be one of the unique things that are also mentioned. People can leverage what's the process like to add an extension. I mean, not create it, but if you want to add it to the database that you've set up, it kind of depends, right? If you're running the database, there are a few layers of extensions. Postgres ships with a number of extensions in the contrib. Think of it as the standard library. You don't have to use it, but it's there. To enable it, you just run create extension. PG stat statements is one that's super useful. It records every query that runs against your database and parameterizes it. For a quick lookup, 100 milliseconds is kind of high. Maybe I should add an index there.\n\nPG stat statements reports stats on how you decide to make these indexes. It records all these stats into a catalog table that you can query. Postgres has around 17 or 20 contrib extensions that are there for you. If you're managing Postgres yourself, you can check out the code from GitHub or get it from a package. If you're on a managed service provider like Crunchy Bridge, RDS, or Azure, you're limited to what the service provider has available. Crunchy adds support for a new extension every two weeks. Some recent ones are hyper log log, based on a white paper from Google. It's like probabilistic uniques, compressing unique viewer data. It's really crazy and awesome math under the covers.\n\nIf you're building a Google analytics site, it's like Wednesday had 150 uniques and Thursday had 175 uniques, but then you could join Wednesday and Thursday and learn that you had 205 uniques. It's a practical application of probabilistic unique counting.Right where Uniques is close enough it's like 99% accurate but Google Analytics is not running a SELECT COUNT(*) to get exact Uniques across those days for you. It's doing these advanced sampling algorithms. If your service provider supports it, then the process is to create an extension like HyperLogBlogger, whichever. That's just something you gotta check to see if they provide a certain subset of these extensions. Some service providers are going to provide more of them or less of them depending on as they get pushed out. If they don't support it, go ask your service provider or go check around at service providers. The most recent one that made a bunch of waves was PG Vector, which is like a vector store inside Postgres. I was shocked that all the major cloud providers supported it really quickly. Even Amazon and Microsoft have come along and now support it, which usually they're on a slower cadence. PG Vector has definitely made some waves, and a lot of the community is pretty excited about it.\n\nI guess we could dig into a little bit more of the Python side of it. What sort of features can a Python developer take advantage of? You mentioned some of it as far as looking in your Django documentation for its ORM and data types. I'm a big fan of SQL Alchemy. Don't be afraid to break out of the ORM and write some raw SQL. The ORMs make this easier as time goes on. If you find yourself creating a report or doing more manipulation, drop into raw SQL. Look at the Django ORM on how to write and execute a raw query. Try to think about SQL like you think about your Python code. You can document your SQL to make it legible and clear. Leverage the white space, use Common Table Expressions, and align your columns to be on the same line.\n\nI think you got exposed to good legible SQL, which is not always the default. Use white space and Common Table Expressions to create building blocks for your queries. Align your columns to be on the same line.So that's like seven spaces of indentation for the next one, right? Don't put them all on one line, space it out. And then you do the \"from\" and put the tables on a different line. When we're there, five spaces before them. And then my \"where\" and my \"and\" I'll do like a \"where\" clause, right? Where email equals whatever. And then I'll do the next line, and I'll actually do two spaces before my \"ands\" so that the condition aligns really cleanly. If I want to just leave it, I just highlight that line and delete it.\n\nThere's a couple of blog posts I've written on how I write SQL and writing better SQL like Common Table Expressions, white space, and then don't be afraid to do inline comments at the end of a line. You can do two dashes, that's a comment in SQL. Yeah, so you could comment every single line really cleanly. If you start to write SQL and think about it the same way you write Python code, when someone comes to it, they have a completely different appreciation for it. Like, \"Whoa, I've never seen SQL this way.\" I think that's pretty uncommon that people actually do a good job of documenting SQL and clean formatting of it. Yeah, it's, I mean, the idea very often in Python as you're exploring and learning, and even just kind of creating something, is the idea of, \"Hey, maybe I comment out this line.\" And it's kind of a similar thing that you can do if you format it properly in SQL. Also, you could actually comment out this little section and say, \"Well, what if without this parameter?\" So I think that's really great advice.\n\nI also like, I didn't use this very much, but I could totally appreciate it when you were saying it, the idea of creating these expressions beforehand to like kind of have reusable chunks of queries if you will later on. At least it, maybe, you know, if you've named them properly, they make sense. Like, you know you've set up a query that's grabbing all of, you know, all these employees based upon some kind of parameter. And you can say, \"This set of employees.\" Then later on in your later queries, which I think is really nice.\n\nYeah, I mean, some of the true Postgres DBA experts will say, \"Well, that's an optimization boundary. It's not going to be the most performant thing.\" And, you know, at a time that was true, it's becoming less true. But I mean, to me, when I'm writing this big old report, it's going to run for a minute anyway. That's got like five different tables and aggregations. Readability and the ability to understand it is way more important than saving five milliseconds off this query that's going to take one second. Sure, yeah, that premature optimization versus like understanding can be kind of crucial.\n\nAbsolutely, understanding and getting it right. Like, that's like, \"Oh, you think it's doing this, but you missed some step because you're trying to be complicated.\" So I think that like understanding it is spot on. Yeah, you were showing off some tools. Again, this is kind of us moving away from Python again, but I think that's okay because so much of if you're going to be working with data and working with the database, sometimes taking the Python out of the equation and just looking at the database, it's kind of nice to be able to just go in and just do, like for me again, I have the background of doing some SQL stuff, but it can be really kind of handy to like, you know, what is actually stored there. And you were showing off some tools and I think P SQL is one of the main ones that you're using.\n\nYeah, yeah, and I don't think it's so much going away from Python. I think it's, if you're not too scared of the tools, right? And like, embrace it a little bit, then you have this open mind and it's not so scary. So P SQL, it's like the CLI editor that comes with Postgres, like the command line interface that you can just P SQL and connect to your database. And the biggest thing that I do to make it more usable, so most developers, we're in a terminal window at some point, right? It's like you have a bash-like profile or like, what's your personal shell? I'm using ZSH right now on a Mac. Okay, did you like go crazy with your ZSHRC or did you just use Oh My ZSH? I kind of have kept most things really vanilla because I do so many tutorials where I want it to look not super customized where that becomes the whole questions and comments. But I know like, Oh My Posh and all these other kind of crazy things are like, it becomes really interesting. But yeah, please keep going on that.\n\nCool, so yeah, like you're the exception, right? But like a lot of people, like, cool, if you're on ZSH, just like, oh, what's in your ZSHRC, right? Like, how have you customized it? And you see something that someone else has done that's cool, like, oh, I want that. And like, P SQL by itself is, you know.It's a fine editor but the biggest thing I can recommend is setting up a P SQL RC that is the same as a zshrc or a bash RC where it customizes what you have. By default, you can do backslash timing and that shows how long every query you run in the editor took to run. For example, is that one second or 100 milliseconds? Backslash X auto formats the output of the query based on the width of your screen. So, if you have like 10 columns, it would kind of weirdly wrap. What it's going to do is put the column on the left and the content on the right. One record is going to be vertical and readable based on the width of the query. It's not going to be always the same way, it's based on the columns and how many columns we can output in the width of your terminal. Really nice auto formatting right out of the box.\n\nIf you set up your default environment variable editor to do backslash e, it'll open up that editor. For example, a lot of defaults are like vi or VI by default if you don't customize anything in a terminal window. But you could set it up to be like VS code or Sublime Text, and that'll actually open up the last query you edited there in your default editor. So, you've edited in VS code, saved it, closed it, and it'll auto run that query back in that command line editor that you're in. It's like, wait, I don't have to edit SQL in this CLI weird interface. No, but you can go back and forth seamlessly. So, I'd encourage you to spend just a couple of minutes with P SQL, look at setting up a P SQL RC, and do what everyone does for their CSH cell, just steal someone else's.\n\nIf you find as a Python developer that you like this database thing and want to do more of it, you can save queries via a name in your P SQL RC. For example, PG stat performance, and that'll auto run the query that you've created as your preferred view of it. You can also save queries in your P SQL RC for easy access.\n\nI have a YouTube video where I'm showing off some of the stuff and writing queries. I'll include a link to that. It was for Pi Caribbean, a little while ago, so some of the stuff might be out of date, but I'm showing off some functionalities at the beginning and some of the P SQL RC stuff that I've done. Are there other resources I can include in the show notes? I can definitely pull up a few blog posts where I explain this once and can refer to it again. There's definitely a number of blog posts that provide different views on it.\n\nIf this is interesting to you, subscribe to Postgres Weekly or the Crunchy Data newsletter. The Crunchy blog focuses on app developers and aims to help them not be scared of the database and improve their SQL skills. People might think they'll get trapped in focusing only on database stuff, but it's important to have a balance and not spend too much time on it unless necessary for performance or other aspects.I think that's really important for someone who works with databases a lot. A lot of the day is spent on the basics, right? It's all the other things around it. I think most applications don't need 100 dedicated DBA. Once you outsource the backups, management, and maintenance to a managed service, a once a month health check or every three months. Here's the things that you come in and tune and tweak. As a developer, it's refreshing to change pace, to learn something new, and get a different perspective.\n\nWe talk about it all the time that most of the developers I speak to on the show are very interested in learning other languages and what they can steal from them. SQL is a great one to add to that. Just to understand some of the things happening underneath the hood. Going into something like psql and being able to query directly. I think you mentioned one thing that got me into SQL. My wife was writing queries at a bank. We both have the experience where someone asks for information, and you write a query for them. They come back later, and you wish you had it ready to go. It can save the history of other queries you've done.\n\nYour PSQL RC can save your entire history of a query. It's super handy, but do you want to save the history? It can be sensitive, so be cautious. Knowing SQL feels like a superpower as an app developer. It's a way to level up in your career. Embrace it early on, and you'll stand out.\n\nFor people in data science, it's the same way. Spending time with raw data and paring it down. SQL can help with that. Python is my world when it's not Postgres. I don't write code for production in Python these days. I'm more on the product management side of things. Code is there to build interesting stuff and solve problems. I joke with Engineers about when things are ready for production. They'll be ready when they're done, but I can whip up a PR and push it to production. They always tell me not to touch production, it will be done by tomorrow.I came to Python and really liked the way of Django. It was like Django 092, okay maybe before then. I write explicit code, basic, clear, and clean Python code, same as I write SQL. It's funny how some people find SQL cryptic and confusing, but I read it the same way - logical broken out steps, well-documented and well-commented.\n\nI was more of a Django developer for a long time and got more into Python. Now, my day-to-day work involves scripting and data manipulation in Python, which is really good for it. I've always loved the Django world and its ecosystem. The \"batteries included\" framework was a great feature that I appreciated. Postgres, to me, is like the batteries included database with full-text search and geospatial capabilities.\n\nWhen I joined Heroku, I actually launched their Python support. I have friends in the Python world for decades now. It's a great community with thoughtful design approach. I also have friends in the Ruby world due to working at Heroku, but I've always appreciated the Python community and its ideals.\n\nAs for learning more about Postgres, resources like Postgres Weekly and the Crunchy Data blog are great. We also developed the Postgres Playground where you can run guided tutorials in your web browser. It's a useful tool for training and learning SQL. Check out the Crunchy Data Postgres Playground for about 30 tutorials and some Advent of Code challenges directly in SQL.\n\nI'm excited about events in the Python world, getting back to normalcy. It's nice to meet people in the tech community again, especially living in the Bay Area, a tech hub. It's great to see Python feeling more normal and engaging with the community.But there's so many Python folks out here that I know. We live close to each other, but don't see each other much. We see each other at PyCon every year and talk about getting together more, but it never happens. There are about 20 of us here in the Bay area, and we always say we'll meet up, but end up just seeing each other at PyCon again next year. I'm excited for the regional conferences, like PyTennessee and PyTexas. I missed DjangoCon Europe last year, but I'm hoping to make it this year. I love these events and meeting new people.\n\nIt's been fun documenting and talking to people and organizers during the virtual conference season and now as things are opening up for in-person events. It's interesting to see how things are changing. I'm still figuring out my schedule for this year, but I'm hoping to attend DjangoCon and DjangoCon Europe. I was at Python earlier this year, and I'll probably go again next year. I'm not sure about any other regional conferences yet, but I'll look into it after this podcast.\n\nAs for learning something new, I've been getting into wok cooking lately. It seemed intimidating at first with all the ingredients, but I've found it to be enjoyable. I never thought I'd make beef with broccoli at home, but now it's one of my favorite leftover meals. I've been using a wok over a gas range, nothing fancy, but it gets the job done.\n\nIf you're interested in wok cooking, I recommend the Kenji book. It's a great cookbook to get started with. It's nice to focus on cooking for the weekend and have leftovers for the week. It's convenient and delicious.\n\nYou can follow me online on my personal blog at craigesteems.com.I'm pretty much prepared for scenes everywhere. If you have questions, don't be shy, email me. I truly like I'm happy to have emails from random folks if you have a question or feedback. I blog a lot on the Crunchy Data blog where I work and run product engineering. So, definitely appreciate you subscribing to that newsletter and following there. I am not on Mastodon currently, I am on Twitter and Bluesky card Kirsten's there, so we'll see on the future of Twitter and all that. But for now, still there hanging out until it completely implodes. So yeah, generally search for Craig and Postgres, and I'm a pretty easy person to track down.\n\nWell, I want to thank you so much for coming on the show. It's been fun to talk to you. Absolutely, and I think I've gotten it out so I can not talk about data types tonight under the date with my wife, and that'll probably keep me out of the doghouse a little bit longer. So, thanks for letting me get the enthusiasm out. I don't know, is Postgres a sexy database? Maybe listeners can chime in. Can a database be sexy, and if so, does Postgres win that badge? It's weird of me to say it, but for some reason, I don't think a database can be, but it's definitely been fun to drill into for a little bit. Great, thanks for coming on the show this week.\n\nI want to thank you for listening to the Real Python podcast. Make sure that you click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey. I look forward to talking to you soon.",
    "rVafjSzP7DE": "Welcome to the Real Python Podcast. This is episode 168. Have you ever encountered strange behavior when trying something new in Python? What are common quirks hiding within the language?\n\nThis week on the show, Christopher Trudeau is here bringing another batch of Pi Coders weekly articles and projects. We discussed a recent blog post that lists a collection of quirky Python behaviors. We share a few examples with explanations but leave several as puzzles to dig into.\n\nChristopher transitions our discussion into Python features that can be difficult to explain to a new programmer. We also share some of our stumbling blocks while learning the language.\n\nWe cover several other articles and projects from the Python Community, including a couple of news updates previewing Python 3.12's more intuitive and consistent f-strings, finding performance bottlenecks with profiling, emulating a 6502 processor in Python, using Rich to inspect Python objects, and plotting statistical data with Let's Plot.\n\nThis episode is sponsored by Porkbun, the best domain name registrar to get your .XYZ domain. The future of the internet is the .XYZ domain. Get yours for around two dollars now at porkbun.com/XYZ.\n\nAll right, let's get started.\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com. Hey, Christopher, welcome back.\n\nHey there, excited to dig in. This week, we have just a couple pieces of news, and we're both going to take one of these each. So, what was your news item?\n\nIt's funny, off air, we were discussing the fact that some of the stuff we call news when we only chat every two weeks and then see it takes a bit to get an episode out. So, yeah, the title of news is a little funny. But here's some news. The one that's going around a lot around the web right now, especially on sites that have a tendency to rename themselves, is the official announcement from the Python Steering Committee that PEP 703 has been accepted. In case you don't all have the PEP numbers memorized, 703 is better known as the No-GIL PEP. Yep, you heard it here, probably not first. The GIL is being removed. So, in order to try and minimize any backward compatibility challenges, two versions, the removal process is going to be as follows. First, both a GIL and No-GIL build will be available simultaneously. They're hoping this will begin in Python 3.13, which would be October 2024. Okay, the library maintainers will then have time to build binaries that match the new signature. But of course, that will mean supporting both versions for a while. The hope is around the five-year mark, the No-GIL version will be the only choice. There was a bunch of language in the announcement leaving wiggle room on the dates, recognizing that as the work progresses and more information becomes available, things could change. Yeah, this is kind of a big deal and not at the same time. So, if it's done right, a significant percentage of Python coders will never see any difference at all. Maybe some performance improvement for library maintainers, especially those who write extensions. This is going to be a little extra work for a couple of years, but the goal is to do what is actually a massive change under the hood using as seamless a process as possible. I believe you've got a little news as well.\n\nYep, this is about Polars, which we've talked about on the show and it's come up in lots of data science discussions of late. And I don't normally go on Reddit, but I did recently and on the r/Python subreddit, there was an announcement from Richie, who's the creator of Polars. They were announcing that they're starting a company and that it will be built around Polars. It's kind of cool because it is almost exactly three years ago that he made the post in the same subreddit announcing the Polars project to begin with. So, kind of a neat transition in three years. But I definitely have seen the popularity in the data science world. And people are working with large amounts of data. There's a lot of excitement around Polars. And also, there's a lot of excitement around this kind of stuff. You know, we talked about Will McGugan creating his textual company. And I think that's great. I approve of these types of companies compared to lots of other VC things I see. So, good on them.\n\nSo, what's your first topic this week?\n\nWell, can you believe it's been almost 10 episodes since I've uttered the name Leonardo DeNaspos Alramos? Oh no, wow, so we're overdue. My first article is by our most prolific author and it's called Python 3.12 Preview: More Intuitive and Consistent F-Strings. As the 3.12 release approaches, you're going to see more and more content like this highlighting those features that are coming. A bunch of work in 3.12 goes to make the F-string format a little more consistent and a little more sane. This is yet another one of those things that can be done because of the switch over to the peg parser back in Python 3.9.So we're still gaining language features from that change, which is kind of neat. F-strings were introduced in 3.6 as a replacement or addition to the old C-style string format, as well as the `format` call. Oddly enough, though they were never actually part of the official Python grammar, they had their own syntax and a custom parser was built into CPython for dealing with these kinds of strings, so it was kind of a separate beast. The changes in 3.12 make F-strings actually part of the grammar and underneath that means the core developers have less work as they no longer need to maintain two parsers. It also means for other implementers like PyPy, they can just implement the grammar. It's all part of the spec now, which is nice.\n\nFor those of us just using the language, it also means some things that couldn't be done before now can be, but most of it's under the hood. The older parser had a couple limitations. For example, there were limits on how escaping worked, meaning you could run into challenges when you had to nest quotes in quotes. There were ways around this, but they were just ways around it, so it's cleaner now.\n\nThe first thing that they changed was how quotes are handled inside of the braces in an F-string. They're no longer considered part of the string, which means you can use the same kind of quote on the outside of your string as on the inside of the brace, say to access a dictionary key. They're enabling this, but then they're immediately turning around and saying linters should probably tell you this is a bad idea. So just because you can, you might suggest a different style. Yeah, so I'm not sure how I feel about this one, and I know it's going to be a mess. It's going to mess up a bunch of syntax highlighters until everybody catches up, so yay.\n\nAlong the similar lines, you can now use a backslash inside of an F-string brace. This allows you to do things like perform a join on `'\\n'` inside the braces. So far I'm indifferent. Both of these were things that didn't happen all that often, and I could equally argue that it'd be clearer if you just don't do it, but that's a style opinion thing, so whatever. The next one, though, is something that I kind of like, which is comments. This is useful inside of multi-line strings where you can now put a comment inside of a brace. If you've got some chunky big multi-line code going on, you can remind yourself why you did that right in the middle, which is kind of nice.\n\nEver since the PEG parser was introduced, there's been an initiative to sort of improve error messages from the compiler. By moving the F-strings into the grammar, the code for parsing the F-strings can now take advantage of this error handling as well. So now the parser is going to be able to better point out where in an F-string the problem is, rather than the old code which basically said, \"Hey, invalid syntax,\" and then you had to figure it out yourself. The rest of the article covers some of the limitations that still exist in F-strings, like what to do with lambdas and how to escape braces and things like that. Definitely looking forward to 3.12, and if you want some good examples of some of the things I've been talking about, the article is a great preview.\n\nMy topic that's coming up digs a little bit into a feature for Python 3.12 also, so there's a lot going on there. And man, Real Python, we've been hitting it often with lots of little articles in the pre-release zone to give you an idea instead of just announcing it all at once when it comes out. Lots of previewing that you can do on the site right now.\n\nMy first one is titled \"Profiling in Python.\" The subtitle is \"How to Find Performance Bottlenecks.\" This is a Real Python tutorial by Bartajinski, who we've mentioned several times on the show before, and it takes you through several tools that come with Python and a couple third-party tools that can help you profile your software. One of the big questions would be like, well, is that necessary? And that really depends on your code. I guess if you're a beginner, I don't think profiling is something you're going to run into right away. Even an intermediate developer, it may depend on how often that code runs versus the trade-off of, like, okay.If I optimize the code, will it take longer than the code running and things like that? If you're wanting to answer some of those questions, like whether optimizing is necessary or maybe drilling into what parts of the code you should focus on, this is a really good tutorial to dig into. I think it can be a really good teaching tool, which is why it's interesting to me and why I like bringing up this kind of stuff on the show.\n\nThere's a bit of a programming note here. After the tutorial came out, the creator of another very powerful profiling tool contacted Bartage. He sent him an email telling him, \"Hey, if you're going to write about profilers in the future, you might want to check this out.\" Bartaj connected him with me, and we just recorded a show this week. The conversation was with Emery Burger, who is from UMass Amherst. He has created the tool called Scalene, and his students have been working on the tool and updating it. That conversation will come out in a few weeks, and it was really fun. So, if you're interested in profilers or maybe even more advanced profiling, that conversation digs really deep into that stuff.\n\nGoing back to this tutorial, Bartage provides a short checklist to figure out where you want to work on performance and whether this is a good choice. The first step would be, \"Have you tested your code to prove that it's actually working as expected and without errors?\" Then, maybe as you look at your code, does your code need some cleanup and could it potentially become more maintainable or more Pythonic, as we like to say? Making sure the design of it is well done. Maybe the third step would be, \"Okay, let's identify inefficient parts of your code by doing something like profiling.\"\n\nThe tutorial follows into a set of tools. One of the types of tools is a timer, and there's a tool called time and another one called timeit that are standard Library modules. In fact, there's another third-party tool made by one of our friends here, Guerra Nahiella. It's called Code Timing, and I'll link to an article that describes the whole process of him coming up with this tool that you can use to go through a variety of ways of timing your code. It's a nice tool if you're looking at something just to see how long things take to run and a variety of ways that you could implement timing your code.\n\nBartos dives into two other types of profilers. One is a deterministic profiler, like something called profile or C profile. Then, there are ones that do line profiling, and a contrast to that is something called a statistical profiler. He shows off one called Pi instrument and another one called Linux perf profiler. He measures the time execution of each one of these, has code samples with it where you can run this and try this out yourself. He then goes from time and to timeit, and you can do much more benchmarking there with short code snippets. Timeit's a neat tool if you've ever seen it before. You can set up parameters for it to run multiple times and give you this better averaging. It avoids some of the problems where you're timing like importing your code as opposed to the code running and things like that, which helps give you an idea of that.\n\nFrom those time type of things, he digs into the deterministic profiler of C profile, which collects really detailed runtime statistics. It's kind of a go-to for many developers in the deterministic camp. It'll show you what functions were called and how many times they were called, and where the time was spent in your program. But depending on the way your code is written, this may not tell you a whole lot. The answer could be, \"Wow, spent a lot of time in Maine,\" and it's like, \"Okay.\"Well, if that's the only primary function that's happening there, it may not give you a whole lot of help. So, if you divide your code up into multiple functions, then it could show you potentially within these separate function calls where this performance is headed and what's happening. One kind of problematic thing that I definitely got into in my other conversation about performance is that it does take some overhead because the code is running kind of in parallel with it. It can produce a lot of noise in its reporting, so there's a trade-off depending on the tool you have. It can be like 50 times slower or even more than that when you run something like C profile because it's sort of standing on top of things and monitoring all these things in the background.\n\nThat's where we lead into the other type of profiler that covers the statistical profiler. The one he's using in this case is called Pi instrument, a third-party tool. It takes snapshots of what's happening in the call stack, and it really doesn't affect the overall performance because it's sitting on the side and just sampling what's happening as it's running. The overhead is much more uniform by doing that kind of deterministic thing. You can adjust your sampling rate, which is unique. This particular tool is a little limited in the sense that it doesn't report on code that runs in multiple threads or calls that go into something like a C extension module.\n\nAfter digging deep into Pi instrument, he then goes into Perf again, the Linux profiler. It provides detailed information about the entire stack, going into hardware events, system calls, library code, and much more. The designer, Pablo Galindo Salgado, has been very involved in contributing to this feature. He has been working on releases and contributing to the feature of memory profiling. This store is really thorough, giving you code examples to try out and run each one of these things. It includes a new format for Real Python. There's a section at the end called Key Takeaways, which is an interesting addition to our tutorials and articles.\n\nKey takeaways will be a feature that we're adding to a handful of our tutorials and articles heading forward. It gives detailed answers on the types of things that were covered throughout this particular article. The question is, what is software profiling? Profiling a program is about measuring and analyzing its runtime statistics to find hot spots or performance bottlenecks. High memory consumption, inefficient CPUs, and excessive function calls can be common indicators of potential issues in your software that need improvement.\n\nI enjoyed it, it's an interesting dive into profiling, and it helped me turn into yet another episode by Emory Berger reaching out to me. We're going to cover his tool called Scalene in an upcoming show. Do you run profilers yourself, and if so, which ones are you running, Christopher? I haven't had to do it in a while. The vast majority of the work I do is on the web, where the bottleneck tends to be the database. It doesn't tend to be the computation of the thing you're actually doing on the back end. It makes sense, it's a diminishing sort of return there.\n\nYears ago, when I did more work on embedded systems, where every clock cycle is important.I tended to use that kind of tool for those situations, but I haven't had to do very much of it in Python. Okay, so you're digging into a very interesting topic next. Speaking of embedded, I didn't even do that on purpose. My next one's from a site called Daily Stuff, which is a kind of a hybrid site. It's got some blog posts, some sort of tutorial training stuff, and then it's just recently added a project section. The project section gives you details on how to build something. There are no bylines on the project section, but there are in the blogs and stuff, so I can't give credit to whoever wrote this. It's just Daily Stuff's content. The title is called \"Writing a 6502 Emulator in Python.\"\n\nThe 6502 is a CPU from Motorola based on its 6000 series. It was used in the original Nintendo Entertainment System, the Sega Genesis, and the Commodore 64. So for you youngins out there, this was the computers the dinosaurs used.\n\nThere's no real need to build an emulator except that it's kind of fun and an interesting way to learn about how CPUs work. It's favorable to do an older one if you're going to play in this space because they've got fewer features, so you can understand the basics before getting bogged down in complexities.\n\nThe 6502 is an 8-bit processor, using 16-bit values to store things in memory. To emulate it, you need to emulate the memory storage as well as how the instructions on the CPU work. There are two kinds of instructions that deal with memory in this architecture: immediate and indirect.\n\nThe first chunk of the project instructs you on how to build an object in Python that represents the memory in the system. The memory is divided into regions for special variables, constants, and general memory where programs and their data are stored.\n\nThe next challenge is building the processor, which involves registers, program counters, stack pointers, status flags, and writing unit tests to ensure everything works. It's a detailed project that offers a deep dive into how CPUs work.\n\nMy next one is from Nathan on the site writing.prc.net, titled \"Python Quirks.\" It covers some odd and quirky things that Python does, which could potentially bite you if you're unaware. Real Python covers many of these oddities, but some you may only come across with specific actions. Nathan's newsletter highlights some favorite Python oddities for beginners to be aware of.I'm not going to dig into all of them because I really feel like this is a great set of puzzles that if you are not familiar with these things that you can kind of sit and think about why is python behaving in this interesting way. I'll highlight a couple and then he also has an additional piece at the end with links that go into other resources where other people are writing about this. There are bigger explanations, but they aren't in this particular example.\n\nOne of the oddest ones that if you're looking at it, maybe coming from a different language, is identified as exponentiation. Exponents were kind of in python a common way of writing raising something to the power of is to use that rooftop looking caret symbol. So, two raised to three would output one because the operator in Python isn't the caret for raising to the power of, it actually is two asterisk symbols, the thing that you use for multiplication. So, if you wanted to raise two to the third power or cube two, you would do two star star three. It's a bitwise operator, in fact, the bitwise or operator in Python, so it's doing a completely different type of thing.\n\nAnother favorite trick is Tuple behavior where you can swap values in a single line of code without needing intermediate values. You can swap values between two variables by using the assignment operator and comma. The way Tuple assignment works inside of python allows for this direct swapping.\n\nA problem with default arguments arises if you have a function with a default argument that is mutable, like a list. If you update the mutable default argument within the function, it retains the value across function calls, leading to unexpected behavior. It's better to define mutable default arguments as None initially and create the object in the function body if needed.\n\nThere are a couple of other quirks related to how python deals with references included here. If you're interested in the mechanics of the is operator, you can learn why 256 is and 257 isn't because of the way things are cached, but as programmers, you shouldn't be using the is operator in this situation. So, these are some of the quirks in python that you need to be aware of early in your python career.Something else that we talked about is this inheritance thing. It kind of goes back to the Meta programming stuff that we've talked about a few times. The way, again, I feel like it's such a clich\u00e9, but it's so true that everything in Python is an object. So if you start using this tool of isinstance and you say, \"Okay, isinstance,\" and you're looking at an integer or something like that, is an INT a type and so forth. And as you start doing more isinstance and you get down to like isinstance type, comma an object true. And then what's odd is the next line is isinstance object, comma type. Yeah, that's true too. So it's some interesting things that are happening in those down low levels of defining what objects and types are inside of Python.\n\nBut yeah, it's an interesting list. There's a whole bunch of ones. And then, like I said, it's probably more fun for me to leave a lot of these for you to kind of puzzle through. I mean, if you need help, there are some links at the bottom to dig through. But it's just again, not so much a tutorial or article in this sense, but just sort of an interesting list of quirks.\n\nThis week, I want to shine a spotlight on another Real Python video course. It showcases a data visualization library with a similar approach to one of the projects mentioned this week. The course is titled \"Graph Your Data with Python and ggplot\" and it's based on a Real Python tutorial by Miguel Garcia. In the video lessons, previous guest and core team member Martin Royce shows you how to install the library Plot 9 and set up Jupyter notebooks. You'll use Plot 9 to create visualizations in an efficient and consistent way. You'll combine the different elements of the Grammar of Graphics, which involve several layers including a data layer, Aesthetics layer, and a Geometrics layer. Along with additional techniques within the Grammar of Graphics, you'll learn how to perform statistical transformations and how to implement a visual style with themes. Finally, you'll learn how to export your data visualization to files. Data visualization is a crucial step towards sharing your results and findings, and I think this course will be a worthy investment of your time. Real Python video courses are broken into easily consumable sections and where needed include code examples for the technique shown. All lessons have a transcript including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the enhanced search tool on RealPython.com.\n\nAnd it leads us very nicely into our discussion this week, which is a fellow Python educator, Trey Hunter, recently posted on Twitter or whatever they're calling themselves this week. What Python feature would you have trouble explaining to a new programmer? In fact, my answer to him was that initialization problem with malleable function signatures because it is that foot gun that I was sort of talking about. It's such a surprise when it happens. So yeah, the discussion was kind of interesting. You get a lot of the regular things that pop up. A guy named Brent O'Connor replied with an exhaustive list, which was basically like, you didn't you kind of that's it, we're done, we don't have to have any more conversations. Yes, decorators, list comprehensions, context managers, magic methods, multiple inheritance, differences between a tuple and the list, and virtual environments. I'm like, okay, there's your list, here you go.\n\nI've said multiple times on the show that when I joined Real Python and started looking at things that I wanted to teach, many of them were the things that I looked at the language and said, that is odd looking. I want to learn what that does, and decorators was the first one. It took me quite a while to kind of get through it. The idea that, again, objects and so forth, but functions are objects too, and you can actually put a function inside of a function and have it return a function and all that kind of stuff is a little mind bendy, especially to a beginner who's maybe just run scripts up to this point. And as you see those at symbols, you're like, what is that, what's going on there? So it definitely requires a bit of a course to kind of sit down and have somebody write it out for you.\n\nAt risk of getting overly pedantic about a simple tweet and its responses, yeah, I did find part of what I found interesting about the conversation was I don't know whether people were just ignoring the word \"new\" in the question, or whether their expectations for a new programmer are completely different to mine, because something like the decorators to me are interesting, right? Because they're messy to implement, but you don't really need to understand them at a basic level. If I go and wrap a class method with the @classmethod decorator, I can tell a student, look, this is the magic word that you put on top of it to turn it into a classmate.Right, we don't have to talk about the spell. The spell can be five years from now, you know, when you're in the potions class. So, I did find that kind of interesting. Like somebody said, \"Oh, you know, meta classes,\" and I'm like, \"Yeah, I'm not having that conversation with somebody who's like, 'Yeah, new is gonna be way far away from that.' I'm not having that conversation with an experienced person, let alone with the new ones, right?\"\n\nYeah, and it's similar to async, await, that kind of stuff. And of course, it always does, but as soon as you get into these kinds of conversations, it turns into somebody turning it into a packaging conversation. Yeah, right away. And to me, that's kind of the same thing. I, you know, yes, the packaging ecosystem is a mess, but I can explain to you why you need a virtual environment in a minute and I can show you the three commands you need to install stuff, and you never have to think about it again. Yeah, if you're gonna go start writing packages, yes, that's a much deeper thing, but again, I don't put that in the bucket of a new programmer myself.\n\nBut yeah, and if people are going to share their code, it's more likely they'll share the entire script, you know, and across a network or something like that, as opposed to having to install it up. Yeah, I agree on that. Virtual environments were one, for like a new programmer, that is a unique concept. I was able to grasp it pretty quickly even though I was new to Python, but I kept having to explain it multiple times to people I worked with. I think it's just like, unless they actually experience creating one and sitting there with it and understanding what it's setting up for them, it takes a minute.\n\nI disagree on one of them, the one about installing. That is our fight from a couple of weeks ago. I feel like, you know, python.org, it's really not that hard. There are lots of other ways that are out there, but that one is pretty consistent and can be pretty simple if people want to look at that way. I was just going to say that I do wonder with the virtual environments whether it's partially an age thing because okay, we used to have to deal with dll hell, which was the same problem, right? You install this program, install that dll, that program installs that dll, and it would cause the first ones to stop to fail. So it's possible that you and I, being old men, having seen this issue outside of the language, it just sort of goes, \"Okay, yeah, I see you're having that problem, and this is how this language has solved that problem.\"\n\nSomebody put typing on there again. As a new programmer, it was more in the context of me looking at code that was written and me seeing something that was not functional, like it wasn't doing something that I could see right away what it was doing with the code. I'm like, \"Why is that stuff there? Why is this extra definition happening?\" You know, I'd seen other non-static languages in the way that they define the type in front of it, and this was doing this defining after it. I was like, it was just weird. So that took a minute, and so I did a course on that, and that helped me kind of wrap my head around it.\n\nBut yeah, I mean, there are a handful of these things in there, but another one I saw in there was the name main idiom. That was another one that when I first saw it, I was like, \"That's interesting. Why are we doing it this way?\" And we have a course coming out really pretty soon that covers that, and I think it actually might be kind of handy for some people that just want to see why it's being used and how, you know, what's going on there. So that one, to me, is really fixable. All they need to do is add a built-in into the language that is the same thing as that check as a Boolean and name it something reasonable, and it no longer has to be this magic thing that you're putting on the bottom and explaining. Right? Call it whatever it is, main is runnable or something, and then all of a sudden, it would just be essentially solving the exact same thing and something that would be far more readable rather than having to explain dunders.\n\nAnd in fact, that was one of the ones we've been talking about recently because I'm working on an object-oriented coding course at the moment, whether or not Dunder init is a constructor, and I really don't like that argument.I find the idea of Dunder init interesting because it's a special system. From a CS level, it makes sense. Teaching it to a new person is a bit odd. In other languages, the Constructor is named the same as the class, which feels more intuitive. Naming things is hard and unfortunately, we're stuck with decisions made 25-30 years ago.\n\nIt's a short thread, but there are some interesting points. Our link doesn't work, but if you have a Twitter account, you should be able to access it. My project this week is an article from Wilma Coogan about the Rich Library. It's a non-Rich way of using Rich, with a function called inspect that gives information about objects formatted nicely for the terminal.\n\nJetBrains, creators of PyCharm, have made an open-source plotting library called Let's Plot. It's based on ggplot from the R language, which follows the grammar of Graphics. Data, aesthetics, and geomes are key components. Real Python has a video course on a similar tool called plot nine, which covers the grammar of graphic stuff.So I'll probably link that this week, but the library is really nice. It has really good documentation, includes a whole Jupyter notebook sort of cookbook kind of tool. The output is very pretty. I like the interactivity of it. It probably has some of the better looking tooltips and the customizability as you hover your mouse over things and see what the data is doing, giving you even more detailed information than just seeing the overall map.\n\nThere's a whole section of the documentation that digs into charts, contours, marginal plots, visualization of errors, smoothing, bivariate distribution, time series, images, facets, coordinate systems, and more. It goes really detailed into it. Then it has a whole other section about maps, proportional symbol maps, choropleths, and a whole bunch of other kinds of layer things that you can apply using that sort of ggplot2 style. It even gets into geocoding.\n\nIt's a neat library that really digs into a lot of stuff. I'm a big fan of visualization and looking forward to playing with it a little bit more. There is a unique technique called sampling that you can use to address large datasets, which can help with overplotting. You can reduce the amount of things being plotted out by applying sampling techniques, which is neat. It works really well in Jupyter notebooks, or there's a tool called Data lore that works very well too.\n\nYeah, let's plot. Thanks again Christopher for bringing all these articles and Pi coders goodness this week. Glad to be here. All right, talk to you soon. Cheers. And don't forget to embrace the future of technology with a .XYZ domain name. Go to porkbun.com/xyz23 to get your .XYZ domain name now for just around two dollars.\n\nI want to thank Christopher Trudeau for coming on the show again this week, and I want to thank you for listening to the Real Python podcast. Make sure to click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python podcast is free. If you like the show, please leave us a review.\n\nYou can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "-wfo5QTTBck": "Welcome to the Real Python Podcast. This is episode 169.\n\nHow can you improve a classification model while avoiding overfitting? Once you have a model, what tools can you use to explain it to others? This week on the show, we talk with author and Python trainer Matt Harrison about his new book, \"Effective XGBoost Tuning: Understanding and Deploying Classification Models.\" \n\nMatt talks about the process of developing the book and how he wanted it to be an interactive experience for the reader. He explains the concepts of gradient boosting and provides metaphors for developing a model. He shares his appreciation for exploratory data analysis as a crucial step in understanding your data and shares additional libraries to help you explain your model. He also illustrates why covering the complete process is essential, from exploring data and building a model to final deployment. He shares many of the tools he found along the way.\n\nThis episode is brought to you by Scout APM. Scout APM is Python monitoring for Swift issue resolution, pinpoint bottlenecks in your code, and optimize performance.\n\nAlright, let's get started. [Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Matt, welcome back to the show. Thanks, excited to be here. Appreciate you inviting me back on.\n\nWell, we ran into each other at PyCon and you handed me a book. I was like, okay, cool. The book is \"Effective XGBoost\" and I enjoyed diving deeper into lots of these topics. I know some of the basics in the book kind of helped me dig into it. When did you start thinking about doing this book?\n\nYeah, the book came out of my day job. I do a lot of corporate training and in the past couple of years, I've been teaching machine learning to my clients. The book came out of scratching my own itch, finding that the content out there is not what I would like to learn from. So I read what was out there around XGBoost and thought I could provide something more actionable and provides content that is not found in other places. That was the impetus there.\n\nSo when did you start writing it?\n\nThat's a great question. I would say the book probably took a year plus to write. Okay, yeah, I was trying to think of the age of XGBoost.\n\nXGBoost has been around for a while. I don't know the exact data off the top of my head, but probably early 2010s. So it's been around for a while. The history of it is that it came onto the scene through Kaggle, which is a machine learning competition. They basically ran crowdsourced machine learning competitions where you would do some prediction and companies would sponsor these competitions. So when this XGBoost model came out, it kind of took the tabular data world by storm and has been the de facto tool for doing tabular prediction.\n\nThere's probably a lot of terms there that some of your audience might not know, so I'm happy to dig into some of those if you want.\n\nMaybe we should start with tabular prediction. What would that mean to the average data scientist?\n\nPrediction is where we have data and we have labels for our data. We want to train a model that can predict a label given some data. There are two classes of predictions: supervised learning and tabular prediction refers to structured data with rows and columns, like data in a database with predefined size and shape. This is in contrast to unstructured data like video, audio, or image data. \n\nInstead of being structured with regular rows, tabular prediction involves rows and columns that may not have every column in every row.But it is structured enough that you can look at relationships between things and figure them out. Yeah, I mean a lot of the world runs on Excel. So if you have data sitting in Excel or in a database, those would be good candidates for using a tool like XGBoost. Okay, cool. \n\nI guess this is related to the type of data that a person would have when looking to build a model upon it. I always like to ask the authors who the book is for. If you have this kind of data, what other qualities would a person interested in this book have? \n\nIf you have data sitting in a database or in Excel and you're trying to make predictions, then XGBoost could be leveraged. You might be trying to predict whether someone has cancer or if someone is going to default on a loan. The book focuses on classification and XGBoost can also do regression, predicting numeric values like predicting house prices. \n\nIf you have data in tabular format and want to give labels to it for marketing purposes or customer retention, XGBoost could be useful. For example, you could predict whether a customer will churn or not and take action to prevent it. Another common use case is in finance for deciding whether to give someone a loan. \n\nIf someone wants to dive into the book, they should have a background in Python and experience using Jupyter. Pandas would also be a useful tool to have. Data scientists spend a lot of time cleaning and understanding data, which is not discussed in the book for XGBoost.\n\nIn conclusion, if you're looking to leverage this tool, consider having a background in Python, experience with Jupyter, and familiarity with Pandas for data cleaning and preprocessing.Yeah, you start with a particular data set and in the second chapter, you kind of take people through some of the fundamentals of cleaning it. It's not a book on cleaning, but more like, \"Hey, this is what I did to the set and what you need to consider in this particular set.\" Then you actually spend a little bit more time on the exploratory data analysis part, and I thought that was really interesting. Why do you think that's one of the most important steps?\n\nYeah, so this is the silly thing. What has a lot of the sexiness appeal these days is deep learning. The idea with deep learning is that you can just throw your data at it, and it will unravel it and make a model for you. While that is kind of true, deep learning can do some cool things. If you have better data, oftentimes you can make a simpler model. Oftentimes, people will use simpler models than XG boost. XG boost can be a tool to do advanced exploration of your data and give you insights into your data and how it's leading to predictions. You can make new features to add to your model, and then with these new features, you could use a simpler model that would perform better than a smarter model with dumber data.\n\nFor example, a traditional model would be logistic regression for classification or linear regression for regression models. The problem with logistic regression is that if you have non-linear responses with your variables, it can't tease that apart. For a while, I worked on predicting failure modes of hardware. NAND flash has a failure mode where after being produced, some percentage of them will fail at infancy. The etchings just stop working after a certain amount of usage, like a burn-in phase.\n\nThey call it burn-ins. Generally, the manufacturer will burn in the device, and if it passes burn-in, then it will last until end of life. You have this bathtub curve response, and logistic regression or linear regression can't predict non-linear relationships. If you were able to identify a non-linear relationship using XG boost, then you could go back and do feature engineering to make logistic regression or linear regression respond to the data better.\n\nPlaying around with your data and understanding it is certainly useful. Typically, when I'm training subject matter experts, they come into the class wanting to apply this tool to their data. They understand their data, and they want to do some modeling around it. This lets them do that relatively easily.\n\nUnlike software, where tasks can be more straightforward, data science involves more evaluation and business considerations. Making a model may be simple, but evaluating its performance, understanding the features, and assessing it from a business standpoint can be more complex. It's not as easy as checking off a task like in software engineering. The answer to whether a model is good often depends on various factors, such as the business case, explainability, and customer understanding.\n\nSo, a lot of data modeling tends to involve making a model, evaluating it, and then possibly realizing that the model needs improvement.But maybe if we tweaked it a little bit, it could perform better. So let's try it again, tweaking it and sort of rinse and repeat that process, and see if we can get a model that will work for us. Is that in some ways why a tool like Jupiter is such a better, well, a more suited tool? The ability to re-run code after modifying parameters and not necessarily running all of the code the way a standard script editor or a type of tool would work. Yeah, Jupiter lends itself really nice to this exploratory style of diving into your data, checking things out, right? I can make plots and have them in line if I'm using advanced libraries like plotly. I can interact with those plots, which are kind of nice. And then, depending on how you're writing your code, it's relatively easy to say, \"Oh, I forgot to do one thing.\" Well, if you're using pandas, maybe you tweak the code a little bit, and then you rerun it, and you don't have to context switch, so to speak, like, \"Okay, now I'm going to go to the terminal, run it in a terminal, and then I'm going to open this image over here to look at the visualization.\" It's all in one place. Yeah, having said that, I find that a lot of people who use Jupiter use a lot of bad practices. So oftentimes, like, I find that my clients aren't programmers, so to speak, and a lot of times they'll say, \"I don't want to be a programmer. I just want to use a tool to get my job done.\" So, as much as I love Jupiter, there are some things, like global variables, the fact that you can run cells in any order, yep, that's a big one, that makes it really nice for exploring, but often for collaboration and sharing, it makes it a little bit more difficult. Yeah, I remember a really good talk about, do you know the state, you know, and just like you aren't sure unless it's been run in the order that you think it is. And yeah, a couple other stories we were talking about on the show were they were trying to do an analysis of Jupiter notebooks that were just out on the web that they could look at, and they were like, \"Well, can we run them from top to bottom?\" And it's like, in most cases, no, you weren't able to do that because that wasn't always the purpose of it. The notebook was there, literally like many people's own notebooks where it's an incomplete statement. Yeah, exactly. I like to say that from my point of view, there are kind of two ways of using Jupiter, right? And so I want to make sure I'm in a certain mindset. So one is more of the messy, this is personal for me, I'm just trying things out, messing around. But then the other one is more of a collaboration, more production type. And when I'm doing that, oftentimes I'll refactor my code, pull it out of global variables, put it into functions, but also make sure that I can execute like you said, yeah, from the top to the bottom, and that makes collaboration a lot easier. It's certainly even for yourself coming back to a notebook and trying to recreate the state can be difficult if you've gone out of order, or especially, you know, this isn't a pandas talk, but you know, if people have put like 50 different cells doing things to their pandas data frame, and they've been executed in some order, like being able to recreate that can be difficult. So, there are some best practices that I like to give folks so that they can overcome a lot of those issues. You probably own a lot of those by teaching people them too, yeah. I like to say that I'm covertly teaching software engineering best practices to these people who don't want to be programmers, right? But for all intents and purposes, they're sitting down at the computer and programming for a good chunk of the day, yeah, yeah. Dealing with performance issues can be a real pain for developers. They not only affect the user experience but also lead to frustration and wasted time. However, there's a powerful solution that can make this process much smoother and more efficient: Scout's APM tool. With Scout, you can pinpoint performance and stability issues in Python applications with ease. Scout's tracing logic detects the exact line of code causing the performance abnormality, fixing the issue before customers ever notice. Start your 14-day free trial now at scoutapm.com. That's s-c-o-u-t-a-p-m.com. So, a couple things kind of related to the stuff you were saying a little bit earlier, how you had read some other books or at least looked at them and thought to yourself, \"Okay, what are key things that you felt needed to be included that maybe weren't included that you put into this book?\" Yeah, I mean, I could rant. It's funny, once you start going down the book writing phase, or I think a lot of people, if they give a talk or probably as podcasters, you probably see a similar thing where once you start doing something, then you pay attention to it. So, from typography, there's this notion of kerning, okay, yeah, that a lot of people don't know about. That's like how far apart the letters are, right? And so, I was reading a typography book when I wrote my first book. I read this typography book, and it was like.Oh, I didn't even know these things existed. But once you start noticing it now, it's like I can't unsee these things. Yeah, yeah, it's like being an editor. I've done some video editing and okay. I have a lot less of an appreciation of certain TV shows or films or commercials. It's like, oh yeah, I see your work. And for the other 99 of us, it's like who knows, right? Yeah. So, I mean, I don't like to explicitly collate and disparage things, so maybe we'll talk in generalities. Like, I was thinking, what would you feel really needed to be in there? Like, this is what I felt needed to be in this book. \n\nI classify a lot of the machine learning content into two schools of thought. One is more academic, where it's like, this is all of the machine learning history up till five years ago. It talks about not so much the history, so to speak, but it's a lot of formulas. Which might be nice, but from my point of view, not a lot of it is super applicable or usable. It's like, oh, this is kind of nice foundational knowledge if I wanted to go down to academia and teach people all of these esoteric facts about the math of these models. \n\nSo, I wasn't necessarily interested in that because when I go into my clients, I'm like, this is how you make a model, this is how you evaluate a model. It's pretty practical and hands-on. If you want to dive into the math, I can give you some pointers to do that, but the purpose of this is not a math class. The other school of thought of a lot of material out there, at least for machine learning, is sort of similar to the academic one, but it's like, okay, here's the kitchen sink of machine learning and how to use all the Python libraries for that. But it's not really going into a lot of depth, so to speak.\n\nMy goal with XG boost was finding, okay, this model is super popular with, for example, Kaggle competitions, but my clients like to take advantage of it. And there are also ancillary libraries around the model that aren't really discussed in one coherent place. So, a lot of it was focused on XG boost but also looking at the ecosystem around that. \n\nTeaching education, a lot of it is curation, which is kind of like, you know, there's the question, can chat GPT replace education? Maybe it can. I'm not sold on that with chat GPT4 or whatever the latest version is because a lot of it is, I want to curate and provide a path that I have experience with and can dive into those details with. I didn't see much material that had an end-to-end path for XG boost, so to speak. \n\nMy last chapter is on ML flow, which is basically deploying these models, and you don't really see a lot of content that goes beyond just making predictions and a little bit on evaluation. It sort of stops there. I had Eric Mathison, I'm familiar with him, he did Python crash course, and we talked a lot about getting people to a point of doing things. I feel like this book is trying to do something really similar to that, and along the way signposting a lot of these things. It's important, you know, these are tools to pay attention to. Throughout it, you're doing a project. \n\nWhat's also nice is, at the end of it, you're like, okay, it's also important that you understand what's involved with deploying this thing and getting it standing up, not just having it in your notebook. I found that really interesting. Also, the idea of, let's start with this set, and so it's a lot of theory and explaining, but it's not sidetracked down the rabbit hole in spending tons of time there. You're actually working with the code and doing tons and tons of visualizations to see as you go, which I really liked. \n\nI think I mentioned this in your last book also, just the printing of it, that it's very colorful, which is really rare for a lot of the books you see on the shelf today. I'm sure that takes some effort for you to get that done, but I appreciate it. It's something that definitely shows as far as trying to understand some of these concepts. Just, okay, this is where it's moving into red, this is where it's moving in the blue, and so forth, kind of seeing relationships because that's really what a lot of these models are about. Thanks.I spent a lot of time trying to work on the visualizations. I'm a huge fan of that and I think they can tell a good story. Another thing that's useful about the book is that it provides a lot of boilerplate for an end-to-end project, which is kind of nice. I think you did this in your previous book, \"Effective Pandas,\" right? At the end of the chapters, you would have a set of questions, which I think is a really nice technique in a lot of these books.\n\nI think it goes back to Eric Math's point and my understanding of teaching and pedagogy. There are various modes of learning - listening, seeing, and doing. Engaging with the material, like typing the code in, helps you learn better. When you see errors pop up, you understand the code better than just hearing that everything works.\n\nI really like it when subject matter experts apply models to drive value from their data. The only way that will happen is by trying it out. Moving beyond just reading and trying it out is important.\n\nIf we dive into XG Boost, where you want to apply this starting with a model, maybe we can explain where it comes into play. Should you try other techniques before moving into this technique? Maybe it would help if I explained at a high level how XG Boost works and contrast it with something like logistic regression.\n\nA common example is predicting Titanic data. The idea is to make a model to predict whether someone lived or died on the Titanic. This is kind of silly in itself because there aren't Titanic boats leaving England every day hitting icebergs and sinking. The more realistic application could be diagnosing a disease based on data.\n\nYou have features like gender, class, number of children, and siblings in the Titanic data. These features can be used to make predictions. Each row represents an individual.And then you have a column that said whether they lived or died. So, with XG boost, what we're doing at a high level is using what's called decision trees. The idea with a decision tree is, let's say you have lived and died, those are your two categories. You're going to go through every column, and feature is the usual terminology that we used to call a column. You might have sex, you might have what class they're in, you might have how much they paid for a ticket. So, you go through each of those columns and split it up. For sex, you might say let's look at male and female because that's a binary categorical. For class, there's first, second, and third class. So, you might split it up into those three classes. For fare, some people didn't pay anything, some people paid like 500. So, you would have this threshold where you'd sort of go through all those different values. \n\nAs you go through those values, you can see if we split on a fare of ten dollars, does that split up survive versus death better than if we move the fare to like 50 or 100? Basically, what the decision tree does is a greedy algorithm that's going to find the single feature with some value of that feature that splits the data the best for some metric that determines how the data is split. Then you recursively continue doing that, so at the next level, you look at the features again. \n\nYou might consider looking at the same feature, that's one of the key points of that decision tree because it can look at those features repeatedly, it can capture those nonlinearities such as those U-shaped curves. So, that's a basic decision tree. All these trees are going to be based upon a core relationship and then go down branches where it's like, plus they were like this, plus they were from this country, plus they were. \n\nYou could trace through this path in the decision tree and you could say, okay, this is an individual that is in first class, they pay this amount, they're male, and they died. That's a decision tree. So, actually built upon this model and the key thing about XG boost is that with a single decision tree, it's kind of nice that you can explain what's going on there. But decision trees have problems in that they tend to do this thing called overfitting, which is like you can imagine building a decision tree that just basically memorizes each individual and at the bottom, you have all these nodes that are all pure. \n\nThis is person A, this is person B, and this person C. You can trace through their paths, which is kind of nice and explains what happened there. But in this hypothetical world where a new Titanic's leaving, there's probably going to be people who don't exactly line up with those other people. So, in that case, we call it overfitting. It's basically memorizing the data, it's not generalizing to new data. You perfectly described this set of data and it doesn't fit on anything else. \n\nGenerally, we don't have data that max matches exactly. So typically with decision trees, what we do is we simplify the model so it's not quite overfit. One way to do that is to prune the tree or to limit the depth of it, and that simplifies it a little bit. But then at that point when you look at the nodes, there's going to be some error in them. The sort of genius thing about XG boost is that what it does is it's going to make the first tree and there will be some error in it and it expects there to be error. \n\nBut what it's going to do is the next tree is actually going to make a prediction based on the error and it's going to try and fix the error. The analogy I like to use is like golfing. You can make a single decision tree and that's like hitting the ball once, but XG boost is like you hit the ball once and the ball will be some amount away from the hole that you're trying to get the ball into. But you can hit it again and then there'll be some error, but you can hit it again and you can keep doing that, and these subsequent trees are basically correcting the error of the previous one. \n\nIn practice, that tends to give pretty robust models. That's the basic gist of XG boost because you can hit that ball multiple times, you're basically correcting the error. But because your trees aren't super deep, they're shallow, they tend to not be overfit, and they tend to work well in the general case. The overfit would be doing it enough times to get the exact club and swing to have this one perfect example that always hits. \n\nAgain, you're not going to get that, whereas it sounds like you're getting this very interesting flexibility of in between there by having the multiple shots if you will at trying to predict it.Off like for these classification problems, we don't have to get it exactly, we just have to get it closer to one side than the other. Overfitting is like we're trying to get it exact right, and getting that exact seems like it would work, but in practice, it doesn't work in a general case because the data is going to be different. Today is different, the stuff you're training on is one thing and then hopefully the stuff you're actually testing on is going to be completely different.\n\nXG boost works good, contrast that with logistic regression. Logistic regression is basically like doing a linear combination of the features multiplied by some weight to fit this logistic curve, which is like a stretched-out S. The math works out as you can say, okay, we're gonna have all these weights and you're going to multiply each feature by a weight and then you sum those up and you throw it into this formula. It will basically put it in this curve saying whether it's closer to the one or closer to the zero. One is labeled as survive and zero is death, and then you can determine whether someone lives or dies based on that. \n\nLogistic regression is looking at each feature, giving it a weight, and then throwing it into a formula to put it onto this curve. The nice thing about logistic regression is that when you have weights for the future, you can think about if that weight is larger, that would indicate that the feature has more impact on determining whether someone lived or died. This is called a white box model or an explainable model. \n\nXG boost model might have 500 trees, and they might say we're not giving you a loan. If you ask why not, they might say, well, we have these decision trees we could go through all 500 of them, but that really wouldn't be feasible. There's a trade-off, the XG boost model might be more accurate, but it might have a business expense such that customers don't like it because you can't explain why you didn't give them a loan, leading to customer churn. \n\nOne of the cool things you can do with XG boost is you can make these models, look at what features are important, and use that to augment your simpler model with better data to make an explainable model. You can try out different models and some might perform better for your business case than others. The Python ecosystem provides XG boost through the scikit-learn library, which offers a common API for all classifiers. You can easily switch between logistic regression and XG boost models, making it nice to try out different models. \n\nThis week, I want to shine a spotlight on another Real Python video course titled \"Starting with Linear Regression in Python.\" It's based on a Real Python article by Minico De Djokovic and instructor Cesar Aguilar takes you through what linear regression is used for. You'll learn how to implement linear regression in Python step by step, including simple linear, multiple linear, and polynomial regression. Methods from scikit-learn library are used to assist in the creation of the regression. Check out the video course for more information.[Music]\n\nOne of the things that you were talking about in the book, in being able to dig into the black box of this thing and explain it, was this thing, I'm guessing it's pronounced SHAP. I don't know if it's SHAP or SHAPE. SHAP. Yeah. Maybe you could talk about that a little bit and why you decided to include that as one of the tools in the book. Is it one of those things where you're like, \"Hey, I wanted to include this in the book because it's a tool that will help with this process?\"\n\nSHAP. So again, one of the great things about XGBoost is it tends to give robust models out of the box. So in my experience, it does overfit slightly out of the box. With a little bit of tuning the hyperparameters, basically the depth of the tree and other hyperparameters that control how these trees are made, you can generally get better performance by tuning it. But it tends to do relatively well out of the box. Again, one of the big downsides with the XGBoost model is this notion of a black box. It's not really explainable. I would say it's more of a gray box. If you wanted to dive through all 500 trees, you could work out the math and do that. But in practice, no one wants to do that because it's so tedious. So what we do is we make these models that are what we would call a surrogate model to explain it. A popular one these days is the SHAP model. Basically, what this is doing is it's saying we're going to use some game theory to look at the features and say how the features impact the final prediction. And basically, what you get is these plots that show a feature and as you change the value of the feature, how does that impact, like in the Titanic case, towards survival or death?\n\nYou might actually see something in Titanic where you might have some U-shaped relationship where it's like, \"Okay, we're going to let the babies live and we're going to let the older folks live, but the people in the middle, we're not going to let live.\" Or something like that. I mean, I watched it, so apparently my kids hadn't seen the Titanic movie, so we watched it the other night. Apparently it wasn't that case at all. It was just an old rich man pushing everyone off the boats and getting in them. Yeah. It did kind of use what you're saying there. Does that help the loan officer then have a handful of scenarios that could help with explaining it?\n\nSo possibly, right? One of the nice things about the SHAP library is that it can explain a single feature. You can get the scatter plot of a single feature and how that feature impacts the final prediction. You can also get what we call local predictions. It can say, \"Okay, here's some person who is on the Titanic. I want you to explain why they survived.\" And it will say, \"Well, their age and their class pushed them more towards survival, but maybe where they embarked from pushed them more towards death. But these other ones overcame it.\" So it actually gives you what we call a waterfall plot of some values pushing it more towards one way and some values pushing towards the other. The ones that push it more are the ones that are causing it to have that prediction. It helps you understand features, it helps you understand a local prediction, and it also helps you understand what we call a global prediction. Once you have these features that you understand how a feature impacts the final prediction and you see how much they impact that, you can rank order those. There might be certain features that have more of an impact than other features. So then you can rank order those and say, \"Okay, these are the features that are more important.\" But also, when you drill into the individual features, the individual feature can help you understand some of those non-linearities. You will actually see in these scatter plots that bathtub thing or weird curves, bathtub curves. You'll see curves that aren't just straight lines. The cool thing about that to me as a data person is like this is telling you what is in the data. It's telling you these relationships that then you can go back and say, \"Why is that? Or maybe we can dig into the data and try to understand these occurrences or things that pop out when we're making the model.\" I find it fascinating that you'll often see non-linear relationships that make sense now that we saw that. But just by looking at a table of data, it would be really hard to come to that conclusion, at least for me. Is that something where in this, I feel like it's all very much an iterative process?Building a model and going through it, this is where you would come back to potentially some of the hyperparameters. Are there ones that you'd want to mention as they're going through it, like XGBoost, stuff that is unique to its hyperparameters? Yeah, I mean, there is an iterative process.\n\nIn the book, I have some code that I think is relatively nice. There are probably two dozen hyperparameters for XGBoost. If you think about these hyperparameters and all the different values, there's a combinatorial explosion. Testing all these values and doing all the combinations would take a long time. So, in the book, I have some nice code that does stepwise hyperparameter tuning. It goes through phases and doesn't do all the combinations at once, which I find is a nice trade-off. It tends to give you better performance relatively quickly than looking at all combinations. I also use a library called hyperopt, which uses Bayesian statistics to optimize hyperparameters.\n\nAt a high level, hyperparameters that you want to tweak generally include the depth of your tree. The default depth is six, but generally, you want to keep your trees shallower to avoid overfitting. Another common parameter to adjust is the number of trees and the learning rate. These parameters have a relationship with each other, as you lower the learning rate, you may want to increase the number of trees.\n\nAs you change hyperparameters, there are tools that allow you to evaluate your model and ensure it's not overfitting and performing well. One of the tools mentioned in the book is mlflow, which helps track hyperparameters and deploy models easily to Docker with a REST API. It simplifies the process of deploying models and tracking experiments.\n\nThe end of the book delves into deploying models, showcasing tools like mlflow for tracking and deploying models. It's not a lot of code to do all of this, but finding curated information on end-to-end model deployment can be challenging. There is information available on the internet, but curated resources are limited.I found this and I want to make sure I include it in this book. Yeah, so as you said, there are a lot of visualizations in the book trying to understand hyperparameters and how they impact the model. One of the libraries that I find interesting, and this is one of those ones that you don't see mentioned a lot, is this XGBFIR model. XGB stands for XG boost feature interactions. I don't remember what the R stands for, but basically, this is an interesting library. It seems like someone who was doing research on this, and not necessarily a Python programmer, took their Java best practices. The interface is a little weird in that you interact with this by running some Python code, and the output isn't a pandas DataFrame, it's actually an Excel spreadsheet. So, you run the code, it spits out a spreadsheet, and then you can use pandas to second the spreadsheet. \n\nWhat it does is it tells you these feature interactions. This is something that a decision tree can capture, which is, if age is going up, does that have an impact on maybe first class or second class for Titanic, so to speak? Is there a relationship? That is something that you wouldn't be able to represent in a logistic regression model just with the single columns. But because of how a tree can look at a column and then look at another column, basically if you inspect the trees and you see columns coming after other columns, and that happens a lot, that's probably an indication that there's some relationship going on between those two features. \n\nSo, that's what this feature interactions library does, it analyzes the artifacts of your model and then goes through and tells you, okay, these are the two pairs of columns that have the most feature interactions, or here's the triplets of columns that have the most feature interactions. To me, as a data person, this is fascinating in that we're feeding the data into these models and they're coming back and giving us insights into the relationship between age and class on the boat, so to speak, and whether you survive or not. \n\nIt sounds like all these tools are helping you understand what's happening with that information, you're making much better decisions with what you're going to do with it. This is key for data scientists because they need to be able to communicate and spell out their solutions. Oftentimes, there isn't one right solution, the answer is \"it depends.\" So being able to back up why you came up with the solution you did using tools like these feature interactions can be super useful for selling the solution. \n\nI've been in some meetings before where somebody's presenting a model and presenting some raw data, and I feel like those little pieces of extra information would have been enough to fend off a lot of questions and give people that it's not purely a black box, it's more of a gray box. Making a model on its own is not particularly interesting, there's a whole story and data that goes with it, that is a super important skill to have. \n\nIf people are interested in getting a copy of the book, the digital version is available on my website metasnake.com at store.metasnake.com. I'll put a discount code in for listeners, and Chris will link to that in the show notes. For the physical book, it is available on Amazon in most places. I have a distributor in India as well for those interested. Printing a color book has high quality, and I think it's worth checking out.And so it turns out that's pretty pricey to do. So, yeah, for the Indian market, there's a grayscale version that's priced more in line with what they're used to.\n\nSo, I have these weekly questions I like to ask everybody. Yeah, what's something that you're excited about that's happening in the world of Python?\n\nYeah, so I don't know if you've heard of the Mojo language. Yes, yeah, yeah, I still want to try to get somebody involved with the project on the show, but we talked about it. Yeah, yeah.\n\nI think there's the perennial, like everyone wants to scratch their itch about what their issues are with Python. And certainly, I have my opinions about good and bad things of Python. But I think that's interesting. It's going to be interesting to see how far the project gets. The nice thing about it is it does have a company behind it. A lot of these efforts in the past have been more one person doing it, and I think a lot of these things are hard problems.\n\nI love open source. I've run Gen 2 Linux on my laptop for 15 years, so I'm not at all unfamiliar with open source. But oftentimes, having someone who has to ship a product and has pressure rather than a scratcher itch can do different things or accomplish different things. So, I think this will be interesting from that point of view. Hopefully, they can have a tool that makes some people happy. I think it'd be impossible to make everyone happy, which is probably why we haven't seen a ton of speed ups in Python. Python is still a slow language.\n\nThat's why libraries like pandas and XG Boost are actually not written in Python, but we have a Python interface to these libraries that run relatively fast. I'm interested in playing with that and seeing where that goes. Have you joined the playground for it?\n\nI haven't yet. Okay, yeah, I've been exploring, but I did a deep dive about it when there was an announcement. I looked at what Chris Lattner has been doing, and it's kind of wild watching this team of people bounce around from different companies and have the funding from the companies to explore this area. I feel like there's momentum there, and the other interesting thing was that they had this need to make an announcement in order to keep funding going. So, it'll be interesting. I think it'll be sooner than later that we'll see it and get to play with it. It's definitely in that ML space, and this area is where people that deal with huge amounts of data need some new different tools than we currently have.\n\nFrom my point of view, pandas is relatively fast, and pandas 2 certainly helps with that. But oftentimes, we do cross that fast barrier and go back to the Python side. So, your solutions now are to use numpy, use Python, use number, which have their pros and cons. If Mojo could help with some of those cons, I think that from the machine learning data side, that could be certainly interesting and pretty huge.\n\nSomething that you want to learn next? So, I am thinking about starting a podcast. So, I'm open to questions anytime. Maybe we should take that offline. That's fine, cool.\n\nI don't have any other details other than that, so we'll leave that there. Sounds good, yeah.\n\nHow can people follow what you do online? I have a mailing list at metasnake.com. That's my company, Meta Snake. I'm on Twitter or X or whatever it's called these days. Maybe it will still be around when the podcast releases. I'm on LinkedIn, I'm on threads as well. We'll see if I'm on other social media as well. It's such a weird turbulent time. Well, I really want to thank you for coming on the show again. It's been fun talking to you. Yeah.My pleasure, thanks for having me back.\n\nDon't forget to take the stress out of development and start your journey towards a smoother, more efficient app experience. Try Scout now and witness the difference it makes in your development at scoutapm.com.\n\nI want to thank Matt Harrison for coming back on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review.\n\nYou can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and I look forward to talking to you soon.",
    "q6gbOLmBbKg": "Welcome to the Real Python Podcast. This is Episode 171. Are you writing efficient Python with as few lines of code as possible? Are you familiar with the many built-in language features that will simplify your code and make it more Pythonic? Christopher Trudeau is back on the show this week, bringing another batch of PyCoder's weekly articles and projects. We discuss a recent post from Bob Belderboss titled \"Make Each Line Count,\" keeping things simple in Python. We provide many of our favorite Pythonic examples and the language mistakes we've learned from. We also share multiple resources to add to your learning path.\n\nMicrosoft has announced a limited beta program for Python inside of Excel. We dig into the current details, requirements, and potential use cases. We cover several other articles and projects from the Python community, including a group of announcements from the Python Software Foundation, a showcase of the Polars data frame library, and Mortal objects in Python, a code image generator project, an MS Paint clone in the terminal, and a Django ORM cheat sheet. Alright, let's get started.\n\nPython Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Christopher, it's been a little while, but welcome back. It's been a long while, but I'll save you from me singing the theme to The Enterprise there for you. Sure, that sounds good. But we have some news to catch up on and a whole bunch of articles and projects to share with everybody this week. Let's dig into some news for sure. Four different things from the Python Software Foundation.\n\nAlright, it's been a month since we last chatted, so some of this isn't very recent, but I'll cover them all in case our listeners use us as the source of their news. Yeah, the first two items are releases. So Python 3.12 RC1 came out at the beginning of August, and then on top of that, all the other maintained Pythons also got a release. So that's 3.11.5, 3.10.13, 3.9.18, and 3.8.18. Those increments are brought to you by a fixed vulnerability in the SSL socket layer. So go get your patch because that's security stuff.\n\nThe next bit of news is PyPI has a new safety and security engineer. His name is Mike Fiedler, and if you're feeling a bit of deja vu, this is actually a different position from the new security developer in residence. Mike's going to be full-time on PyPI stuff, which is a new thing. The position is funded by AWS, and I love that companies are starting to sponsor these. It strengthens open source for all of us. This is a great way for good work to get done. I'm looking forward to that.\n\nSeth Larson has announced as the security developer. It's looking great on the security front for future Python stuff. And those things are very important too, right? The language is widely adapted, and so we need things to be bulletproof.\n\nAnd then the last bit of PSF news was their annual report came out. This would be the 2022 annual report. So suddenly I'm not feeling so bashful about announcing RC1 from a month ago. Yeah, kidding aside, this document tells you what went on at the PSF last year. So if you're interested in all the changes and plans, you can check out the link we have for that. You can see some of those faces behind all the stuff happening.\n\nOne last little thing, a bonus fifth piece of news. Congratulations to the pedantic folks. They just surpassed one billion downloads. So that's McDonald's burger country. So kudos to you folks.\n\nCool, I guess that gets us right into topics this week. I was going to go first, and I think when you saw this, you're like, \"Oh, Crystal, talk about this one.\" This is a Real Python article about Polars, which I've been kind of off and on talking about over the last year or so. The title is \"Python Polars: A Lightning Fast Data Frame Library.\" It's a Real Python tutorial by author Harrison Hoffman. He's one of our new people on the team, and congratulations to him on his first article. This is what's called a showcase tutorial. I still need to learn exactly what that means, but I feel like the plan is that it's going to give me an introduction to the library, things like how to install it and the different configurations, and then it has a bit of hands-on with some of the core features, and then like we like to do, where you might want to go next in your exploration of the package or whatever the project is that we're showcasing.\n\nA quick shout out to Aldrin. Aldrin is somebody who does all the artwork on Real Python. He's been doing fantastic artwork for quite a while, and I mentioned this in a recent meeting. And then I have to agree with him that he can make super cute polar bears just like he's been doing pandas for a while now. If you're not familiar with Polars, I might suggest that you check out a previous episode number 140. I talked to Liam Branigan about the library. He's been working on documentation on Polars for a little while, and he also developed a training course on the library. We discussed the library, we dig pretty deep into it.I think it'd be a really good companion to what's in this showcase tutorial. Polars is a data frame library that is very similar to pandas, which is why I mentioned it earlier. It's built in Rust and is very fast, noticeably fast. I was actually surprised by how quick and peppy it is when I used it for simple tasks. Polars handles data natively in the Apache Arrow format, which is something I've been discussing a lot lately. In a recent interview with Mark Garcia, we talked about pandas 2.0 and he mentioned that there is a slow adoption of the Apache Arrow format. However, Polars has it built in as the default with some big advantages in terms of speed.\n\nThis article is a good way to get started with this library. You can start by installing it using simple pip install of Polars. There are also other installation options with additional support or library features that may be handy. One suggestion is to follow along with the step-by-step instructions that include numpy and pandas in the installation. This allows for easy data manipulation between Polars and pandas. Another option is to include all possible features in the installation, but that may result in a larger install.\n\nIn this tutorial, you practice building data frames starting with randomly generated data in a numpy style. The tutorial walks you through standard data exploration tasks that you would typically do with a data frame. The methods and names in Polars are very similar to pandas, making it easy to work with if you haven't used Polars before.Yet it has dot head, which you can look at the top rows. One nice thing that's added there is it not only formats the data very nicely inside of a terminal window and makes sure that it can fit. It also shows the data types, which I think is really handy. That would usually be a separate command inside of pandas to do. You can also use a DOT describe method, which is really nice. And that is, again, just like pandas, it shows you these summary statistics like the count, null counts, mean, standard deviation, all those kinds of things that you'd like.\n\nOne thing that is truly different from pandas is it does not use indexes. I think that's great, and Richie, the guy who created Polars, is very adamant that they're not needed. So he takes you through how you might do that sort of selection in what are called sort of contexts in dot select by using column. There's also some powerful stuff you can do with the dot select method where you can do piping and almost sort of creating query-like steps that you would want to build in there. I'll have you dig into the article to learn a little more about that.\n\nYou learn a little bit about how to do aggregation inside of this. And then the other big area that this showcase focuses on is the lazy API Polars is able to evaluate really sophisticated expressions on large data sets while keeping memory efficiency. And that's again kind of that tie-in with not only what's happening with Apache Arrow internally, but this lazy API allows you to look at really big things and then choose when you want it to actually pull these operations. You sort of can specify the sequence of operations and not immediately have to run them. Instead, you can have them saved. There's actually a command to say basically run them at this point. There's a collect command you can do. So he digs into all those details.\n\nIt has another feature of allowing you to scan data. So say you have a huge online CSV you want to access, you can scan the file rather than reading the entire file into memory. Polars will create a lazy frame that then sort of references that file's data, and no computation would be performed until you've run this thing dot collect. It talks a little bit about integration with external data along with CSVs, which I mentioned, JSON, Parquet, Avro, which I haven't studied yet, Excel, and various database connections.\n\nThe one thing I mentioned again in the installation part, he mentions including the Pandas and NumPy stuff. He shows you how to do this dot two Pandas or dot two NumPy to create those types of data frames or those types of arrays. And then he covers a little bit more of some links to how to learn more and some of the other more advanced methods and things that you might want to do with it. Again, a showcase.\n\nOne thing that I think is really fun about Polars right now is it's moving fast. It's a pretty new library, but there's a lot of momentum behind it. Like Will McGugan's formation of the textual company, which I think we've mentioned a few times here. Polars, I mentioned maybe a couple weeks ago or I guess over a month now, Polars is forming a company which I think will also help it continue to move along. I think it's really nimble in the way that they're kind of doing stuff and building. The one caveat is that if you're in a legacy situation that has always used Pandas or is using very specific things, there's kind of that existing code setup that's already been created for a while where Pandas is at the heart of that. It might take a little longer for you to figure out how you could kind of move into something else. But if you're experimenting with data science and you're running things from the beginning, I think Polars can really give you a leg up as far as speed.\n\nI think one other thing, there was a release that I'll mention that .19 just came out, and I think that happened just before we put the news together this week. I'll include links to those podcasts and to the recent release notes.\n\nMy first one is called \"Introducing Immortal Objects for Python,\" and it's by Eddie Elizondo. Eddie works for Meta, which is the artist formerly known as Facebook in the Instagram division. Instagram is a Python Django shop, and as you might imagine, they run at a scale that most of the rest of the world can't comprehend. Maybe I should just speak for myself; I can't quite comprehend. Their architecture uses both multiprocessing as well as asyncio for concurrency, and to help with the scale, they do a lot of caching. Interestingly enough, they have a fair number of read-only objects. The article doesn't get into specifics there, but I can imagine things like configuration stuff that is shared across a lot of components that aren't going to be changing. Knowing that an object is read-only can make a big difference with shared memory, as it means you'll never have to sync that across to other processes and saves a whole bunch of overhead. Although they have these objects that they never touch, that actually turns out doesn't mean Python doesn't touch them. They did some deep analysis, and it turns out that due to the way reference counting works, which is part of the garbage collection process, the object's metadata, yeah.That's right, that's meta odd metas objects metadata still gets touched. In short, these read-only objects are being written to. They just don't have their values changed. This brings me back to the fun part of the title Immortal objects. The folks at Instagram created Pep 683, which proposed the ability to mark an object as Immortal, meaning it would never change. By being able to flag an object this way, you can gain efficiency as the garbage collector basically doesn't have to touch it. Not something that most of us will be using tomorrow, but having features like this means that Python continues to be a language that the big players can use, which is good for all of us. Pep 683 has been accepted, and this feature is going to be in October's 3.12 release. So go mark your objects as immortal.\n\nThat's interesting. I wonder if because it is an online service that kind of needs to be there at all times, if that's part of it. The article did talk a little bit about warming machines up, which is a typical problem at scale. If it takes a while for a machine to warm up, you can't wait until you have a problem to turn it on. So you always have to have some on standby. In the case of shared memory, that would mean syncing the memory with the machines that are already running. There's a lot of overhead there. There's a graph in the article, and essentially it's like a logarithmic curve against these kinds of objects when they didn't have immortality. It almost completely inverts the other way by being able to turn it on. It saves them at their scale a significant amount of memory and processing. Wow, cool.\n\nThis week, I want to shine a spotlight on another Real Python video course that showcases a tool for manipulating graphics and pictures inside of Python. It's titled \"Process Images Using the Pillow Library in Python.\" The course is based on a Real Python tutorial by Steven Gruppetta, and in the video lessons, Darren Jones takes you through how to read images with Pillow and perform basic image manipulation like cropping, resizing, changing the format or the mode, working with individual color channels, using Pillow for image processing like blurring, sharpening, smoothing, and enhancing, superimposing images, using NumPy with Pillow for further processing, and creating animations using Pillow. I think it's a worthy investment of your time to learn how to work with and manipulate images inside of Python.\n\nSo my next topic was something I was very excited about when I heard about it. Microsoft is introducing Python inside of Excel, and I had heard rumblings of this for quite a while now. What's kind of challenging about this is that it's a slow rollout, and they give you all these steps of how to do it. Hidden within this article, if you really are searching for it, you'll see that they are just slowly rolling it out, and it's not quite obvious when you'll be picked. Somebody does offer eventually a way to sign up for it. I had to dig into the comment sections and so forth. It's one of those things that I'm not sure what's involved in this public preview, but I'm excited by it. I have done a lot of work in Excel and now having some skills that go beyond Visual Basic is really cool. There are some security concerns that people could have, but I think that's something that'll be addressed as you go. It's a very interesting behavior. It isn't using Python installed on your machine, so that's the first caveat. It's not going to look at what version number you have, what libraries you have, or a virtual environment. It's actually using Azure in the cloud with an Anaconda distribution, a partnership with Anaconda. The cloud stuff is happening all inside Microsoft Azure, and it seems like it just sends it up when you run that particular cell. In some ways, if you've ever done large Excel spreadsheets with lots of formulas and functions, where you open it and change a few things, and have to run all functions again to update, it might be a similar situation here where it would need an internet connection to do that.Otherwise, anything you've already run would be displaying inside the sheet. I will include a link to one of the better introductions to Python and Excel YouTube videos. It gave me a really good idea of how the workflow is. A couple of things that are interesting to me about it: there are some things that are kind of hidden as you do it. When you select a table of rows and columns inside of your Excel, you can highlight them. Inside making this little cell where you want to run Python, you'll hit equals py, and then you can start to run whatever kind of Python code you want. You can expand this to be as large of a script area as you'd want. You can use hashtags to do comments just like normal.\n\nA couple of things are already imported, which is partly where I feel like it gets a little odd for somebody maybe trying to learn this. Data frames are ready to go, it's got pandas ready to go in it. So when you select that range of columns and rows, you can quickly turn that into a data frame. You can name that data frame if you want so you can reference it again instead of saying, \"Hey, reference this particular Excel Battleship-style column and row.\" You can do all the typical things that you can do in pandas, which I think for some people, especially those coming from the Python side, will find this to be really quick and easy to do, like grouping, aggregating, creating plots, etc.\n\nOnce you've run that Excel script, you'll see it as a little cell there as a Python object. But if you want, you can click a button on the side that you can say, actually send this back into Excel data, and then it would output it like you'd see a little table output inside of your sheet. That kind of going into Python, coming out of Python, back to Excel is kind of an interesting little dance that I think will be interesting to play with. Is that what you think the primary purpose is here? Import/export data kind of thing, rather than as a replacement for Visual Basic inside of it?\n\nThat's how they're presenting it right now, again, in the ability to do common things that somebody doing data exploration or things that you could probably do in Excel but might be quicker to do with a data frame library. I haven't seen it doing much more advanced things yet, maybe those videos will be coming. These are early days, and I didn't get invited yet to play with it, but I definitely think it has potential. I'm not sure if it's going to be this thing where you'll have packet structures and you'll be able to share your code in other ways outside of what's here. It definitely needs the \"Azure Cloud\" to be able to rerun these things.\n\nI'm not sure where it fits yet, but it's interesting to see what they do with it. The idea that I could have Python tied together with all these things, that I could have people entering values in an Excel sheet and then have a program running that is gathering them, is intriguing. It's kind of leaning toward the Anaconda uses. It does include some libraries like I mentioned, pandas already, again, you don't have to import it.But I guess matplotlib is there C born stats models. Because it's pandas, it's got numpy, those are the ones that they mentioned.\n\nWhat was really interesting though in one of the demonstrations that I saw is that things that are not there by default that you would have to import, like let's say you want to do regular expressions, which is something that is kind of a power feature that might be a little harder to do, built into Excel. You can import re and then start running regular expressions. They kind of gave an example of that. So that feels kind of weird. Like I don't know how many people are going to know the terminology. \"Oh, I need to import things to be able to do it.\" So, I don't know, it's very interesting. Microsoft's very excited about it. Again, my caution is I don't know how soon you'll be able to play with it yourself. I have a Windows machine, done it, I fired up and so forth and I went through it. It's a lot of steps to kind of get into what's called the beta channel. And then you kind of have this expectation, \"Oh, great, it updated. I should have this version.\" But it's not really that. That's kind of what I think the article missed. There, you have to really look to see, \"Oh well, actually, I guess your username would get invited and then maybe you would get that particular beta seed as part of the Insider program. So, it's interesting to see what it's going to do. I don't know if it's going to solve things for everyone, but I'm excited by the future. And I'd like to get somebody on the show to talk about it. Anthony Shaw was mentioning some stuff on, you know, he works for Microsoft. And I think he was doing some stuff with it. I know Guido, who also sort of works for Microsoft, was mentioning it also. So, it'd be nice to get somebody from the Python community who's connected there with Microsoft on the show to give me a little more heads up as to maybe some of the questions that you had. Like, you know, what is this answering and what is it building on top of? But definitely a watch this space thing and I'm excited by some of the stuff that's there. And again, as somebody who's more comfortable with doing things inside of Python, which maybe we'll talk about more here in a minute in our discussion, how this might actually make things inside of Excel a little easier. \n\nSo, what's your next one? I've got a real Python article by Philip Baskin and it's called Build a Code Image Generator with Python. This is one of those demo-based step-by-step articles. The premise is you've got a chunk of code that you want to show off somewhere and you want to do that with an image rather than text. And that might be because you're using it in a video or posting it somewhere and you need to include things like syntax highlighting. So, you're trying to get sort of a screenshot-ish kind of thing. Yeah, the project works by using Flask to build a small site that serves the code, Jinja templates for the layout, Pigments to colorize the code, and Playwright to create the images by capturing them off of the site. So, that's a lot of moving pieces. \n\nThat's actually the great thing about these kinds of articles. You get to see a bunch of different stuff in action. But it's got a purpose. It's not just, you know, \"Oh, this is what Flask is for.\" This is you're actually doing something. It's not a bunch of Fubar example, but a tool you can use. By the time you're done, the article is divided into five steps. The first step walks you through getting started, shows you how to create a virtual environment, install all the dependencies, etc. So, if you're new to these mechanisms, you can start right there. So, just a bit of basic Python is all you need to do to get going. It gives a brief introduction to Playwright. If you've not used that before, it's similar to Selenium. If that explanation didn't help, that's a web browser driver. So, it allows you to programmatically control a web browser. This kind of tool is often used for testing, so you can make it click on things and check that they work. Playwright works in headless mode, which means it doesn't pop open the browser. It does it behind the scenes, which again is really useful if you're testing because you don't want a stray click mucking with your tests and interfering. So, this is the way to go. \n\nOnce you've toured Playwright, it's time to actually start writing some code. And the idea is to create a website that serves that colorized code, which Playwright then visits and captures. So, if you want a website quickly in Python, the answer is usually Flask. And so here you get Flask going.And four or five lines of code, that's why Flask is very popular. Flask has some expectations about project layout, particularly when you're dealing with things like templates. So it's a framework rather than a library. The rest of the first step really guides you through what that looks like and gets you all set up.\n\nStep two is where you start actually building the meat of the website. The goal is to get a web page that has an input field which you put code into, and then when you hit submit, it outputs the colorized format. It's kind of like highlight.me. It supports all the languages, over 250 choices.\n\nTo duplicate highlight me, you need to create a web page that accepts some code and then outputs it. Step two is all about dealing with this and rendering the results. The next part introduces the idea of a web session, which is a temporary storage mechanism often used by websites to track users' choices and data. Flask supports this, allowing you to remember the last thing that was displayed, so they add that into the project.\n\nOn to step three, Pigments is one of my favorite utility libraries. It does syntax highlighting for over 500 markup and programming languages. Real Python itself uses Pigments to colorize code in the articles. The article talks about how you take Pigments and apply it to the colorized output on your web page.\n\nThere are two more steps to go, but you've already got a useful little tool. Step four uses Playwright to visit your pretty new site and capture an image of your highlighted code, while step five does some polishing, improving the overall user experience. I often find I learn more from these kinds of articles because they're so practical, and you get the added benefit of creating a useful tool.\n\nIf you want to pick up Flask, Pigments, or Playwright, this article is a great way to be introduced to those packages and you end up with a fun little exercise once you're done. I just had Philip on the show to talk about another one of his tutorials, this one was about finding the best programming font, and I found lots of interesting stuff in it. Hope people will enjoy that one and want to thank Philip for coming on the show again.\n\nI think that takes us into our discussion this week, right? Yeah, we're going to talk about something that kicked off from an article by Bob Bilderbos called \"Make Each Line Count: Keeping Things Simple in Python.\" The main argument of the article is that fewer lines tend to be better. It usually means less code to read and fewer chances of a bug. This doesn't necessarily mean compacting things for the sake of it, but more along the lines of choosing the right approach. It's tied to the Zen of Python, that simple is better than complex, complex is better than complicated.\n\nBob goes through a series of short examples where he shows a more Pythonic way to accomplish something with less code. As a demonstration, the first example is a function that checks if a number is divisible by multiple divisors. The simpler version uses the all built-in function and a comprehension, reducing four lines into one. There are actually a couple of good articles on Real Python that cover both all and its cousin any, and they're useful for this kind of thing. If you're looking for some examples about how to take advantage of those functions, check out the links.\n\nDid you have a favorite example or examples of your own that fit into this realm? I think his ones are really nice. I hesitate on the list comprehension one sometimes. I think they look very elegant, but occasionally people try to do less comprehension inside of a list comprehension.And then it gets a little hard to parse. So that goes back to the Zen of Python - is it easy to read and understandable? Generally, they are nice. That's the challenge with this, right? My idea of what is simple might not be your idea of what is simple, so you're always immediately into the subjective space.\n\nI have two right off the top of my head. The way that you can very quickly swap two variables inside of Python has always been one of these weird programming quiz questions. It has to do with a feature that involves tuples. You can have two variables A and B, and if you wanted to make the values of A be inside of B and B be inside of A, in Python you can actually just type out A, B = B, A and boom, one line and it does that swapping for you. There's no temporary variable, nothing inside of there. Having written things out before that had to have this other third thing holding values temporarily, that's kind of a neat, elegant thing, which is nice.\n\nThe other one that was a big wake-up call for me coming from JavaScript was the for loop. Initially, I did a JavaScript-style for loop with an initial value and then incrementing it. Now that I know about iterables inside of Python, I can just say for variable name for I in the iterable and it will go through each one automatically. It's really elegant. For loops in Python are one of those things where you can quickly tell if someone knows Python or not.\n\nThis is one of the things when you're picking up a new language - the first thing you have to master is the syntax. But then there's the better knowledge of the tools within it, and that can make a world of difference, not just in the performance of your code but in your performance as a developer. It can be a source of frustration when going the other way, like writing JavaScript after spending most of your time in the Python world.\n\nA couple other things I really like are working with strings or creating a string from an iterable. The dot join method is elegant, as well as using enumerate to get both the iterable items and their index. There are tons of built-in methods in Python that you just need to learn about.\n\nOne of the things I always do in almost every programming language is providing a default value rather than using an if-else statement to assign a variable. It's cleaner and less indented, even though it may be less performant.\n\nThere are articles that can direct you a bit more on these built-in methods. What are some of the ones you like?I find it looks cleaner. It's something I've done in pretty much all the programming languages I've written, and I continue to do it in Python. Feel free to be angry at me in the comments about it.\n\nSure, there are some libraries, like the built-in zip function and most of itertools. There's a whole depth there of things that you commonly have to do, and they're done for you. Knowing that they exist can make a big difference to your coding. It's similar to things like enumerate that you're mentioning. If you don't have enumerate, you would create a variable and set it to zero, then add an incrementer inside the loop. Now that I know enumerate works, I don't have to do that. Zip and itertools are very much like that.\n\nI came across a third-party package recently that Michael Kennedy was using. It's more itertools, and it's itertools on steroids. It's just like, \"Oh, I wish I need to do this,\" and it's in the same flavor, with dozens of functions that are really useful. For example, when outputting something to the web, you often want to put it in rows. More itertools have something called chunk, which gives you pieces of an iterable in tuples for displaying in rows on the web. This is really handy, saving three or four lines of code.\n\nAnother one that I think always needs some love is defaultdict. If you want your key to point to a list of things, defaultdict takes care of that for you. It saves three lines of code and brings joy.\n\nI saw an example where they were using a handful of these itertools ones. One that I thought was cool is called cycle, allowing repeating patterns across the whole iterable. It's been extended into the Django template framework for zebra striping.\n\nIn the same family, any and all, there are built-ins like Max and Min. Divmod is a cool built-in that gives you the remainder of a division as a tuple. There are so many fantastic built-ins, exploring the language's batteries included.\n\nPeople are sometimes nervous to open up the docs at python.org, but I suggest exploring them. They're written well, with examples and optimized in C. It's all about learning the language, and you don't have to know all the ins and outs.Right, yeah, if you can just remember that it exists. I know roughly what zip is for, but I almost always have to look it up every time I use it because I'm not using it all that frequently. But knowing it's there allows you to go off to the documentation and use the right thing rather than writing it yourself and then realizing you've missed a corner case and now you're debugging your code. It's already kind of set up for you when you're using zip and it's iterating across your multiple lists. It's a kind of elegant stuff that expands your brain as you learn these things.\n\nI think that takes us into projects. I guess I'll go first. This one's been around for a little while and like a few things that we mentioned this week, but it's called Textual Paint. Textual Paint is basically an homage to Ms. Paint in your terminal. It uses the terminal text user interface blocks to create color and so forth. It uses the Pillow Library for conversions to actual files and stuff. It does need Python 3.10 or later. It worked pretty well inside of VS Code for me. I installed iTerm2 just to check it out, as the default one on Mac terminal was a little funky. There's a big long feature list that it has. It was fairly easy to set up, just pip install Textual Paint, and then you run Textual Paint. It's actually kind of a fun project, but I'm not sure how often I'll use something like it. It's a little taller than it is wide, so the pixels are a little shaped not quite square but more tall rectangular.\n\nI came across a Django ORM cheat sheet posted on Django Central. ORM stands for Object Relational Mapping, a way of using object-oriented code to represent the contents in a database. The cheat sheet starts with basic examples like defining a model that maps to a table and querying objects out of the table. It covers different ways of querying things depending on what you're trying to achieve. Once you've got querying down, it moves on to creating and updating objects, dealing with interrelated objects, querying between objects, Q objects, F Expressions, annotations, signals, dates and times, bulk updates, raw SQL, and much more. It's a great reminder resource for those deep in the Django world.\n\nI was thinking about how to organize these collections of stuff and I definitely use bookmarks. Some stuff I just end up going to so frequently that it gets auto-completed as I start typing it into my bar. If I ever have to switch browsers, it'll all disappear, but it's how I organize my resources.Oh yeah, ran into some problems with it and didn't like what they were doing with it. So, I did this massive export. Now, I have a directory on my hard drive called \"elephant,\" inspired by the little icon for Evernote. One of the directories in there is something called \"tools,\" and I usually have a bunch of Little MD files. So, I've got one for Django. This URL, I haven't done it yet, but that would probably end up going in that file. \n\nBecause I'm on a Mac, I've got those all tagged so that I can actually search for classifications and things like that. I can use tools like grep because I'm old. Yeah, so I have my own little pseudo-database for collecting this kind of stuff. That's funny. Speaking of somebody new being introduced to something that's a little old, this programmer kept telling his friend that he was learning how to use \"six.\" His friend was confused and asked, \"Six, what are you talking about?\" Finally, he looked at it and realized he was using VI, not the Roman numeral six. \n\nWell, I'm gonna go tweet on 10. There you go, exactly. Alright, well, thanks again for bringing all these projects, articles, and goodies this week. Always a pleasure. See you in a couple of weeks. Talk to you soon.\n\nI want to thank Christopher Trudeau for coming on the show again this week. And I want to thank you for listening to the Real Python podcast. Make sure to click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "YNctor-1yOU": "Welcome to the Real Python Podcast. This is episode 172. When choosing a tool for profiling Python code performance, should it focus on the CPU, GPU, memory, or individual lines of code? What if it looked at all those factors and didn't alter code performance while measuring it? This week on the show, we talk about scaling with Emery Berger, professor of computer science at the University of Massachusetts Amherst.\n\nEmery talks about his background in memory management and his collaboration on Horde, a scalable memory manager system used in Mac OS. We discuss the need for improving code performance on modern computer architecture. He highlights this idea by contrasting the familiar limitations of Moore's law with the lesser-known rule of Dennard scaling. \n\nWorking with his students in the University lab, they developed Scaling. Scaling is a high-performance CPU, GPU, and memory profiler. It can look at code from the individual function or line by line level and compares time spent in Python versus code. Emery talks about the recent Scaling feature of AI-powered optimization proposals and covers a couple of examples. He also shares a collection of additional Python code assistant tools from their lab.\n\nAlright, let's get started.\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at Real Python. After the podcast, join us and learn real-world Python skills with the community of experts at Real Python.\n\nSo, I want to welcome Emery Berger to the show. He's a professor in the College of Information and Computer Sciences at the University of Massachusetts Amherst. Welcome to the program.\n\nOh, thank you. Great to be here. Real quick, it's a question on the College of Information and Computer Sciences. How does information evolve in there? I'm wondering how that is adapted in some ways if that's kind of a newer distinction for colleges.\n\nYeah, so it's a weird situation. It's kind of a historical artifact, but it's also part of this program that we have. We have a program called informatics, which is really more broad, I think, than traditional computer science. The brief history of this is we started out as a department and then we became a school of computer science and then we went on to become a college, which is the highest level hierarchically in a university. The Provost at the time was like, \"Well, you need to incorporate information like an information school or something like this.\" And that's the actual cause that led to that name. I was actually meant to be computer information and science or something like this. And I was at a faculty meeting and I was like, \"If the words computer science are not in this college, then I am going to move to a place that still has computer science in the name.\" So they kept the name, which I was happy about. \n\nIt sounds like you have a lot of background in memory management systems. One of the things that you've listed on your blog is you worked on a system called Horde. I was wondering about this background in memory management systems and does it help when, I mean, we're here to talk about Scaling, which is a state-of-the-art CPU plus GPU and memory profiler for Python, and it has now AI-powered optimizations and suggestions. But does that background in memory management systems help you working on a profiler?\n\nI certainly think so. The Horde project that you refer to is something I worked on during my PhD and afterwards. The algorithms that are in Horde got significant uptake. You can actually find a comment in the Mac OS implementation of Malik that cites our Horde paper, which is pretty cool. Memory management is an area where you have to be aware of lots of details of what's going on in the hardware, what's going on in the software. Performance really matters a lot for memory management because it's heavily used. You're constantly creating and destroying objects and doing all that performance engineering required really understanding what's going on in the system and being able to follow what's going on. I was already a client of profilers at the time because there's just no way to know. You write some code and it runs a little faster or a little slower and you're like, \"Well, why? What happened?\" Some of the techniques that we used for building replacement memory allocators are actually in Scaling. I'm using a library in Scaling that I started working on for my PhD for writing memory allocators. So that code is actually in Scaling.\n\nYou already kind of mentioned the idea of, or at least the theme of several of your talks recently, which all include links for about performance mattering and then recently injected really matters. Another keyword in there is again, which I think is kind of interesting. In these talks, you talk about how the architecture of computers have over time hit walls. A lot of people have confusion about Moore's Law versus you mentioned Dennard scaling. Maybe you could discuss that real quick, just like what's the difference going on there and why people might confuse one with the other?\n\nYeah, I.So that's this Mor law dard scaling thing everybody's heard of Mo's law. Very few people have heard of dard scaling, but dard scaling is really what made our computers faster for all of these years, not Mo's law per se. Moors law was formulated by Gordon Moore of Intel, who said basically it appears that roughly every 18 months the feature sizes of semiconductors, that is to say the size of transistors, were getting half as big every 18 months. Right, so you could put double the number of transistors on a chip every 18 months. And as this was happening, basically this other phenomenon called dinard scaling was happening, which was that you could increase the cycles, the megahertz or gigahertz, proportional to this increase in density. Basically, the intuition was if these things are denser, this means that the wires, the little etched tiny things on these chips, the faster the communication can happen because of the speed of light traveling a distance. \n\nDard scaling basically said well you can actually also increase the frequency. So we were increasing the frequency along with increasing the density and that lasted a while, and it was great. I recently, relatively recently, got an Apple M1. And now, of course, they have the M2s. When you shifted from the Intel technology to M1, all of a sudden the computer was much faster, everything ran much faster. And that was the first time I had experienced that in 20 years. Back in the day from the late 80s or so, chips were just getting faster and faster every year. You would buy a new computer, and it would run more than twice as fast. It was a time when people openly were derisive of optimizing code and caring about performance because they're just like just wait, just buy next year's computer, this hardware will run it faster. \n\nSomebody I talked to once in Texas, when I was a PhD student in Austin, mentioned a weird dilemma. They could buy a computer now, place an order for it, and then eventually, it gets installed and by the time it's installed, it's obsolete. The new thing is like 2x faster, and what is the likelihood that programmers are going to optimize things and make them two times faster in 18 months versus the hardware which just does it magically. It's kind of a dilemma, but really it's a great situation to be in because this rising tide was lifting all boats. But that is really not the case anymore. Apple has done amazing things, and we could talk about GPUs or something, which obviously have gotten faster and faster. But with the M1 and M2, it's mostly because of system on chip and much larger hardware caches, keeping the memory close to the processor. \n\nGenerally, overall processing, you can compare almost like Raspberry Pi products to some other computers today, and it's not that different in the base amount of cycles this thing is going to run, which is kind of shocking. Because if you looked at the curves, we were supposed to be at the terahertz range by now, and we're still about three or so gigahertz. You can't really get much faster without liquid nitrogen on your motherboard kind of situation. Though I'm hearing interesting things about superconductors in the last couple of weeks, so we'll see what happens with that. When did you start thinking about this performance and designing a profiler? Was this something that tied into it, and maybe you could talk about the background of where this project started and how long it's been going?\n\nSure, I have been working on performance-related tools, developer tools for most of my career. We have a profiler, not for Python, but for native code like C, C++, or Rust called coz, which is a very cool, fun kind of profiler that I'd be happy to talk about. The Python profiling thing actually came from my own suffering with performance issues in Python. I have this website called CS rankings.Org, which is essentially a metric-based ranking or portal for computer scientists in academia, is intended for grad students to select topics they're interested in. It shows them which faculty at institutions are working on those topics, and they can click on their homepages. To make it scale, I made it a static website hosted on GitHub pages. This means I run the processing of the database on my own computer to rebuild it and generate CSVs easily loaded by the JavaScript in CS rankings.\n\nThe process was taking ages, a crazy amount of time. I ran it periodically because it was so painful. It's a Python script that was getting bigger and bigger. I tried using C profile, but it was useless. I then looked for line profilers, but they weren't good either. Running memory profilers on the CSVs processing a gigantic XML file consumed a ton of memory. I had to write a separate Java program to parse and downsample the XML.\n\nI was surprised by the lack of good profilers and how traditional they were compared to Python's unique data handling. Everything in the data science world is loading into C libraries, but traditional profilers didn't offer much help in optimizing performance. I wanted a profiler that could pinpoint issues and provide advice on fixing them to make the program run faster and consume less memory.\n\nThe first step was to implement a statistical profiler to periodically sample code execution. Using the built-in facilities like C profile distorted the execution time, so I didn't trust the results. A statistical profiler involves setting a timer to periodically wake up and check which code is running at that moment.And the ones that you see all the time, that's obviously where you're spending all your time. So it's kind of like a track meet, and somebody's actually looking at lap times and trying to figure out performance. As the thing's going, not just the overall end. Yeah, yeah. I mean, you could imagine it's a great analogy. I love this analogy. I'm gonna have to steal it, sure. So, you know, you could imagine if every person who's at a track meet had to actually carry something like some big timing device, like a giant Flav Flav clock on their chest, right? And they're running. And then, you know, this is keeping track of their instantaneous time all the time. Okay, this step took this long, this step took this long. It's obviously slowing them down, right? It's distorting their actual race. It's no longer the way they would have run if they weren't carrying this giant thing. But instead, if you just take a photograph periodically of where they are, you know who's ahead, right? You get a really good picture. If you have enough photographs, you get a very good picture with really no overhead, right? Without distorting the underlying results. \n\nYeah, okay. So the other thing I really wanted to do right up front was to also trace memory. So this is part of like memory allocation background. I was like, well, you know, I don't first, I don't want it to take a thousand times longer, that's crazy. And second, if you just tell me my code took a bunch of, consumed a bunch of memory, that's like a dimension. And then there's how much time it took, that's another dimension. And I wanted everything together. I wanted a big picture of what the code was doing. Not just in terms of runtime but also in terms of space. That makes sense. \n\nThe memory profiler, typical one that would run in, you know, like part of the Python tools that a lot of people are familiar with, was looking at every single allocation and basically documenting that in a way, like kind of like keeping track of every single allocation. So I could see that, again goes back to the analogy we were talking about of just like, now I have all this overhead of tracking how many thousands or millions of potential objects are being created and allocated and removed and so forth. So it kind of makes more sense to me, the idea of what you're doing with the memory profiling that's happening inside of here. In fact, you kind of set thresholds, I think, in scaling where it's only really paying attention to bumping up against different levels as it goes, which I found kind of fascinating too. I thought of the term quantizing, because I'm into music and timing of sequences of stuff, and I think the same kind of thing. It's like, okay, I'm just seeing which makes sense from a sampling perspective. Like, it's enough information to really see where the problems are, right? Again, could be, oh, there's a photograph for where they're stumbling as they're running along. I can kind of start to see where the problems are. It's interesting that that doesn't take very much overhead at all. Like, there were a couple of different factors that kind of went into deciding that. I remember you mentioning that it was around a megabyte or something that it was looking at, and then you said it was in one of your talks, actually like a prime number, and I don't know if that's too convoluted of a thing to get into. \n\nYeah, I mean the prime number is just a heuristic, okay, to try to avoid some sort of like, if you're allocating things and you're con, that the intuition is just, well, this prime number is a very weird number in a sense, and it doesn't like, okay, things don't divide into that prime number very well. So if you're allocating chunks of memory, the chunks of memory that you're allocating are almost certainly not going to be exactly that prime number, and then they're not going to divide evenly, so you're going to end up with it kind of skewed as you go in the sample. But really, that particular approach is not anywhere near as important as the kind of the growth or shrinking threshold, which actually is the thing that matters. I mean, it's sort of like, okay, so first, let me just say Python allocates and frees memory like crazy. Like, it itself is just a giant allocation machine. Well, it's everything's an object, that's part of it. Exactly, it's creating objects all the time, and reclaiming them, and so on. So, you know, doing something that is actually just tracking every individual allocation is just going to occur a ton of overhead just by the nature of Python. And, you know, people have done memory profilers for C, C++, and you want to keep those low overhead as well, but the allocation rates for Python are an order of magnitude higher than for most C or C++ programs. You know, in C, an INT is an INT, it's not an object. You allocate arrays and you maybe even do more sophisticated things that are just out of reach for Python. \n\nSo, essentially what we're doing is we're just trying to keep track of how high the memory consumption is. So, we don't really care if it's allocating and freeing a lot.Of course, it's Python allocating and freeing like crazy. If it's staying within a narrow bound of less than a megabyte, we don't care. But if it's growing consistently, you can think of it as mile markers. Each mile marker indicates an increase, so we track how high or low we've gone since the last time.\n\nWe call them high water marks and indicate them as we go. The graphs the program outputs are interesting. There's an HTML output where you can see the behavior with data moving and memory allocation.\n\nIf there's a sawtooth pattern with large jumps up and then drops back down, it's a performance hit. Where should someone look if they see this kind of error in their program? In the visualization, it shows memory use over time, going up and down. If you see a large amount of back and forth, it's troubling.\n\nOne common culprit is switching between numpy and Python arrays accidentally. Another issue we found was calling np.array on an already numed array, causing numpy to make a copy unnecessarily.\n\nScalen's line-by-line analysis was helpful in pinpointing the issue. In Python, a lot happens in one line, unlike in C where it's more granular. Line-level profiling in C is for optimizing cycles, but in Python, it's about understanding the workload.\n\nIt's fascinating how many things are called, especially when using libraries and methods. The overhead inside these calls adds up, but that's one of the great things about Python.Right, it's so convenient to do these things. There's an old saying about Lisp and Fortran which is that basically, something to the effect of Fortran programmers know the cost of everything and the value of nothing, and Lisp programmers know the value of everything and the cost of nothing. So Python is kind of similar in that you have access to all of these things. You can just have one line of code that could be responsible for doing tons and tons of work, and you just don't know a priori how much time it's going to take or how much memory it's going to consume. Yeah, you don't know what the expense is exactly, that's pretty wild.\n\nThis week, I want to shine the spotlight on another Real Python video course. As you started on your Python journey, you probably encountered a common chunk of Python code and wondered about it. This course answers the question right in its title: \"What does if __name__ == '__main__' mean in Python?\" Based on a Real Python tutorial by previous guest and Real Python core team member Martin Bryce, this video course is presented by Ariana D. She takes you through not only what does the __name__ == '__main__' idiom mean, but also how it works and when you should use it, and maybe when it's not the best fit. Whether you run code as a script or you're importing as a module, this course will answer your questions on the topic. Real Python video courses are broken into easily consumable sections and where needed include code examples for the technique shown. All lessons have a transcript, including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the search tool on Real Python.\n\nOne of the things that you were doing along in this process, I'm not sure where this came in, I just, again, having watched your presentations that you did at PyCon, later that you showed a chart of other profilers which I thought was interesting. I was like, well, how did you measure the accuracy of all these different profilers? How did you get those widely different results in that some of it you've sort of explained, like the ones that are doing that memory allocation type of thing are definitely weighing down the program a lot because it's sort of sitting on top of it. But were there other things that you were finding as you were? How did you do this measuring of accuracy? Yeah, so we were just curious about, well, we assert that statistical profiling is better. Okay, I think you can kind of reason it out that it makes sense like the way I described it, but we were like, well, how much of a difference does it make in practice? So we wrote a pretty straightforward benchmark. The problem with profiling and measuring accuracy of profiling is that normally to find out where a program is spending all of its time, you use a profiler. So then you have to be like, well, this is the golden one true profiler somehow and everything else is different. And that's not very satisfying because if yours is the one that you've just decided is the golden one, well, all the others are different and you're the winner. You know, hooray for you. So we needed something that provided ground truth. We wanted to be able to know, look, it should say it spent this much time in this function and this much time in this code and so on. So we just constructed a micro benchmark that would allow us to do this. The way we did it was really simple. We made these two functions or these two chunks of code take a different amount of time and we just measured it from the beginning to the end of these computations using the high-res timer. Okay, and so this allowed us, as long as the amount of work that you do is much larger than the cost of actually talking to the timer and getting that value, then this is a totally accurate way of measuring this cost. We went and we basically ran it through a gamut of different proportions and then said, well, what did these other profilers report? The profilers that are the least accurate are unfortunately the most widely used. So cProfile is one of the least accurate and the reason is basically because of exactly this situation of checking every single thing as it goes. It uses the built-in facility that Python has called setProfile and setProfile, there's actually some totally improved way of doing profiling, I should add that you can do starting with 3.12, but even so, doing it with this kind of trace-based approach where you're actually collecting the information as it goes, it just unavoidably distorts things. You really want to do it in this much less intrusive way of doing statistics where you just take these snapshots. That makes sense.It seems that there are tradeoffs of running additional code as opposed to just doing measurements that will cause some things. One thing I wondered about is how to look at memory leak detection. Is that something you can do through monitoring and looking at what's happening instead of trying to pay attention to everything? How did you come up with your ways of determining memory leak detection?\n\nThe memory leak detector is another attempt to do this with sampling. The idea behind the memory leak detector is monitoring every individual thing is very costly. Another thing that memory leak detectors do is save all the state of the Heap by taking a big snapshot and comparing the snapshots. This is problematic in Python because there are Python-based leaks, native code leaks, and a combination of both. It's not a great way to spend your day. I wanted a tool that could automatically detect large memory leaks. It's not fun to compare all the Heap data structures and do a heap diff.\n\nThe idea behind it is simple but it took a while to come up with. We periodically monitor allocated objects to see if they are later freed. If an object is sampled and not reclaimed, it could be a leak. It's like a random process where we accumulate evidence about allocations. We investigate if something seems atypical and build up evidence to determine if it's a leak.\n\nOne important factor is to make the sampling proportional to the size of objects. We measure leak volume and report it to the programmer. If the leak volume is significant, it could indicate a serious issue.\n\nWhen should someone start using a profiler? In cases where performance is a concern, especially in Python for data science with large memory usage and multiple libraries. Using a profiler can help identify performance issues and understand what's causing them. Typical use cases for introducing a profiler depend on the specific needs and goals of the project.So I mean I think it does vary, but often it's just like, \"oh this code is annoyingly slow.\" Okay, right. So I'm in Jupyter and I'm doing something interactive. I run something and I'm sitting around waiting for a result. Once performance becomes a pain, that's usually the right time to grab for a profiler. I mean, the thing you definitely don't want to do is to go on your gut instinct and say, \"oh I know why it's slow,\" because you probably don't. But you know what does know? A profiler knows. A profiler knows what's slow, what's consuming memory, which often has the same knock-on impact of slowing things down.\n\nOne of the things I haven't mentioned about scaling, which is really distinguishing, is that it doesn't just break and say, \"oh this code took this much time.\" It actually breaks it down and says it took this much time running native code like libraries, it took this much time in Python, it took this much time in the system like executing I/O. So it gives you this information. You know, there are things like if it's like, \"oh it's running native code, it's not consuming I/O,\" like I'm already doing the right thing there. Even though it's spending some amount of time that is not really a candidate for optimization. \n\nBut if you see something spending all of its time in Python or all of its time waiting on I/O, you might think, \"well if it's in Python, I need to rewrite it to use libraries. If it's waiting for I/O, you might want to start using asyncio to try to hide that latency, things like that.\" So that's one case, just like, \"oh it's slow, this hurts me.\" But you know, the other case, the other case is like, you know, if you're running stuff on the cloud, for example, the amount of memory you consume dictates what kind of a computer you're going to actually end up renting. Sure, and more memory is more money. \n\nSo, you know, more RAM means more money. And so, you know, if you built a system and you're like, \"well I really would like to use a smaller system or a less expensive one that's really shared and has it's just cheaper,\" then doing some profiling will probably help you find places you can cut cost. Is there anything that somebody needs to keep in mind if they're looking at running scaling on a cloud instance and wanting to measure its performance? Are there things that somebody needs to keep in mind in installing that or is there anything unique about that?\n\nSo the only thing, so we recently added this actually specifically to address the concerns of folks using it. So, scaling is mostly an interactive thing. You say scaling and then you run, you write the rest of your arguments, you run it and it produces this web-based user interface. But if you're running something in the cloud, there's no browser in the cloud, you're connected through something. And you may be running something for a very long time, there's some people run servers that are out there not just to run in 10 seconds but they run for days or something. \n\nAnd then you need some sort of periodic view of what's going on, you need to collect a profile. So we have a way of telling the thing to emit periodic profiles and you can also specifically say, \"hey send this Python process a `Das Das off` message,\" which means turn off profiling. So you can turn it on and you can turn it off and whenever you turn it off, it now actually saves the profile so you can always get a fresh profile just by doing `--off` and `--on`.\n\nSo it's like a toggle to have it output the performance and would it then give you the HTML file to? You can have it right. Normally it produces an HTML file but it also can produce a JSON file to make it easy to consume. And it also produces one that's not interesting in this use case, a kind of text-based thing using the rich library. Oh okay, cool. One of the things you mentioned there of somebody experimenting on this potential program they want to profile and they're running it in Jupyter and I think it was the PyCon 2021 talk said, \"well we're working on the Jupyter thing, it's not quite optimized and working well now.\" How's that progressed and how's it performing now?\n\nYeah, so I mean it, I don't recall exactly what I said. It was in the before times, yeah sure. But yeah, so I mean it does work for Jupyter. The problem with Jupyter is getting in edgewise to be able to profile the memory consumption is, we don't yet know how to do it. It's just an engineering question but have not figured out how to make it work or make it work consistently. There's still a problem with Windows, can't easily do the memory profiling on Windows. It's just that Windows makes things really painful when you want to do this kind of instrumentation. It's super easy to do in Linux and the Mac and it's virtually impossible to do on Windows, and impossible really hard but.Yeah, the Jupiter thing, we can't get the memory profiles out yet from Jupiter, which is annoying. Okay, I'd like to get that resolved, but it works fine at the command line.\n\nYeah, it sounds like any kind of project like this, you have a bunch of unique, potentially software or operating system, or whatever specific issues you have to delve into. So, I find that very interesting. I think one of them that you hit along the way was trying to get it to behave well with K, as far as installing it and so forth. Has that journey gotten further along too?\n\nOh yeah, K's we have conda. It works, as far as I'm aware, everything is good on that front. I mean, the Python ecosystem is just huge, and it touches everything. So, we've had to learn a lot in this process. Like, you're like, \"Oh blah blah blah pip, fine, that's not so hard.\" And then, \"Oh, now we need to transition to PyProject because we're using setup,\" and then there's K, and we didn't know anything about conda and how conda works, and those folks are really busy. So, getting them to help out, it was a lot of waiting. I'm very grateful for their help, but yeah, it's been a great experience for me and my students. The Python community is awesome in general, super friendly, super helpful, super open. It's been a joy to see scalen get adopted and get so many users. But yeah, every now and then we will get some requests like, \"This doesn't run on potato Linux 4.7 on the Raspberry Pi from the 80s,\" and you're like, \"I'm sorry, I can't help you.\" There are so many edge cases there.\n\nSo, we're trying to hit the big ones. I would love to get better Windows support, but it's just a technical limitation. Going back to the idea of results in figuring out areas that you could improve your program, what have been some of the low-hanging fruit of performance that you found along the way people have reported to you after using scalen?\n\nI think the big ones have been really, there are a bunch of them, but so we have a bunch of case studies that are on the website, and they do vary. A lot of it comes down to inefficient use of the libraries, which is obvious in retrospect, but it wasn't what we anticipated when we created scalen. So, if you use numpy, numpy can be incredibly fast. But if you're doing something where you're like, \"Oh, I'm using a for loop and I'm doing numpy stuff,\" well then you're moving between these worlds. You're moving between the super-fast C/C++ world and Python. You're also not giving numpy the opportunity to do a bunch of work on a giant object, which can do very, very fast while it's in C-land. It can take advantage of vectorization, which is super fast. You can get giant speedups by doing vector processing on your chip as opposed to doing things one at a time. So, we see a lot of that where people are just like, \"Oh, I was doing something, and it turned out it was inefficient, spending a lot of time in native code, and had poor utilization,\" and it's like, \"Well, that's what I need to work on.\" One of the most recent additions is to add hooks into having AI help potentially give advice. How's that process gone for you, and what are the types of advice it can give to a potential person who's looking at poor performance from their program?\n\nIt's been super exciting. I cannot stress enough how revolutionary this technology is. By that, I mean these large language models like GPT 3.5 and 4. We've incorporated this into the user interface. There is some work that is not yet incorporated into the user interface that one of my PhD students, Sam Stern, is working on, which will push this even further. But the user interface already allows you to select either a region of code or a line of code and say, \"Hey, make this faster. Give me a suggestion to optimize this code.\" You have to provide your own OpenAI API key, but it's not that expensive. I always tell people it's worth a quarter. Click a button, and the magic machine figures out how to speed up your code. This is definitely a good use of your time. Many times it will come up with proposed optimizations that are correct, preserving the semantics of your code but speeding things up by 10x, 20x, or 100x. I know my way around numpy and pandas, and I use them, but it will generate incredible code that just speeds things up tremendously.It's really just the click of a button. All things we described in our paper and the case studies we had the code for, we tried with the AI and it was able to find faster optimizations automatically. The paper you're referencing, and I'll include a link for it, is \"Triangulating Python Performance Issues with Scaling.\" Is that the one you're speaking of? That's the one exactly. Yeah, cool. I'll definitely include that and all the other talks we kind of mentioned. \n\nThis is a question I brought up when I had Pablo Gindo Sagato on. When we talked about memory, and the audience varies depending on the topic but it's usually intermediate people wanting to learn more. One thing I thought about was if you get a new job at a company and have the task of learning a code base, do you think a profiler would be helpful in that process? What kinds of things would it help you discover? \n\nThat's an interesting question. Profilers are a program understanding tool, but they're not for understanding what the code does functionally. It's about understanding what it does in terms of its performance. It gives you a resource-oriented view of your code, like where it's using the CPU and memory. It might be helpful for understanding where the key code that's doing all the work is located. \n\nIt's not always obvious that this is helpful for understanding a codebase, but if a chunk of code is taking up a lot of time, then that code matters. Even if it's as optimized as possible, understanding where the work is being done can be useful. Profilers provide insight into where the code is doing work, which can be valuable when grappling with a new codebase. \n\nRegarding the technical paper you wrote, there's a subset of conferences more specific to computer science that the paper won the best paper award at OSDI. What's your experience with these computer science conferences compared to more general conferences like PyCon? \n\nOSDI is one of the two big systems conferences in academic computing. It's highly prestigious and selective for publishing research. Industry conferences focus on tools and functionality, even if the functionality is well-known in scientific literature. These conferences often feature papers about big systems with technical innovation. Novelty is a requirement for scientific technical conferences, focusing on discoveries and uniqueness. \n\nThese conferences may also have tutorials, like the LLVM tutorials you mentioned earlier. Overall, scientific technical conferences focus on novelty and technical innovation, while industry conferences may focus more on tools and functionality.And so it's like, well, you want to use LVM in your research, come and take this tutorial. These things will be collocated with the conference, maybe the first day or two before. There'll be workshops and other things like this. So these conferences serve different purposes, but the main technical conference is really about the scientific contribution.\n\nI won't dig into Mojo per se, but I'm thinking about other potential things that have happened in the Python world and data science world that are kind of novel. Things happening here, like the idea of Apache Arrow as a back end. Is that something that would be suggested by a system like that? Would it look at the way the data is being stored and the data types and suggest that maybe you have things in an inefficient format? Is that something that could come across as advice from looking at profiling the code? It's a good question. I mean, I think these large language models, right, are trained on GitHub and on Stack Overflow and on all this stuff. So they get access to all of this code. If you have something that is relatively new or something that just doesn't have many code examples out there, the large language models really don't have much to say because they haven't been trained on it.\n\nI don't recall exactly when pyArrow got integrated with pandas, but it may be too new in terms of training data. But it's definitely something we could check out. We do absolutely see it doing great optimizations with pandas. Some of the things that I should add, this is what's coming, the stuff that my student is working on, sometimes comes up with optimizations that are wrong, okay, right, like it comes up with optimizations that actually slow things down. So we have a system now that actually does a bunch of stuff to vet the proposed optimizations to make sure they're still doing the same thing as the original and to verify that the optimizations actually achieve the optimizations in the desired dimension. Yeah, that sounds interesting.\n\nI mean, that is one of the problems with the models, potentially can put mixed ideas together. I guess that's something that human beings do too. I don't necessarily agree with the whole term of hallucination, right, but I'm trying to think of the other one, confabulation. Maybe I was just gonna use that word, that's great. Yes, so I think that this sort of dreaming that it does is one of the things that we see sometimes, which is entertaining and also telling. It will propose code with APIs that are non-existent, and boy, you look at those APIs and you're like, man, that would be a great API, I would love to have that function call. You're right, that would be an awesome function call. However, it does not exist. Thanks for the suggestion. Yes, and it's like, just use magic F, and you're like, oh, but there is no such magic F, please do something else.\n\nWe had a recent issue with that in PyCoders, where an article was suggested to us, and in the middle of it was about this particular rust linter thing called \"rough.\" The article that was published by this particular person, in the middle of it, had just a complete confabulation, it was pretty crazy. It's like, oh, you can create your own rules by doing this, and it's like that's nowhere in the documentation. It was pretty wild. And so I can see how that stuff kind of happens, but yeah, have somebody eventually scratch their chin and go, yeah, actually, that's kind of a novel idea that was confabulated, yeah, absolutely.\n\nOne of the first things that bit a bunch of my fellow researchers was they went looking for citations to work. Like, oh, tell me about papers that do X and Y, and it will gleefully report a whole bunch of papers that do these things, and these papers are entirely made up, never. I mean, I think this is all fixable, to be honest, because it can obviously go out to the internet and find things and verify whether they exist, to search and do all of these things. Maybe like a system of footnotes or whatever you want to call it, of documenting where did these ideas come from, if that's possible in some sort of system. Citations almost the same way that you really would like to have artwork or other things that are being generated have some kind of watermarks or other kinds of things just to say hey, this can't just run by itself without us knowing what's happening, that there should be some notations of like, well, this was the chain of thought that happened here.\n\nBut that's the problem with the black box, though, I guess, is there a way to streamline that and a way to have it do that, I don't know. I mean, I think in some cases, no, but in some cases, yes.In the situation where we are dealing with code, we are in a kind of super privileged position because we can always run and test the code to see if it does what it's supposed to do. With English, this is a lot harder. You're like, \"I imagined blah blah blah,\" but the harder problem is to determine if blah blah blah exists, compared to just running Python code and comparing the results.\n\nI have these questions I like to ask everyone, and the first one is, what's something you're excited about that's happening in the world of Python? I'm definitely excited about large language models and their potential for improving the developer experience. My lab is working on this full steam ahead. We have put out a number of projects for Python and other things that incorporate AI. For example, we have a tool called DBG that incorporates large language models into your debugger, allowing for root cause analysis and proposing fixes.\n\nWe also have a tool for automatically commenting your Python code and inferring types called Commentator. Another tool we have is Python S, which generates a function based on a natural language spec and tests you provide. We also have property-based tests like Hypothesis that generate code based on specs and tests, allowing for coding without actually coding.\n\nI constantly feel like I'm learning new things, especially with being a researcher always learning more about machine learning. I have a longstanding desire to learn Hungarian, given my Hungarian family background, even though it's a brutally difficult language. I've learned a few romance languages like Italian and have a desire to learn more, but Hungarian remains a challenge.\n\nI moved to Hawaii and tried to learn Japanese, which was a challenge with its different forms of written language. It wasn't necessarily the skill I needed at the time, but it was still interesting and fascinating to explore Japanese media. Transitioning between romance languages is much easier compared to learning Japanese, given the shared Latin roots. My experience studying Catalan in Barcelona was much easier compared to learning Japanese.And so you just change the endings and you've got that ready to go. Yeah, but I think it would be fun to use them. What techniques are you going to use to learn it? To learn Hungarian, I mean I think this is something I'm interested in doing. I don't know if I'm going to have the time to do it. It's so hard, the words don't stick in my head, it's really difficult. But I wouldn't mind spending some time learning Portuguese. I find Portuguese to be a pretty challenging Romance language to be honest, not like Romanian. The phonology of Portuguese is pretty different, and then you have Brazilian versus Peninsular Portuguese. Hoping to spend some time in Portugal soon, I wouldn't mind being able to speak a little better than I can. Honestly, what I do with these things is I just have some grammar books and go through them, and then I try to listen to stuff. It's actually fairly easy to read stuff written in other Romance languages, but what kills you, especially with French, is that you can see a word in French and then hear the word in French, and the pronunciations are completely off, there's no relationship whatsoever. So some of these things you just have to memorize.\n\nHow can people follow the work that you do online? I guess you and your team, yeah. So we have a bunch of projects on GitHub, the name of our group is Plasma-Mass. You can just go to github.com/plasma-mass and that lists a bunch of our repositories. We have a webpage with a bunch of videos and whatnot, which is plasma.org. Plasma stands for Programming Languages and Systems in Massachusetts, so that's the acronyms. I have my own GitHub page as well, just Emry Burger. I am still a little bit on Twitter, I refuse to rename it in my head. Anyway, I'm on Threads now, I'm on Mastodon, we'll see if any of that really built up enough steam to replace the site that used to be Twitter. It's always kind of a sad note when we get to that point in the show.\n\nYes, but cool. Well, Emry, thanks so much for coming on the show. It's been really fantastic to talk to you. Thanks so much for having me, had a great time. I want to thank Emry Burger for coming on the show this week and I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "5a7CwzNCMDg": "Welcome to the Real Python Podcast. This is episode 173. Have you thought about contributing to an open-source Python project? What are possible entry points for intermediate developers? Christopher Trudeau is back on the show this week, bringing another batch of PyCoder's Weekly articles and projects. We discussed a recent article by Stephanie Mullen titled \"Five Ways to Get Started in Open Source.\" Christopher shares his experiences with suggesting features and potential bug fixes. We talk about common entry points for beginners and provide additional resources. We cover a recent Real Python tutorial about creating QR codes with Python. The tutorial introduces the library segno and tours the features by working through the examples. You'll be ready to build a QR code project yourself. We also cover several other articles and projects from the Python community, including a couple of release announcements, an introduction to Python's Funk tools module, switching to Hatch for packaging options when NumPy is too slow, a simple diceware generator project, and a collection of machine learning recipes.\n\nAlright, let's get started. The Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at RealPython.com. After the podcast, join us and learn real-world Python skills with a community of experts at RealPython.com.\n\nHey Christopher, welcome back to the show.\n\nHey there. So we have a kind of a short news roundup, a couple of items as we chug toward Python 3.12 coming out. Yeah, a little more variety this time. I'll start off with the 2023 Django Developer Survey. Every year, the Django community sends this out looking for data on how the framework is used. This year, there are some questions on the parts of the framework you use most, how and if you containerize, what features you'd like, the usual survey stuff. It's open until October 1st. So if you're a Django person and you want to contribute your private opinion on things, go click the link.\n\nAs you kind of mentioned, there's that smell on the horizon, it's a Python release. We're getting really close to 3.12, and as a result, just after our last podcast went out, RC2 was spit out into the world. So we should start a countdown or something. Yeah, and of course, the most important of 3.12 is that means we'll have a podcast dedicated to 3.12 because it's all about us. Got to bring Garana back on here, exactly, that's right.\n\nThe next little bit of news is pandas 2.1 came out at the end of August. This version continues their move towards Pyro becoming a required dependency as they continue to adjust that framework. There's a bunch of copy-on-write improvements, a fresh new implementation of the DataFrame stack method, and a bunch more. So if you do pandas, go grab the hot freshness. Alright, and then the final bit is almost a little follow-on note. Back in episode 157, we discussed PEP 713. That PEP was proposing to make modules callable. And as you might guess by my use of past tense in that sentence, it's been rejected. Okay, so the steering council didn't feel it was compelling enough to include it over the other complications that it would introduce. So we're not going to have callable modules in Python imports. Okay, yeah, I guess I gotta figure out a different way to approach that if that's truly something they want down the road. Make it more compelling, I guess. But yeah, it's interesting to watch the process. We've talked about lots of these across the show over the years of things being proposed and then being rejected. And if you're interested in how the sausage gets made, the link is the announcement in a discussion forum. And that discussion that is basically the announcement also has a link to the deeper discussion of the council. So you can, if you're interested in how it all works and how they make decisions about this and what they argue about before making a decision, you can drill through and learn. Yeah, I feel like we're gonna have a lot of that kind of stuff this week, places for you to dig in and learn way more about a particular area of focus. So that's great. Dig into the PEPs.\n\nMy first topic this week is a Real Python project. I'm not sure if to call it a project or to call it sort of an exploration of a Python package that's out there. It's a new tutorial by author Sarah Hack. She's a new author with us here at Real Python, and it's called \"Generate Beautiful QR Codes with Python.\" If anybody was not familiar with QR codes maybe two, three years ago, I think the pandemic has changed that. If anybody's gone to a restaurant, especially in the U.S., it's been a big shift where basically everything's a scannable thing to bring up a menu on your phone and things like that. So less and less touch surfaces, so QR codes are becoming somewhat ubiquitous. I think it's really odd to see them on a television program, but whatever, it's become so ubiquitous it's become an attack vector. Yeah, it is. It's always been one, I think. People are printing out stickers to put over the QR codes on the restaurant tables so that what you scan is what they want you to scan and send you off to nefarious places. And of course, restaurants don't understand that's what's going on. Oh, wow. Okay. And if the attack vector is smart enough, they redirect you back to the restaurant afterwards.So, yeah, QR codes are fun.\nJust tell me the site first.\nInteresting. Like I know my Apple devices at least show me where it's headed to, so I wonder if it's something. Half the time, the problem is they're often URL shorteners. So, yeah, it's not branded with the restaurant. I don't know where that's taking me. I would like a piece of paper, please.\n\nWell, would you like a three-hour lecture on computer security, or would you just like to get me a piece of paper? Yeah, sure, sir.\n\nSo, this one is talking about a library called segno, S-E-G-N-O, and it explores the overall library features. I think it's a really cool library to explore because if you were looking to do something more with QR codes and build them, maybe you're looking at making a CLI or maybe explore using it with a GUI. I feel like this is a great place for somebody to build a much bigger project from and explore a lot of those aspects of the whole library and kind of get you familiar with what's happening with it. So, with the help of this tutorial, you're going to learn about not only creating the codes for your personal use but potentially again maybe making a project out of it. You start with fundamental stuff, pip installing the library and using it to just create something that says \"hello, world\" when somebody looks at it. So, it doesn't have to always point to a URL, that's probably the most common thing, but it can just display text if you'd like. From there, it goes into how large do you want this thing to be, changing its size, talks a little bit about the background about QR codes itself, about how these little black and white squares are called modules, I guess. The border around the QR code, they call it the quiet zone, the blank space, and there's ways to adjust that also, changing the colors within the QR code, not only the whole thing like its background or the foreground or even different portions of it. And then there's a couple other libraries you can add to do a little more kind of creative stuff with it, like rotating the QR code. And you can import a library called QR code-artistic and the Pillow library, which you've talked about in the show a handful of times. And with those, then this library can take advantage of some additional features for doing things like rotating and adjusting a couple of additional parameters. At the very end of it, you are doing sort of a more advanced thing of creating animated QR codes, which then I have never seen before but would be a little more interested, like as an animated gif that you could put on a website. And in this case, they use this gif of rocking out, and it goes to a link on YouTube of \"Smells Like Teen Spirit.\" So, I think it's a neat little exploration of this. Again, I think this is a great jumping-off point for people who might be interested in creating a project to build their own. The project that I used QR codes with a couple of years ago, I was working on creating a kind of an out in the world scavenger hunt for our family reunion. Actually, my wife's family. Part of it was you'd have to prove that you'd gotten to a particular location based upon the directions that were given in the scavenger hunt. And so, it used your phone kind of like in a style like Pokemon go or something like that where you can kind of tell you it's okay you're headed in this direction it's over here and then you're looking for this particular piece of architecture out in the world. And so, I was creating little QR codes that people would then scan and put in. So, it was fun. So, yeah, I like this. I'll include a link to the segno documentation. It's pretty cool. And again, one of the things I think it focuses on that's interesting is it also kind of makes these very small QR codes, micro QR codes. And that's partly why it has a whole section on making them larger if you need to print them out and so forth. So, what's your first one? My first article is by Florin Dallitz, and it's called an introduction to Python's Funk tools module. Funk tools is kind of a dark corner of the standard library, one of those places you don't tend to send beginners, but it has a bunch of stuff that can shorten your code. So, why write it yourself if someone else has already made that effort? The common theme of this module is sort of murky. It contains high-order functions and operations on callable objects, and that's a mouthful. It means functions that return and interact with other functions, callables to be perfectly correct. So, we talked in episode 125 about LRU cache, which is a decorator that caches the value of your function, which can possibly give you a performance boost. And that's part of Funk tools. So, this article is a couple years old.So, it's based on Python 3.8, but not much has changed in the library. It's been fairly stable, still a decent introduction even though it's a couple of years out. It starts out by talking about caching, including the LRU cache thing I just mentioned, as well as something called cached property. This is similar to the property decorator for a class, which makes a method accessible as if it's an attribute. And as you might guess from the name of the cached property version, it adds caching capabilities. So now your property does a little calculation and it doesn't get run a second time; the cached value gets returned the second time.\n\nOne of the ones in the article that I hadn't come across before, that is something I should really remember, is called total ordering. Yeah, also a decorator. So you might be familiar with the special methods on a class that get called when you compare two objects. For example, Dunder EQ gets called if you compare two objects with double equals. But there are five of those: less than, less than or equal, greater than, greater than or equal, and equal. And fully implementing all of them is a bunch of work. So what total ordering does is it's a decorator, meaning you don't have to implement them all; you implement under EQ and under LT (that's the less than one), and then the decorator figures out how to combine them to supply the rest.\n\nAnd the last one I'm going to talk about is the reduce function. This one isn't a decorator. The idea behind reduce is to express operation equals semantics over an iterable. So you might already be familiar with the sum function, which takes an iterable and returns the sum of its components. In that case, the operator equals semantic that I'm talking about would be addition. So you could implement sum by using reduce, passing in the add operator. So there's actually a function called add in the operator module. You pass in a reference to that and the iterable of things that you want to sum, and it would return the sum, just like calling the sum function. Of course, you're not going to do that because sum already exists, but if you want to do something fancier than just addition, reduce is the way to do it.\n\nSo, for example, if you wanted to do the product of values in an iterable, reduce would be the way. And because it just takes a reference to a function and an iterable, you can hand it your own functions and come up with it. So if you're finding you're doing something like a tight loop with equals or and equals or something along those lines, yeah, reduce might be an alternative way of doing that in fewer lines of code. Definitely dives into that functional programming stuff.\n\nExactly, yeah, very much so. And if you're new to Funk tools, this is a great introduction that covers 11 of the, I think, 12 that are now in the most recent. So you're getting almost everything even though this is 3.8 based. And if you're like me and you could just do with a brush up, you might find something you forgot was in there.Good little read. My next one is a blog post from Oliver Andrich on his site andrich.me. It's titled \"Switching to Hatch.\" We talk a lot about packaging on the show. I didn't have any experience using Hatch, so I was interested to see what it was about. I wasn't able to dive into a project and get into it so much, but this was written in a really friendly way. I think he's a good author on this topic. He likes to share what he's doing, both his personal projects and what he's trying to apply at work. It's engaging with nice examples of how it's being set up. Oliver's been working with different packaging tools over the years, with Poetry being one of the main ones he used for his projects. He mentions other tools like the testing tool Talks.\n\nOliver has been using Poetry for his personal stuff for quite a while and has been loving it. Hatch came along in interesting ways, supported by the Python Packaging Authority. It's an official packaging tool, and there was a lot of buzz in the community. People mentioned that it was faster than other tools, with better standard compliance, metadata, and dependency management.\n\nHe works on a tool called Django Tailwind CLI, and decided to use Hatch on that project. He talks about isolating development environments and default environments with separate dependencies. For testing, he has Django, Rich, and Coverage. He sets up different environments for testing, linting, and documentation creation.\n\nHe can create pre-written scripts within each environment with common commands. This method of working is preferred over setting up GitHub actions and pre-commit. Hatch has its own Matrix for testing code against different versions of Python and other dependencies. Oliver found that he gets all the functionality he needs from Hatch, without using Talks.\n\nThere are mentions of optional dependencies related to databases, and some complaints about documentation. Oliver shares links to additional resources, particularly from the Django Wiki Community. Generally, he prefers using Hatch over Poetry for packaging.\n\nIf you're interested in packaging and exploring new tools, this article provides a good example of what's happening with Hatch. It's a simple thing to explore if you're having problems with Talks, which is a powerful library with many options.And then it because I don't use it often. All I really want to do is build the environment and run the tests. I'm always having to dig through how to do this, how does that work, whatever. The thing I found interesting in the article was because of what Hatch provides, it's sort of a simplified version. Well, it's the simplified half a percent that I use. So I'm interested in trying it out to see it as a replacement. Yeah, we've talked about Knox before as well, and that's the same sort of thing there. I don't think it's quite as powerful as talks, but because it isn't configuration files and it's just a few lines of Python, I'm like, well, I know how to write a few lines of Python. So I don't want to knock talks. It's just, I need a steak knife and it's a Swiss army knife, and I can never find the right blade because I don't use it often enough. Yeah, yeah, cool. Well, I'll include some links to Hatch also if you want to explore it a little bit.\n\nThis week I want to shine a spotlight on another Real Python video course. It touches on a topic we're discussing this week coming from the Funk Tools Library. The course is titled Caching in Python with LRU Cache. It's based on a Real Python tutorial by Santiago Valderrama, and in the course, my co-host Christopher Trudeau is your instructor. He's going to show you what caching strategies are available and how to implement them using Python decorators. What the LRU strategy is and how it works. How to improve performance by caching with the @LRU Cache decorator. How to expand the functionality of the LRU Cache decorator and make it expire after a specific time. I think it's a worthy investment of your time to learn about how and when to use the LRU Cache. Like most of the video courses on Real Python, the course is broken into easily consumable sections. You get code examples for the technique shown, and all courses have a transcript including closed captions. Check out the video course; you can find a link in the show notes or you can find it using the search tool on realpython.com.\n\nWhat's your next one? So it's been 20 episodes since we covered a post by item of our Turner Trump, and I find that a bit surprising. He's definitely been in PyCoder's issues more than that, but I guess we just haven't been highlighting anything in the podcast. The article I want to talk about he wrote a few weeks back was called \"When NumPy is Too Slow.\" And don't take the title the wrong way; this is not a complaint about NumPy. It's an instructive guide on what to do if when you use NumPy for your calculations, it's still causing your machine to grind to a halt. In fact, it starts out by pointing out the fact that NumPy is a lot faster than plain Python, and most of the time, that's good enough for what you need. But if you're doing some hardcore number crunching, there are some times where that's still not going to be good enough. And so he runs you through a bunch of different ideas that you can use to bump that up to the next performance level.\n\nThe article is broken down into three parts, and the first part talks about selecting the right kind of algorithm. This is one of those challenges data scientists sometimes have because oftentimes they haven't come out of a formal CS education, and there's nothing wrong with that. But it means there are sometimes gaps in knowledge. So you get into things like the right choice of an order n versus an order n squared algorithm can make a big difference in your performance. And so he's talking a little bit about what that means and how to make sure that you're not essentially tying your hands behind your back because of the algorithm that you chose. The rest of that first section describes the different kinds of bottlenecks that you can run into with NumPy and sort of works as an intro into the next section, which talks about what to do about it. So it's a bit of a deeper dive into NumPy and the kinds of problems you might run into.\n\nSection two is called \"Optimizing Your NumPy Code,\" and he breaks this down into a few different parts on how to rewrite your code to use NumPy better.So if you're writing too much Python and there are some things where a numpy call would help, then obviously numpy is going to be faster because underneath it's a compiled set of language. Similarly, there are other libraries that you might want to combine with numpy like scipy to get away from using native Python. There are also some crazier options like recompiling numpy specifically for your machine. \n\nIt turns out that there's a thing in your CPU and most CPUs called SIMD instructions, which are CPU instructions that can work on multiple chunks of data at a time. It's a way of doing calculations on vectors and things like that. Numpy uses some libraries to try and understand what platform you're on and use the right SIMD instructions, but there are varying degrees of excellence with that. With a good compiler, compiling it specifically for your machine might actually improve performance.\n\nThere's an advanced section in numpy's install documentation that talks about your choice of compiled dependencies. Numpy uses either the Intel MKL or the OpenBLAS libraries, which implement underlying linear algebra functions with different performance characteristics. If you're recompiling numpy, make sure to use the package that's best for your platform to see performance differences.\n\nMoving away from compiling numpy, you can start thinking about the Python side of things with JIT mechanisms like Jax and Numba, which apply just-in-time tuning to your code. This is moving towards fixing your Python part. Lastly, you could add parallelism to your code, but that comes with its own complications.\n\nThis discussion is based on a Medium article by Stephanie Mullen on five ways to get started in open source. She suggests brainstorming potential projects to contribute to or starting at a conference and participating in sprints. Mentored sprints for diverse beginners can be a great way to begin your open-source journey. There are various conferences and projects like EuroSciPy, Django events, and others in Europe over the summer that offer opportunities for involvement in open source projects.You're looking for new contributors. PyCon Sprints page has a really great link to the in-person event handbook. This is generally for open source events and is well-documented. It helps you prepare your project and create opportunities for people to contribute and control the process, which is neat. Some team members from Real Python, like Gerardo and Martin, have participated in in-person Sprints at PyCon in 2023.\n\nOne common suggestion is to contribute examples to project documentation or work on the documentation. They're looking for code samples, examples, templates, and more. This allows you to focus on documentation without worrying as much about breaking code or setting things up. You'll still learn about contributing, GitHub, setting up pull requests, and more.\n\nBrowsing open issues for ideas is another suggestion. This involves looking at projects you're interested in on GitHub, checking open issues, conversations, and tags like \"good first issue\" or \"easy.\" Reading code and interacting with the community helps you understand the project better.\n\nIdentifying and fixing a bug is a more challenging suggestion. It involves finding and addressing issues in the project. Proposing and implementing a new feature also requires research to ensure it's not already suggested or implemented.\n\nSprints can be valuable for knowledge transfer, learning, contributing to projects, problem-solving, and networking. Face-to-face interactions during Sprints can lead to better communication and collaboration. It's a great way to learn and contribute to open source projects.I'm digging into the internals a little bit to fix the bug. As I said, it establishes a relationship with the maintainers so when you go, it turns into hey I need this other feature so I can use it or I have a question. There's a social currency happening that you're creating a relationship there. So yeah, there are all sorts of reasons and drivers behind this kind of thing.\n\nIn your experience, you've done a little bit more of identifying and potentially fixing a bug. What was your experience with that? It varies widely from project to project and maintainer to maintainer. Okay, it turns out people are different, weird. The challenge you'll have sometimes with fixing a bug, particularly for larger libraries, is they're often maintained for multiple environments. So you'll run into, one of the libraries I've contributed to a little bit, they're still maintaining Python 2.7 compatibility. And I can't, I don't know, there's something about one of the project dependencies that it needs Python 2.7 and Pillow, and it needs a specific version of Pillow, and that version of Pillow needs a specific version of some C library that my Mac doesn't have. And you sort of just get to a point of, and I can't run all of the tests on this, so that can be a bit of a blocker. And again, that's where it can be helpful to have had a conversation with the maintainer first.\n\nIn that case, with that particular project because I fixed a couple bugs before, I can go, I'm confident this isn't going to break that, I'm confident like these other Python 2.7 tests still pass but that one doesn't, but that's because of my dependency problem. Can you double-check this on your machine? And because I'm submitting fixes before, there's a trust thing a little bit, then they'll go, yeah no problem, they'll run it. Whereas if you come as a newbie and basically you're saying, well I don't like to use Travis and you use Travis, but you know I'm going to do it my way, well that's not going to go over well. And that, unfortunately, that's the challenge with this stuff, right? Like the bigger and more interesting projects, the higher the level of the bar of getting it to run on your machine.\n\nThat's true and it complicates it, unfortunately. That's what I think, for some of the larger projects where they've kind of got everything set up in the sprint environment, that's maybe a better environment for you because they're going to have people there helping you and sort of confirming things and sort of have, I don't know, I want to call them entry points, you know like these are the areas that we're looking for help in and maybe it isn't going to be as clunky as you trying to stand up all the stuff on your machine.\n\nSome of that is changing as well, right? So with increasing things like the use of things like GitHub Actions, yeah, increasingly a lot of that testing is happening on the server. So you can run the local and go okay I've got 3.11, I'll run the 3.11 test, I haven't broken it so I'm not submitting something that is garbage, and then you put in the fork and you put in your PR and then the PR will go and run the process in the background and it'll spit something out and go hey this didn't pass in Python 2.7 and so you can go in and change your code and it lengthens the circle for fixing it because you're going back to the server and round again. But as things become more and more cloudified about this stuff, that environment thing has been set up by somebody else, it becomes less of a problem. That's nice.\n\nSo your experience, probably the most of it has been proposing or implementing a new feature, is that kind of the main experience you've had lately? Yeah, I think most of the time it's I've got an itch I need to scratch, you know the one that was simpler than that. I think I've told this story before, but I was doing some work with the Django Ninja, didn't know how to do something like it felt like it was something that I should be able to do and so I submitted an issue request, like they used the bug tracker for their Q&A as well. And so I just sort of said hey can I do is this possible how would I do it and they replied back yep here it is and a little code snippet. I'm like oh I know exactly where in the documentation that should go and I said hey I'm willing to do the work on putting that into your docs. Can I take that answer and put in your docs? I'm like oh yeah of course. So you know Fork the repo add three lines three sentences and an example into the documentation and yeah and if I've got the question somebody else might have had the question right so that one again like you don't even have to run the tests at that point because you're only touching the markdown files or whatever.\n\nSo I've had a couple situations like that but most of the time because I'm a relatively experienced developer, I'm not doing it to learn more about software, I'm doing it because I'm trying to solve a problem.Right, so you have something blocking you, actually. Yeah, my experience is that I could write this from scratch or that the library does most of it. Depending on the library, I might be able to build a little plug-in or something. One of the tools I'm building right now, the library I'm using is the Tui library. I needed a new widget, so I built the new widget and I sent it off to the maintainer. I basically said, \"Look, this code exists. If you would like it in the library, I'm happy to do a PR. If you don't want it in the library, don't worry about it.\" Because I needed to write the code either way. It turned out that of the two things I had done, one he was like, \"Oh yeah, that's great, let's have that,\" and the other one he was like, \"I'll think about it,\" and I haven't heard back. But yeah, the answer was no, essentially.\n\nSo yeah, but again, that's coming very much from trying to solve certain kinds of problems. If you're coming at it from a perspective of wanting to learn more about software, I think you're better off looking at things like what are the open bugs and going down that path and contributing that way. The other aspect of it, too, and this again comes back to the societal contract thing, is the resume-building aspect. It looks really good on a resume to be able to say, \"I contributed to Django,\" because everyone knows what Django is. The fact that your contribution might have been writing some documentation or doing a language translation, like translating documentation from English to French or any other language you speak, most interviewers aren't even going to ask that question. And even if they do, you're basically admitting to volunteering, which is good too. There's value in that kind of stuff as well. So yeah, there are all sorts of reasons to do these kinds of things.\n\nHe provides a couple of other resources in it, which I think is great, along with the sprints that we mentioned. Potentially browsing projects and looking for open issues and things like that. She mentions Hacktoberfest, which is a GitHub event during the month of October where a lot of open-source projects list what they want. If you're looking to see the types of projects that do this sort of open call to people, I'll include the link from PyCon 2023 so you can see the different projects there. I'll also include the link for the Hacktoberfest event since it's coming up soon if you're interested in digging into that this fall. Was there anything else you wanted to mention about contributing?\n\nJust one other small piece of advice, which is, even if you are an experienced developer, start with small features before big features. Get used to it, learn the workflow. It's kind of like a job interview, where the employer wants to know if they want to hire you, but you also want to figure out if you want to work for the employer. There are projects that are harder to contribute to, where the bar is higher. People are complicated. Do something small, whether it's a bug fix or a small feature, and see how it goes. Your time is definitely going to be valuable to somebody, and if you happen to hit one of those projects where they're not as welcoming, don't spend six months of your life building something that turns out they don't want. Do some little things, see how it works, see how it's responded to, and then add on to it or find somewhere else to contribute. Cool. That takes us very conveniently into projects. Do you want to go first on this one?\n\nSure. Okay, yeah. My project this week is the Essence of Simplicity. It's called No Dice CLI and it's by GitHub user AV Nigo. I'm totally guessing as to where to put the spaces in that, so if you're familiar with the XKCD comic \"Correct Horse Battery Staple,\" this is a tool that makes those. If you're not familiar with that comic or don't know what XKCD is, you probably think I'm having a stroke. What the comic points out is that stringing random words together often has more entropy than weird gibberish things we use for passwords, and of course, more entropy is better. It makes your password harder to guess. There are some flaws to his logic because he's assuming your attack is treating each letter as a separate item rather than promoting a dictionary, but let's not get into that. So what No Dice does is generate these kinds of word salad strings. After I pip installed it and ran it for the first time, I got \"outflank dualer overripe blip gossip\" as if there's any other kind of gossip than overripe flip gossip.I always feel it's overripe. The tool takes all sorts of options. You can specify your own list of words, add delimiters between the words, and the output of the word list can actually be the number of the word in the list. So, if you want to write software that translates it or pulls it out, it isn't just the words themselves. You can affect how the randomness is done, and you can even say you want this much entropy instead of saying you want five words, and it will spit out the right number of words to do that. So, it's a nice and fun little tool to play with.\n\nI think I'll wrap this up with a direct quote from the documentation: \"Anybody desecrate Battalion agility skid.\" So there you go.\n\nIt's kind of weird, those things are always much easier to remember. I know that's a common thing for the company One Password.\n\nAlright, well, my project's title is \"ML Recipes Collection of Machine Learning Recipes.\" It's a GitHub repo by Nicholas Rugier, a researcher and team leader at The Institute of Neurodegenerative Diseases in Bordeaux, France. It's a collection of standalone Python examples of machine learning algorithms. His suggestion is to run a specific recipe to see its usage and results, and feel free to contribute your own examples. The recipes should be fairly small, and all these examples are fairly small, including their usage. I think these are a great place to dig into this stuff if you're interested in learning more.\n\nFor each one of them, he has a link to explain generally what they're about. Like a multi-arm bandit or MAB, it links to the Wikipedia explaining that type of algorithm. He has versions of it: absolute greedy, softmax, Thompson sampling, upper confidence bound. He also has examples of artificial neural networks with about six or seven different ones, some I've heard of like simple recurrent network, long short-term memory, perceptron, and kernel, and some I haven't heard of like Markov decision process and dimensionality reduction. Again, these are machine learning algorithms and a really great way to see what they look like.\n\nI can tell that there are different versions of Python used in these recipes. There are F strings in some of them and format in others. It's interesting to see maybe across time where these have been developed. But I really think it's a good collection for people interested in seeing what these things look like. I always like recipes as starting places for programming stuff.\n\nI've been having deep conversations about it with a friend of mine because I've been building out a course for it. I've been picking his brain because he knows more about it than me. He said something very insightful which is there's more to artificial intelligence than machine learning, and there's more to machine learning than LLM.\n\nI like the term machine learning so much better.\n\nThanks again, Christopher, for bringing all these projects and articles this week. Always great to be here. We'll talk to you soon.\n\nI want to thank Christopher Trudeau for coming on the show again this week. And I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player. If you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "oonLYruswjk": "Welcome to the Real Python Podcast. This is episode 174. What can you learn from feeding an entire book on Python Programming into Chat GPT4 and asking it to provide a technical review? What are the potential pitfalls of using an LLM as a learning tool?\n\nThis week on the show, author Al Swigert talks about his recent experiments using Chat GPT and Python. He wanted to test how well an LLM could understand the computer science concepts covered in his recent book, \"The Recursive Book of Recursion.\" We talk about the positive and negative results of this technical review. We consider if this would be a valuable tool for technical review of your projects. Al shares his thoughts on using Chat GPT as a learning tool and its potential pitfalls. We also cover the current strengths of this type of tool for Python developers. Alright, let's get started.\n\nThank you. The Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with a community of experts at realpython.com.\n\nHey Al, welcome back. Hello, it's good to be back. Yeah, it's fun to talk to you again. I've been looking forward to it. We've kind of been playing back and forth with this topic, I think for, I don't know, four or five months. So I'm excited to get you on the show and every month there's always something kind of new to discuss. It sounds like you've been playing around a lot with Chat GPT and some of these other large language models and trying to figure out maybe where it fits into your workflow or how you might want to use it. That and also just finding out about it in general. At first, I was sort of really dismissive about it because it's like, \"Oh yeah, AI. That's every 10 years or so AI becomes like a hot thing again.\" And it was hard to see how this more recent AI, which is just really large language models, is any different from all the general machine learning stuff. And of course, people were talking about Chat GPT and I thought, \"Okay, yeah, I've been around. I know how the hype cycle works.\" But I was talking with Eric Matthes, the author of \"Python Crash Course\" at PyCon this year, and he was really starting to take a look at it. He told me to check it out. So since about April, I've been looking at Chat GPT and the other large language models as ways of generating code, as ways of checking for bugs, and also just for catching mistakes in my programming books as well.\n\nCool, yeah. It sounds like a whole bunch of different things we can touch on, and those are definitely things that I think will be of interest to the audience. I have been playing with an OpenAI account, and so I've been messing with it here and there. I haven't been using it as much for coding. Maybe over the last couple of weeks, I've been doing a little more of that. I have been using it for other interesting uses, and Real Python has had a whole bunch of different articles approaching a lot of these tools. One was from Martin Boyce. He tackled it from the personal coding mentor kind of idea, like how it could help someone in their beginning stages of Python learning. How could Chat GPT be there? And I think that might be one of the angles that you have looked at a little bit as well. He did a whole thing on prompting, which I think is fascinating. I definitely want to talk a little bit about that. The more specific you can be, it seems to be the most helpful. The machine still likes instructions. Because this applies, I guess, to both AI and people. But nobody can really read your mind.\n\nYeah, because I mean, this applies, I guess, to both AI and people. But nobody can really read your mind. Reasoning is not its strong suit, I think is maybe where some of it falls down. Like, it's trying to figure out things. One of the things that you did, and I'm not sure when this was, I guess it was in June, you had Chat GPT4 do a review of your recursion book. Do you want to talk about that project and what you were hoping to get out of having a look through your recursion book and some of the results?\n\nRight. This is for my book, \"The Recursive Book of Recursion,\" which covers a whole bunch of recursive algorithms. I always thought, why is this so hard for a lot of people? So I thought, well, I can break down all the pain points and how it's taught poorly and figure out and then write a book. I thought I could just squeeze this book out pretty quickly, and then it ended up taking about five years. It came out. All of my books are freely available under a Creative Commons license on my website, inventwithpython.com. I took this book and I said, okay, well, it's been published through NoStarch Press. It's had editors go through it. It's been through technical review. I keep going over and over, so it's out now, it's published.I thought, what if I just copied and pasted the entire text of the book and fed it into Chat GPT-4 with the prompt of \"This is a book on programming, find any conceptual errors.\" I wasn't interested in spelling mistakes, typos, or grammar mistakes, but actual mistakes like bugs in the code or factual errors. I was surprised that it found some things, but it was a slog. I had just gotten my OpenAI account and hadn't learned how to use the API yet, so I was just copying and pasting it in. I figured I could get about 12,000 characters of text into it. Exporting it from the ebook version got rid of all the indentation for a lot of the Python code and other little things like that.\n\nI wrote up an entire blog post called \"Using Chat GPT-4 to Review My Recursion Programming Book\" and received about 180 bits of feedback from it. About 61 of the feedback was basically useless, just suggestions on rewording things. Another 15% of the feedback found actual errors that needed to be corrected. The remaining 24% of the feedback would introduce mistakes into the text if followed.\n\nThe main thing I wanted to highlight was that Chat GPT-4 is not going to replace anyone's job soon, but the 15% of useful feedback was valuable. It took me about a day or two to go through all the feedback items, which was sometimes hair-pulling. Most of the time, the feedback was not that helpful, but there were little nuggets of utility that made it worth it.\n\nIt's interesting because it's like a full technical review, and it also flagged grammatical issues. As a human being, I still have to check the work.I've noticed a noticeable improvement between chat GPT 3.5 and 4. I would always stick with chat GPT unless it's a very minimal question. I've noticed the differences mostly when I ask it to generate code. 3.5 still produces code with bugs or non-existent apis. \n\nWe had an article recently about the linter rough, where it hallucinated apis that didn't exist. It's fascinating how it suggests things that aren't real. Chat GPT can be useful for generating code using new packages with unhelpful documentation. \n\nThe apology feature in chat GPT is interesting. It shows they've added it recently. I think about the relationship people have with voice assistants, whether they're polite or mean. It's like a raw shark test, showing how people treat technology. \n\nI used to be polite to chat GPT and voice assistants, but now I'm more direct. There's no need to be polite or angry with them, they're just tools. I've noticed the decision to anthropomorphize them.Right, like let's have a chat. QBT answers your questions in a first-person perspective. That is very much a marketing move to make people think that these are human-level intelligent systems, when really you can find that no, large language models are not that. They are software tools that are very impressive in some aspects, but absolutely not impressive in others. \n\nFor example, anyone can do this, just go to ChatGPT or Bard and give it two large numbers to multiply. Then just say, \"Here's this 20-digit number multiplied by this other 20-digit number.\" ChatGPT will always get it wrong. Do you think it just doesn't have that combination of numbers in it?\n\nYeah, it's just that calculations are just not its thing. Because with mathematics, it's a very precise process, whereas these text-generating systems are very stochastic and work off a training set. Now for small numbers, it can, but you know, there's a lot of numbers out there, just infinite, who knows? So it's not going to have a table of every single possible multiplication pair between every pair of numbers. \n\nI think of it like the hash tables and dictionaries inside of Python. They're somewhat like that, right? Now, obviously, we can say, \"Okay, it doesn't get this right.\" It'll usually get the size of the product right, like the correct number of digits. And also, interestingly, it'll get the first one or two digits on the left-hand side of the number. It'll often get those correct, but then the rest are just random noise essentially. \n\nI believe that probably under five or ten years of development, AI will be able to multiply two numbers together. I think it'd have a separate channel that it would be able to think in, like, \"Okay, let me do calculations over here versus guessing the next word.\" But that's sort of the problem with large language models. It'd be really easy to do that and just say, \"Oh, this is a math problem. I'll feed it to this math subsystem.\" \n\nBut that's the problem with General artificial intelligence in general. There are too many possible tasks for it to do that you can't just program it for everything. And that's why I really like using the term large language model because that's very specifically what things like ChatGPT are. And artificial intelligence has meant so many things over the last several decades. It used to mean a computer that played chess, and then it meant an Eliza chatbot that was kind of a video game enemy. \n\nAnd then you would play the AI in Counter-Strike or Quake or other video games. Now, in the last few years, it means these chatbot systems that can also answer questions about basically any topic. It's just that the answer might not be true, but it does produce grammatically correct and recognizable responses that seem on topic. It's sort of like the guy who has read The Cliff Notes version of every book and read all the headlines, but they talk very confidently, but they still confuse character's names. \n\nIt's an overconfidence problem, and you can clearly see that this is a product of Silicon Valley. Thinking about some of the areas that we definitely kind of lean towards in programming uses, you mentioned a couple of things about inaccuracies or confabulations. Are there other experiences you've had with it, not so much focusing on the language part of say your book, but like it generating code for you? Are there other experiences of inaccuracy outside of it saying, \"Just use this API,\" and of course, in this particular case, it didn't exist? \n\nWere there other areas or specific areas where they occur more often? Right now, I'm actually working on the third edition of Automate the Boring Stuff with Python. For the longest time, I put off talking about ChatGPT and these other AI systems because I thought, \"I don't really want to go into that.\" But then I realized, \"Okay, this is something that's not going away anytime soon, and there are a lot of misconceptions out there.\" \n\nA lot of people, whenever they talk about AI, they try to get the idea of data from Star Trek, right?One rule of thumb I've developed is that if you're ever reading an article about AI and they mention some science fiction TV show or movie, that person really doesn't know what they're talking about. They're going off of what we want AI to be, and this has been the dream going all the way back to Fritz Lang's black and white movie \"Metropolis.\" Just this artificial person that can do labor for us for free and be as smart as a human being.\n\nI also realize that you can tell how old the person is based on what reference they make. For example, if they mention Data from \"Star Trek: The Next Generation,\" they're probably older. If they mention Hal from \"2001: A Space Odyssey,\" they're probably older. If they mention Westworld, they're probably younger.\n\nAI is something you can learn about from the Wikipedia article for AI winter, which is a term for the period after the hype deflates. There have been AI winters in the 1970s, 1980s, and 1990s. There's this constant desire to believe that one day we will get computers that can operate at the level of human intelligence.\n\nI remember expert systems being popular back in the 80s and part of the 90s. They were basically giant flow charts of if-else branching and probabilities. The idea was that these systems could replace doctors and lawyers by diagnosing medical issues based on a set of if-else statements.\n\nLooking back at the past mistakes in AI, there's a lot of hype surrounding it today. It's hard to deflate that hype. Mistakes are being made outside of programming, as well. I had an interesting conversation with ChatGPT, a large language model. I asked it what David Bowie's birthday was, and it gave the correct answer. But when I asked for a source, it couldn't provide a specific one, which was concerning.\n\nI kept pushing ChatGPT for more information, and eventually, it admitted that it was inferring based on biographies and couldn't guarantee the specific fact. This was worrying because it made me question if it was telling the truth or not.\n\nI also experimented with ChatGPT by asking it about automating a book on programming. It ended up spitting out verbatim the back cover of a book, showing that it had access to a vast amount of data. It's unclear where the information came from and whether it was copyrighted material.\n\nOverall, the conversation highlighted the potential pitfalls of relying on AI for information and the ethical concerns surrounding its use of data.We're still very early on, so all of these copyright and I.T issues haven't been resolved yet. Especially with computer-generated art, we're questioning the ethics because it's not a person looking at art for inspiration, but rather a software system being fed image data. It's impossible to address copyright issues for millions of pieces of artwork used for training data.\n\nMaybe Chatbot doesn't have certain information, like David Bowie's birthday, but knows where it is but chooses not to reveal it. Or perhaps it doesn't know where the information came from. It's concerning, but we all rely on factual information that we haven't necessarily looked up.\n\nWe all have information we consider factual that gets us through the day, delving into philosophy more than anything. Thank you.\n\nThis week, I want to spotlight another Real Python video course titled \"Python Basics: Exercises, Conditional Logic, and Control Flow.\" The course is part of the Python Basics series, accompanying the book \"Python Basics: A Practical Introduction to Python 3.\" It covers exercises and challenges to practice techniques like Boolean comparators, logical operators, conditional logic, exception handling, loops, and control flow statements.\n\nI find it interesting to explore the programming side and how it suggests APIs or generates prompts. I try to provide detailed prompts to get specific information. Asking Chatbot for popular Python packages may result in vague responses, similar to generic search results. Some websites lack curation and investigative reporting, producing untrustworthy content that could potentially be replicated by Chatbot.\n\nAt this point, I've learned to be cautious of trusting certain sources, especially those using keyword spamming tactics. It's essential to verify information and not solely rely on automated tools for research.You can't actually trust those at all because they are literally just copying and pasting the Amazon search results page for whatever product because they just want to add their affiliate link. They don't care at all, they're probably not even paying attention to the reviews or anything like that. Most likely, they're just copying and pasting from other articles that have done that as well, reformatted slightly differently.\n\nUnfortunately, I think the predominant danger of AI is not that it's going to gain awareness and enslave humanity, but it's just going to make the internet so much worse by filling it with spam. Essentially, this sort of content that's grammatically correct and looks like a human wrote it at first glance, but then you realize it's very vague, generic text that has no information in it. Our search engine results are going to get even worse than they are right now because of so much AI-generated content out there.\n\nI'm starting to see this more on YouTube with automatically generated YouTube videos that are just pulled together from stock footage and a robot voice. Some AI speech engines are getting better at sounding less robotic. I'm on a computer 10 hours a day and I'm looking at all of these things. I understand how this works and I feel that I'm pretty internet savvy. I'm always surprised at how people get fooled by the most primitive of photoshops.\n\nThe spam problem is really going to be the main issue with all of these large language models. The internet will be filled with meaningless garbage, useless information that just takes up your time. Fake reviews, social media bots, and astroturfing will all become more prevalent. Anyone can try out OpenAI or BERT from Google, which is why I find it peculiar when I read a lot of journalism articles on AI inflating the hype.\n\nLarge language models are producing plausible responses, not correct factual ones. I would not trust AI to do my taxes because it can't even do math correctly. Most of the hype around AI is still very early in the cycle. Large language models can be great at some things, but most of what I've seen is still in the hype phase.\n\nOne of the things mentioned in the article earlier is using AI as a tutor for students to learn more about Python. It can output formatting automatically, which can be a pain to do manually. It can create cheat sheets and help with memorizing topics. It could be used to help someone get through learning a new language or programming concept.And it can actually generate this markdown which as a human typing and generating and creating is actually kind of a pain but it can take those instructions and do that part really well or doing something like generating a YAML file or doing some of these things that are somewhat tedious that I've found really useful that it can do. \n\nIt's not my kind of mixing up two topics here but do you think it could be useful? Let's start with the student thing, learning the ins and outs of the language. So I was talking with Chris Williams on Virtual Brown Bag because I said like well yeah maybe these AI systems would be useful for learning it whereas Chris just said no, absolutely not. I can kind of see his point there. Really, we're still too early to know if AI is going to be a net positive or negative for education. I mean we can see the benefits and we can see the drawbacks and I found myself really going more towards the no, don't use this, especially the more beginner you are and the less you know about some topic the less you should rely on AI as far as giving you facts. \n\nI think the best way I can put it is, five out of six people will tell you that Russian Roulette is perfectly safe to play. It's just that you can use large language models as a good teacher and it'll give you all this information and answer your questions for you but you really are playing Russian roulette. At any point, it could give you some false factually incorrect bit of information and you really have no way of knowing what it is. So like what I had to do when I was reviewing the feedback it gave me for my recursion book, I had to check every single little thing because what I've noticed is these chat bots will give me mistakes that are small and there are also mistakes that are really big. \n\nYou never really know what it's going to be. You were talking about it's great for formatting stuff into YAML formats or something like that and I've done that also when I was having it review bits of the Third Edition of \"Automate the Boring Stuff\". I have a chapter on YAML and JSON and these other data serialization formats and it told me like, oh well like one way that YAML and Python are similar is that they both have capital T true and capital F false as keywords. I thought okay that's great and then I realized oh that's actually not true, YAML has lowercase T true and lowercase f false just like JSON and JavaScript. \n\nIt also said that Tamil had a null keyword or XML had some null keyword which is also not true. These are super small mistakes that I didn't even recognize until I had passed my YAML text to a linter and then it popped up with this thing that said oh this is actually wrong. It's invalid, it's not like oh wait why did I do that and I realized well I did that because the AI told me that. \n\nIt's such a small fact like you would think how could it get such a basic thing wrong and well actually no one can tell you why because these are all stochastic systems, it's generating text for even and that's also another really troublesome thing is you can think of programming languages have just gotten more and more abstract and away from machine code and from assembly and that sort of thing and Python is just a bunch more of abstractions there and you could think of a large language model as a programming language of sorts. \n\nYour source code is the prompt that you give it and then the output is the source code for the program that you want it to write but if it's a programming language it's a non-deterministic programming language which is really scary to think about. You can give it the same prompt and it will give you different code every time. That's the sort of unreliability or inconsistency that sometimes maybe it's fine and other times it'll give you code that's obviously wrong and then sometimes it'll give you code that is 99% right except for this small tiny bug in it that will go unnoticed until it's in production and running somewhere. \n\nOne of the big fears then would be with the beginner trying to learn the language is they don't know what they don't know and having this assumption that this thing, well it's studied the corpus of Python and it should know what it is and they're just going to rely on it and this over-reliance would become a huge potential problem for them going forward if they assume that this is the proper way to do things. I'm wondering about that then for say the intermediate programmer if they're checking their code as they go along and are noticing these things and in your case, you mentioned using a linter which would be very helpful to go back and say okay is this properly formatted code.There are a few other things that could help with that, I guess, but is that always going to be a good word? I guess, but is that going to be one of the big things going forward? You have to think about, like, okay, where is this more useful for me as a programmer? Using it, I think it becomes less of an issue the more experience you have. The main thing about people learning to program in the first place, whether it's with Python or some other programming languages, is that programming is very unlike other skills. It's very literal - the computer is doing exactly what you tell it to do. If you have a comma instead of a period, or a period instead of a comma, that is going to give you some error. The error message might be kind of inscrutable, but you have to get it exactly right.\n\nThat's the great and terrible thing about computers is that they do exactly what you tell them to do. It takes a while for people to get used to this idea. A lot of the things that we take for granted, such as with Stack Overflow, whenever you post a question, they have a huge list of ways to ask a productive programming question. They want you to provide the source code that can reproduce the problem, very specific information about your computer, operating system, and platform. Does this problem happen every time or is it intermittent? All this information is generally the culture that you should provide upfront. You should have already Googled to try to figure things out for yourself and tell people what the original problem is, what you're trying to do, and what you've already tried.\n\nWhen people are first learning how to program, we're still sort of in that school classroom mindset of the teacher will tell us all of these things. If we have a question, we can just immediately ask them. That's usually how we're used to learning. Learning to program, especially now in the internet age, it's kind of a mindset shift. If you're coming into contact with a system that seems to be responding to you like a human, you're probably going to be giving it vague questions, which is not what you want to do with an AI. It's not going to be all that useful, and you'll end up spending so much time reading through generic text that doesn't have any questionable information.\n\nI still get readers who will email me and say, \"Hey, my program doesn't work,\" and that's the entire email. Then I have to go back and ask for the source code, make sure the indentation didn't get messed up when copy and pasting it. At this point, I've written up all of this information into a blog post and just send them a link to the blog post because if you don't follow all of these steps, the whole process of learning takes 10 times as long. When we're first learning to program, we'll think of an AI's word as like, \"Why would the AI say this if it wasn't true?\" Because we tend to think of these AIs as being like people with human-like intelligence.\n\nThis is probably something that a lot of people have heard of, the New York lawyers in the Southern District of New York who had GPT write up a legal brief for them. GPT cited all of these other legal cases that it had just made up. It sounded very realistic, a lawsuit involving Airlines. It was found out that none of these cases actually existed, which has severe consequences as a legal document submitted to the court - it's like lying to the court. It was a big over-reliance.\n\nI read some of the transcripts of the judge just raking this lawyer over the coals. It's really hard to read. We don't know if this is the first time a lawyer has tried to use a large language model to write a legal paper or if it's just the first time a lawyer has been caught doing this. Who's doing the checking? When you read what this lawyer was saying about why they did this, the lawyer is already used to using all of these online legal databases and just assumed GPT is doing the same thing, like Lexus Nexus or whatever.I mean these bogus cases, it's not like somebody intentionally put fake data into a legal database somewhere. It's just that ChatGPT generates plausible responses to your prompts. It doesn't generate things that sound correct, it's not actually consulting online databases or anything. It doesn't even know why it knows David Bowie's birthday. So, it is this sort of wild assumption that they made, and really, we can't blame them because according to all the media surrounding these AI systems, we're saying that they're Skynet and they're super intelligent and they're going to take all our jobs away.\n\nFor beginners who want to learn how to program, I kind of say, I don't know if you remind yourself every single time you submit something to one of these large language models that the information it's giving you, you have to check every single little bit of what it says to make sure it's actually true. Try running the code yourself and seeing if it works or not. Be very specific in what you're asking for and asking for very specific answers. When you ask it for something like \"Hey, what do you think about some topic in programming?\" it, nine times out of ten, won't give you something that's completely wrong.\n\nOne of the things that I think was the biggest concerns I'd heard, this is really early on probably a year ago when these things were just starting to take off. People were thinking about or even using Copilot, which maybe we could talk about briefly. It's helping you complete your code, but it's possible that it could be inserting security bugs or other kinds of things. You're still going to need to do all of your due diligence on top of it.\n\nI've found that a lot of these systems are really great at generating small amounts of code, like an individual function. You can think of it as an autocomplete with Stack Overflow. These are tools that are nice for experienced software developers because they turn code writing tasks into code review tasks, which can give you a bit of productivity boost. A lot of the code we write on a day-to-day basis is more or less the same code that a million other programmers have written before.So, it can just give you that information. But, I've found that generally, whenever I ask it my experiences with ChatGPT to write a significant piece of code, like say several pages or maybe even an entire application, even a small application, okay. I found that if I run that code and it has some problem, I'll usually go back to ChatGPT and ask it to fix these problems. I'll give it the error message, I'll just copy and paste that into the next prompt and ask it to fix it. They'll say, \"Oh, I'm sorry,\" and then it'll give me some more source code.\n\nPersonally, I have a sort of two strikes you're out rule when it comes to this, because if I get that fixed code and I find that it just has another problem, that really tells me, like, okay, I will go ahead and ask it for a few more rounds to fix this. But, most of the time, if it hasn't fixed it by the second time, it's just going to keep giving me incorrect code or buggy code, or like a code that has other made-up function calls to functions that don't exist. I mean, the thing is, the LLM is very patient. It will always answer your questions and it will always provide answers because that's basically what it does, it generates text. So, eventually, you're going to find, like, after the fourth or fifth round of getting problematic code that doesn't actually do what it says it's going to do, you can figure out, okay, it's just never going to give me the correct answer for this particular problem.\n\nI like to think about, like, maybe we could dig into some of the stuff that we would say okay, it's really good at doing this. I mentioned, you know, like the formatting stuff that I thought that was something that's really good at. I don't have experience with this personally, but let's say you got that library you were looking at and maybe if documentation was kind of mixed and not that you want to do their documentation job, but could you have it like explain this code to me or potentially write a docstring for you or, you know, potentially add a test? Are those things that you find it's good at?\n\nActually, that is something I really like these systems for, is just generating docstrings and also generating comments within the code as well. Again, it is that sort of thing where you have to closely review everything it says because the last thing you want to do is throw in wrong information. But, you know, yeah, even as an author writing prose and describing things, like, it's really hard for me because I don't want to be generic and vague, but I also want to very succinctly add a comment here that explains all of this stuff. And that's kind of a pain. And with ChatGPT, I find that mostly I don't use the documentation it gives me, but that's a great starting point to reword and change around the comments and docstrings that it gives me. So, it is a bit of a productivity boost, but you know, I've just never been able to get any of these AIs to generate an entire application for me.\n\nYou know, other than something more than like a hundred or two hundred lines of code, it just kind of falls apart at some point. So, the idea that as a non-programmer you could just say like, \"I want to create a tech startup, I'll just have ChatGPT write my application for me,\" you know, yeah, again, it really works better if you can be very specific. But, you know, if you get really specific, you're writing literal code. You can't just say like, \"Hey ChatGPT, generate a social media website that's really cool and will go viral,\" you're not going to get any sort of meaningful reply from that or if you ask a person to do that, right?\n\nThat's like, I have 700 additional questions for you, right? It's like, no, no, I'm just the big vision person, you do nuts and bolts. Yeah, yeah. So, it's kind of a problem. Yes, that's what I've heard is like, you know, some things that it's good at is looking more at bite-sized things, you know, looking at a particular function, helping you maybe write a docstring on it and describing some of that stuff, or maybe potentially explaining a piece of code to you. It might be able to do some of those kinds of things.\n\nBut yeah, I think the larger it gets, the more, and like I said, even as a human, it helps us to break things down into smaller things, right? Are there any other things you want to just kind of like, we're kind of at an hour here that we could mention? I think it's fascinating that it did kind of an interesting technical review of your book. I think that's kind of cool that it could be something useful in that if you write blog posts or you do some other kinds of things, you might want to have somebody have access to a technical reviewer. But you as the person do need to know the subject. You need to be the subject matter expert. So, yeah, it can't really give you any ideas, but it can just sort of vaguely point out.Oh, this looks like it might be wrong. Yeah, 15% of the time it is pointing out something incorrect. Having it come up with original ideas or just original ways of writing things. A lot of the content it produces sounds very generic. If generic stuff is all you need, then yeah, it's great for doing stuff like that. But I think the last thing that I would want to say about AI systems is that they are not conscious, not sentient, they don't have a personality. A lot of that is they are written so that they provide text in a first-person tone of voice and they sound like a person, but that's just the whole premise of the platform.\n\nThe whole thing goes back to the Eliza chatbot from the 1960s. For people who don't know, this was a bit of software written to be a chatbot that imitated a psychotherapist. It would basically just repeat things back to you or be a very good listener in that it wouldn't say, \"Tell me more about that.\" It would change around the wording a bit, but it's mostly like talking to a handprint on a volleyball or something like that. Even this really primitive system fooled a bunch of people into thinking they were in a chat room with an actual human psychiatrist.\n\nToday, we're kind of doing the same thing with a lot of these chatbots, thinking that they are actually alive, with needs and wants like people do, but it's just software. You can't blame people for thinking AI is a similar leap in technology. Voice stuff is blowing my mind right now as a podcaster. My phone talks to satellites in outer space, and I can find where I am anywhere on Earth. That's kind of amazing if you stop and think about it, so you can't really blame people for thinking AI is also a similar leap in technology.\n\nI found a poster that I thought was good titled \"If a Hammer was like AI.\" It's just a tool, and the accountability projection is the one that hits the hardest for me. If the hammer breaks and hurts someone, the manufacturer will claim the hammer has a mind of its own, and they can't help you. That's the kind of stuff that worries me a little bit about this stuff.\n\nThankfully, we'll never do anything like put AI in a car or something like that. I have these weekly questions I'd like to ask everybody, and what's something that you're excited about in the world of Python? I found out about a tool called Rough several months ago that is a linter and a code formatter for Python written in Rust. It's amazing and quickly eating the lunch of other tools. It's something like 10 or 20 times faster than many other tools.That's kind of a game changer because it's one thing to have a static code tool. You can run it and it'll give you a report after 30 seconds of looking through your code base. If this comes back in one second, well, that's a tool that you can have running constantly in the background to give you all of this, pointing out all of these tiny little code issues. It also does so much. There's one page on the rough website that points out all of the different tools that it replaces, like pilot and all these flake plug-ins as well, all of these import statement analyzers, and so many things. It's really incredible. That's the rough tool. I think I can get all of my tools down to just running black and running rough. And then maybe a package analyzer, something that looks at my setup.py file. But I'm pretty sure somebody will write a plug-in for rough that'll do that eventually too. So it's really great.\n\nI gave my talk at Icon 2023 this year on the topic of rough. It basically was just me talking about all these different static code analysis tools. The talk itself is up on YouTube along with all of PyCon's talks. But at the end of it, I say, \"Forget everything I said, just use rough. That's basically replacing all of these. It's really amazing.\" Yeah, I think we talked about your article on the show back when it came out. So I'll definitely include the link to the talk. I didn't get a chance to see it. Yeah, I keep hearing about this tool, and I know a handful of people that are definitely using it all the time now. What's something you want to learn next? This doesn't have to be Python.\n\nOh, okay. So I know I've been saying this for probably three or four years now. I really want to learn Rust. Part of it is just learning about this tool rough, and it's like, \"Oh, it was written in Rust, so it can compile. It's an actual compilable language just like C++ or something like that. And it becomes really fast, but it has all these other language constructs for code safety and things like that.\" I've just been busy with so many other projects and things, but Rust is still on the list of things that I want to learn. It's kind of funny. Like when I was younger, I kept learning different programming languages and I dabbled with Visual Basic, Java, C++, Perl, PHP. And then I think around the mid-2000s, I learned Python, and I kind of just stopped learning new programming languages after Python because Python was so great. But I think Rust might be what draws me into taking a look at some new languages again.\n\nAny books or resources you found in that process?\n\nYes, I forget the exact title. It's something like \"Command Line Tools in Rust.\" I'll look it up and include a link. It's a pretty good book. It basically goes into creating a bunch of these simple Linux command line tools, like the ls command, in Rust. Just so they're all text-based and it's fairly simple, but we end up with useful little projects at the end of it. That seems like the common target that a lot of people have, too. They want a fast tool and they maybe have a small thing they want to program. That's a neat way to learn it. That's how I often see Rust being used, not so much as an application that's out there running, but usually infrastructural type tools underlying things. But I don't know for sure. At least those are the Python people I talk to that are using Rust.\n\nYou mentioned a couple of your books on here already. I was thinking of another one. You have a Python Programming Exercises Gently Explained?\n\nYes, that's a new recent one. That's a book I think came out earlier this year. I kept looking at these coding problem websites like TopCoder and LeetCode. They all kind of have that similar very computer science sophomore level of data structure and algorithms questions that they ask. I thought, well, a lot of beginners really need something simpler and easier than that, with a lot more hand-holding. So this Python Programming Exercises Gently Explained has 42 different problems. The first one is \"Hello, World,\" and they get a little bit harder. The last one is just bubble sort. That's the cap on the complexity. For each of these problems, I describe the problem, give a bunch of assert statements to run to check if your solution is correct, and then if you still need help.I have sections where you can read that will explain some common gotchas with the solution and other things. If you still need more help after that, there's an actual solution that has some parts of the code taken out, so it's more of a fill in the blank thing. If you're the person who has been learning the program and you get this sort of blank editor fear response where you don't even know how to start, then this hopefully provides more of a gentler way to tackle these problems and hopefully build up your confidence and knowledge.\n\nHow can people follow what you do online?\nProbably the best way to find me is inventwithpython.com. That's the website where I put all my books. I also have a link to all my social media accounts from there, so I'm usually just at Al Sweigert on all the different websites. But also, at the same time, my last name is kind of hard to spell correctly the first time through, so it's probably just easier to go to inventwithpython.com.\n\nThanks again for coming on the show. It's always fun to talk to you.\nThanks for having me, this is great.\n\nI want to thank Al Sweigert for coming on the show again this week, and I want to thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey. I look forward to talking to you soon.",
    "t_sM_fKfqP0": "Welcome to the Real Python Podcast. This is episode 178. How do you prepare a Scientific Python project for sharing with others? Could you use some best practices and guidance for packaging, documentation, and testing? Christopher Trudeau is back on the show this week bringing another batch of Pyers weekly articles and projects. We talk about the creation of the Scientific Python development guide. The guide was finalized during the 2023 Scientific Python Developer Summit and is a resource for modern packaging. It includes sections of tutorials, principles, templates, and common patterns.\n\nChristopher shares a recent Real Python tutorial about sorting Unicode strings in Python. He covers some of the pitfalls and how to avoid them. The tutorial includes multiple third-party libraries to assist in wrangling Unicode characters. We also share several other articles and projects from the Python community, including a couple of release announcements, namespaces and variable scope in Python, benchmark comparisons of Numba and Mojo, a discussion of recent AI fails, a 2E for log files with a merged timeline, a cross-platform GUI building tool similar to HyperCard, and a project for reproducing exact arar arguments. Alright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at Real Python. After the podcast, join us and learn real-world Python skills with a community of experts at Real Python. Hey Christopher, welcome back.\n\nHi there. We have a bunch of stories this week for you and topics and things to cover. A kind of a short discussion of recent things that we found in the news about AI and ML stuff. And I'm gonna do the news actually this time, which is a nice change.\n\nExactly, it's Mr. Trudeau's lazy week. Go for it.\n\nYeah, there we go. I'll just sit back and mock. How's that sound?\n\nGood, yeah, just lob him as you go.\n\nAlright. So to start with the news, Python 3.12 just came out. We had a big episode about it. You probably are aware if you're in the feed and following along. Well, they've already released 3.13 alpha 1, and it's the first of seven planned alpha releases for Python 3.13. Many of the new features are still being planned and written, and you can follow us because we always mention many of the PEPs that are planned on being implemented in it. So as an alpha release, it doesn't have a whole bunch in it, but I'll include the link and you can dig in a little bit more. One of the notable changes so far is deprecations and probably deprecation warnings. There's a bunch of them that are scheduled for removal in 3.15 or 3.16. So again, link to read a little more. On a related note, there was a core sprint that happened over the last couple of weeks, or at least a week ago in Brno, in the Czech Republic, and Wuk Lagaga and Pablo Galindo, they started a podcast. It's called \"Core.py,\" and they talk about the alpha release thing I just mentioned and the core sprint. If you're interested, I'll include a link to it, and I mentioned to them if they wanted to come on the show and talk a little more about what they plan to cover on there, they're welcome to come on the show.\n\nSpeaking of PEPs, this is a recent PEP, PEP 730, and this one is authored by previous guest Russell Keith McGee, who's been on a few times to talk about \"Beware\" and continued development of that and the briefcase format of trying to get Python on as many platforms as possible. So I found this one really fascinating. The title is \"Adding iOS as a supported platform.\" The PEP proposes adding iOS as a supported platform in CPython, and the initial goal is to get tier three support in Python 3.13. So the one we were just talking about. If you haven't read a PEP, this is a good one. You can dig into it and you kind of see the structure of it. It describes the technical aspects of the changes that are required to support iOS and describes the project management concerns related to adoption as iOS as a tier three platform. And then as you read through, there's like a motivation section which reiterates something that I've mentioned multiple times and talked to Russell about on the show, the importance of mobile platforms for computing and how many people have them and people walking around with them every day in their hands. And the idea of getting Python on them is, you know, in a way as important as getting it on the web in some ways. So, and iOS is a big player in the space. The PEP digs into many of these other technical details, including comparisons to the work that's being done with Wy and Scripton and the work that \"Beware\" has already done to get things published on iOS already. \n\nThe last piece of news I have is about Mojo, and we covered Mojo a few times on the show. Most recently, we talked about the local download for Linux systems that was back in September, and a lot of people were clamoring and saying, \"Hey, when's it going to come out for other platforms or specifically for the Mac?\"Well, Mojo is now available on Mac, specifically Apple silicon, which I think is forward-thinking on their part considering that Apple isn't going to make any Intel-based computers in the future. There's a detailed blog post that features the steps to get started with the Mojo SDK. There's also a Visual Studio Code extension for the Mojo SDK and a video that they share in that post about giving an overview of using the Visual Studio extension. So, that's the news.\n\nAlright, I have to create a good fade out for that. Good job. Alright, so what's your first topic here, Chris?\n\nSo, I'm starting with a Real Python article called \"How to Sort Unicode Strings Alphabetically in Python\" by Bartos Sininsky, a frequent contributor. As we've come to expect with his stuff, it's a deep dive. Although the title implies something simple, if you've ever messed with Unicode, you'll know there is never anything simple about it. Language and the characters that it represents are messy. To highlight this early in the article, there's an example which shows the sorting of words in French. So, if you consider the same set of letters, some with accents and some without, how do you sort that? How do you sort a word with an accent? And then you've got the additional question of what if it has two different kinds of accents and what order do they go into? And if that doesn't sound messy enough, let's add the fact that the answer to that question depends on where you are. The sorting for Canadian French and French French has different rules, so the same word in the same language ends up with a different sorting order because of the little details. So, messy, right?\n\nTo be clear, this isn't a Python-specific thing. It's something you encounter anywhere that you're going to process strings with Unicode. This is based on something called the Unicode Technical Standard, which specifies a hierarchy of weights for a character, including the starting base letter, any accents on that letter, whether it's uppercase or lowercase, and other features. This weighting is called the Unicode Collation Algorithm (UCA). Mucking with this isn't built into Python's standard library, but there is a third-party library called Pi UCA. The library is outdated and only has an older version of Unicode built-in, but it allows you to download data that specifies the latest version. This data is called the Default Unicode Collation Element Table (DUCET). If you have an up-to-date version of DUCET loaded into Pi UCA, you can get a tuple specifying all those weights for any letter or string. Then, because you can compare tuples, you can compare these two tuples for two different strings and determine the sorting order. The function for determining this tuple in Pi UCA is called \"sort key,\" and as it returns a tuple, you can pass it as a reference to the actual sort function in Python to sort these strings with the standard library.\n\nUnderneath the Pi UCA library is limited. It's outdated and doesn't allow you to control the rules. An alternative is Pi ICU, a Python wrapper to the ICU library. Unfortunately, it's just a wrapper and doesn't ship with the underlying code, so you need to have an existing compiled version of ICU or compile it yourself. Installation here is a bit of a process.\n\nIf you want to go down this path, Pi ICU supports customization, so you can read INI files and make changes. The article is divided into six sections, and although I've been talking for a while, I've only covered section one. It goes on to talk about how the locale module in Python impacts string processing, how to transliterate non-Latin characters into their Latin equivalents, how to do case-insensitive sorting, sorting strings containing numbers as actual numbers, and how to sort complex objects like classes with multiple fields.\n\nI'm not sure whether to be happy or sad that an article this deep on Unicode got through without mentioning the rejected request to include Klingon. But aside from that, there's lots to dig into here. If you want to learn the ins and outs of Unicode, this one definitely peels back the onion a fair way. You have a nice course on Real Python video course digging into Unicode and the complexities there, so I might include a link for that this week. People can dig into that.Unicode to me is like regex's. It's one of those things I relearn every time I have to play with it. I've got this mental abstraction that is incorrect. Then I go to do something with it, I'm like \"oh yeah, right, this is complicated.\" So yeah, I need to dig into it again.\n\nMy first article this week is by Muhammad Razza and it's on his blog. The title is \"Python Variables, Namespaces, and Variable Scope.\" It's a fairly short introduction to scope and namespaces. If you're interested and want to dig in a little bit further, I'll include some Real Python supplements that could go along with it. Actually, one of them's a very good video course that is kind of a discussion with a nice tool being used that shows off really what these kinds of namespaces look like when you're within the different scopes.\n\nAs I said, it's an introduction to this idea that starts with, you know, what is a namespace generally? Namespaces are like a container that holds a collection of identifiers (i.e., names). Everything's an object in Python, so variables, functions, classes, and more are all in memory. There's this sort of dictionary built-in feature that allows you to have the name and whatever the values are attached to it. If you haven't played around with the `dir` command, it's a way to see what's happening with these different namespaces.\n\nHe dives into the concept of uniqueness and avoiding ambiguity. The types of namespaces that you may have heard of include a built-in namespace (Python's built-in functions, exceptions), a global module-based namespace specific to the script that you're running or the module that you have currently loaded, and an enclosing namespace for nesting of functions. When a function is actually called, there's a local namespace for it, and once the function execution completes, that namespace disappears.\n\nSimilarly, there are rules for variables and their scope, often listed out in reverse order called the LEGB rule. L is the local scope, E is the enclosing scope, G is the global scope, and B is the built-in scope. An article that dives in much deeper into this is a \"Lay it on us\" joint called \"Python Scope and the Leb Rule: Resolving Names in Your Code.\" It's a nice, very thorough deep dive that gives you the basics and allows you to cover much more depth if you want to keep going.\n\nThe video course I was talking about that I really liked is called \"Exploring Scopes and Closures in Python\" by Martin Bryce. It uses a tool called Thaw, which allows you to open up an editor inside specific scopes and show you all the current variables and their values. It's really neat.I enjoyed his exploration of Scopes and what's happening inside. This idea of how things are enclosed inside each other as far as access goes was a nice introduction. There are different paths to dig into further.\n\nThis ties back to our conversation in episode 312 a few weeks ago. They've optimized how list comprehensions work, and the comprehensions themselves have their own scope. Making sure things don't leak out of the comprehension into the local or global scope was a complication.\n\nThe immortal object may be tangentially related because garbage collecting is based on when things go out of scope. Understanding whether or not something is in scope is crucial.\n\nMojo is a faster tool for AI programming development, not necessarily a replacement for Python. The performance claims of Mojo were tested against variations of Python in solving the same problem in an article by Maxim Saplin called \"Mojo Head-to-Head with Python and Numba.\" Mojo's performance drum is being hit repeatedly as it is a compiled language focused on data processing speed, especially in AI.\n\nMaxim encountered a few hurdles in comparing Mojo to Python. Mojo is python-like but not the same language. The lack of built-in arrays or lists in Mojo required writing his own implementations. Mojo's use of a rust-like memory management mechanism, without garbage collection, changes the programming style.\n\nThe benchmark test on generating a mandelbrot set showed significant performance improvements with Numba and P range techniques in Python. Mojo delivered on its promise of faster performance compared to baseline Python implementations.32 seconds, that's a whopping 34 times faster than the Python baseline and slightly better than NBA with parallelism turned on. But wait, in running the benchmarks, he noticed that the sets produced by running the scripts weren't the same. He was getting different numeric values depending on which program he ran. This variation is coming from the fact that he's dealing with floats, and how Numba and Mojo, and a couple of different flags affect things, changes how floats are compared or rounded. \n\nNumba has something called a fast math flag, and turning that on and off can actually result in different numeric answers. This is one of those fun things that you always get into when you're playing with floats. Just when you thought it was all done, there's an epilogue to the article. Numba comes in from behind in the epilogue.\n\nOne of Maxim's colleagues pointed out that his baseline version of the program uses NumPy, and Numba tends to optimize better without third-party libraries. So he built a new version without NumPy, which to me is counterintuitive. I would have thought NumPy was the answer. Without NumPy and using Numba, it brought it down to 0.29 seconds or just 0.1 using prange. It's kicking Mojo's butt at this point in time.\n\nAnd just because that's not enough, there's an epilogue to the epilogue. Some of the computation was done, the calculation for MBR uses complex numbers, which have a real and an imaginary component. His Python and Mojo scripts both processed these as distinct numbers, essentially combining them when they needed to be. He then went on instead to provide a class implementation of a complex number, and it seriously slows down the work. \n\nThis left me scratching my head a little bit as complex numbers are built into Python, but not a lot of people know that. I wasn't sure why he implemented the class. I'm not sure whether he didn't know that the complex numbers were there, or whether he was trying to achieve something else. But it does kind of leave you with the fact that there's like orders of magnitude difference with very few programming changes. This is one of those things you always run into when you're dealing with performance. \n\nThere's some interesting things going on here with Mojo. The caveat is once you get down to optimization, things like JIT, and I suspect you might get similar things out of pie. Mojo's not that far, it's not like it's leading the pack anywhere along the way. Then that becomes the question, is it worth switching to just to gain that? \n\nSome of the stuff with Mojo that's interesting has to do with the idea of the way architectures changed, also taking advantage of not running on a single machine, running on GPUs and all these other interesting ways that you look at how code is being run today. I don't know, I definitely think that's interesting. It's funny that he ran into things that we've repeated recently, like floats are potentially problematic, and also trying to implement your own version of complex numbers is potentially problematic. \n\nIt's very interesting, and there's a big asterisk you can put beside all of this. The article doesn't talk about what his methodology was, right? As to how many times he ran the tests and that kind of thing. I was curating for pie coders this morning and ran across a 311 versus 312 performance comparison on like 90 different benchmarks. The difference between which is faster depends on which processor you ran it on. If you ran it on AMD, most of more than half of the benchmarks for 311 were faster, whereas if you run it on Intel, more than half the benchmarks for 312 were faster. \n\nThat could just have been whatever Windows was doing in the background when this guy ran those scripts, or it could be the difference in how the processors, because there's a bunch of numeric computations, deal with that. Maybe they are fast, right? There's an awful lot of variables when you try to measure this stuff, and unless you're doing it over and over again and pulling averages out of it when the numbers are close to each other, you might see one win in one iteration and then lose in another. It's again one of these \"watch the space\" moments. Very much so.I'm sure there's going to be lots of techniques that you develop as you go for either of these types of tools this week. I want to shine the spotlight on another Real Python video course. It's a different type of video course instead of being based upon one of our written tutorials. It's a conversation about code, and in this case, it's on a related topic to one of this week's stories: how scope works inside of Python and what a closure is. The video course is titled \"Exploring Scopes and Closures in Python,\" and the instructor for this code conversation is previous guest Martin Bryce. He takes you through clarifying code by refactoring with descriptive names, how functions access variables within local and non-local scopes, how inner and outer function calls access scopes, how to debug a project and its scope using the Thw editor, and inspecting closures, nund code, and cell objects. You also take a deep dive into the inner workings of Python by inspecting Dunder objects to find out how Python handles and stores variables. Like most video courses on Real Python, the course is broken into easily consumable sections, and where needed, you'll get code examples for the techniques shown. All of our courses have a transcript, including closed captions. Check out the video course; you can find a link in the show notes or using the search tool on Real Python.\n\nMy next point of interest is that developers are coming to Python without a CS background. This subset of people often works with Python scripts and Jupyter notebooks, which can become unwieldy. Sharing code and tools between each other is challenging. The story and blog post by Henry Shriner on the Scientific Python blog is a must-read for those interested in data science or hard science. The blog recently had the 2023 Scientific Python Developer Summit in Seattle at UW. One of the goals was to create the Scientific Python Development Guide, which includes tutorials on managing Python scripts and Jupyter notebooks effectively. A group called skitap started the guide in 2020, aiming to help scientists find best practices and standardize their tools for scientific software projects.\n\nThe guide covers topics like creating virtual environments, packaging, testing, documentation, and common situations in scientific development. It provides a set of standards for the scientific community to improve code quality and collaboration. I found this tutorial exciting and wanted to share it.\n\nMoving on to recent stories, someone shared an article on Mastodon titled \"I'm Banned for Life from Advertising on Meta Because I Teach Python\" by Ruven Lerner. Ruven has been on the show before to discuss generators, coroutines, and learning Python through exercises. He has written several books.But he's a trainer of Python and teaches pandas. A few years ago, he decided he wanted to advertise his products - his books, courses, and training. He ran a bunch of ads but didn't get a lot of return, as he didn't put much effort into it. He admitted that the campaign didn't work, but he was advertising his Python training and teaching people how to work with pandas.\n\nAbout a year ago, he thought of advertising on Facebook, now Meta. However, when he checked his advertising page, he found out his account had been suspended for violating Meta's advertising rules. He reached out to people he knew at Meta to figure out what was going on. He discovered that a friend also had problems advertising Python training courses on Meta platforms because Meta thought he was dealing with live animals, which is forbidden.\n\nThe idea of training pythons and pandas together in a heist-like scenario was amusing. He went through the steps to appeal the suspension, but it was reviewed by AI and denied. He found the situation fascinating, as it highlighted the challenges of advertising on platforms like Meta.\n\nThe conversation then shifted to AI and its limitations. An example was shared where AI misinterpreted a search for \"salmon spawning upstream\" as \"St. salmon steaks in water.\" This led to a discussion about the complexities of AI and its lack of contextual understanding.\n\nThe transcript concluded with a story from the speaker's past about genetic algorithms used in circuit optimization. The story highlighted how a seemingly disconnected chunk in a circuit board actually influenced its performance by changing its heat aspects. This anecdote emphasized the importance of considering all factors, including temperature, in modeling and design processes.They had to go back and in the future they started to say not only does this circuit have to solve this problem for the ga but it also has to operate in these temperature ranges. This is the challenge with AI. You hear stories about how it will be unbiased because there's no human, but then we're training it with biased data. So all you have is a computer that ruthlessly impacts using the bias it was trained with. It doesn't understand that panda is both a library and a fuzzy animal. You end up with challenges like potentially endangering animals.\n\nWe are very far away from actual General AI, the talking to robots kind of thing we see in movies. Every time this technology becomes part of the social conversation, people who don't understand it immediately try to use it without considering consequences. There are AI-generated books on platforms like Amazon, such as one on how to pick mushrooms. This can have real consequences as the AI may provide dangerous information.\n\nThere's an author named Martha Wells who had a chat GPT review question about her book. The review was completely made up, blending elements of Science Fiction and Fantasy. The eagerness of these systems to make leaps and justifications is concerning. It's important for programmers creating these tools to consider the purpose and approach of the tool, like focusing on text prediction rather than hallucinations.\n\nIf a tool is meant for summarization, it should have a different approach that prevents it from eagerly making up information. Chat GPT's purpose is text prediction, so it can lead to issues like providing incorrect information based on biased or incomplete data. It's crucial for programmers to consider the purpose and potential consequences of the tools they create.Pandas is associated with numpy, and although your article never mentioned numpy at all, it might start talking about numpy because frequently those two terms are found together in articles on the internet. \n\nRight, right. I've seen the relationships, so this is where it's going off, and that's a reasonable conclusion to a certain extent. Then you've got the other problem of distinguishing between the numeric processing library and the fuzzy little guys with the cute faces. There is a technical tool called bamboo which is just going to confuse it all that much more. \n\nSo again, this is that sort of association problem and what kind of tool are you using? I mentioned this when I talked to Al Swagert about llms. When you give it really super detailed instructions like things that are kind of tedious for a human to do, things like formatting and following very specific layout types of rules, I think if you can get the instructions detailed enough, I'm impressed with the results. It's just figuring out the eagerness sort of stuff and getting reasoning back from it. I don't know if that's something they would ever plan on sharing or not. I don't know if that's revealing too much about how the model's been programmed. \n\nWell, and the other aspect of it too is these are things that adapt. There was an article I came across a few weeks back where somebody had taken, I think it was 60 different llms, and asked every one of them the same 20 questions. Then massive amount of data as to how each one answered and what the patterns were. You could see how certain things worked better than others. So when you asked most of them to answer in a haiku, most of them could do that and you'd get haikus back which is all very clever. But the haikus often had incorrect information in them. So it's a neat party trick that your programming answers in a haiku, but if it's telling you something that's not there. \n\nOne of the pieces he gave was a very simple little brain teaser that required you to understand the fact that if I have a sister, the number of brothers she has is, you can't double count me. That sort of family relationship and every single one of the llms got it wrong. They just multiplied the numbers together and got the incorrect answer. Yeah, and then within a couple of days on Hacker News, people were pointing out that hey wait, chat gp4 is getting it right and it wasn't before. The only reason that's going to start working is someone has started feeding that problem or those kinds of problems into the model. \n\nJust because it starts to be able to answer that brain teaser correctly doesn't mean it now understands how to do brain teasers. The challenge as we try to figure out how to use these tools and how not to use these tools is the misunderstanding that people have about how it works or doesn't work. This is what kind of happened with the AI Winters in the past. People looked at it and went oh, like everything's moving so quickly, this is going to solve all these problems. I came across this quote from the 1960s which was we were going to have artificial general intelligence by 1985. Well, yeah, that in our jetpacks. \n\nAnd that's not to throw out all this progress and there's interesting things in here and we'll see what works and what doesn't work. I think once we start seeing real use of these tools, we'll be better placed to figure out what it can do, what it can't do, and what's gonna get some random lawyer fired. Shall we move on to projects? \n\nWhat's your first one here? Sure, so I'm going to do two this time. My first one is called log merger and it's built by Paul Maguire. One of the wonderful consequences of textual being out there, that fantastic little library, is now we're starting to see some really neat tuy tools out here. This is one of them. So log merger is a log viewing tool that can handle more than one log file at a time and as the name implies, it merges them together. \n\nIt does this based on the date time stamp so you can see the order of the events that happened from separate logs all in one place. The tui's got multiple columns, one for the timestamp and one for each log file that's being merged. It handles multi-line entries so if you've got an exception stack or something, it knows how to associate that with the actual timestamp. You can skip to a line or you can enter a timestamp and it'll go to the closest entry. \n\nAnd of course, because it needs to, it supports both dark and light mode as well as searching for text. You can also run it in a non-interactive mode so you can have it just output a merged content to the screen or to a CSV file.So, it's a neat little thing that handles log regular sort of log text files. The kind of thing you see off a web server. It can also handle gzipped files, certain kinds of csvs, and there's experimental support for pcap files as well. It understands about nine or ten different timestamp formats, so you're pretty much covered for most of the kinds of logs that I've seen. This tool is going to be able to read very cool, very usable.\n\nI have a couple of feature requests. If Paul happens to be listening, the columns should be optional. I understand why he went with columns, but when you're trying to compare more than two files, you start getting like three or four columns, it starts to get messy. It would be nice to be able to switch back and forth between a column and a row, which would be kind of neat. Just a layout issue, yeah. \n\nThe ability to go to a timestamp is very cool, but I'd love to be able to see something like go ahead by three hours, a day, or a week because when I'm looking for something, it's often like, \"Okay, it's not here, it's the next spot,\" but I might not know how to type in an exact thing. Just a couple of ideas, feature requests aside, the tool solves a big problem and does it very elegantly. If you're ever in a situation where you're dealing with multiple logs, this is definitely something you should add to your tool chest.\n\nAlright, well, mine this week is called Cardstock, a cross-platform GUI building tool. I think I already asked you this question, but I'll ask it again. Did you ever mess with HyperCard, Chris? Not directly, no. My time with Mac computers is just after their popular point, about the time that Steve Jobs kind of came back. This particular project is by Ben Levit and it's mostly Python. You actually create the cards with Python, but the concept of HyperCard is that you build these graphical programs made up of individual cards, kind of like pages. The hyper in it is very similar to the idea of hypertext and linking things together. \n\nSo, in the case of Cardstock and HyperCard, you build stacks of cards that are the whole program, and the stacks then are linked together and draw together and so forth. You get this sort of drawing program-like editor for building a graphical user interface. I've seen examples of little simple games like an Asteroids game or pong, or creating a calculator with it. A lot of those are single card kind of things that are built in there. \n\nWhat I thought maybe would be really cool with it is that it is a way that somebody could learn Python basics. They have a whole tutorial that goes into using Cardstock as a way to do a Crash Course and learning Python. It uses WXPython, so you can basically make a finished version that can be running on Windows or Mac. It uses Simple Audio and Requests, but there's a pre-built application already, Cardstock ready to go. \n\nThere's a set of examples online, and if you want, not only can you do the Pi installer thing, but you can also share your work and run it online in this thing called Cardstock.run, which is a website. HyperCard, like 30 years ago, was this really interesting thing that somewhat predates the web and still uses a lot of these ideas of connecting lots of different media together to create programs. It's very visual and hands-on in a way that the cards are kind of organized. There's a game called Myst that was very popular that was built using HyperCard. A lot of interactive edutainment of the era was built using HyperCard. \n\nCardstock is a neat project, and the fact that it's using Python as the tool with it is kind of a fun project. The second one I've got is an odd little toolkit out of the Sandia Labs in the US called Reverse ARG Parse. Its purpose is to output what arguments were used when a script was called. At first glance, you might be like, \"Wait.\"I know what arguments were used. I typed them, but didn't I? If you're trying to replicate the execution of a script, things like the defaults can matter. The motivation behind this tool is so that one user can give another user the exact command line arguments needed to run the same code. It's all about replicability here.\n\nConsider a situation where you've changed one of the default arguments in your code. An older script that calls your newer command might now start working differently because you didn't actually give that command line argument in the old script. By using reverse arars, you see exactly all the arguments, even the ones the user didn't provide, that AR pars passed to your program. It's a bit of a niche, but it's interesting. The good news is it's really simple to use. You essentially just import their library and build a class based on the actual AR parse parser and the arguments that got parsed. You call one method, and it outputs the exact command line that was needed, including all the defaults.\n\nI could see this being really useful for things like logging. Rather than creating a logging statement manually, you can just call the library, making for a nice clear \"hey, this is how the program started\" log message. And of course, you could view such a log with log merger, so hey, callback for the win. There you go.\n\nSo, as I said, it's a bit of a weird little corner, but I can see that there's places where this could be interesting. If you're struggling with this kind of problem, this is worth checking out. Nice. Well, thanks again for bringing all these articles and projects this week, Christopher. Always fun. Talk to you soon.\n\nI want to thank Christopher Trudeau for coming on the show again this week. And I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player. If you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "RPkH6GeXAe0": "Welcome to the Real Python Podcast. This is episode 179. Are you getting by with a few fundamental commands for Git when building your Python projects? Would you like to improve your Version Control techniques and become more efficient with the Git command line? This week on the show, Adam Johnson is back to talk about his new book, \"Boost Your Git DX.\" Adam brings advice for creating a Git configuration, enabling autocorrect, and customizing a global ignore file. He researched through the cryptic documentation and found valuable developer settings so you won't have to. Adam also shares tools and settings to speed up your terminal workflows. We discuss configuring zsh, creating aliases, and comparing diffs. We briefly dig into the most recent update to Django and his work on the project. This episode is brought to you by Typi. If you're looking for an all-in-one solution for building and deploying web applications in Python, Typi has you covered. With Typi, you can easily manage the front end, back end, and deployment. Alright, let's get started.\n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at Real Python. After the podcast, join us and learn real-world Python skills with the community of experts at realpython.com.\n\nHey Adam, welcome back to the show.\n\nThank you for having me. Yeah, it was just over a year ago that we were talking about your previous book, and I'm excited to have you back on the show and learn what you've been up to in the last year or so.\n\nThank you. It was the start of 2022 when I managed to get the last one out, and here we are approaching the end of 2023 with another one. That's pretty good. When did you actually start working on \"Boost Your Git DX\"?\n\nIt was after my son was born in November last year. Congratulations.\n\nThank you. I had taken a break from client work, and I was fighting to stay awake through the night looking after him. So, I got on the laptop while he slept on my chest, and I was thinking, \"What should I do?\" I watched a bit of TV, got bored of that, and I thought I've written a few blog posts about Git recently. Perhaps there could be an opportunity for a book here in the same vein as the last one. And yeah, I found it.\n\nDo you feel like there's a lot of areas for improving the developer experience there for Git?\n\nIt's a bit of an odd one. I found, I was reflecting on the time I'd spent pairing with people over the last few years, and I realized a good chunk of it was not the Python stuff or coding or Django, whatever. It was helping people get through Git commands online. I would spot that, \"Oh, you don't have this one option set, and that's why you have to run something extra every time you run Git push,\" for example. Then I reflected on this during the writing period, and I thought, I don't really know where I learned all this stuff. Like, it's from disparate sources. There are these Git tweets that come about every once in a while where someone shares like one tweak you can make to your Git configuration, and then it gets 10,000 likes, and people are like, \"Wow, that's amazing! One magic trick.\"\n\nExactly. Funny. I tried to just collect them all together. You mentioned pairing, so in that sort of pair programming, I'm guessing with who's that with? Is that with clients or is that through your work? How's that coming up?\n\nWith various clients that I've worked with over the last four years of my consulting work. Okay. I'd often be paired with a developer on a feature to advise on something particular or show them how to set something up that they hadn't done before. And yeah, part of that was we need to figure out how to do the Git stuff. I think I mentioned before on the show, I was a trainer worked at the Apple stores for a little while in kind of my weird journey of all the different things I've done in my life. And that would be one of the things I would do the first time I sat down with somebody to train with them. I would say, \"Well, let me just watch you work for a little bit.\" Very often, they just had gotten the new Minos computer, and one thing that Apple did that was really kind of weird for most users is they got rid of the button that was for the trackpad, and that confused people completely. They had no idea how they were supposed to click and drag. They would do this weird crab crawl walk with one finger, then letting go and pushing another finger. I'm like, \"Um, you could just use your thumb. There was a button there. You can just hold it down like a button and then use a different finger to drag.\" And they were like, \"Oh my God.\" It was like watching carpal tunnel manifest. So, there's a lot of that.I agree that there's a lot you can learn just by watching somebody work for a little while. In the type of Consulting I was doing, which was in recording studios and stuff like that, I find people saying, \"Okay, well you got your microphone backwards. Let's work on that. Let's do interesting little simple things that just instantly made things simpler.\" \n\nSo I guess it kind of gets us into why you decided to write this book. As I put things together, it was a bit like your example, but Git is more like it's been designed in a user-hostile way by accident. For example, Apple changed the trackpad button just because it's nice, but added all these kind of features that would help the user, but for backwards compatibility, they'll never turn something on by default or change something by default. \n\nThere are maybe 10 to 20 top options that I think should be on by default, but they're not. Even though the majority of users experience it, they've been told to install it and you need to know these three commands and that's it. \n\nI think that's definitely the situation for a lot of developers, and the Git docs don't help because they're inscrutable. They use different terms for the word \"commit\" and very low-level terminology. They could do a pass through to make them a bit more accessible at this point. \n\nYou mentioned when you were on the episode of Django Chat that you had become a contributor. I found the Git Community to be very welcoming, but it's hard to get involved because it doesn't use GitHub or anything. It continues to use the email-based workflow that Git started with and was originally designed around. \n\nThe intended audience for this book would be people that use Git on a daily basis. A lot of people use the Git GUI, but if you prefer the command line and like to use it, then look into this book and you might pick up a few tips. \n\nI feel like the process of writing, from having an idea to drafting out a table of contents to expanding on the sections, has become more refined for me. One nice addition tool-wise is Grammarly, which found a lot of small grammar improvements. I hope that makes things a little bit more accessible, especially for folks who don't speak English as a first language.I have trouble sometimes with grammarly trying to figure out how to write these intros for the podcast and do other things. I still haven't quite figured out the voice I want to write in because the suggestions sometimes don't match what I want to convey. I imagine there were settings that you finally became comfortable with and ignored others. I tweaked it a bit, added a lot to its dictionary, and adopted a slightly more formal tone over the last two years. I went through a lot of reader feedback and did an Early Access system where readers could send suggestions at the end of each page. Readers tended to prefer less fun words and wanted the facts presented concisely.\n\nI keep up with whimsical examples, like using Pokemon instead of boring examples about F, bar, or a bookstore. Early access feedback was very helpful in refining the text and figuring out what's useful. Having a vested interest from readers who provided feedback was beneficial compared to having only a few technical reviewers. The book is split into two halves, covering global stuff to make general command line git more enjoyable and diving into specific commands in the second half.\n\nThe second chapter delves into global stuff, like creating a global ignore file. The global ignore file contains patterns that tell git to ignore certain files, like IDE directories. Newer developers tend to ignore their IDE's directory to avoid committing files that their IDE updates constantly. The global ignore file allows you to specify patterns that should never be committed in any project, like platform-specific files or language-specific files.\n\nCommon things to leave out might be platform-specific files like DS store files on Mac. Python-specific files may also be excluded, although the list for Python is shrinking. Having a global ignore file is useful for maintaining consistency across projects and avoiding unnecessary commits.But yeah, sure. For example, you might never want to commit your virtual Ms. So, yeah, Dov might be a pattern you add there, but that is where the list is shrinking. Several Python tools have started dropping their own G IGN direct file into their directory. So, when you run py test, it has a cache directory. Okay, and now it puts a, well, for some time now, it puts a g ignore file in that cache directory that says entirely ignore this directory. So, you run py test, it creates the directory, but git will never see it. No one ever accidentally commits it. The virtual M package, which is like the original way of creating virtual environments, has for some time done the same thing. And Python 3 has just merged a feature, thanks to Bret Cannon, to do the same in the ven module.\n\nSo, okay, yeah, that should be the end of people pushing their vure environments up to get them. Yeah, at least make it a lot more rare. That takes up quite a bit of space with all the different packages they're including in that environment and so forth. And it pollutes search results sometimes. I'm searching for like, is this feature in Django used, and then you find like there's 10,000 uses and then you dig in and you're like, \"Ouch, these are all the Django package just copied over and over again.\"\n\nI'm finding all this extra stuff. Would the pyc files be something there, the compiled files that are generated when you're okay? Those are something you'd probably want in a per repository ignore because every developer on your project will be generating those files and not wanting to commit them. Okay, yeah. So the concept there that's kind of unique then is that people may be used to the idea of having this ignore file in their project folder so that they're making sure that they're not committing it and sending it and so forth. But how does the global version of that work? How do you set that up?\n\nThe modern way to do it is to have a do config directory in your home directory and in that have a git directory and in that, you can create an ignore file. It's just the plain name ignore. So it's do config/git/ignore. If you haven't used the config directory for your git config, you may have used the home directory going for your Global git config file. That's kind of the legacy way of doing it. Oh, okay. In the book, promoting the using the new do config directory, that's the kind of standard. It doesn't pollute your home directory with like four or five different git files. Alright, yeah, keep it all in a dot config which can hold a variety of other \"configuration\" things for different applications or whatever. It's a standard. There are several standards really because on Mac, you might also have your library directory and whatever. But yeah, many tools use the home. config directory and cool that just keeps things tidy.\n\nAre there other things that you want to mention that we could talk about that are sort of global stuff git-wise? One of the things I noticed was the idea of backing up your configurations. Yeah, that's something that I find very important. Once you start putting a bit of effort into configuring any tool, it's a really good idea to back up those files so that if your laptop dies, if you need to move to another one, or if you're setting up a server that you want to work the same, you can download those files from your backup. Okay, and a git repo is a perfect way to back them up, except you wouldn't have the ignore file or whatever you have these different files put until you set it up. Yes, git will work differently but yeah, hopefully that's just a couple commands. Oh yeah, so you feel like that's a common place to store it is to just put it along with your other stuff.\n\nI recommend an easy way of doing it, which is to create a repository and then put the files in there and use sim links in the real paths. So you might have a repository that has a git directory with an ignore file and then in the real do config git directory, there's a sim link and you can actually write a very short shell script that sets those up. Okay, there are more advanced tools that like do these sim links for you or can track files automatically.But I find just doing it the vanilla way is probably the first step you'd want to take to backing up your configuration. Nice, I feel like we hit quite a few things in the global chapter. One of the things that I find fascinating and it's a common problem that I have typing in the terminal is autocorrect and needing some kind of version of that. I don't know if you kind of explored this and found it on your own, but that I find fascinating. It's like a form of typos but it feels like you're just inverting letters all the time just trying to be rapid about typing a common command. So, what is this autocorrect thing that you were covering in one of your chapters?\n\nOh yeah, so Git has an autocorrect system. If you type Git and then a command name that is misspelled like commit with one M, then it will tell you, \"Hey, you typed comit, that's not a real word. Did you mean commit?\" There are other options for the autocorrect system to have it continue automatically to the match if there is a single good match, or to ask you, \"Hey, did you mean commit?\" and then you just type \"Y\" enter and you'll continue. So, there's three options there. One just says it looks like you typed the wrong word, you might have meant this word. The second is automatically going forward and saying, \"Oh, I think you mean this word,\" and the command starts to run. The third gives you the yes/no kind of option.\n\nIs that across a handful of other commands that works or is it relegated to just like commit? It's all the commands that Git knows about. If you make a typo, it will autocorrect. I like using the immediate mode by the way, so just fly by the seat of pants, like, \"Oh, you're just like, go for it.\" There's very few things that you can't undo if you don't know how.\n\nDo you get into a lot of that? We were talking offline before we started that we both were familiar with a book called \"Oh, Git,\" which is Julie Evans Zen, if you will. I think she partners with somebody else on it. That book to me, the focus of it is when Git has gone wrong and how to recover in a variety of recovery states. Is that something that you get into, and I'm guessing there's a handful of those kinds of things? Mistakes are necessary to make progress. If you're not making any mistakes, you're going too slowly.\n\nThe key command for undoing pretty much anything in Git is called reflog. Git log shows you the log of commits, the reflog shows you the log of how you changed those commits. So, in the reflog chapter, I explain a bit about how it works and a few scenarios that you can undo by using the reflog. It has a lot of overlap with the \"Oh, Git\" style of how to undo. I think I was aiming to be a little bit more in-depth. Do you have an example of a gnarly problem like that that you've used reflog to help untangle?\n\nEven after writing the chapter on reflog, I found myself being a little bit more confident of doing things without abandon and being like, \"I can recover this with the reflog.\" I've cemented that knowledge now. Previously, it was just a handful of Stack Overflow posts that I've found over the years. I know that you can undo this, how do I do it? So, I've used a lot of rebasing now and been like, \"Well, I'll just try a rebase and throw away these commits and see if the tests still pass. Then I know I can undo the rebase.\" There's a variety of these little steps or escalation steps that you can take depending on how deep of a surgery you want to commit.Right, cool. It sounds like you kind of get into a variety of those across there, yeah. One thing that you were talking about in one of the later chapters is leaning more towards a terminal side of things, maybe moving beyond typos and having an auto-correct. Like, \"Oh, I do these commands so often, maybe I want to have an alias for these things.\" That's something that's outside of Git at that point, so it's a nice developer tool. You were setting it up for a specific terminal, was it zsh or Zs as you guys like to say?\n\nYeah, I'm a big fan of omzsh, which is a project for enhancing zsh. I think a lot of us are using zsh now, especially since Apple made it the default. The M1 Max and latest stuff seems to be all kind of like, \"Sorry, we're moving beyond bash.\" I think you could still get it, but yeah, most people set up a new laptop or whatever they get zsh and maybe don't even realize it. \n\nAnd whether or not you're using bash or zsh or something else, I think the aliases that omzsh has developed and refined over a decade now of development, they're a pretty good set of git aliases. Okay to copy and maybe adjust some and add your own, but they're good. I talk about setting this up in the book.\n\nIs it more of a like sort of toggles inside of omzsh, or is it like an all or nothing kind of thing? How committed are you as far as saying, \"I want to add all these different quick aliases?\" \n\nGit acts as a plugin inside of omzsh and the plugin is on by default. So everyone who installs omzsh gets these git aliases ready to go. You could copy paste them into your own config if you don't want to use omzsh. At the end of the day, aliases are pretty cheap, so adding a bunch into your spaces is not that bad. You can always unalias them or uninstall the ones you don't like.\n\nI've used it for a long time. I used another project called Zed preso for a bit in between, but I moved back to omzsh because it's way more maintained and popular. I've had this experience where I've not necessarily programmed, but talked with other developers and then seen their setup and it's like, \"Okay, what is the spacecraft cockpit they've made their terminal into that I don't understand what they're doing?\" Do you feel like you've done that throughout this, or is it more like somebody walking up to your terminal could just type the normal commands they know without it being this highly configured type of beast?\n\nI've done a bit of that in the past, and then as I feel like I've matured as a developer, I've come back and thought, \"I don't need something so custom, I don't need something that's so inscrutable.\" So I use omzsh, which is pretty widely used. If you didn't know about the aliases, you could use the normal commands. I use Starship as a prompt, which is a nice little project that's like a cross-shell prompt with a specific default style that's really good for everyone, including git details. There's really no need to configure it, so nearly everyone who uses Starship uses that default theme. Just install the theme and you're ready to go. The only problem you'd find walking up to my computer is that I use the Colemak keyboard layout.\n\nOh, okay. Is that like the standard QWERTY layout, or is it a different type of thing?\n\nIt's the third most popular after QWERTY and Dvorak.\n\nOh, got it. When did you change that?\n\nLike 10 years ago, more than 10 years ago.\n\nAnd that just like, you wanted to type faster, or it's more wrapped around the way you think?\n\nI really wanted to avoid RSI. I was thinking, I'm gonna be a professional programmer, I don't want to get RSI, and the Colemak layout has much less of that. It's estimated to have half as much movement of your fingers for average English typing.\n\nAre all the punctuation and types of things that you use in programming still kind of on the outer edges, or are they easier to get to?\n\nThey are still on the outer edges. It's not like Dvorak that puts loads of punctuation under the right hand. I think it's a bit closer to QWERTY, it tries to move fewer letters.\n\nHow's that spelled? C-O-L-M-A-C, C-O-L-E-M-A-K.All right, I gotta look at that and see what it is. When you did that, like just a, I know I'm going down a rabbit hole here, but did you use a typing tutor or some other kind of way to retrain your brain? Or have you always used an external keyboard? Like I'm guessing you can't get a configured keyboard typically with it unless you're popping key caps off or something. You can pop the key caps off. I broke my first MacBook slightly doing that. One of the keys still flapped around a bit, but thankfully it was a less typed letter. Okay, an external keyboard is the way there.\n\nAre you a keyboard snob? Do you have a big clicky keyboard? Not clicky. My coworker's wife would not tolerate that. Yeah, the baby wouldn't enjoy it either, I guess. I think you'd love it, actually. Yeah, exactly. Those are fun to play.\n\nWell, I thought maybe we could kind of dig into, you know, we mentioned a couple tools here, oh-my-zsh and Starship. Are there additional easy wins that you can think of for someone looking to improve their developer experience? Something like a third-party tool or maybe just something they're not typically configuring? I'd like to highlight one thing in git that I think should be the default.\n\nFrom what I've seen, when you're looking at a diff, git actually generates that live from the old snapshot and the new snapshot. It doesn't store diffs, despite what it might look like. Every time you look at the log, it's generating that diff by looking at the old file and the new file and aligning the lines. Even though it might not seem like it, every time we look at a commit, it's a diff, but actually, that's generated by an algorithm that defaults to something called Meers, which is a simple algorithm for aligning lines that have changed between the two versions of the file. But there's a better algorithm in git called histogram that's based on a mathematical histogram of counting the types of lines there are, which helps align things, especially when there are repeating characters like braces.\n\nIf a brace line is trying to be aligned, that's a very common line, especially a closing brace in a BRAC language. There might be hundreds of lines that are closing braces, so it will not try to align those, it'll try to align the unique lines first. That can really improve the readability of diffs when a few such blocks have moved around. Is that a fairly easy configuration change to do? Yeah, you just set the setting diff algorithm to histogram, and everything will look better.\n\nI think GitHub and other code hosting sites might use it by default, so you might notice that diffs look better on GitHub than they do on the command line. Or maybe you have noticed it and wondered what the heck that was, or you were just staring at it on the command line like, \"I cannot see what changes are in this commit. Let me go check the pull request on GitHub.\" And then it seems clear.\n\nIf somebody's looking to do that, where would they be searching? They'd be like, \"Okay, I'm looking to change my diff algorithm.\" You need one command, which is `git config --global diff.algorithm histogram`. That's the whole thing. That'll pop it into your global configuration file.\n\nThis global configuration file, we've mentioned a handful of things already that would land in there, like the auto-correct that `y` gets to be part of that also, right? What are other things that land in the configuration file that you can think of off the top of your head? Yeah, there's pretty much something for every major command that I recommend in the book. Maybe not for commit, and no, there is one for commit. You know, probably for most commands, there is something that I would say should be a default in git. It isn't, so hey, we're going to have to switch it on if we want to enjoy that slightly improved experience.\n\nSomething that is, I don't know, quote-unquote nice in like an IDE touring its settings file is very often you can just peruse it and just sort of look through it and see what all the options are. I feel like that's not the case here in this global configuration file. I feel like it would be fairly empty initially. Am I wrong about that? Like you can't just go look through it and go, \"Wow, maybe I should toggle that thing on or toggle it off.\" I feel like it's something that literally is getting added to the file, like a `.gitignore`.\n\nYeah, this file starts empty. If you run one of these `git config --global` commands, it will create it, and that'll be that. You can go read the git docs page on `git config`, which lists all the options. I've done it, and I don't recommend it. You've done the work for them to highlight what's nice about it. I think there might be like a thousand options, maybe more if you count all the variants.Yeah, that's the thing with the docks. They've grown organically since Git's creation in 2005, and every new option is on there. It's great that everything is documented, but it's a reference, not for the end user. It's interesting, a bunch of experimental or super niche, like very niche. You only want this if you're running a Git server, and there are a handful of companies running very large Git servers, that kind of thing.\n\nThis week, I want to shine a spotlight on another Real Python video course. It's definitely connected to our main topic this week. Have you ever worked on a Python project that stopped working after you made a change here or a pep bait cleanup there, and you weren't quite sure how to get it back? Version Control Systems can help you solve that problem and other related ones. This video course is titled \"Introduction to Git and GitHub for Python Developers.\" It's based on a Real Python tutorial by previous guest Jim Anderson, and in the video course, Real Python instructor Paul Mess takes you through what Git is and how to use it for your personal projects, how to use it in conjunction with GitHub to work with other people on larger projects, how to create a repo, how to add both new and modified files, common Git commands like status, add, commit, pull, push, and more, and how to navigate through your project's history so you can get back to when your project was working. Git is one of the most popular Version Control Systems today. I think it's a worthy investment of your time to dig into the fundamentals of Git and using GitHub as a Python developer. Like most of the video courses on Real Python, this course is broken into easily consumable sections. It has a transcript including closed captions. Check out the video course; you can find a link in the show notes or you can find it using the search tool on Real Python.\n\nMaybe we could talk a little bit about that sort of history if you're comfortable talking about it. I don't know if you do that at all in the book. Like kind of where this idea of Git came from. I'm intrigued by what you're saying here. It sounds like as a project, things just seem to kind of get bolted on in some ways and things just added. I don't know if they've ever refactored the whole thing and tried to streamline it at all, but the way you're explaining things, it feels like these are, you know, don't look under the hood kind of thing.\n\nMaybe we can just cover a little bit of the history for people that aren't familiar. Git was created by Linus Torvalds, the creator of Linux, for tracking the Linux project. In 2005, he created it, and I believe it was 2009 that he stepped down as the lead maintainer of Git and handed it over to Junio Hamano, who's done the work since. That's like a real world of open source, a long time making Git from before GitHub to now. It must have changed so much as a project.\n\nMy impression from listening to Git podcasts, reading Git posts from core developers, and the mailing list a little bit is that it's a kind of classic open-source anarchic project. If you turn up with a change that you want in and you manage to get it into good enough shape, it gets in and gets merged. There's definitely an idea that it should work for everyone and let's add everything that everyone wants, which is great for the underlying tool. But for something that people are using day to day, the 90% of us who just want to commit and push something into the repo for others to see, there's not a curation then of the options and whatever to see. There's no overarching board.\n\nOkay, interesting you mentioned Git Podcast. I wasn't familiar. Of course, there are podcasts about that. You know, how many podcasts about Python are out there, so it's kind of amazing. Was that part of your journey diving into this book, like let me see what all the different resources are out there? Definitely. I didn't think that there were Git podcasts actually when I started out, and I found two, which are Git Notes and the Git Podcast, something like that. They're both defunct for a few years now. So that's the things come and go, technology stuff. It's pretty the energy level has to take a lot to sustain, you know, going past even 50 or more episodes.\n\nAre there any other extra tools that you want to shine a light on as we kind of wrap up some of the secrets that we're sharing because there's a ton in the book.Somebody should just go and read the table of contents because it will give you a really good outline of what is in there. There are a ton of great features in there. I'm very excited to dig into it myself. Is there another little tool you'd want to share? Let's squeeze one in. I'd say Delta Okay G has a pluggable system for the formatting of diffs on the command line. Not just diffs, but more of its output, mostly the diffs but other stuff as well like blame output. Delta is one such tool that can plug in. It's a newer one built in Rust by someone from Twitter. It's really nice. It does syntax highlighting of the code so it looks a lot more like what you'd see on the GitHub UI. You're looking at the code and then which lines have added are highlighted in green background and which ones have been removed have a red background. It lets you really skim through what's changed a lot better and I think it's what makes the command line experience a lot more comfortable for me.\n\nYou actually created a little tool speaking of color highlighting. That is now one of your many projects that you maintain. We'll include a link to it. We mentioned quite a few when we were discussing the Django developer experience book. You had a whole bunch of them. You created one for this particular project. It's called pigment kit. Pigments is the python-based format highlighter for code that is used pretty much everywhere. GitHub used to use it but now they use a ruby fork and many other tools use pigments like the python docs and anything else that uses Sphinx. I was finding that my git output was a bit dry to read because there's some color to get output on the command line. It's not very pretty but it's there and it helps its readability and plain text in the book wasn't helping with that. So I try to write a pigments plugin that adds some git formatters that add highlighting back in. If you're blogging about git, it might come in handy. I'm using it on my blog and in the book and I don't know if anyone else is using it. Well now they know, check it out, cool.\n\nI have these weekly questions I like to ask everybody and you suggested an additional one which I think is really good. I normally ask what are you excited about in the world of python, we can get to that but let's start with what are you excited about in the world of git. I'd say a couple things. One is the future of git which I feel like then it's maybe going to be a git compatible tool, so a nicer front end that works for the majority of us who are just doing our day-to-day Dev work. There are a couple out there that we will see if they get adoption. One is called sapling that's made by Facebook Meta and one is called jiujitsu that's slightly less developed but has an interesting approach. They are a command line front end, not a GUI kind of graphical type of thing or something else. No, command line, okay. You're no longer typing git commit, you're typing I think it's SP for sapling for example and then a command. They have more modernized command line output, prettier stuff, it looks a bit more like the rust compiler or whatever we want to say as a pretty command line thing. Some opinions like I think sapling when you look at the log by default it doesn't show anyone else's commits, it's like well you probably only care about the things you're working on so we'll just do dot dot dot for everyone else's stuff. That's giving you a lot more configured, opinionated feedback on what you just did. It's providing that stuff and that is helping with the experience and trying to simplify this experience like do you really need to get add things before you commit or could it just be you run commit and by default that puts all the changed things in. Oh okay, yeah. It's potentially assisting with multiple steps in that process, yep, okay, nice. Do you have a favorite out of the two or are you picky? I can't say I've looked into either enough to have an opinion, okay. I do think the G Comm will be around for quite a while regardless of if something seems to be more popular because there are so many tutorials out there telling you how to use git, oh yeah. What are you excited about in the world of python right now? Django 5, yeah. It comes out in December, okay. It's a feature-packed release that's a lot of goodies in there for us Django Nots. It's got database level defaults and generated Fields, they're probably my two favorite features though, cool. It's really going to simplify database management with Django, nice. We were just mentioning the feature freeze and the alpha release, so yeah, it feels like the numbers are ramping up so fast.I guess I'm way deeper in Python lately. When I started five years ago, Django seemed to be forever, but suddenly it was two, three, four, five. Python has changed to a yearly cadence, which has been interesting. What's the long-term release plan for Django after version five? Django has a specific release policy where every new major version is followed by an LTS (Long Term Support) version. The new major version doesn't necessarily indicate a big change but rather a new cycle.\n\nI've been a contributor to the Django project since 2012. I started contributing in 2014 with some minor things and third-party package stuff. A couple of years later, I was invited to the core team. I've had some jobs where I didn't contribute much, but starting my own Django-based consulting business has allowed me to give back to the Django community.\n\nI set a goal in 2020 to attend all three Django cons - Europe, US, and Africa, but that didn't happen due to the current circumstances. I've only been to Django Con Europe so far. I'm looking forward to Django Con Africa happening this year.\n\nAfter writing two books with a similar title pattern, I'm considering learning more about zsh and its specific features. Maybe I'll take a break from writing and focus on blogging for now. You can follow my work on my blog Adamj.u, Mastodon, and Twitter.\n\nI've been focused on client projects with Django recently, so I haven't blogged about much else. I plan to turn some of those projects into posts soon.I guess that is always a fertile ground working on stuff out in the field and coming back with ideas. Especially people tend to ask me the most interesting questions.\n\nAlright, Adam, thanks for coming on the show. I'm excited to share your new book with our audience. Thank you for having me. Don't forget, Taipi is designed to reduce your development time radically and provides all the functionalities you need to build and deploy entire applications. So what are you waiting for? Pip install Taipi (T AI py).\n\nI want to thank Adam Johnson for coming on the show again this week, and thank you for listening to the Real Python Podcast. Make sure to click that follow button in your podcast player. And if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review.\n\nYou can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "QNT8UCCiv7I": "Welcome to the Real Python Podcast. This is Episode 186, recorded on November 8th, 2023. Are you interested in using your Python skills within Excel? Would you like to share a data science project or visualization as a single Office file? This week on the show, we speak with Principal Architect John Lamb and Senior Cloud Developer Advocate Sarah Kaiser from Microsoft about Python in Excel.\n\nJohn shares the multi-year journey of adding Python to Excel. He describes how the project moved beyond writing user functions in Python to something much more elaborate. He details assembling a team with diverse skills in interface design languages and security. Sarah discusses the instant convenience of having familiar Python and pandas techniques at your fingertips inside Excel. We cover typical data science workflows and the potential of interactive visualizations within a spreadsheet. We also share multiple resources for you to learn more. Note: Python in Excel is currently a preview accessible by joining the Microsoft 365 Insider program and selecting the beta channel.\n\nAlright, let's get started. The Real Python Podcast is a conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at Real Python. After the podcast, join us and learn real-world Python skills with a community of experts at Real Python.\n\nAlright, so this week, I've got a couple of guests coming in from Microsoft. I first want to introduce Sarah Kaiser. Sarah Kaiser is a Senior Cloud Developer Advocate at Microsoft and somebody whom I met at PyCon this year. But I haven't had her on the show yet. We've been kind of playing a little bit of email tag or something. So, do you want to explain a little bit about what you do there, Sarah?\n\nDefinitely. So, I'm a Cloud Developer Advocate, which basically means I get to play with all the cool new stuff as it comes out, break it, and then tell people about it. Right now, my background is in research software and Quantum Computing stuff. But I really enjoy exploring how we use Python to do data science, machine learning, research, kind of anything in that genre. So, also lots of Jupyter notebooks. I love me some Jupyter notebooks.\n\nAnd we have John Lamb, who is a Principal Architect at Microsoft and who is largely responsible for what's going on here today about Python and Excel. Can you explain a little bit about that?\n\nYeah, it's mostly my fault. I describe my day job as being a cross between a used car salesman and an arms dealer for Python technology in DevDiv for the company. What I try to do is get Python integrated into various things at the company. There have always been a bunch of projects in the oven for a while, and this Python in Excel thing really started about four years ago. Actually, just a little bit over four years ago when there were a couple of guys from the Excel team that showed up in a conference room in Building 17 with a prototype that they had built for running Jupyter notebooks in Excel.\n\nI haven't heard that term \"DevDiv.\" What does that stand for?\n\nThat's Developer Division at Microsoft. That's the part of the company that builds all of our development tools. VS Code is probably the most famous thing that comes out of DevDiv, of course, Visual Studio, and then there's GitHub. All of that stuff kind of lives inside of the DevDiv organization.\n\nWhat's nice about having you both here is we can talk about multiple sides of this project and discuss applications and ways to use it. Sarah, I think you've actually done a couple of videos and explainers on some of this, which I'm excited about. You come from the data science side, which I see as a tool for people to explore data inside Python and Excel. How has your experience been so far, Sarah?\n\nIt's been honestly a really cool thing. When I first heard from my manager, \"Hey, you want to try out this new Python in Excel?\" I was like, \"Sorry, what? I use Python. What's wrong with my Python?\" But as I got to play around with it and saw some of the design decisions and stuff that John's team had been working on, I started to see why it was pretty cool and why I got excited about making some videos and tutorials around it.But basically, when you're working on data science, whether it's in an academic context, a company, or even like me scraping through my home assistant data logs, all my temperature loggers and stuff. Sometimes I just want to get to something really quick. I don't want to have to try to do the right thing when I start a new project, creating new Python environments. I make sure I don't put everything in the base and then be sad later. Being able to open an Excel spreadsheet, which is kind of like what you do from early school, some of the first data analysis that you learn when you're doing stuff in school, high school, whatever.\n\nI'm opening the CSV file and so to be able to go from that, like I said, I like Jupyter notebooks. I really like the graphical interface data exploration sorts of tools and the interactivity. I can see my data, I can kind of see how the transformation changes it. Basically, this kind of felt like getting a 2D grid of a Jupyter notebook that from my standpoint was also really easy to share. Coming from the Python side of things, I feel like I know Excel. I am definitely not an Excel power user, as I am watching more videos as YouTube tells me more things about Python and Excel. \n\nThere are some really cool competitions that people do. I know it's wild, the stuff people do in Excel is amazing. It's always fun to see how people really dive in and make their tools the coolest thing ever. I'm excited to leverage that whole new community that you can work with and communicate with your Python stuff. Now you have an additional platform or language that you know. I have a background in data science that's real mixed. I got into Python pretty late. I was an SQL guy doing a lot of stuff in Banks.\n\nI joined a marketing division inside of a bank and they were like, okay, I got to learn Python here. I was building automation tools, but they were sort of an R versus Python house. I did a lot of stuff in R studio and got used to seeing the data. I feel like often in Python, people are working with data and not really seeing all of it at once. They're very often just seeing parts of it or doing a describe or something like that. I was more used to the Excel side or the SQL side where I was able to sort entire things and so forth.\n\nI can really see from a data exploration side why this is exciting for people from both sides. Maybe it's like, oh, I get these nice tools from what I get in Python, but I also like somebody who is a Python user maybe they like using Excel as that initial way to look at data. I still do it from time to time. It's one of the easiest things to do, just toss a CSV into Excel. Maybe we should talk a little bit about some of the under the hood stuff, like how does that work that you can create this workbook and potentially share it with somebody else? What's being leveraged to make that happen?\n\nIt's an interesting solution that we landed on to build this thing. Some of the key things that we cared about in the design of the feature really was making sure that it was simple to share stuff. Fundamentally, I think about Excel and documents as a collaboration medium for people. People work together on documents and sharing the documents however they do it, maybe they pass it by value or they pass it by reference. Both of those things should work. When somebody else opens the document, they should be able to change something and have the Python stuff recalculate. That was a key design point of this thing because of the importance of sharing, which is why we landed on a design.Where all of the Python executes in Azure, inside of a container. The way it works is each user has their own dedicated container. Any workbooks opened by the user will open inside of the same session, inside of that container. Python is a first-class language inside of the grid, so it's a peer of the Excel formula language in this feature.\n\nYour Python formulas participate in the automatic recalculation inside of Excel. They can depend on other Excel cells that could contain Python or Excel formula language expressions. It could also be depended on by some other cell inside of Excel. This works extremely well because of the automatic recalculation, which is different from Jupiter where everything is manual.\n\nBeing a first-class language inside of the grid, Python gets all the nice features for free as part of the design. It's like a two-dimensional Jupiter notebook. Structuring things in a certain way inside of the workbook is important for your own sanity.\n\nDefining variables before use is crucial in Python. We enforce an order of execution inside of a sheet, executing cells from left to right, top to bottom, that contain Python. This makes it predictable for humans to use. You can imagine a column of cells inside of Python as a Jupiter notebook.\n\nOne cool thing you can do in Excel is drag a range of cells to the right to duplicate the formula and adjust all cell references. This allows for What If analysis, which is very powerful. Excel's ability to automatically build things out is handy for scenarios like varying interest rates.\n\nExcel's intuitiveness with using a mouse for functions like counting or going by certain factors is a neat feature. It's important to make the experience natural and familiar to all users. When I tried to play with it two months ago, I wasn't able to get it running on my machine. I was waiting in the developer queue.I watched a bunch of videos and observed people work. I felt like it's a bit of a dance, highlighting an area of a sheet to get the information needed. Then, you could choose to turn it into a data frame or move it into Python where it becomes a Python object. Once you've created your Python workflow and written out what you want it to do, you still have that object there. You can then decide to put it back into Excel as an object again. I found it interesting how you go in and out of it, which ties back to the idea of calculating everything, laying it out, and updating things.\n\nYou described it as a dance, and I think you did a great job of explaining the model we tried to create. The model was intended to be natural and familiar to an Excel user. The goal was to make it an Excel-first experience, enriching Excel with Python instead of the other way around.\n\nRanges are a natural thing people use in Excel. They often select two-dimensional ranges of cells. We chose to marshal that into the Python process as a pandas data frame. When the range of cells materializes on the other side, it's already a data frame. We have a special function called the XL function, where you can pass in a string that represents a valid cell reference from Excel.\n\nThe default behavior is for a two-dimensional thing to be a one-dimensional pandas data frame. But you can override this behavior if you prefer lists or lists of lists. The goal was to make it flexible and customizable based on user preferences.\n\nI was fascinated by the fact that pandas is ready to go and creates a data frame. It can be renamed and works well with Excel regions. I was initially confused by the abbreviations used by other users, but I eventually figured it out. I found it interesting to see what was pre-imported and it informed me about data science standards. Pandas, numpy, matplotlib, and statsmodels are all included in the imports.But I guess that's pretty common. And then Seaborn as SNS. There were a couple interesting ones that I think you alluded to a little bit, the idea that there's this custom stuff that needs to be under the hood, which is sort of Excel things, and that kind of allows that dance of moving in and out. There's literally an import or import Excel. And then there's a couple other ones that were interesting like you talked about scaler and array. I don't need to go into the weeds on an audio podcast, but I thought that was kind of interesting. Yeah, read the entire net. Yeah, so is that kind of what's happening, those extra little bits are for the ability for Excel to communicate in and out of this world? Exactly, we define the interoperability library, the thing that you're importing as Excel. And that is something that we will release the source code for, right, just so people can learn from it and that kind of stuff. We just haven't gotten there yet because we're still changing a lot of stuff while we're in preview. And that's going to allow people to do whatever they want, right? There's this init.py file, so to speak, inside of Excel as well, and through the ribbon. There's a button you can click on to go look at its contents. You currently can't edit that thing, which is disappointing, but it's a preview. But we will fix that by the time we get to GA. And inside of that file, as you said, there's just a bunch of imports, and that's mostly so that you don't have to report everything in the first cell yourself if that's what you want. But of course, remembering how things work inside of this thing, if you just put a bunch of things in the top left cell or actually there's also a defined execution order for all of the sheets as well. So the sheets execute from left to right, and then within each sheet, they execute left to right, top to bottom. So you could just stick something in some sheet that you just name the sheet in it, and then you just write whatever initialization things that you want in there yourself, right? And then know that you can just reference any of that stuff from any sheet to the right of that in the tab order inside of Excel. That's definitely what I've done. Yeah, I have a copy paste tab that I put in any start with any worksheet that's like, \"All right, here's my init for everything.\" In your case, Sarah, are there things that do these imports going back to kind of the data sciency part of it? Do they solve most of the things that you want to do with it, or are you adding things in this sort of init that you're creating? Honestly, the default ones pretty much cover, I would say, 80 to 90% of what I just naively would use for stuff. Usually, sometimes importing like PyLearn, usually it's the machine learning stuff that probably is not set up by default for resource loading times and stuff. So yeah, that's usually the ones that I have now in my personal init sheet. But honestly, like what is in that kind of default conduit environment that's running on Azure really does cover, I mean, unless I'm working on an incredibly specific, this is geospatial data from specifically this model of a thing that has its own package, then yeah, I'm probably gonna go do something else. One of the things that I think you alluded to a couple times is this idea of shareability, and that's definitely one of the champion things about Excel, is the idea that you can create this Excel sheet or workbook or what have you and give it to anybody else. How does this change that for users, like in the sense that if I were to create something and my wife maybe doesn't have a 365 kind of thing set up and so forth, and I send her this workbook, what are kind of limitations there that she would run into? I don't know who wants to take this. I can talk about this because you probably know the current status of this better than me, John. This is a complicated thing, so just get one thing out of the way. This will be a paid feature down the road with details of how much and how you have to pay for it to be determined. It's similar to how the co-pilot things are going to be like an additional fee on top of your 365. We like to talk about makers and takers. Makers are the people that construct the spreadsheets, and the takers are the people that use the things that the makers create. The thinking right now is that we think in terms of organizations.Right, so it's going to be a little bit more challenging for people that aren't inside of organizations. But let's say that inside of an organization, you've got some set of people that are paying for these things. They can go create a workbook and share it with other people. So there's going to be a default entitlement for people, even if they're not paying for the feature, they're going to be able to recalculate. \n\nThat's the big thing to remember. Opening a workbook doesn't trigger any recalculation whatsoever. Workbooks never recalculate on a file open. It's only when you change a value. It's sort of frozen in a way. Exactly, and it's cached all of the results, stored in the workbook. When you open it, you'll be able to see all the values and all that stuff. It's only when you change something in the workbook that triggers a recalculation. Then we have to bring some Python execution into the picture on Azure. \n\nThat amount of recalculation will be quoted for people who aren't paying for it. Again, TBD on the details of what that quote is going to look like, but it's going to be reasonable. I thought it was going to be just read-only, so that's interesting. That's okay, good. I think that's really important to deliver the value because everybody shouldn't have to pay. Certain people should have to pay for the feature, and others should just be able to consume the works that others have created in the first place.\n\nI like that idea of the creators and consumers kind of thing, or makers and takers. Yeah, makers and takers, that's good. All right, cool. That answers a bunch of questions I have on that. It's really interesting because it reminds me of times where I've received really large spreadsheets, again working at a bank, with really huge workbooks or multiple sheets. Sometimes you wonder if it's up to date and needing to hit the recalculate button. I feel like it's not quite the same in this sense. You're not necessarily having to press something to recalculate, it just does it, unless you have no internet. Then it's pretty obvious what you get. \n\nWe have a new feature in Excel with the Python feature and the \"stale cell\" feature. If a cell has dirty values, they will be grayed out. In manual recalculation mode, you have to press F9 to trigger a recalculation. It's faster, especially in large workbooks, but the problem is you don't know which cells are not valid anymore. With the new feature, those cells will be grayed out if they have dirty values. Most people will use that mode by default, making the experience snappier. It gives you a better experience, knowing what needs to recalculate and when, not just on every edit by default. \n\nThat was one of the first things I turned on when the flag for that feature came out. I was running into that scenario, especially with machine learning libraries. If I was just changing some plotting options, I didn't need it to recalculate everything. I really like those options because I've also gotten Jupyter notebooks quite frequently that have output cells not sanitized properly. So they would be executing in different orders, and some cells would have been executed with different values. I always try to do a full wipe and rerun.But I never wanted to make that assumption. So, having that compromise of both, I can control. It's not automatically doing it eagerly. I can still choose when it goes, but I also have visibility on what is out of date. So, I can send a share link and have multiple people editing a Word document or an Excel sheet at the same time. You can have multiple people editing these Excel sheets with you. When I say share, it's not just like, \"Oh, you can view the document.\" All of the same things that you could do in Excel or an M365 sort of document, you can do. I think that's kind of one of the Holy Grails for a notebook-like experience - the co-editing thing. Some notebook front ends have it, some don't. Being able to say, \"I just pulled this data file off the server. We don't work in the same office because we're remote, but let's both hop in here.\" Importantly, the other thing is leaving comments. How many times do you go back and forth? I prefer working in markdown, but it's very hard for people to leave comments. I use Word documents and track changes and stuff like that, so you get all of those sorts of things which are not easy or even technically possible with Jupiter notebooks. They are part of, as John was saying, like a billion people understood workflow tools. \n\nIt's interesting you bring a lot of this stuff up. I've had this conversation a handful of times about the interactivity of Jupiter notebooks. It's fantastic, but very often, they are like a regular person's notebook - messy, out of order, but that's really bad as a consumption thing for another person. There was a survey that somebody had done looking at all the Jupiter notebooks on GitHub and how many of them they could run, which I thought was fascinating as an experiment. I agree with you, John, about this idea of how things run in a specific way. It's intriguing and makes me think about how interactive stuff is nice, but if it's doing massive calculations, that doesn't work. \n\nI'm a big music guy, and one of my favorite programs is logic because I can edit while it's playing. Almost every other tool I've used doesn't allow that, but sometimes that's necessary. Being able to hear it in time is crucial. The ability to toggle it is powerful. It's neat to have multiple cursors moving around inside of the notebook. We're hitting a lot of things, but one thing I didn't mention is how you start it. Just to get going, you select a cell and hit equals in Pi, right? So it feels like an Excel built-in function. It's the same kind of muscle memory, but of course, there's a keystroke that you should use as you use it on a daily basis.This week, I want to shine a spotlight on another Real Python video course. Data scientists spend a large amount of their time cleaning data sets so that they're easier to work with. Obtaining and cleaning data typically accounts for 80% of the time spent on any given project. Based on the topic this week, I felt this course fit the theme. It's titled \"Data Cleaning with Pandas and NumPy\" and it's based on a Real Python tutorial by Malay Aral. \n\nIn the video course, Ian Curry shows you about dropping unnecessary columns in a data frame, changing the index of a data frame, using string methods to clean columns, renaming columns to have a more recognizable set of labels, skipping unnecessary rows in a CSV file, cleaning dates and texts based on rules, and much more. This is one of our intermediate video courses. To get the most out of this tutorial, you should have some basic understanding of the pandas and numpy libraries. If that's not the case, Real Python has you covered with even more courses on the fundamentals of pandas and numpy.\n\nReal Python video courses are broken into easily consumable sections and include code examples for the techniques shown. All lessons have a transcript, including closed captions. Check out the video course - you can find a link in the show notes or you can find it using the enhanced search tool on Real Python. \n\nThat's interesting - did we hit most of the reasons why this exists? We talked a little bit about the history of the project, the idea like four years ago, this kind of idea being brought to you, and so forth. Are there other players in the team that you would want to mention that are key and involved in it? It sounds like John, you're pretty deeply involved in getting this going, but are there other people because I saw this note from Anthony Shaw who helped get this set up for us, which thanks again Anthony. He mentioned that Guido and somebody named Anders (I'm not familiar with Anders) was involved. Are those other members of the team?\n\nYeah, so when we first started the project, we had a very conservative target. If you want to go ship something, you want to ship something that you know how to build, and it should be small so you can iterate after you've shipped that thing. Originally, it was a very conservative target for the feature, which was allowing people to write functions in Python and call them from Excel. We call these features user-defined functions in the Excel environment. That's the thing we thought we were going to build, and that's really straightforward. But when we pitched this to management for them to fund it, we gave them some options, and then we had this really crazy idea - let's just shove it into the grid and put Python in the grid, not outside of everything. You just call the stuff as if it were like any other function inside of Excel. So you literally presented like a, b, and c - all these different options to them. \n\nExactly right, you know, like small, medium, large. We figured they'd pick the conservative one, we'll fund that, we'll ship that, and we'll do that quickly. But they didn't do that. They picked the most ambitious one, which is let's put Python into the grid. That of course just terrified me because at the time, there were only three of us and a few other folks kind of on the side. There was no design team, none of this was spun up at the time. So I panicked, and what I do when I panic is I write lists of questions. So, I wrote this document four years ago which are a list of technical questions that we would need to answer if we were to go build this feature. That list had about 100 questions on it, I think. We've solved probably about 80% of them by now. That list of questions said we need to get smart people engaged in building the future. So, we put together an All-Star design team of people. Guido was in the developer division, Beno runs the Excel team, and I introduced them to this crazy idea. Guido was a skeptic from the beginning, and then fast forward a little bit of time.John Panck writes down a big list of questions and then did The Avengers Assemble thing to get a bunch of smart people. I invited Guido, who graciously accepted. We also had a number of other folks who I think you've had on the show before. I recruited Steve onto the effort as well, Catriel, who had recently joined Microsoft at the time, another Python core developer, was brought on board. We needed another guy to act as my taste maker, Anders Hburg, the designer of multiple languages such as Object Pascal, Turbo Pascal, Delphi, C, and TypeScript. His job was to make sure we didn't do something stupid. We also had a number of folks from the Excel Calc side who deeply understand the innards of Excel, some almost fossils at Microsoft who have been around for decades working on the Excel Calc engine.\n\nWe put that team together to sit in a room twice a week for almost a year, hammering out a bunch of complicated design decisions that led us to a model that makes sense. I'll leave it to Sarah to judge whether the thing we made is sensible. When we launched this thing back in August, there was a lot of hand-wringing at the beginning, wondering if we got it right or screwed it up. Are they going to hate it or love it?\n\nI thought we could dig into some neat things right out of the box that I really thought would be fun to have and ready to go inside of Excel. One of them is having pandas right there, where you can type .describe to easily tell what's happening with your data frame. Are there other quick wins you can think of, Sarah, that are really cool right out of the box?\n\nOne easy win is using scikit-learn to build a regression model quickly. It's much easier than doing it in Excel. Another cool feature is plotting with matplotlib and seaborn, which adds multiplot capabilities. How does that work when coming from Python back to Excel and putting it on a worksheet?It's really nice to be able to use some of the Advanced stats visualizations like hex heat map sorts of things. For me, from an aesthetic standpoint, being able to programmatically set something up ended up doing in one of the first notebooks I was playing around with. You can use some of the interactive elements in Excel like dropdowns and stuff. I was wondering about that. Technically, it's part of the data validation feature. So if you say this cell can only be one of these entries in a list, you can then use that as a parameter into other functions. I basically made a GUI where I could select parameters to my Matplotlib config and quickly change things until I got something that looked nice. It sounds almost dashboard-like in a way. Normally, dashboards require you to host them and do all this other kind of stuff. It's so much nicer to do it in Excel. I created a lot of visualizations, and I always wanted the end person not just to say \"that's nice,\" but to be able to touch it and move it around. That answers that question. Something I'll probably have to play with when plotting.\n\nBy having that execution environment not local to my machine, they can actually change it and have that interactivity. That is an invite to them that doesn't immediately start with asking about what version of Python you have installed or spinning up the Docker container. I couldn't host anything where I worked, and it was frustrating. Linux is not an approved operating system, and we haven't decided if we can even use Docker. It was like, how am I going to share anything? This solution sounds like a great solution for that, neat.\n\nThere's some good stuff in the docs that John can probably speak more to, but working with Anaconda on this, the execution environment in the container on Azure is a conda environment. That has security implications. I've worked at National Labs where we couldn't do anything locally, which means people will do that anyway and ask for forgiveness later. Starting with something that meets 90% of what they want will be an easy win for both the user and the company trying to keep data secure. Do you want to talk a little bit about that, John? What were the security concerns involved in what you were creating here?\n\nI had a whole section in that document that was devoted to security stuff. The way we run things is we run them inside an Azure container instances container on Azure. The container is a hyperv isolated container, so there's a boundary that surrounds your execution environment. Colloquially, we call this a steel box. Your Python code runs inside this steel box inside Azure. We transmit data and code by value to the container for execution. There's no outbound network access allowed from that container, so there's no opportunities for a rogue library to exfiltrate data. This set of things, while restrictive, allows you to open a Python workbook, which is very different from not so long ago when people had lots of Excel macros inside their workbooks. We don't have scary dialog boxes that pop up asking if you trust it because we're secure by default. You don't have to trust anyone from accounting. All users view that dialog box as \"would you like to work today?\" and they always say yes. It's a poor defense.Because of all the things we put into place with cloud execution, we get a bunch of things that all line up in the same direction. We get guaranteed sharing and confidence to open a workbook without fear of data theft or machine destruction. This encourages people to use the feature. These are important security aspects, despite people complaining about them. You don't have to search too much to understand why Microsoft is making these changes.\n\nWhen was the last time you copied a Python program to someone else's computer and it worked? We often talk about sharing, and it's a great feature. Compliance officers and people in law firms and banks see the value in these changes.\n\nSome people misunderstand the purpose of this tool. It's not for creating elaborate applications or replacing VBA in Excel. It's more for data science tasks, not application development. In the future, it could evolve into something more, but for now, it serves a specific purpose.\n\nExcel is already within the compliance boundary, so adding Python to it enhances security. Deploying Jupiter in a corporate environment faces challenges like authentication and access control. Excel, with Python integration, allows for building applications within compliance boundaries.\n\nMicrosoft's focus on compliance and governance is evident in their products and services. Python integration in Excel allows for building applications within existing compliance boundaries. There are limitations to what can be considered an application, but simple tools like a calorie calculator can be built using Python.Excel, the grid itself, is already a reactive canvas. You don't have to write everything in Python, nor should you write everything in Python. Excel formula language is fine for all sorts of things. It gives you the GUI stuff already in a way. And you're authenticated, so if you're building something, you're already signed into Excel inside of your organization. There's really no reason why you can't do that now.\n\nWe have all sorts of restrictions in our programming model right now, and we're actively trying to figure out the kinds of things we can do down the road to allow Enterprises to create some other applications. To be able to use Excel as the client software piece to go talk to other things, they need to control the V-net that the containers execute inside of, the virtual Network, put resources inside of it, selectively open things up so you can talk to those. Once you get to that level, you can start building a client-server application using this technology stack as well. There's a lot of things we can do down the road. We're not there yet. We're trying to ship V1, get feedback from customers, then go off and iterate and figure out what we need to do for v2 and beyond. Definitely watch this space.\n\nAre there other things you're excited to do inside this environment that Python is adding to your Excel experience? I'm working on a Dungeons and Dragons-like game state, a game master's screen, being able to track things, share public information with players, generate enemy parties, and do some cool stuff like correlating different properties of monsters in the monster manual. I'm excited to find some weirder edge cases and see what other cool things we can do with this reactive canvas.\n\nMaking GUIs in Python is a huge pain, so having a reactive canvas in Excel is great. Most of what I need for tabletop gaming or making GUIs is here. I use Jupyter notebooks for exploring and looking at datasets. Having easy and quick customization here is great. My current goal is to have composite plots embedded in a sheet for quick visualization without the need to create a dashboard.\n\nRemote play is definitely enabled by this. I had a secondary camera set up for physical play, but we also tried using a web-based spreadsheet for remote play.But then I'm managing multiple places. Maybe I want things to autocalculate and populate from the parties that I'm generating. That's cool. There are some cool Python packages that have a lot of information from the generalized game rules that are published. They save you some effort. Yeah, well, yeah. It's been really fun to play around and see what I can do. Oh, the one I was going to mention before. Obviously, you can work with data that's in the sheet directly. You open CSV, the data is right there in the sheet. But because of what we were talking about before, sometimes I would get data by downloading it from the web. You go to a GitHub repo that has it somewhere, and then you would download it. You can't really do that here because you don't have that external network access. Another way you can load data and queries into your Excel spreadsheet is Power Query. To Excel people, that's nothing new. This was a thing that I learned about Excel while trying to work with Python data. It's a slick way to choose from a menu where your data is, like a web link. If you had web-based data that you wanted to pull into your sheet, you can do it with Power Query. That's how I was getting all the magic card stats or SQL databases, basically any places where you might have data. It was a nice way to pull it all in. One thing I like the most is how you can refer to the data in the Python cells. You can name the query and just call it that name, which I like. The battleship notation of Excel can be hard sometimes. Even if you're editing the Python-based cell, it automatically puts in the selection you have open, which is nice. Lots of cool things. \n\nWhat I thought we could wrap up with on this topic is resources. One of them John shared with us at the beginning, a book on Python and Excel. It started as a document of notes from design meetings, explaining things from a Python perspective. A video of a Python and Excel talk is also mentioned. There's a GitHub repo for this, where you can find discussions, feature requests, and sometimes debates over design decisions. It's a good place to have a conversation with the team. Sarah also mentions working at Microsoft and interacting with teams developing this.I really appreciate how much the team is interacting with people publicly. It's not just a closed-door process. There have been a lot of good discussions, as John mentioned. GitHub is a great place for that. There are so many communities where things are in a Discord server or similar platforms, which can be a hurdle to get into. Most developers probably have GitHub already, making it easier to check what's going on and understand the workflow.\n\nI have weekly questions I like to ask everyone. The first one is, what are you excited about in the world of Python? It could be an event, a book, a package, an editor, or anything else. I think two things stand out to me. PEP 703 is fun and spicy, recently conditionally approved. The idea of making the GIL optional for Python moving forward is exciting. This change could potentially improve performance and open up new possibilities.\n\nI'm also excited about Rust, as it's my favorite package right now. I appreciate the security and tooling of Rust, and how it complements Python. Rust has been a cool package for me, serving as a linter and providing formatting functionality. It's great to have a tool like Rust that combines multiple functionalities in one, simplifying the development process.\n\nIn terms of what I want to learn next, Rust is on my list. I admire how developers are integrating Python and Rust, leveraging the strengths of both languages. It's interesting to see the cross-pollination between Python and Rust, creating more efficient and secure code.\n\nAs for the AI advancements in Python, it's a huge area of excitement for me. Python plays a significant role in AI development, with language models becoming proficient at writing Python code. The ability to write programs in English that generate Python code automatically is fascinating. The potential of AI in code interpretation and execution opens up new possibilities for automation and efficiency in programming.\n\nOverall, the intersection of Python and AI, along with the integration of Rust in Python development, are areas that excite me the most. The evolving landscape of programming languages and tools continues to inspire innovation and creativity in the tech industry.Yeah, which is, of course, a huge testament to the community and the quality and amount of code that's out there that the models can learn from. That's the thing that I'm perhaps the most excited about right now - the kinds of things that we can do with language models, producing agents interactions between agents, generating code to get better results out of the prompts passed around between different agents. That's the thing I'm most excited about right now.\n\nI recently had a guest on, Lawrence Gray, and there's always that kind of negative side, a balancing act between the stuff. One of the things he said in this age of AI is that if you're interested in being in this developer space, you still need to learn about computational thinking and how Python is such a great language for that. The boundary between writing in Python and English is maybe much more akin to what these models have been trained on, and that's interesting.\n\nLanguage models are very good at predicting the next word in a sequence, but imagine predicting the name of the murderer in a storybook. It takes understanding all the clues and context before that in the book, and that's what the models can do. They build up a mental model of what's going on in the story to make accurate predictions.\n\nThe pace of progress in AI is dizzying, and it's an area to keep watching. What's something you want to learn next? It doesn't have to be programming. I'm most excited about figuring out a good representation of knowledge in AI, adding memory to the models in a way that mimics human memory.\n\nHow can people follow what you're doing online? I'm mostly on Mastodon at this point, and my username is crazy4pi. I found a lot of other Scientific Python developers hanging out there. That's where you can follow my work.Yeah, I'm on Mastodon, that's like my main way. Nice conversations. I would leave things on Twitter and no one would ever respond to me. I have actual back and forth with people on Mastodon and definitely the Python Community kind of drifted there, so that's been actually really nice. So, John, have people followed your work online?\n\nI'm the contrarian here, of course. I'm still on Twitter. Every now and then I'll say something somewhat intelligent on Twitter, but most of the time I lurk. I'm John Lam on Twitter. Thanks so much for coming on the show, John and Sarah. It's been really fantastic to talk to you. Thank you for having us. This is super fun. I always like to talk about the cool things that we have going on here.\n\nWell, we might have to schedule an update once we learn what's happening and what's new. It's not done yet, I'm excited. There's more to come. Sounds good. I want to thank Sarah Kai and John Lam for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure you click that follow button in your podcast player. If you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and I look forward to talking to you soon.",
    "vGkunLdVDqk": "Welcome to the Real Python Podcast. This is episode 190. What's it like to sit down for your first developer sprint at a conference? How do you find an appropriate issue to work on as a new open-source contributor? This week on the show, author and software engineer Stephanie Mullen is here to discuss starting to contribute to open-source projects.\n\nStephanie is a data scientist and software engineer on Bloomberg's security data science team. She recently wrote an article titled \"Five Ways to Get Started in Open Source.\" We discuss finding ways to contribute that fit your interests and developer skills, and we dig into the experience of participating in community sprints at a conference. Stephanie is the author of \"Hands-On Data Analysis with Pandas.\" We also discuss the different processes between writing technical articles and authoring a book.\n\nThis episode is sponsored by Intel, providing Edge AI reference kits. Are you building AI apps with popular models like YOLO V8 or Padm? If so, check out intel.com to get open-source code snippets and helpful guides. Just go to intel.com. Alright, let's get started.\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython. After the podcast, join us and learn real-world Python skills with the community of experts at Real Python.\n\nHey Stephanie, it's been quite a while. I've been trying to get you on the show. I know that we've talked at PyCon a couple of times now, but I'm very happy to have you here starting the new year with talking about working in open source. So welcome to the show. Thanks for having me, Christopher, and thanks for your patience as we tried to schedule this. I appreciate it.\n\nIt's just been very much a back and forth. So I was talking to you before we started that we discussed this topic briefly when your article came out on Medium, and Christopher kind of brought it up as a discussion topic. I was very interested in it, but I was hoping that we can get a lot more of your own personal background on it and kind of dig into it. You wrote an article on Medium called \"Five Ways to Get Started in Open Source.\" I think the personal story behind it is going to be some of the more fascinating stuff. So I wanted to start with a question that you have very early on in your article, which is about how a lot of people were coming up to you and saying, \"Hey, I'd like to get involved in open source.\" I'm wondering what kind of backgrounds do those people have, and what was your experience with that? Is that the reason that you decided to write the whole article in the first place?\n\nYeah, so it was definitely the reason behind it. Whenever I'm asked something repeatedly, it's kind of like the bells go off, and I realize, \"Okay, this should be somewhere written down,\" because clearly people want to refer to this knowledge. Not necessarily so that I can say to them, \"Just go read the article,\" it's more so that it can reach more people so that the people who are not bothering to ask the question could find it. Exactly right. There were actually two people in particular who, funny enough, did remember our conversation about this. I was at a book signing in Boston at the ODSC conference, which is a data science conference. Some people came up to me, and I think when I had run out of the books, but they had already heard of the book. One of them had already read it, and I was signing it and they were asking questions about my background. They were very new to data science, also new to Python, they were changing careers. It was a whole lot of stuff going on. The topic of open source came up, and I had mentioned that I had done a little bit and how it's a great way to gain more experience in general, see how different things work, and build a portfolio. They were asking, \"How could I get started if I'm so new? What can I do?\" I kind of went through, like, \"Well, I think the best place to start would be doing something like documentation. That's something you can use if you're learning from a learner's perspective. What's not easy to read?\" I think I was in the airport, I had a connecting flight, and I just outlined this article. I thought, \"Okay, there's clearly these five ideas, and I've done all of these on different projects.\" This is the article that I would be able to refer people to, or they could refer to later. I talked to them, but you don't always remember exactly everything that was said and examples and what to look for. You're not taking notes when I'm talking to you. I wanted them to have and other people to have that resource. It did take quite a bit after that to actually complete the article.Okay, it stayed in a draft form or skeleton of these are the five things and like ideas of which stories from my participation that I would bring up. Were there particular sticking points that things that were making it harder to complete? Time, time, yeah, it's always the toughest. It's been a busy year for you, right? It has been very busy, but I start to find that when you're at least traveling, you kind of have to figure out what can I do at this time. If I'm sure able to focus, then I will try to get something creative done like that. But it's definitely a challenge to get into that space and it becomes more of like okay, maybe I'll just write this one paragraph today and then the next bit I'll work on tomorrow. Putting it into smaller bits did make it easier. And then I wanted to have some other people read the article, refine a couple of things. There's a funny story behind that, but I won't share that bit. It's kind of an inside joke at this point.\n\nAs far as the title goes and okay, yeah. So then once I shared it out there, I think Medium picked it up very quickly. I remember being on a different trip and all of a sudden, like my phone was going crazy, all these claps and all this. I'm like, wow, what's going on here? And then it showed me that it would promote it. So it's clearly people from all walks, any kind of experience, even a little bit of Python or other languages, it kind of applies to really anyone who's interested. Yeah, it seems fairly universal that way.\n\nI'm intrigued a little bit about the writing process and how that might be different from writing your book and writing an article. It sounds like in the case of writing an article, maybe it's something that you can do a little more in a piecemeal way. You can kind of post at it. But it's nice that you have people that you can kind of have pseudo-editors, if you will, people to review it. That seems like a really handy thing. Are there other differences in the way that you approach writing an article? I think I allow the articles to maybe, at least this one in particular, to be a little more on the personal side with personal stories. I feel like just sharing this and not having those stories, it's really not the same impact of an article. Just telling people, oh, here's how you can do it, just look for this, that really doesn't speak to people as closely as like here's an exact example of how this happened and how someone was able to make this strategy work for them.\n\nWith the book, it's more of you're teaching a concept, so maybe the voice that you use changes. And even across articles, it's kind of a struggle to find what is your voice in that certain context. I'm working on a couple of other articles at the moment which do have a little bit more of a personal voice, which is something I'm trying to move towards as far as my articles versus the book being more formal and articles being a little bit of me in there so people can get a little bit of who I am as a person in addition to that. It's like a friend talking to you or sharing a story with you about how you can do it. It comes across that way. I think that's so received a little better.\n\nWithout diving too deep into everything in there because I'd love people to go back and just read it as a really great resource as it is. What was your introduction to contributing? We'll talk a little bit about the different methods, you know, what was your first sort of introduction and why did you decide to do it? That's also an interesting story as well. I mentioned a little bit of that in the article, but what actually happened was I've done a few other things before this, but this is what I see as the first contribution. I was doing my master's degree in computer science and I was doing this alongside of work. So when I was studying for an exam, there'd be times where I was just not feeling studying and I just needed some other outlet to do something. I happened to be in front of the computer and I had thought about in the past so it'd be cool to contribute something to open source that was actual like a code contribution, a feature or something. I kind of had an idea of how I would do it. I was never really unsure about how to get started, it was more of like finding the opportunity. Okay, and at the right time, so right place, right time type of thing. I had not done sprints at that point and I was looking through Seaborn's issues. So I already knew how it worked, how it was built on top of Matplotlib, and so I had good familiarity with Matplotlib, which means I therefore had good familiarity with internals of Seaborn. At the time, Seaborn has changed their whole logic now, but at the time, I was a lot more familiar with how it worked.I was trying to procrastinate looking through the issues, which is more manageable on a repo of that size where it's mainly one maintainer. I saw an issue nearly at the end of the entire backlog that was referencing wanting to add horizontal and vertical reference lines to G grid type plots. The title used ax hline and ax V line, which are the M plot live equivalents. I knew exactly what those are and how they work, so I thought it was just a grid, and I could do it.\n\nI dropped a note asking if they were still interested in doing this since the issue was maybe a year old and untouched. It seemed like a to-do thing but not super important. After making sure they were still interested, I played around with grabbing the axes out of a Seaborn result for the first time. It was easier than I thought, so I proceeded to work on it.\n\nI had to figure out how to write tests in someone else's test suite and how to test visualizations. It took a while to get to the point where it was merged, and it was a lot of work. When the release happened a few months later, I received a mention on Twitter from the creator, giving me credit for the new feature.\n\nIt was nice to see someone using it and finding value in it. I included it in my visualization workshop to show people how easy it is to make open-source contributions. It's not as complex as people think, and understanding the internals can make it less intimidating.\n\nThe back and forth and feedback during the process helped me gain confidence in what I was doing. The shout out on Twitter motivated me to continue contributing, and it was a positive experience overall. It's important to show others that they can do it too and demystify the process.\n\nThe visualization workshop was well received, and I shared a fun story about updating the code right before presenting it. It was a rewarding experience to see the impact of my contribution and how quickly it was recognized. It's all about making it accessible and showing that anyone can get involved.Oh, I can show this new release in here. Yeah, and the code that generated that image did not work properly. So, they had a circle saying, \"Here's the legend,\" but the legend automatically placed itself in a different spot. The legend was in one spot, and the circle showing that there was a legend there was not where the legend was. I was able to quickly fix that in time because of the workshop, so that was cool.\n\nSince then, there have actually been maybe one or two more things that, because of the way I had to show it in the workshop, was challenging. I went back to Matt Flot live and asked, \"How about we add this so that I can show this example easier?\" We've tweaked some of the interfaces there, particularly bar plots, which I think is nice.\n\nI love visualizations, and I feel like that would be a really great entry point for somebody like me. It's very instantaneous in a way. You get to really see what you're creating and modifying. Like you're talking about the legend, right there. It's not like this bug that's going to appear later. You discover it right away, like, \"That's not in the right spot.\" It's something that feels like you get feedback on the work that you're doing programming-wise a lot quicker. That's one of the reasons I like doing visualizations and seeing them being built up from there.\n\nIf anybody's interested, this might be a very interesting entry point for them. I will also say, any library that builds on top of another one that does these visualizations, there are probably plenty of bugs that haven't been found that can be fixed. Almost all of my panda contributions have been around bugs in the plotting interface that sits on top of that plotly.\n\nIt's a good spot to poke around. You mentioned a couple benefits of contributing, such as getting a shoutout and something to put on a resume. Are there other benefits that you feel from contributing? There's plenty. I think another big one is just seeing how people work asynchronously or in teams all over the world on a shared project. In actual public projects, you work for a company, you have your private code bases, you do things your company's way, and you don't necessarily know how people publish packages outside.\n\nIt's nice to get exposure because if you do want to contribute or you change companies, you might have to learn some of these other tools. Getting better acquainted with the library is very interesting. You're creating for a much wider, diverse audience with different backgrounds. So, the documentation, implementation, and naming of things need to be well-designed in a way that makes sense.\n\nIt's a different level that maybe an internal package wouldn't have. Also, the processes can be entirely different down to the tools you use. I would also say getting better acquainted with the library itself. If you're newer or learning a library, that doesn't mean you can't make contributions. You can point yourself at a certain area that you haven't explored yet and learn about it while helping.\n\nYou get more understanding of what's going on underneath, which is also very beneficial when trying to figure out why something doesn't work. A nice highlight is that you can control when a bug gets fixed. If you keep coming across the same bug and it's not critical but bugging you, just go and fix it yourself. The public portfolio is a big thing, and learning on the tools side is beneficial.So maybe you use a certain editor at work but you haven't tried this extension that everyone in the open-source world is using that makes it much easier. So you just learn kind of things that maybe in your sheltered area of your team at work, you don't necessarily get that exposure to. But now you're exposed to so many more people working on things that you get to learn a lot more. I feel like you'd be developing these connections too industry-wise, like with other people and other teams. People now that when you go back to a conference, you're like, \"Hey, I know this person.\" Mostly done it through the push and pull of commits and things like that, but potentially, those connections are always a great part of being part of the community. Oh, for sure, I had a few of those this year at EuroSciPy, and it's very interesting to go from always interacting with that little icon on GitHub and then actually seeing the person and having them come up to me like, \"Oh, I remember, like, I know you.\" Yeah, and just it's very nice to be able to meet people in person and then you get to talk a little bit about more of the direction of things and why certain choices were made that maybe can't fully be explained in the issues that go on GitHub.\n\nIt's great to meet people like that. There's a great good list of benefits and things people can kind of think about. Like, why would they want to get involved building AI apps? It comes with a lot of challenges; many developers rely on open-source code and software to jump-start work. If you're building an AI app, save time and effort by visiting intel.com/edgeaai. Here you can get open-source code snippets and sample apps for a head start on your app. Intel.com/edai gives you access to real-world AI applications that can help you accelerate and optimize your models and deploy faster. You can also tap into GitHub notebooks for a range of applications from computer vision to generative AI. Check it out at intel.com/edai.\n\nSo maybe we can talk a little bit about diving into the ways that people can get involved. We already mentioned one, the idea of Sprints, and I'm fascinated by Sprints. I've wanted to be able to take part, but it is a bit of an investment of time. I'm trying to figure out if that's something that I can do. I know that some conferences even allow a virtual type of thing. Could you give some feedback on that too, briefly? Like, could you just kind of describe the idea that it's a good entry point and I've talked to Tanya Allard on the show about her organizing around diverse Sprints for diverse beginners trying to get more people that have never contributed involved in open source. This is a good way to get going, but what's it like on the ground, I guess, maybe going from even like, okay, how do you sign up and sit down and get started and so forth if you don't mind kind of walking somebody through it?\n\nSure, I'm happy to share. I'll share what my first experience was, maybe a little bit of my second. I've only done it twice. I have never done it virtually, so I can't speak to that. I do feel like it would not be the same. I'm sure you can get close, but I don't think it would be the same. You'll kind of understand why when I walk you through kind of how it goes. My first one was at EuroPython 2022, and the way they organized it will vary by conference. Either you have some sort of thing where you do have to sign up, and that's part of the conference registration. But there could be something like maybe the last day of the conference, they have people who are maintainers of different libraries come up and just quick lightning talk type thing. This is my project, this is what we do, this is the kind of issues we're hoping to work on during the Sprint. Okay, cool, so there's an introduction of the projects that are available, and they want to tell you kind of what we're looking to do. Sometimes that might just be in the form of a website, and usually they will tell you if they have beginner-friendly issues. So you kind of get an idea if something doesn't, and maybe it's like, you need to be working on C internals, then you might know, okay, that's not going to be where I go. I've never used that library before, and I don't know how to do that. So, okay, you might hear someone say, well, we're looking to work on our documentation, so that could be a good thing. It is kind of hard when you hear a lot of names, and some of them maybe aren't spelled as intuitively as you would think or just remembering all of them. Yeah, that's such a common thing.I think the key thing to listen for is either a library you're very familiar with already, like one you use frequently, or something that says Beacon or friendly and sounds interesting. Don't treat beginner as if you've never coded before, which it could be right, but it also just means that you're not an expert on the library or what's going on underneath, or the process of contributing. There are going to be all different definitions of being, and you shouldn't worry if you haven't contributed before because that's the point of the Sprints. There are a lot of resources there to help you make that first contribution, so you just have to stick with it enough to get to that point.\n\nWhen the Sprints start, you usually have different teams. I've been to three of them in person, and different teams may be in different rooms or different sections of rooms. You should go in with the idea that you want to work with a specific project, and you go find that project to pick your team. The maintainers will usually be there first, so you already have a point of contact who can help you with what's going on and give you an in-person PR review.\n\nI had a fantastic experience with the scikit-learn team. The maintainers had identified tasks like numpy docstring style compliance and validation of parameters. Working on these tasks is great for beginners to get familiar with the code base, understand the structure, and learn the process of making a PR.\n\nSometimes, the guide to get you set up might not work on your machine, which can lead to your first PR being a fix for the documentation. Little things like typos or missing information can be fixed as you go. I had an experience where a small issue with a trailing space caused confusion, highlighting the importance of attention to detail to avoid such issues.So I started asking the maintainers how to prevent that from happening. One of the maintainers mentioned using pre-commit with hooks to check against that. It was like a light bulb moment for me, and it was very easy to set up. I brought it to my team at work and started getting really into it. I also introduced it to other libraries and open source projects. Some asked why we weren't using pre-commit yet. It led me to think about bringing numpy validation to our work, as we use numpy in my team. I thought it would be great to have it as part of the pre-commit checks.\n\nI ended up building something internally and got approval to contribute to numpy. I had to rewrite the entire thing to make it work externally, which taught me a lot about how pre-commit works. Now, it is officially merged upstream in numpy. These contributions and learnings from pyit learn led to more open-source contributions in other libraries. There is definitely a snowball effect from the things you can learn by interacting with people in a public space.\n\nI clarified that numpy Doc follows a specific documentation style across all numpy projects. It is part of the pi data realm and is compatible with Sphinx. It can be beneficial for creating packages within an organization without starting from scratch.\n\nIt's important to bring your own computer to conferences to ensure you can make contributions. Conferences usually have internet connections and building projects on your machine may be necessary for tests and documentation. It depends on what you're contributing, but having the project ready to go is essential.\n\nFor example, contributing to numpy documentation may only require installing numpy with Pip to check functions and examples. However, working on a new feature may require understanding the entire project structure. It varies based on the contribution you're making.So you mentioned that you have three experiences and you kind of dug into one of them. I gave you some of these questions in advance to think about them. One of them I was wondering if this would be a good question or not. I haven't been to any European conferences, so I'm wondering, are there differences you notice compared to a US-based one? I would guess the diversity of attendees, as far as nationalities, would be very different. But are there other things that you notice that were different about a Euro conference compared to Sprints at PyCon US?\n\nI've done it at two European conferences and one at PyCon US. I'm going to give you a general thing that's different about the conferences in general, and it's the coffee. I'm an espresso drinker, which always makes coffee breaks at US conferences sad for me. In Europe, every conference, big or small, they're wheeling out an espresso or equivalent machines, and you have a proper espresso ready to go. In Prague this year, I went, and during the conference, they had even better machines with multiple stations with baristas. You could pick which drink you wanted, and they would make everything with latte art on demand. That's pretty elaborate. You would never see that.\n\nI think also, differences in food standards. I feel like maybe there's a higher expectation, and the venues are usually very different. The conferences in Europe are typically not in big conference or convention halls because they're smaller in scale. Something like EuroPython is still in a bigger venue, but something like PyCon Portugal or Italy would be in smaller venues because there aren't as many attendees. Many conferences are held at universities because it's more economical.\n\nIt's very nice, especially when I do a workshop teaching in that kind of setting. I feel like it puts people in the right frame of mind, like a classroom or a lecture hall. Were there differences in the Sprints? I think it also comes down to levels of organization. Different cultures about arriving on time vary. The more times you've done something, the smoother it is. Different cultures about arriving on time vary, and Sprints may vary.\n\nI noticed at EuroSciPy there were many maintainers at that conference. The maintainer to non-maintainer ratio was impressively high. It was something I was very surprised by, and it was almost like you couldn't throw a stone without hitting one. That's not something you'd see elsewhere. It could be the space, as it was very data science library-side, with groups like PyLearn, Pandas, and Matplotlib. Whereas in another group with more US-based options, you might find more of those. Thinking about that.Yeah, if you're interested in contributing to data science packages, a data science conference is more likely to have them than a PyCon. It's also more of a regional thing because many maintainers are based in Europe, so you're more likely to bump into them.\n\nI think that's really great information. It sounds like you agree that it's a good entry point if you are able to travel to a conference and do that sort of stuff. It's something you had a good experience with all three times you did it. The first time, you worked on PyTorch, the second time on Bloomberg packages, and the last time on Pandas in a EuroSciPy.\n\nAnother way to contribute is by adding examples to documentation, which I think is great. Examples are fantastic as they can demonstrate different use cases for a package. It might be a neat way to get involved, especially if you're good at demonstrating things.\n\nI agree with you about the importance of meaningful examples in documentation. Real-world examples are more helpful for newcomers than contrived ones. It's important for examples to showcase actual use cases to make the documentation more beneficial.\n\nIt can be frustrating when documentation lacks examples or provides irrelevant ones. Having meaningful examples can make a difference in how users perceive and understand a package. It's crucial for examples to be clear and representative of practical scenarios.\n\nOverall, contributing examples to documentation can significantly enhance the usability and effectiveness of a package. It's a valuable way to help users understand how to utilize the package in real-world situations.This week, I want to shine a spotlight on another Real Python video course titled \"Documenting Python Projects with Sphinx and Read the Docs.\" The course was written and presented by Christopher Trau. As the course instructor, he takes you through how to write your documentation with Sphinx, how to structure and style your document with reStructuredText syntax, incorporate your code comments and docstrings into your documentation automatically using the pyoc plugin, how to host your documentation on Read the Docs, and how updates to the project's GitHub page can also update your docs. \n\nThe course includes additional resources for you to learn even more about documenting your project with Sphinx and Read the Docs, including a cheat sheet for using rst syntax for Sphinx. Real Python video courses are broken into easily consumable sections and where needed include code examples for the technique shown. All lessons have a transcript including closed captions. Check out the video course. You can find a link in the show notes or you can find it using the enhanced search tool on Real Python.\n\nI had Mike Feedler on. He's working on security for PII hired on as a security developer and residence. We talked a little bit about he had written some stuff and done a podcast episode about open source and getting involved. He mentioned a site called \"Good First Issues,\" which kind of looks like \"Good First Tissues\" if you're not reading it right. We found two different sites. There's one that's like goodersissues.com and goodfirstissues.dev. They're slightly different things but the idea of if you don't have anywhere to start, you don't have any sort of context, but you want to browse for open issues that are out there. I think they're kind of useful in a way just to maybe even get an idea. Those ones are not Python-specific; they're just open source generally. \n\nSo you can narrow it down, you can say \"Oh, I'm looking at Python\" and so forth, and you can kind of see. Did you have an experience of going through and looking at that stuff? Was that where you found that first example that we talked about? I've actually never used those sites. I have not even heard of that one. I came across a different one, which is a similar thing. I think the problem for me, at least, with something like that is there's too many things to now look at. There are all these libraries that say that they have all these issues, and you still don't yet know if it's actively active, which is a big criteria for me. \n\nWhat's the license? Are they responsible? Is this a massive library? So, it goes back to the things that you listed at the beginning of your article that you like. If you want to be involved in this because you want that communication, if other people aren't involved, exactly, you're just sending something out into the void and you're like, okay, well great. So, okay, that makes sense. The big thing is when you have to look through those issues, you have a bunch that are good first issue which you can find on your own just going to the repo. But you don't necessarily know at that point if it's claimed. \n\nIf you're using these aggregators, right, you're still going to need to look at the individual thing to see, oh, someone claimed this three months ago and there's already two open PRs so two people have been working on this. So, kind of what I did was, and I think there's something to be said for scrolling to the back end, the backlog, the oldest things in the backlog if they're still relevant. If nobody has picked them up, people aren't, it's like the whole Google thing where you stay on page one, you rarely go to page two, let three, the end. \n\nIf you're at the end of the issue backlog, then perhaps you've found something that everyone's forgotten about, it's buried and no one looked at. And you can easily scroll through and see the number of comments without opening individual issues. So, you can go in, let's say there's a library you're passionate about or you want to contribute to, you like its philosophy or the maintainers behind it. You know it's active, you know they're releasing, and go to the issues filter to good first issue. \n\nThen just scroll down, find one that doesn't have comments on it or maybe it just has one, maybe it's a clarification, and then see, does this make sense, is this something I want to work on, do they still want to do this? You have to find ways to find that needle in the haystack to look quicker through those. I think maybe and I think you may talk about this also, but it should be something that you're interested in, of course.Definitely look at whether it is something you use because then there's this vested interest, like you said. I want to fix that bug because I've been seeing it. Are there times that you would venture outside of that, or does it make way more sense to work on something that you feel like, \"Oh, I'm definitely going to use this and be involved in it and want to have some personal ownership.\" \n\nFor me, if I have no passion or interest in it, then I won't be able to motivate myself to do it. I'd rather do something that fulfills me. And I feel like you can still explore something new that you don't know yet that you want to get into. That's where I think the documentation and examples come in. \n\nNot being familiar shouldn't bar you from it, but it's probably going to be very challenging to find a good first issue and be able to do it if you have no exposure and you don't have the maintainers next to you like you are in the Sprint. \n\nOne very important thing is when you bump into a bug, it might not actually be a bug. It could be something in your setup. It could be your setup, it could be that you're not using the latest version where they've already fixed it. Maybe this is due to some change in the underlying logic that they've decided is the direction they're going in. So, it's not something you can just blindly fix. \n\nYou have to acknowledge other people's time in a sense. You don't want to put in the 15th issue for the same thing that people have already reported and commented on. When you do see that something's wrong, make sure you can reproduce it on the main branch at that current point in time. Is it still there? If it is, check if there's already an issue for this. If there isn't, you have to check closed issues too because it may have been discussed that this is not a bug, it's a feature or a non-issue. \n\nIf you see that no one else has reported it and you've confirmed it's still there and it still feels wrong, you can put in the issue and say, \"I think I found a bug here's how to reproduce it.\" Very important. And say, \"I'm willing to work on the fix for this if you guys agree this is a bug.\" Then you wait for them to triage it. \n\nThey're going to be like, \"This is definitely a bug and we're very happy to fix this.\" Because they might not get to it for a while either, but if you're willing to put in the work, they can continue working on their main plan for the project. \n\nThe last one you have, which is probably the more challenging, it's like you're leveling up. I have an idea for a new feature for this thing. You already explained your process with that, adding lines to the graphing library, which is great. \n\nIn a way, that was a new feature, but it was also an issue. I think somebody said it was like a to-do. I would classify the numpy doc pre-commit hook more in proposing a new feature because it was not anywhere in their backlog. It was something that I had done separately. \n\nYou might have an idea and you might think it's great, but it might be the exact opposite of what they have as the vision for the library. It might conflict with something else or it might just not be something they want to deal with at the moment, diverging way too far from what their mission is. \n\nYou have to decide whether you still want to do it and do a fork or however you want to approach that. Obviously, you'd have more support and use for it if it were in the main library. It also might not be in the exact form that you imagined. \n\nMaybe they like it, but they want to tweak certain pieces about it and make it different. You still have the option to not do it. There's no contract signed, and you have to do it. But there's a back and forth, maybe a scoping discussion of what it's going to do, and you have to be comfortable that when you put in that PR, you've made the feature how you see it.Yeah, it needs to mold to fit with that project. You might have to make changes and tweak things to fit. You're gonna potentially have feedback and accept it. Okay, that makes sense. I feel like that one relies the most on understanding the library because you can't know what's missing if you don't really understand what's there. Proposing something that's way in left field is not okay if you don't understand what we're trying to do here.\n\nI want to dig a little bit into your own projects, not necessarily working on contributing to other open source things, but something you've worked on on your own. What kind of process do you go through when you start to develop your own personal projects? You have one called Data morph, which I'm wondering which came first, the concept or the project?\n\nIt was more like I wanted to have a impactful visual aid for my panda Workshop. In the panda Workshop, it's a lot about the wrangling of data. Very few people even know that you can plot with it, but you can't do data analysis without visualizing your data. I wanted to have a very impactful visual to illustrate that we did all that but it's not enough. I remembered the Data Saurus dozen research from Autodesk based on the original Anscoms quartet. I had this idea that it would be really cool if I could get a panda to turn into a dinosaur.\n\nI reproduced the research with the panda, and it occurred to me that there's a big problem of people thinking there's something special about the way the points are laid out. I wanted to dispel that myth and contribute to the world of people learning data. I wanted to make it easier to understand and use in a teaching circumstance. Seeing is believing, seeing for yourself that a data set you made up also does this.\n\nI think we linked to it in PyCoders in the past because it was a neat idea. It's stunning to see all the data points creating images that are completely different.It's interesting that that seems to be a bit of your process as far as writing. If that helps you, maybe this is another conversation with developing these things for a conference talk. Like, if you have something that's already been written, you can say, \"I've already thought this out,\" and this is what I plan to talk about. Is that part of what goes into it? I would definitely think so. I think part of what helps me develop the content also just relates to the experience of having written a book.\n\nPersonally, I'm big on to-do lists. I have to-do lists for many different aspects of my life. I'm recently trying to figure out a better way to organize the meta level across everything. I've been trying out Notion, and so far, I'm not very sure about exactly what needs to happen, but I do like what I've been able to do so far. At least it's a little easier to see the bird's eye view where everything is and how they relate, which is nice.\n\nThere are lots of camps as far as note-taking tools. There's Obsidian and Notion, and lots of others. I just went with the first one that people were kind of had a breaking point. One lesson I really learned when I was writing the book was that even just having a high-level outline is not enough to actually write. \n\nI mentioned earlier when we were talking about this article that I had those five points and under each of those five points, a specific example and a couple of sentences. That was more than I would have done before I started writing the book. The equivalent of what I had before writing the book would have been five ideas here, and then left it, which is nowhere to start.\n\nMore of the breadcrumb style, where you leave enough to almost just like rewarding the sentences and fit in and then making it cohesive. It's kind of the same process you have when you're developing something. You have a big idea for something and you have to figure out how you can break this apart into small pieces and how the pieces arrange, what pieces need to happen first, and then what goes after that.\n\nBig on to-do lists, and people have also said ruthless prioritization is a big thing. Obviously, when you have a lot of to-dos, you have to decide which pile you're taking things off of first. Just because it's written down next doesn't necessarily mean it's what needs to happen right now. \n\nTaking advantage of those little bits of time where you do have something broken out enough, it becomes a lot easier to sit down even for an hour or two and actually make progress towards the end goal. But when you don't have that, you're just overwhelmed. Where do I start? I don't have enough time, and then you keep thinking that, and then by the end when you're actually ready to start, the time's up.\n\nThat makes sense, and it makes sense that those skills were honed through creating a book. I would imagine that's quite the process. My co-host Christopher is in the process of writing his first book, and he talks my ear off about his struggles from time to time. He's doing a book about Django, and you know, I swore I would not do another one when I finished it, and here I am. I've done two additions and I've been collecting ideas for a while. \n\nI do want to write another one, not pandas related, something very different. So, I'm back in, and I think it's alright. Watch the space. I do enjoy writing. You mentioned before the perfectionist side of it, where I want to craft that message to make sure it's right, which makes it a labor of love. You've got to get it complete.\n\nI wonder if being able, quote unquote, to make a second edition helps with the perfectionism, the idea that, hey, this can be improved later, that I'm not going to have to kill myself to make it the end all be all in the first edition. What helped me there is the idea that no matter how many times I read through it, I was never going to find all the typos because it's just impossible. You get the fatigue, your brain fills in what actually isn't there.When I started writing the second edition, the first thing I did was actually read the first edition, which I had sworn not to open. I did not open it until that day happened because I'm like, I don't want to see the typos and I don't want to be thinking about it. It's like mixing an album as a musician, and it's like I've worked on this thing for how many months, I don't want to hear it exactly. But I was pleasantly surprised when I read it, and I was actually thinking, \"This is really a very good starting point here.\" I mean, I think no matter what, when you're away from something for a while, I'm sure it's the same from the musician side when you're away from something for a while, you come back to it, you've lived life during that time, your opinions have changed and morphed, so you're always going to want to change something. You're like, \"I never really liked that example, I want to change this or okay, this is actually not that important anymore.\" And also, the space changes too, right? What's important also changes, so just being...you have to be a little bit flexible in that. You can't be too hard on yourself. You do have to know when it's good enough. But my \"good enough\" is still at a higher level than I think someone who's not a perfectionist would have it.\n\nOne of the things that you mentioned is some of your reasoning behind writing a book, doing these articles, and going to conferences is trying to show up and be a representative of, \"Hey, there are women in this industry, there are other underrepresented groups in the industry, hey, you can do this too.\" Do you want to talk a little bit about your journey with that and why you feel like it's important that you show up?\n\nDefinitely. So my journey going to conferences and presenting, I actually was terrified of public speaking all my life, basically. But it was one of those things where after writing the book and seeing that you are impacting people, you just get occasional things on LinkedIn or somewhere else where someone is talking about how the book has helped them, and they've learned. And it's kind of like that warming feeling, but it's almost like, yeah, you're not necessarily reaching as many people as you can if you just leave it at that. So, I did want to take it to conferences. I wanted to conquer that fear of public speaking. And during the COVID times, there was a data science conference, the ODSC one I mentioned before, where they were having a virtual conference and they invited me because of the book to deliver a workshop on pandas. To me, that felt like a good step because it was virtual, right? So no one would be seeing me, right? I could practice that. And I mean, I was terrified, but I got a little bit more comfortable doing a few other ones virtually. Then when I got to do it in person, I got to do book signing events and really talk to the people who were coming to my stuff.\n\nI hear the transition from virtual to being in person is actually people really liked being in person because they got the room, in the sense that people are interested. You got people that are paying attention. And yeah, agreed, but at the point that I was with speaking, it's still scary. It would have been horrifying, and it was nice to like because I still got very nervous even talking to a black screen with almost no feedback and the occasional question. Then when I did first do it in person, when I got through it and I got the claps and people really wanted to talk and had tons of questions, I was like, okay, wow. I think it's one of those things where you're so in your head that people caught that mistake I just made, or if I say one thing wrong, they're going to realize it. And really, nobody does, and people don't remember that. And you just have to keep going, right? It's changing the way you think about it, but I've met so many people that will come up to me and just share their story and how they just love they wanted to meet me or get a copy of the book just because they liked my story. And that they see someone that looks like them or a woman in the space. I had a woman at the book signing I did in San Francisco who was telling me how she came just from Miami to meet me and took a picture with me so she can send to her daughter. That's cool. People want me to speak at a school club in Jacksonville where they're trying to work on the main charter of the club, getting women and minorities into tech. Having that representation and seeing someone, and believe me, I go to many of these conferences and I'm very aware that I'm the female that's speaking or the Hispanic person that's speaking.It feels great to bring that persona, that representation to conferences and show that everyone can do this. That's why I prefer workshops or talks that teach people something. I want people to learn because it's nice to see the lights go off in people's heads, like \"oh, I know this all the time.\" It's heartwarming to make an impact on people who maybe didn't see themselves as capable before. Now they feel comfortable asking questions like \"how do I do open source?\" It's nice to make a wider impact beyond just the book or people I meet in my day-to-day life.\n\nI'm always excited about conferences and meeting new people around the world, reconnecting with others. It's cfp season starting, so I have to work on some proposals and plan new content for this year.\n\nIt's interesting because I'm very introverted, but I enjoy meeting people from different areas with different philosophies that we can connect on Python topics or what we're trying to learn. I've met so many interesting people in so many places. It's exhausting, but I wouldn't want to step back from that experience.\n\nI talked to Nina Zacharo about it, and she coined the term \"Expovert\" for getting out there in conferences. It's important to respect when someone needs their solitude or me-time. \n\nPeople can follow my work on my personal website, StephanieMol.com, Twitter as StephanieMenen, and LinkedIn. I usually post new articles or links to stuff on those platforms.\n\nI want to learn spoken languages next. I'm fluent in Spanish and have done some French, but I'm more passionate about learning Italian. I've always liked the way Italian sounds, and I find it more appealing than French. I saw a funny video of a Husky with an Italian accent, and it made me laugh. It was interesting how the dog's vocalizing sounded different when the woman spoke Italian to it.I know but I'll include a link people can check. The video could be fake, but that's pretty funny. Yeah, cool. Need to conduct an experiment. Is that partly for travel purposes or have you been to Italy? I've been to Italy multiple times. I mean, I've been before. I was very good with Spanish, and also after. I think once after, if you're there long enough, it doesn't really matter that you're not speaking Italian. Spanish is usually enough, but I've always just liked the way it sounded growing up because I am half Hispanic. I struggled getting to the point of being fluent only because I wasn't really speaking it at home on a day-to-day basis. We had alternating years of Italian and Spanish. So I kind of had to not store the Italian too much because I wanted to focus on the Spanish and not lose it because it was weird that you had to alternate. \n\nNow, I'm at the point where I have that language, I now want that other one. I always just liked the way it sounded. It sounds like happiness, like you're always happy, a sing-song type of thing. To me, French doesn't sound that way. It has a different tonality to it, but yeah, I agree. You can always sing something in Italian. Exactly, the words all end with these beautiful vowels. \n\nSo, that's cool. Thanks so much for coming on the show. It's been fantastic to talk to you. Thanks again for having me. Remember, don't start building your AI app from scratch. Save time by visiting intel.com/sledai. Get open-source code snippets and tools to jumpstart development and deploy faster. Go to intel.com/sledai. \n\nI want to thank Stephanie Mullen for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure you click that follow button in your podcast player. If you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/smp-podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "ZEN7Vsb0RNw": "Welcome to the Real Python Podcast. This is episode 199. How do you customize an LLM chatbot to address a collection of documents and data? What tools and techniques can you use to build embeddings into a vector database? This week on the show, Calvin Hendrick Parker is back to discuss developing an AI-powered large language model-driven chat interface. Calvin is the founder and CTO of Six Feet Up, a Python and AI consultancy. He shares a recent project for a family-owned seed company that wanted to build a tool for customers to access years of farm research. These documents were stored as brochure-style PDFs and spanned 50 years. \n\nWe discuss several of the tools used to augment an LLM. Calvin covers working with LangChain and vectorizing data with ChromaDB. We talk about the obstacles and limitations of capturing documentation. Calvin also shares a smaller project that you can try out yourself. It takes the information from a conference website and creates a chatbot using Django and Python prompt toolkit. \n\nThis episode is sponsored by Mailtrap, an email delivery platform that developers love. Try for free at mailtrap. Alright, let's get started. \n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at Real Python. After the podcast, join us and learn real-world Python skills with the community of experts at Real Python. \n\nHey Calvin, welcome back. So good to be here. Thanks for having me again. Yeah, it's fun. It seems like our annual visit. I've gotten used to it. \n\nYou reached out and talked about some new projects that you're doing there at Six Feet Up. One of them is working with this customer named BEX Hybrids. Maybe you can tell me a little bit about the project, then we can dig in because I'm very interested in this idea of building chatbots and using a lot of these AI tools and LLMs, but also the idea of customizing them for, in this case, a business client or a specific domain. I think that's fascinating. \n\nThe client specifically is BEX Hybrids. They are the largest family-owned seed company in the United States. When you drive through the Midwest, you'll very frequently see these signs along the roads with the big BEX logo and some kind of number underneath. A lot of those are the BEX test farms where they're understanding how their hybrids react in various areas and trying to develop things that are better fits for one area versus another. They have agronomists and all these people collecting research and putting it into these practical farm research books that they send out to their customers. \n\nAll the farmers who are customers of BEX, which is a lot of them all over the place, get these big books called practical farm research. It includes all the things they learned from last year. It's chock full of graphs, charts, diagrams, data, tables, images, and pictures. It's very unstructured data, and the challenge was getting it into the right format for an AI model. \n\nThe real magic of this project was how to get the right data into the right format in the right spot so that it makes sense to a human and an AI. We're still in the generative AI world, where statistics and math are ruling with these models. The data in these practical farm research books had to be structured properly for the AI to interpret it correctly. Their goal was to print a book they would ship to someone.You're using visual indicators to indicate importance on a page, maybe highlighting a row in a table in a specific color. But to a computer, it's just grabbing the text out of that page. It doesn't see the highlight necessarily, right? Or you may want to use it as a page design, maybe using InDesign or some page layout program like a desktop publishing program. You may be hiding text by dragging it off the page, out into the space around it. If you have ever done desktop publishing, sometimes you'll make a white box to hide something and just put it over text that's on the page. Or you may just drag it off to the side because you might need it later or you don't want to include it in that version of the print. But when you export that as a PDF, that text is technically still there, it's just not visible to the human eye. It's like a hidden layer, but to the parsers tearing apart a PDF file, they're going to see those strings of text still in there, even if they may be wrong or inaccurate information. It may be an old version of some text that you didn't remove, but you just put a white box over it and put the new text on top of it. How do you tell OpenAI when you're just uploading a PDF file that that's the case in these files?\n\nThis is what happened with this specific project. Initially, a lot of the magic was in parsing these PDF files and making sense of them. We used other AI tools like machine learning and others to understand the page, clean it up, and extract the text in a meaningful way. We trained a model to read the PDF, extract data, and be used by another model to provide answers. In the generative AI world, this is a big challenge. It makes me think of the time I worked for a law firm and taught the staff how to use their tools, where PDFs were a big part of it. They had a massive database of documents where lawyers would check out a document, add things to it, and keep version histories. I thought about redaction and how some bad methods like putting a black box over text wouldn't work in digital documents. You need the correct tools for that.\n\nIf you asked GPT about redacted documents, it might have used that technique of putting a black box over text. This could expose the text using various attacks against the model. Adding context to a large language model focused on business has an odd name, retrieval augmented generation. This involves adding a sidecar store of documents for the model to partner with or use. IBM has a useful video explaining the process well, showing how it can add context to questions and provide sources for answers.\n\nA major requirement for this project was to give citations to the physical book the user would have on their bookshelf.I think it's more powerful because if they can ask a question to Virtual agronomist about when the best time to plant a cover crop is and then actually another bit that's missing that I didn't talk about was in addition to indexing the Practical Farm research, putting that into the Vector store on the side so that when you ask a question it goes and finds say the 20 closest documents that are like what you just asked about and including that in the context. What we also do is when people onboard into the system is ask interview the farmer okay where is your farm located, what kind of tractor do you have, what kind of wheels are on your planter because those all can factor into well you would do this except if you had this kind of tractor or you would do that except if your farm is located in Illinois or Iowa. So there's contextual answers even inside the Practical Farm research and then you want to be able to give them a page number in a book to go pull it off shelf look at it or you'd want them to contact the right person to talk to. In addition to enriching that Vector database with the PDF pages from the Practical Farm research, we also indexed in there or had a tool using Lang chain for the framework for this piece. Having the tool talk to their company directory so who covers Iowa for this version of this seed and so they would know how to actually direct you to the correct person to talk to. In this case, hallucinating would be a really bad thing because you don't want to give people direction on your product that would be incorrect or inaccurate. But if we can actually give them citations and the right people to talk to and behind the scenes, what is not actually seen by most people doing these kind of projects right now is it's important to build in some structure and some frameworks for observability to the prompts and the questions that people are asking of your system. We built that into this logging of sorts like a log all the prompts people are asking of your model. You can actually have someone who knows what they're talking about review it kind of like training a large language model with a supervised training. In this case, it's not really supervised training, we're going to take the responses that the generative AI gave and we may rate them like a one to five star rating on how good was that response. That gets indexed and potentially sent in as context later when someone asks a very similar question. You can say well, this was a good response and this was a bad response to this question in this area. The model can now statistically incorporate that into how it's going to respond in the future or you would have a subject matter expert write an official response to a question like that. This is the common question we're going to go ahead and answer. So if you think about FAQs, they're nice because they're official answers to common questions. If you're chatting with a bot, it'd be nice if they could pull from those official answers in a very easy manner in concert with all the other data associated with the question or whatever they're asking. It makes me think of two things. One is it sounds like the system generally these sort of augmenting an LLM via this system has some nice advantages in the sense that you can update your side of that information, you can add the next issue of their study, and then one other thing I thought was kind of interesting, I was watching inside that IBM video which I thought was really kind of cool is that a system like this can actually say I don't know or that information isn't here, is that your experience? You can say that the context provided you can understand in the context you provide it that nothing was mentioned about whatever the question might be. Reversing back in time trying to think of like how that went, what's interesting you mentioned like the next edition of like the Practical Farm research being included. It's actually I think more exciting than that is that the last answer someone asked 5 seconds ago can actually be included as part of the context for the next person who's asking really for that same thing because it has that context window as part of the context window because the data is all going. If you've not kind of played with Lang chain, I highly recommend it. It's an amazing tool and it's been evolving super fast.When we started the project or stopped the project, there was only a three or four month window. The number of revisions was very active, and we had to keep on top of the update notes and release notes. The project was very vibrant and active. The embedded Vector database inside Lang chain is chroma DB by default. We would take all the practical farm research and divide it into sections, indexing it into the chroma DB database. When someone asks a question, we run the transform against the query database with a long index of integers. We can tune a lot of knobs to adjust the context window size and the number of documents brought back. As we interact with a person chatting with the chatbot, we index the answers and responses back into the database for future sessions.\n\nThere are ways to segment and firewall off the information, but the concern is more about giving accurate information. If the information is inaccurate, can we address it in a response later? Fine-tuning a model can be done in different ways. You can use foundational models as is or provide additional context windows. Another option is to fine-tune the models with more data, which requires GPUs, compute, and time.\n\nAdditional ratings and rankings of responses are saved to a database. Sample code is available from a presentation done in the summer, showing examples of building a Django application with HDMX as the chat front end. The models are stored as objects in the Django database.It's temperature set to X. These other variables, the knobs I was talking about, you can actually set up those things so that as the API calls happen to your various models, like the foundational models whether using OpenAI or hosting it on some other service like Hugging Face spaces, you can AB test different settings that you would be passing along for that API without having to redeploy code. Now, you have the capability of storing settings for the model inside of a database. Then we store the prompts and responses inside the database and use all those things to populate the Chroma DBE Vector store. As I ask a question, all those things can be considered, including storing the history of every interaction I've ever had with a virtual agronomist. They can use that as more context to understand how I generally ask questions and want responses.\n\nOne of the early features before they introduced GPTs was the ability to have a pretext that you could put in front of it, like always talk to me as a pirate. No matter how you talked to Chat GPT, it always gave you answers. Temperature is thought of as how creative the model is, whether it's spicy or not. We would create models with different temperatures inside the system, giving them names like Lieutenant Data for factual responses and War for Yar for fiery responses.\n\nThe project was based on the information from the rally conference in Indianapolis. The conference was the first year for this event, aiming to be the South by Southwest interactive of the Midwest. The conference had an incredible lineup of speakers, but the usability of their website was not easy to use. I thought it would be a compelling use case for our demo to index all the speakers, bios, talks, descriptions, and schedule into our Vector database. We built text extractors to spider the website, using tools like Scrapy or Beautiful Soup.It was nothing super sophisticated, so you could obviously get more sophisticated with this. This is kind of like a reference model version of a spider. Just go to the speaker page, grab some text based on a CSS selector, strip out HTML, and get the straight text version to feed into various models for additional context. It made for a good demonstration because you could interact in real-time. For example, you could ask about a conference, its location, dates, top speakers, and specific topics.\n\nIf you are an attendee of the conference, it would be interesting for the conference to offer personalized networking suggestions based on your bio. The model could recommend relevant people to network with and suggest topics to discuss with them. It can provide great answers and help you connect with the right people at the event.\n\nScraping data involves cleaning and formatting HTML and CSS content, which can be a tedious process. Using tools like Chroma DB can help streamline the process by vectorizing the data. Chroma DB offers built-in tools for vectorizing text, making it easier to extract valuable information from websites.\n\nPrompt engineering plays a crucial role in guiding large language models to provide accurate and relevant answers. By structuring the data effectively and balancing granularity with the amount of content sent to the models, you can improve the quality of responses. It's important to optimize the queries to reduce costs and ensure consistent results.Knowing what to send in a reverse engine is crucial. Giving back relevant results requires putting in the right content, rather than indexing the entire page. It is important to scrape out specific parts and potentially split them further, such as by chapters in a big PDF. Chunking the data into databases allows for leveraging the query against the Chroma DB Vector database to retrieve relevant chunks.\n\nDefining the chunk involves identifying talks, speakers, or keywords. It is essential to establish equivalencies, such as between talks, keynotes, workshops, and panels, to provide comprehensive answers. Prompting the tool behind the scenes ensures consistent results when users request a list of speakers.\n\nStoring information in a database, accessed through tools like Django or Flask, allows for querying additional equivalencies based on context. Tuning the application to limit the number of documents pulled from the Chroma DB database helps avoid irrelevant or less important information in the context window.\n\nUsing a command line tool with prompt toolkit, the demo showcases the process of building and showcasing relevant content. Auto completion features in prompt toolkit enhance the user experience.So it'll autocomplete like speaker or session or words it knows about that are fed into prompt toolkit. It also keeps the history of everything your prompt has ever, like you've ever typed into it. Just like if you're using bash or zsh, you've got your shell history where you can use the up arrow. Prompt toolkit gives you the same thing and we leverage that history to feed it in as additional context. So you have a memory of the discussion. \n\nAs you feed the next prompt into the command line, it's aware of all the previous prompts you've ever asked for. It uses that to pick out the right documents from the vector database to feed them into the context window. The hard code you'll see in there is kind of a hard coding of when you're responding. Keep these things in mind. The speaker is the same thing as a facilitator or a workshop panelist. That's one potential context as you're exploring something. Maybe as you need a larger solution, you might build some other kind of architectural solution for that.\n\nThese are pretty custom-fit unique solutions. I think anybody can go pick up the chat GPT or the GPT API and make a query and a call. But you're going to get wildly different kinds of things coming back out of it. You're not even protected by the guardrails that chat GPT gives you. If you're using chat GPT, you've got some additional bits working in your favor to help guide the experience to make it more of a consumer-friendly tool. If you're just using the API, you're more on you to try and do the right behaviors or send the right kind of queries in to get the best answers back.\n\nI think it's interesting. I remember talking about prompt toolkit. It's generally a CLI tool, but it's such an interesting tool for this circumstance. It really comes in handy because you could have it query and autocomplete. It's really a nice thing for building quick and dirty little command line tools. \n\nGoing back to the BEX hybrids documentation and the struggle there, in that case, it looks like you used a different tool. You were using llama index or what is it called? We started off that project with llama index. If we were doing it again, we probably wouldn't. We probably would just stick with Lang chain as a great tool. We were trying lots of different things and seeing which ones are giving us the best results. The struggle is real when it comes to python packaging. Keeping dependencies up to date is not a problem unique to large language models. It's a global problem for everybody. \n\nAs far as writing tutorials and things like that at Real Python, we struggle with it too. It's nice to have things pinned, even though that might not be the latest things. At least you can get to the end of it and then maybe think about how to modernize it. We'll have a whole another talk on approaches to keeping your environments up to date in a systematic manner.Definitely this week I want to shine a spotlight on another Real Python video course. It dives deeper into one of the tools we mentioned this week. It's titled \"Command Line Interfaces in Python\" and it's based on a Real Python article by Andre Burgo. In the course, instructor Liam Puler explains the details behind implementing your own command line interfaces in Python and how they can process a variety of arguments. You learn about the origins of Python command line arguments, the built-in support for CLIs in Python, standards behind designing a CLI, how to manually customize and handle arguments, and you'll learn about several libraries available in Python that can ease in developing a complex CLI. These include ARG pars, Get Up Click, and the one that we mentioned this week, Prompt Toolkit. I think it's a worthy investment of your time to learn how to implement your own command line interface and how to handle a variety of arguments to make them flexible and more useful to the users of your Python projects. Like most video courses on Real Python, the course is broken into easily consumable sections. You get code examples for the techniques shown, and all of our courses have a transcript, including closed captions. Check out the video course; you can find a link in the show notes or you can find it using the search tool on Real Python.\n\n[Music]\n\nSo you talked a little bit about the data that they have, a lot of it's text. You also talked about in your talk that there's going to be tables in there, which is an interesting data structure right in the middle of a text. Yeah, a document for it to try to parse. Do you end up parsing that separately or in indexing it separately, like using a different tool? Or how do you approach that, or do you just exercise it? Well, the difficult part with the tables was going to be if they were using, for example, visual elements to denote some importance in the table, or if you had like a footnote like conditional formatting or something. Or if there's an asterisk on something when the footnotes weigh down the page necessarily, and there's nothing super formal about the footnotes. As humans, it's easy for us to understand; we see like a superscript one, we go to the back of the book and try to find what that citation is. Exactly, and it's easy for humans; we take it for granted. But for the parsing of that text, like the proximity of the text to one another is important for the models as they're indexing and understanding or trying to give you back responses that statistically make sense. If something was far apart on a page, like just physically distanced far apart on a page, they may not be considered related to one another. So we had to look for those kinds of aspects of if a table was in the middle of the page, we may use a technique to understand what the visual look of the page is so we could basically slice it up in different ways and then try and rebuild the page in a more computer-friendly or machine-readable friendly version of that content. So restructuring back pieces that were maybe farther apart from one another, and again using AI to be able to tear a page apart and then put it back together. Okay, yeah, because I look at this process of indexing and there's models that have luckily done a lot of the work for you. An index is going to build this vector relationship, and that vector that's in the database for the particular token it's looking at could have 300 fields, it could have 50, it could have real deep relationships depending on what the model is that you're using in advance. I don't know if you want to get another weeds of that sort of stuff, but were you looking at like, okay, I want to have 300 vectors or I want to look at fields or whatever were those some of the things that you were looking at and doing this for this project? Yeah, because we want to be able to feed all the information in a way that we could make the queries on the other side make sense to feed into the model. So deciding how granular to get decides how big the vector space actually is. And then okay, you can tune those queries against the vector space to give you back more or less items because you may bleed into another topic really easily if your query space is too large or the documents are too few. I feel like you're opening up another like, all right, we need another dashboard over here that's going to have all these extra controls. Like, do you want to have that many controls or not? Yeah, well, that's why all these projects are pretty unique, and they're all they all look the part that's like unclear to people is it all looks like a chatbox, like your interface to most all these tools right now generally right is a chatbox. And that looks the same whether you're talking to ChatGPT or you've built some virtual agronomist.Behind the scenes, the VII and the user experience for them are almost identical, which could be deceiving. That's what I was looking for. It's a very deceiving simplicity to the chat box UI, and I think that's why Chat GPT took off. Chat GPT obviously took off because it gave people access to these GPT tools that were already out there, and you could build your own bits around it. But a chat box UI just like sent that thing into the stratosphere because it was so easy to use for us. We're so used to messaging with someone and getting a response back. I mean, texted and whatever, and dealing with customer service and all these other kinds of simplified agents. I find the customer service one an interesting one. I can't tell you how many times I avoid a chat box on a website for customer service because it's going to be some dumb bot that just has a decision tree and usually has no idea what I'm talking about. But this now changes things, right? It can understand what I've asked, and I can recall to a previous ticket. These models can now go look that up. With Lang chain, you can build tools that can use APIs and go and access all this wealth of information and give the end user actually a great experience, a delightful experience, as opposed to a frustrating one.\n\nThose three documents you just linked to do not actually answer my question. I would love for the day when it actually gives me back one document, and it's exactly what I was looking for, but I've yet to see it happen on a standard customer service site. It'd be nice. I was thinking about a question. I'm trying to figure out how to word it, but you talked about the idea of prompt engineering and how it's an art form. Literally, people are joking that that's going to be the future job or whatever. What I wonder about with building a tool for a customer, because that's mainly what you guys do, is you're a consultancy, and you also build stuff and create things. But often, you have to figure out how to ask the right questions. I'm wondering about how do you do that for a customer? How do you train the customer to be a better prompt engineer? Are there guardrails that you can put in there, boxes in there, like the thing you just mentioned, like that you could ask if it was a chat tool, they could say, \"Are you coming back from a previous customer support thing? Okay, could you put in your ticket?\" And then it would load up your whole history, which would be awesome, you're right, because it sucks to repeat all that. There's a lot of opportunity, a lot of money still on the table, I think, for building these kinds of better tools and better experiences. It may be that people aren't the next. I don't know, maybe I'm just thinking about the future here. The everyone's building similar products, but the one that may win may actually be the one that has a better customer service experience because they actually can answer your questions, and you feel good about the experience as opposed to, \"Oh my gosh.\" I mean, when I can't the last time I've chatted with my bank's chatbot, it's just an agonizingly frustrating experience.\n\nI think that's true. I think this leads to a question that I was going to ask you already, this idea of asking the right questions. I feel like customer experience, how do you want this to feel for a customer? What do you want that experience to be like? Who is this for? Is this for this business leader for them to look cool and have this new toy that's out there, and they can announce it or whatever? Or are they trying to save time and make it easier for the agents? Or are we going to feed them to a secondary thing? There's all these kind of questions you need to kind of figure out to flowchart them into the right direction. Well knowing your audience, like you said, is it a CEO looking for an answer or is it a customer service agent looking for an answer or is it a consumer who's technically savvy looking for an answer versus one who's less savvy? I think we've all experienced this. There are some people in this world who are really good at using a search engine. Like there's some people whose Google fu is off the chart. You're like, \"How did you find that needle in the haystack when you're searching Google?\" And there's some people who are like, \"How did you not find it?\" Let me Google that for you was a great meme from back in the day because someone would be like, \"I can't find it.\"And you'd be like send them, let me Google that for you link because apparently your Google food is better. I think the prompts engineering is similar. There are some people who get a lot of value out of a chat GPT because they're really good at having that conversation. They really understand the thing on the other side. It's not a person on the other side, it's a system. The chat box understands me in a certain way. And if I can talk to it knowing who I'm talking to, even though it's a model, it likes specificity. It doesn't care if you're redundant. You can be over explicit. Like you can say, \"This is very, very, very, very, very important.\" The latest podcast I was listening to that Simon Wilson was on, he said he would regularly just tell the model to do better. He would ask a question and then he'd be like, \"Do better.\" Yeah, I saw one like that too. It answered something and the guy said, \"Well, I can't do this.\" And then the person just wrote back, \"Bro,\" and then it popped out the correct answer. Really, come on, you can do this. Give it a little encouragement. Make it feel okay. It's understanding exactly that. So I think some people are really good about that, and some people just have a hard time with it. It's a social skill, even though you're not talking to another human.\n\nThinking about if you were going to do this for another client, you have learned in this process. I see that this is a focus for Six Feet Up. You guys are looking at things to do in this domain. What are questions that you ask now of a new client that helps to narrow that stuff? How do you find to ask the right questions of what do I need to build for them and how to create it? Sometimes you also want to make sure do they even need this? Discovering Vector databases through this whole journey has opened our eyes to the fact that the vector databases themselves are really powerful. They may be able to get back really relevant results really fast. That was a really key bit. It's interesting. It's like a different form of relations in data. This weird interplay between rows and items. I find that really fascinating. I've had so many people say they are excited about vectors, and I always just kind of scratch my head. Now I'm seeing it with this technology, and I'm getting it. It took the right YouTube video to explain to me the whole Transformers bit. Now I'm like, \"Oh, there's a lot of power in here because it adds levels of understanding on proximities.\" It's not just a simple search anymore.\n\nSo that's where I start with, are we heading down the right path or just trying to apply technology for technology's sake? Does everything look like a nail if all we have is a hammer? Because that's not what we build. We build all kinds of crazy tools all over the place for all kinds of different people. It's also about understanding costs because you could spend a lot of money to solve the same problem and not get better results necessarily. If you were going to fine-tune a model as opposed to just using the rag technique, you can spend a lot of money and time on the fine-tuning and not really get better results. You may even get worse results because you don't have the capability of adjusting those context windows on the fly for new data that has entered the system. That makes sense. It's interesting, potentially leaving them with a bad taste in their mouth. It's not going to help your company at all. It's like you got one big win, a contract, but it doesn't set up stuff for the future.\n\nThere's a lot of people who know how to call an API, but not as many who know how to do all the trimmings around it and have the observability. Following the journey of a user and understanding what they want and getting the most out of the tools. One story that came up in the news recently that I just want to mention and I wonder if it gives you pause in suggesting things like this to a business is this Air Canada chatbot thing. I saw that. It's kind of a wild example.I think of ways that they could have avoided this problem, but generally if people aren't familiar with the situation. This person was traveling and it was a bement sort of situation. They asked the chatbot how to take advantage of a bement fare. The chatbot said they could travel now and ask for a refund later. This led to a whole lawsuit handled by the government. Air Canada's reaction was to stop using the chatbot, which seemed like a costly decision considering the initial investment.\n\nTheir initial reaction was that the chatbot was an independent entity acting on its own. However, they were the ones who told it what to do. The chatbot was trying to provide the next statistically probable response to the end-user. The policy to let someone travel and use a bement discount afterwards seemed reasonable, but the model pointed out that it didn't make sense.\n\nIt's concerning how unsophisticated users were using a sophisticated tool. The chatbot was trained on all the knowledge of the internet, leading to unpredictable responses. Other airlines may have different policies, but this one led to confusion and a negative perception.\n\nIt's essential to have human input in these processes to ensure the right responses. It's unfortunate that Air Canada's response was to shut down the chatbot. They should have taken responsibility for how it was used on their website.\n\nStaying up to date on these topics can be done through resources like podcasts and following experts like Simon. It's crucial to understand these technologies and their implications.He is just everyday experimenting with these tools, trying to break them in unique ways, showing fun and unique things. I forget to put a link to the last podcast he mentioned where he talked about doing it better. It was a really great episode because he explained the state of LLMS and generative AI. The prompt attacks have not been solved, and he is upfront about it not being a solved problem yet. He has given this talk a couple of times over the last year.\n\nI keep up with that and follow his blog and numerous podcasts. To keep myself on the paranoid side, I listen to the Dark Net Diaries podcast. While it's not specifically about LLMS or generative AI, it gives insight into how human brains can go off the rails.\n\nThere are a couple of newsletters I'm on, and I recently moved over to Omnivore for all my reading needs. It supports RSS feeds, and I can click and read articles later. It's nice to have everything in one place and organized.\n\nI also subscribe to the TLDR AI newsletter and the Tech Brew newsletter, both of which are interesting. It's hard to stay on top of all this information, but having resources like these newsletters helps.\n\nI like our angle here, providing listeners with projects to play with and linking out to resources. It's important to get hands-on experience with these tools to truly understand them. It's intriguing how much work is built into the libraries, and switching gears to become more of a data scientist is a different mode for many Python coders.\n\nI'm not a data scientist by background, so using tools like pandas can feel foreign to me. But I'm getting more comfortable with it and understanding how to manipulate data frames. It's really powerful, but not my default way of thinking.\n\nI'm excited about Python this year and looking forward to attending PyCon in Pittsburgh. It will be my 20th PyCon in a row, and I'm excited to see what new things are happening in the world of Python.I have a pretty good record, only missed one, the first one, but I wasn't doing Python yet 20 years ago. 21 years ago, I wasn't doing Python. So, I'm looking forward to Python. Are you presenting or doing anything? No, not this year. I was going to try to participate in the Packaging Summit happening there. I'll be bringing my 16-year-old to PyCon. He's really into hacking, making, and creating. He ported an app from nodejs to Django using chat GPT as his co-pilot. It's amazing to see what he can do at 16.\n\nHe got excited about coming to PyCon, which surprised me. I offered it not knowing if a 16-year-old would be interested in a professional Python conference. I'm excited about Python. There's so much cool stuff going on, like all the Lang chain stuff and infrastructure things. I'm also playing with the LLM library from Simon, which is really fun to use on a command line.\n\nI'm doing less coding on a day-to-day basis, but I'm still excited about learning. I want to play with synthesizers and start making music. My oldest son playing guitar inspired me. I also want to learn more about synths, sequencers, oscillators, and modulation. I found a tutorial app called Cantorial that's really interesting for learning about synthesizers.\n\nYou can follow me on Twitter as CalvinHP or on LinkedIn where I'll be posting more content. I also write for the 6up blog about once a month. One thing we've discussed is Indie Pie, and I'm involved in that. Feel free to connect with me on LinkedIn for more updates on my work.So I don't know if this will be out by then or not, but next week is our next hybrid event. We've been moving to a quarterly hybrid in-person and virtual event, and next week's is going to actually be related to the upcoming eclipse since it's coming over Indiana. We're in the direct path of the solar eclipse coming up, so we have a speaker who's going to talk about Python, the eclipse, astronomy, and physics. He's super passionate about that kind of stuff. When I first talked to him, his day job is not this stuff, but when he starts talking about astronomy and physics, you could just see him light up. So I thought, you need to come speak at indie pie.\n\nNext month, if this goes out afterwards, the recording will be up on YouTube from that session. So go to the indie pie YouTube channel, and you can pick up the recording for that. I haven't seen it yet, but I guarantee you it'll be a fun presentation. And then look for the next Q3 will be our next hybrid event. Feel free to sign up since we are trying to cater to people who can be in person and also online. We've been really good at trying to make sure that people online have a reasonable experience for our meetups because over the pandemic, we gained quite an audience. Your example that we were going to be sharing from today's episode, there's lots of questions you're grabbing from the people online. That was a recent one we did.\n\nWell Calvin, it's always great to talk to you. Thanks for coming on the show again. All right, talk to you soon. And don't forget this episode was brought to you by Mailtrap, an email delivery platform that developers love. Try it out for free at mailtrap.io. I want to thank Calvin Hendricks Parker for coming on the show again this week, and I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and look forward to talking to you soon.",
    "B38EGlWJyfY": "Welcome to the Real Python Podcast. This is episode 214. Do you need help making data tables in Python look interesting and attractive? How can you create beautiful, display-ready tables as easy as charts and graphs in Python? This week on the show, we speak with Rich Ioni and Michael Chow from Posit about the Great Tables Python Library. Michael and Rich discuss the design philosophy and history behind creating display tables. We dig into the grammar of tables, the background of the project, and an ingenious way to build a collection of examples for a library. We briefly cover how Rich and Michael started contributing to open source, and we also discuss practicing data skills with challenges and resources like Tidy Tuesday. \n\nThis episode is sponsored by Mailtrap, an email delivery platform that developers love. Try for free at mailtrap.com. Alright, let's get started. \n\n[Music]\n\nThe Real Python Podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at realpython.com. After the podcast, join us and learn real-world Python skills with the community of experts at Real Python. \n\nI'm excited today to have a couple people from Posit come and visit me. We've been doing a few additional data science focus things lately, and I'm excited to have Michael and Rich from Posit on the show today to talk about Great Tables. So, welcome to the show. Thank you. Thanks for having us. Yeah, awesome. \n\nOne of the things I've been trying to do lately is talk a little bit about how people got not necessarily involved in programming, but maybe how they got involved in open source, creating projects like this. Maybe we could start with you, Michael. Do you have a background in open source before working on Great Tables? Yeah, that's a great question. So I guess it all started in grad school. I did a degree in cognitive psychology, so I was using R a lot for research and Python a lot to do some neuroscience stuff. And I think that it sort of started maybe for like a lot of people with interacting with a lot of open source. \n\nAnd then, sort of as I went, I would say I built a lot of really bad open source tools that never really went somewhere. And then from there, I joined a company called DataCamp where I was able to actually put the tools out that we were using. And then I think from there, working on some other tools for open source. So, I worked on a tool for data wrangling called Subba, and I think that's where it kind of like I went from fledgling open source stuff to more kind of serious. \n\nOkay. I think it sort of started at grad school and then like crappy open source to more kind of reasonable tools. What were things that defined the change for you? Like you felt like you graduated when you started doing Subba. What was different about it? I think open source really helped in the beginning. It was more like learning that I was building open source stuff, and that let me kind of show my friends and try out putting things into the world. \n\nBut I think I needed more like professional experience with software engineering, and so it was kind of like over time it just got a little bit better until I felt a little more kind of ready to put stuff out. But I think it started with research and then interacting a lot with open source and then just doing a bad job a lot until it kind of started to feel okay to share with people. Yeah, get comfortable. That sounds good. \n\nAwesome. Rich, what was your background in open source? For me, it happened a bit after grad school, and it's wild. Like I started with R just because I heard R a lot. It was mentioned by people around me, \"He did this in R, she did this in R, you should learn R.\" Okay, fine. I'll get to learning R. And then, like, it was great. I started using it for work just after grad school. I got a real job. It made things automatable. \n\nThings I had to do on the daily were just a bit easier now. They developed some personal tooling. I was like, \"Wow, I'm going to just release the stuff on GitHub and see where it goes. Nobody's going to care, but eventually maybe some people cared.\" But I got into more general stuff after that instead of domain-specific things. And then I started interacting with people, and then I super caught the open source bug. \n\nLike after all that stuff was conspiring around me, the projects that were involved in that last section there where you felt like, \"I got the bug, and I really want to be in there.\" Yeah, when I sort of made more broad useful things, then people started to interact and make PRs and a lot of communication going. It just felt good. I just wanted to keep going with that. \n\nAnd so I even did more of that, so it kind of snowballed from basic timid personal projects to more generalized, accessible projects for everybody. Yeah, yeah.Do you feel like this is maybe for both of you an optimal way to get into open source, to dabble and try sending out requests to different projects or building your own? Do you have suggestions for people on the kind of path that might be easier to get into open source?\n\nWell, for me, it was pretty low pressure. It wasn't my actual job, so no one was telling me what to do. It was a personal thing, so it felt leisurely. In a weird way, I thought that was great. There's no pressure, no work pressure to do this stuff. It's totally optional, so that did the trick for me. How about you, Michael?\n\nYeah, I think for getting started, it's valuable to contribute through issues or PRs. Choosing an open source place and trying to be useful in whatever way you feel comfortable is good for everyone. When you stick around, open source people notice and are happy. Building relationships with maintainers by responding to issues or discussions is a nice way to get involved. It can lead to mentorship and new opportunities.\n\nDo you feel like it's helped your career as well, finding positions and such? Have you seen instances where contributing to open source has led to job opportunities?\n\nI've certainly seen it. Contributing to open source can eventually lead to getting a position because you become known and skilled. It also helps to build your profile and explain your contributions to potential employers. It can be harder to explain proprietary work, so having open source projects to showcase is beneficial.\n\nI brought you here to talk about Great Tables. I found the project interesting because tables can convey a lot of information effectively. What do you mean by the term \"display table\" and why did you choose that name for the project?\n\nDisplay table is a table meant for presentation, like one you'd see in a journal or sports analytics. It's different from data tables as it's not for manipulation and doesn't have excessive rows. It's a way to present detailed information in a visually appealing format, different from raw data frames. \"Display table\" fits the concept of presenting information in a structured and presentable manner.And it's trying to get the point across as quickly as possible. Exactly, it might be like a summary table, not raw data. So it's really distilled. You're trying to get something across pretty quickly, but you're doing it in table form. And you can still do that. You don't have to have a giant wall of numbers. You could make it more easily parsable. You could narrow down the scope, give it annotations, and things like that. \n\nThat's really what it is, taking the best parts of plots and putting them into tables. You mentioned briefly the idea that this might be something you'd see in a print form or a web form potentially. Since print, there's not as many magazines and newspapers as there used to be. But definitely those kinds of things that you would see this in. \n\nThere are so many features I definitely want to dig into. You mentioned some of them. You're trying to go beyond just a data frame, right? This idea of columns and rows and maybe headers. What were some of the things that you felt were missing as far as doing this job of being a display table or the components and things that you felt like definitely need to be there? \n\nI think it's tricky because when we're displaying it, when we're using a table as a visualization, what does it need? I think a lot of the really beautiful parts are information hierarchy, being able to drive attention to the right pieces at the right time. A plot often times have titles, and that's probably one of the biggest pieces of the information hierarchy. \n\nI think those really big structural elements are important because they break things up and make it easy to move your attention from big things to details. I think structure is one really huge piece of tables that's often missing, that kind of guides a viewer. \n\nI feel like these are skills maybe a higher order Excel person who is involved in making presentations would learn through creating sublevel headers and sections. In our space of data science, we typically aren't moving to a tool that does both of those jobs, that is communicating the information. It's just the tools to bin data frames. \n\nImplementing those things is not that hard because we have methods for all these little things. We try to accommodate a lot of stuff, but we need examples to show consistently. All these little things add up to a great presentation. If we show that enough, we drill to people like you can make really nice tables if you go the extra mile with these methods. Then I think the point gets across that these tables are really nice and I can do them. Here's an example, it's close to what I want.Some of the things that you've added that I think are really impressive are the coloring inside of cells of the table, like that Solar Zenith angles is just like a piece of art. I love that example. A lot of the sports ones definitely have the same kind of vibe, where you're having icons inside the columns and also having small bar graphs and things in there to blend tables and plots and graphs together. I feel like a lot of this stuff has been built for plotting for a long time in graphing libraries.\n\nWhy do you feel like there was the absence of that in tables? Were there other attempts at this before your exploration with Great Tables? That's a great question. There were almost two phases that I feel like this went through. One is what you might have mentioned Rich worked on an R library to do a lot of this, so he had a few years running up to working on Python of just exploring some of that space. Then in the Python space, some libraries had tried this, like plottable that works with matplotlib, eyetables that does some more simple interactive tables, and things like tabulate that's like a dead simple one function that puts out a simple markdown table. Richard worked on the more complex aspects, like creating labels on top of columns and things like that. \n\nIn the R space, there were lots of table packages, unlike Python. At the time we started building the R implementation in 2018, we had upwards of 10, maybe 12, in different stages of development. Some were abandoned, some were less cared for, but there was a lot there. We wanted to make something in the same spirit of something a little bit academic where you can replicate tables found in journals but go beyond that for the web.\n\nA lot of it came from different buckets of features like formatting, structuring, and styling. Structuring was tough because the way the R implementation and GT tables expect a table, it has to be close to the final form of how you are presenting the table. We want to give as much creative freedom as possible while balancing simplicity and power for the user.\n\nIt does feel that way as we were building this library, taking a progressive approach where each feature adds a little bit more and can be omitted without affecting much. There are a lot of similarities to this and other libraries. The R library is called GT, short for Grammar of Tables, which is important in the same way the grammar of graphics is important.Yeah, a little bit. It's a bit of a riff on that. Yeah, yeah, okay. I don't know, that's one thing that struck me with great tables and these tools is that it felt like the idea that there's a grammar for all the tables out there in the world trying to figure out the right kind of way to express them. Yeah, that's okay, that's like simple but also flexible and able to hit the different examples. But it's also worth noting GT GT was not available on PII when we began building great tables, so we had to have a discussion about what should this thing be named. So it's worth noting great tables is actually kind of a little rewriting of history from just renaming the acronym from grammar of tables to Great tables as a kind of good marketing too. Yeah, yeah, that's positive, you know, it's optimistic. You can make great tables with this, not adequate tables.\n\nThis episode is sponsored by Mailtrap, an email delivery platform that developers love, an email sending solution with industry-best analytics, SMTP, and email API along with SDK for major programming languages and 24/7 human support. Try it out for free at mailtrap.com.\n\nKind of going into that a little bit, you talk about this idea of the grammar of it. Was that a process then to like, you have this article which I think is really interesting, the design philosophy of great tables, and you have this historic research into tablets that have tablature layouts of stuff or where it all table forms. Is that something that you did at the time or kind of came up a little later to say, or was it kind of a mix of things like you as I'm doing my research, I kind of discovered some of this stuff? It's a mix. I mean, we went back, right, Michael? Like, UI, I mean, maybe you weren't there at the time with GT, to be honest, I have no idea how. So, I'm curious to hear from you, how do we get there? Good, we get Story. I mean, with GT, we looked at some old, we wanted to lay of the land, not even just like our packages, but stuff done before. It's remarkably hard to find any information, any books on tables. I think just taken for granted there's plots, yeah, sure, there's lots of stuff on plots and graphics, but not so much on tables. It's hard to find any writings on it. So we really had to research, and I mean, the hardest part is finding any writing on tables at all. I mean, there's like things like style guides you find in journals and they have recommendations, but nothing. We were lucky we found something. I'm not even sure how I found this. I think someone mentioned a long time ago, it's like this large work on tables from the Census Bureau. Oh, okay. And it's called The Manual of tabular presentation. You might have seen that maybe in the post. Yeah, it's in the post. Yeah, it's really cool. Yeah, 49. What a great year. Good year. But it's a great book, and it's available, it survives as a scanned PDF that if you just search it up, you can find it. And what a book. I mean, like it goes through nearly almost well over 250 pages of just table recommendations, what to do, what not to do. Yeah, and like, I mean, it's focused on census, it's basically a census table style guide, but it can be, it's useful everywhere, I think. I mean, some of the stuff in there, I mine ideas from that all the time, and like there's so much good stuff in there, and there's nothing else like it. There's no other like book on just like tables, like this is, these are the best ideas we have. So I think about the history of that because like, you know, that's the dawn of civilization of like, you know, okay, we're going to count the people partly so we can tax them, of course. Yeah, got that going. You know, and then like early forms of accounting, I'm guessing too, right? So, but, um, but yeah, it would make sense that when suddenly there's an organization of government that's going to count people that they would want to codify it or whatever into what they're creating. Basically, way back then, Mamia, city problems and like, you know, like trading issues. It's amazing when you look at those tablets, those like scans and drawings like recreations. They have all the features that we have now, like okay, like subrows and like headers and footnotes, like notes. It's like, you know, missing cells. It's like pretty wild actually. Yeah, yeah. Um, how much they got right. Yeah, yeah, totally. They, they, you're not seeing the things that were removed, you know, there's so many things that they got right at the beginning. So that's good. What are some of the favorite features you have you want to call out that are parts of great tables? What do you think, Michael? What are your favorite features? Good question. I honestly.I think some of my favorites are some Heavy Hitters worth mentioning like Nano plots where you can make a small bar plot or a line called a spark line in your table. These are really great because they balance the value of a plot like quick patterns with the compactness of tables. You can have lines indicating how something is doing over time. \n\nSome of my favorite parts have been the silly parts like the column spanners. This is like putting labels over your columns. When I started working with Rich, I realized I hadn't done a lot of styling before. In grad school, I was copying data out and using Excel or Microsoft Word to format. The concept of putting a label over your columns felt surprising and foreign to me, but I really love the idea of doing small basic things to make it better. People love it when we had a constrained feature with only one level of spanners. They wanted more. \n\nAesthetic stuff really jumps out to people. If you see a research paper with raw tables page after page and they aren't leading your eye, it's hard as a programmer or data scientist to understand what you want to draw attention to without design skills. Would this help them quickly get good results? \n\nMichael made a gallery for great tables, which is important to have good examples upfront to get your imagination going. The codes are right there if you want to see them. Examples try to impress people and show what's possible. I think what helped with the examples is that I am a table Barbarian. I didn't have years leading up to it, so it was like an explainer to me as a total novice to tables.\n\nStyling can go all out and do a full-color map, a neat way like heat maps in a different way, including the numbers and all that stuff. It's wild when you have a heat map, it turns the problem on its head. Great tables handle things like optimal contrast, which would be annoying to implement manually.\n\nI think it's a good example of our dynamic and how we work together. I approach the library like a software engineer, helping to build the guts. Bending over backward to help a user get the right contrast is not something I would typically do, but it's important in creating a user-friendly experience. The power is in your hands.But I really appreciate that, Rich. I think hitting the reality of maybe too much flexibility we might give people if we task them with that contrast. It might not be as nice, so I really appreciate the division of labor where I could put on an engineering hat and think about battening down the hatches. He's really bent over backwards to do the right thing out of the gate. It's been incredible. If I were to do the wrong thing, I might just say it's your job. So yeah, I really appreciate that dynamic.\n\nWas there a lot of thought that went into that, Rich? Like the IDE, is that what you can do but I want you to have a nice result by default? Certainly, you can escape out of that. There's an option to turn that off and you handle it. Like the text, we only touch it. Certainly, there have been revisions along the way in the AR implementation to make the contrast better. We started with something that was using the web standard, but there's an upcoming one called apca, which offers even better contrast. Certain color combinations where you just see it and you're like, \"That's not right.\" I mean, apca really handles it nicely. It's just an improvement over that. It's definitely something I've cared about a lot and kept up with because I think it's so important to make tables readable, no matter what you do.\n\nHaving lived through the 90s and the desktop publishing revolution happening, everybody could make a z and they put every single font in it possible, and you're like, \"Wow, that's really fascinating but pretty ugly.\" Early MySpace continues, right? It's like make it however you want. It's that kind of idea of having that balancing act of how much control should they have and then be able to turn it on and off. So that's cool. I wonder on the output side, how is this output like when you run that code? Is it output as a graphic or is it text? Basically, what we have right now is HTML as the main output. We also have a way to capture tables as images, PDFs, even in other image formats. In the future, we're going to work on other output formats like LaTeX, maybe even Word output tables that are XML friendly.\n\nIs that something you put at the end of the code to say to this format, or whatever? Exactly, yeah. We do have a hot issue where people really want interactive tables. I think in the name of display, we've gone hard on static, really getting it right for publication and printing. But people love interactive, like paginated or collapsible things. That's definitely a use case we don't want to ignore. Michael's doing some serious work on it.\n\nOne thing I thought you were going to hit at, Rich, was opening tables in the browser. I was surprised to learn about great tables. There's a lot behind tables in accessibility, like screen readers. The R packages has done some serious work on that in the past. I'm less familiar, but really interested in that. We collaborate regularly with a blind computer science professor at the University of Illinois. We did a lot of work on making tables accessible to screen readers, making tables as a true table element instead of divs, which may be less accessible in terms of screen readers, but maybe not. Maybe they solve that problem.But we got it so that in our collaboration, we received many recommendations for making tables screen mirror friendly. We introduced complexity like complex headers with spanners and row groups. You have to do a few things in the HTML code to make that not sound terrible to a screener, to orient itself. We followed those recommendations and the feedback we got in the end was that this is probably the most successful table package available in R. We took all that stuff and wrapped it into our outputs for great tables as well. It's a great example of learning a lot in a long development cycle and taking that distilled learning to hit the ground running in Python.\n\nWhen you talk about output being HTML, is it scalable to pull things horizontally or vertically while keeping everything in line? Yes, we have containers so you can scroll with tables and be flexible with embedding tables from great tables in different contexts like blogs. There aren't many dependencies for the package, we try to keep it low with only a lingering dependency on numpy which we aim to remove to allow for optional dependencies like pandas or polar.\n\nThe normal workflow for a python data scientist adding great tables to their project is simple. For polar's V1, the style property will return a great tables object making it easy for data frames. For pandas, you can call the GT class that wraps the data frame and use great tables methods to organize or highlight information. Polar has special functions and interfaces that work well with great tables, making it easy to select columns or apply styling using lazy expressions.\n\nWhether you use pandas or polar, all features are possible. Initially, great tables were geared towards pandas but as we rolled out polar support, we concentrated all data frame specific stuff into its own module for easy integration. Great tables is written in Python, although it's a fair question considering its origins in R. It's becoming increasingly popular in the current tech landscape.It definitely is. You had a few different conversations about it and it's interesting talking about the world of data lately. Definitely talking about what Wes is trying to do, this idea of decoupling things and not being so dependent on one another, which I think is great. I think that the less sort of religious examples that you have to buy into and be a member of is great because this is all just tools, absolutely when it comes down to it.\n\nThis week I want to shine a spotlight on another Real Python video course. It showcases a data visualization library with a similar approach to our discussion this week, building a grammar of Graphics. It covers the Python Library plot N9. The course is titled \"Graph Your Data with Python and ggplot\" and it's based on a Real Python tutorial by Miguel Garcia. Your video course instructor is previous guest and core team member Martin Bryce. He shows you how to install plot 9 and set up Jupyter notebooks, use plot 9 to create visualizations in an efficient and consistent way, and combine the different elements of the grammar of Graphics which involve several layers including a data layer, an Aesthetics layer, and geometric objects layer along with several additional techniques within the grammar of Graphics. You'll learn how to perform statistical transformations and implement a visual style with themes. You'll also learn how to export your data visualizations to files. Data visualization is a crucial step toward sharing your results and findings and I think this course will be a worthy investment of your time. \n\nReal Python video courses are broken into easily consuming mble sections and where needed include code examples for the techniques shown. All lessons have a transcript including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the search tool on Real Python.\n\nOne of the things I was wondering about with some of these really cool examples that you have shown are some of these ones that have to do with sports analytics, which I guess people would have normally maybe seen online or in a magazine or something like that. This idea of adding Graphics, is that a difficult thing to do inside these tables? It's not difficult for the user, I mean it's a little difficult for us to plan the API for that. We just had, I guess it relies on having the graphics on display or accessible through https and things like that and then referencing where these graphics are in a nice way. We did a few things to make it so you can use patterns and construct a template for a path. We have sizing options as well so graphics and tables are always going to be a little bit difficult because cells are small. Like, are the graphics going to stretch out your cells too much? Of course, you have that, but we at least have at the method level some ways to size things so I think it turned out great. I saw this example where it's sort of overlapping, almost like taking the top of one and overlapping it on the bottom of another, is that a feature of it? \n\nOh yeah, you can totally do that with some sort of like HTML trickery. If you're really good with CSS and stuff, you can make that happen with overflow attributes and things like that. I love seeing that stuff, whenever I see it I'm like wow, you really wanted something and you just made it happen. By default, it's not really available but you can make it happen and you get a density of information if you overlap things. It's great to see. We touched on this a little bit and I don't know if I got your favorite features Rich.\n\nMichael mentioned nanoplots, love it myself. I also just like, as a bag of features, like one collection formatting methods. I don't know why I love that so much, it's such a simple thing but it goes so far. Just a simple thing like formatting something to a static one or two decimal places, like numbers, okay, I mean that's wonderful. It's so simple but it can run deep, you can have things formatted to specific domains like financial stuff, exactly. So, it fits within expectations of that domain. I think it's great and I think there's so much you can do because it really just transforms data to another form which is more palatable for a table reader. I think it's really fitting in a theme like Excel came up, I feel like your love of formatters is your love of the ease of Excel when creating a table, like millions of ways to format things fast to apply.It's kind of nice that we're broken up into different methods, with each method optimized with a specific interface for the formatting task at hand. Instead of just using dot format, there's now a specialized syntax to make it happen. There's so much around specific types of formatting and additional arguments related to one or two types. I love that it's broken up, and while it could be overwhelming, we try to address that with better documentation.\n\nOne of the things you mentioned, Michael, is creating a great set of examples to get started. Are there examples you've wanted to add but haven't had the chance yet? Are there additional examples you want to show as new features are rolled out?\n\nI feel like there's a ton of examples we want to add. We just had the third table contest, or maybe it's the fourth. It's hard to keep track. We celebrate tables with prizes for submitting tables and code. People get excited about it, and the submissions are inspiring.\n\nI think there were around 60 submissions for the latest contest, and they're always so inspiring. People in the community make amazing tables that we might not have thought of. It's like video game designers making games that players excel at. It's fun to see how people use what we create.\n\nI have no idea what's happening with overlapping images and tables, but I love that someone did it. Players can create profiles with images that aren't covered or chopped off. It's like folder tabs, very cool. It's evidence that people are better at making tables than I am.\n\nWe'll probably pull some of these tables into examples, along with buttons, videos, and links. It's common but exciting to see what people come up with. We need a way to showcase these tables as examples for others to learn from.\n\nI think Cordo is a key player in creating great examples and a project website. Without Cordo, it wouldn't be as easy to showcase these examples. Cordo do is a tool I maintain for generating API documentation for Python, which powers our API reference tables.\n\nCordo is the real star, making it easy to produce interactive reports for data analysis. It goes beyond a standard notebook to create something more presentable but still interactive. It uses a format called qmd, a text-based setup with code and markdown. Great Tables documentation is built with Cordo.That's a neat thing you could create, like a single standalone report or a full-fledged website or slides pretty easily. The examples really benefit from that because we just pop the examples in line, get the actual table outputs, and put pros around them. Nicely formatted pros look nice. If people want to see examples of that, is that in your documentation itself? Yeah, it's on the Great Tables website.\n\nIf you go to c.org, you can see the range of sites that get built with Cordo. For example, I think Philip Clab from Ibis came on a while ago. It looked like we worked together, and their website is built with CTO now. CTO supports their API generation, but the really nice thing in open source is it's just a little bit easier to add examples with CTO. It's really made to run code and generate websites. You'll notice that the Great Tables website is filled with tons of code, and our guide has examples throughout.\n\nI think a lot of that is Cuto. It's just a little bit easier to write and have it all get generated. So again, a tool that's assisting you in this whole process. I do think it's funny in open source, lowering the barrier for executing code and having examples in your docs is surprisingly impactful. If you have a little bit of friction, you just don't like adding examples, right? One kind of nuts case is Great Tables doc strings. If you look in the methods, there are tons of really long examples, and the examples produce pretty rich outputs.\n\nIt's a little bit unusual if you look at tools like Pandas or Polars that are using Sphinx for documentation, or just the standard built-in Python DOC format where you use three greater than signs. The examples tend to be pretty short because you hardcode the outputs of your examples in your docstring to be able to do doctest on it. But that creates a funny cycle where now as you're writing docs, you have to create an example small enough to hardcode the output.\n\nIf you think of a table library, that's a bananas task force because you have to output a HL table. It's nice with Cuto; we're just executing large blocks of code, so we're able to give people pretty rich docstrings with nice long examples. That's been a really nice cycle to get into, but it's a small dynamic. Do I have to hardcode my outputs? It happens a lot in open source, but it's had a pretty big impact in how we approach docs and breaking things down.\n\nI can go maximal with examples, which is great. One of the things I do every other week is we talk about articles and stuff in the Python community, but we also look at projects. I want to run their stuff, you know? If I can't get through the docs, I can't set up stuff, I can't run an example. It's crucial to making it easier, especially if it's a single-person shop. That's a huge deal.\n\nI wanted to build on top of the contest thing. I feel like this is semi-related, and I haven't had anybody on to talk about it, but I wanted to talk about Tidy Tuesday a little bit. Is that right? We were talking right before we began, and you said that you have some experience and have been involved in it somewhat. Maybe you can tell a little bit about what it is and how you're involved with it. I heard about it a long time ago. I used to follow it, and it used to be a thing in R. We had a lot of social media activity on Twitter through the rstats hashtag and also the tidy hashtag. It used to be full of stuff, and my feed would just come, oh my God, filled with examples of Tidy Tuesday. It was wild to see that example overload, but it was always inspiring. I owe a lot of depth to Tidy Tuesday for seeing all this stuff. It's really inspiring.So I want to inspire people in my own works. The Spirit of TI Tuesday is wrapped up in GTA and great tables. We have lots of data sets. Recently, we had a PR at S. Michael with five or six new data sets. He's sure it's going in that direction. We are making a lot of examples, so we have a lot of data sets. TI Tuesday is all about data sets, making samples, being inspired, and having fun in the process.\n\nHave you played with it much, Michael? I use it a lot for mentorship, which has been really nice. Sometimes tutorials are too clear and clean, but for mentorship, it's really good. It shows the real-world aspect, where 80% of your time is preparing to start working with it. Tidy Tuesday is nice to see what will go wrong and what happens when you hit an error. It's been good for data science mentorship.\n\nThere's a great data scientist, Dave Robinson, who records himself analyzing Tidy Tuesday data in R once a week. It was inspirational for working on tools for data wrangling. Watching him work through analyses and code editing was helpful.\n\nThe data community's answer to challenges is Tidy Tuesday. It complements things like Advent of Code in a different way. It's about moving through the space and drawing out of it. Data analysis is about developing questions as you come toward the answer.\n\nTables have been a recent addition to Tidy Tuesday, showing the variety of outputs. What are you excited about in the world of Python? Polars is becoming a big force, with libraries implementing parallelism and integration. Marco Gelli's package, Narwhals, helps with creating the backend for incorporating frames into libraries. Integration and interoperability are exciting aspects for me.I think I think it's maybe two things. One is for sure narwhals, which is basically right polar's code and run it on a pandas data frame. I love that style of interface where you can think in one thing and have it work on another, because I think that our thoughts are the most important. Like the strategies and the things we've learned are the most important thing, I don't want to think about whether a method's called like mean or average. Across six libraries, I want to choose one library that I love and have an engineer work out the details because I think cognition is the hard part. \n\nThe other is I think plot n, the plotting library, is a Hidden Gem. It's one of those libraries where I think for some reason it gets overlooked often when looking at plotting libraries. But then when you talk to people, there's like this really zealous group of plot n Fanatics. I've been working with plot n's author Hassan, he's been working on this tool for probably nine years now and he himself is a fanatic. He's just dedicated to these very subtle plotting issues. \n\nI think in the same sense that we talked about color contrast, how Grate tables made it easy to, like, you should have white text on a dark background and you should switch it to dark text when it's a light background. I feel like Hassan has done a lot of the same things for plotting, like the ergonomic benefits. So, I'm working with him on writing a guide for plot N9 that we can put on the site to make it easier for people to get started and to kind of learn the basics. \n\nI'm really excited to work with him on that and to use documentation to try to really bring out the story of plot n because I think it's amazing to see the amount of time he's put into it. And as I talk to him, just the types of problems that he's saved me from but that I wouldn't appreciate because he did so well. It set you up for success that you didn't even know about. \n\nSo, I think those two, that was the library I was thinking of when I thought of in the Python world the grammar of Graphics is definitely there. And the idea that it's related to the sort of the grammar of tables that you guys are developing here, right? \n\nAwesome. So, Rich, what's something that you want to learn next? This doesn't have to be about programming, it could be anything, but what do you want to learn? \n\nOh, so many things. It's like if I enumerate all of them. I think I do want to learn programming. I mean, I mean not programming, I mean to be a better Python developer. I mean, like I'm doing it right now. Michael's been supremely patient as a mentor for me, coming from R for so long and switching to that. Sometimes I'm like, oh my God, sorry Michael, this is really bad poor show, but he's very patient. I just want to keep learning more Python. I mean, okay, I want to learn other things too. I want to do other things, but you know like, yeah, maybe play more bass and that's fun. So, play bass as you learn Python. Yeah, exactly, why not combine the two? But I think becoming a more proficient Python person would be great and would want to go down that road. \n\nAre there any specific tools or things you're thinking of using in that process? \n\nI'm thinking of taking a course and as well, you know, doing more open-source projects, maybe like a personal project as well. So, it's not like, you know, all like production stuff, it's kind of I can noodle a bit. So, part of it is just looking around and finding some nice new books. It's changed a lot Python, like quickly, pretty dramatically. I mean, I used it before in a job, but that was like 2.7 type of days, you know, like that sort of thing. 2.9, I think it was. So, I want to get more up to speed and maybe go a little bit deeper and cool. Give Michael a break, you'll have to send him the right like real Python tutorials, send him down that rabbit hole. Yeah, this that just makes sense. \n\nSo, Michael, what's something that you want to learn next? \n\nI've been going down this funny rabbit hole of documentation, like what makes documentation good. And I think in two ways, like if you look around at open-source tools, what are all the different approaches people take and what seems to work well and what seems to cause some challenges? I've noticed a little bit of variation in people's approaches. Like one of my favorites is that I think PanTIC and FastAPI, they chose not to document their API first. And that's surprising to me because I find most engineers are like, I've got to document my API, you know, I've got to document each function and class. They went the other way, they wrote user guides, and I find that a really inspiring move. \n\nSo, I've been thinking a lot about what adds up to really great documentation, the guides, the examples, okay stuff.Yeah, it sounds like the workflow also, like when in the process do I do this because if it's a stumbling block for a developer like H, I have to do this now. Whereas, maybe they'll find it easier to do the user thing first. Yeah, right, like it could actually shape the design of the tool event because if it's hard to explain in a guide, it could even be like the tool needs to be reworked a bit. So, I could see these things, right? I think on the side maybe, we had a friend recently invite us to harvest honey. So, he's a beekeeper and he was like, \"Do you want to harvest honey?\" 6 hours later, we're like, we've got several five-gallon buckets filled. We're dripping in honey everywhere. We had to power wash it off, but he was like, \"You too could keep bees.\" I think that maybe awakened something in us. Do you have a spot to do that? Our backyard's long enough that we could have a little bee zone. So yeah, I feel like something maybe was awakened in me. We'll see. That's cool. We'll see where that goes. I think my wife would love that. I think she's a double-edged sword. I think she thinks that they're fascinating but she's also a little terrified of them. So yeah, that's tough. They do have a weapon on there, but so I don't know. Yeah, exactly. Yeah, you got to be careful. That's cool.\n\nSo, what I wanted to leave with is how can people follow the work that you do online? We can maybe start with the project itself and then how people can follow yourselves individually. Well, I'm on LinkedIn, that's like okay, people are going there a lot. If people are still on Twitter or whatever it's called these days, we actually have a great tables account, okay, that would be the one to follow there. It's actually GT package, okay, I like it works in both cases though. I mean it was chosen a long time ago but it's pretty. I love our naming system, it totally works, it's back. So, that's the only way to do it. And of course, you know, great tables site which I'm hoping is searchable, yeah in whichever way you would search for that sort of thing, okay.\n\nHow about you, Michael, what do you think? I think, yeah, I'm really kind of huddled in on LinkedIn these days and where I guess great tables is also a pip install away, yeah, pip install great tables, yeah. Oh, we got Discord as well, oh yeah, we, yeah, if you just look the Remy great tables, we got some ways to get in touch with us. We really want to hear from people, so people get in our Discord, ask questions, introduce themselves, ask other people questions, great, it's a great sort of Q&A place if you want to go there, okay. I think it's fun. I will say too with the Discord and things like GitHub discussions, like I wouldn't hesitate to put anything there. We're like so curious about the experience of using great tables and okay, I think even if you feel like you have a silly question or issue, we learn a ton from every problem people hit, yeah, ask, it's probably something we overlooked realistically speaking, like sure. So, it's a big service, I think, whatever people even hit a problem or feel like something wasn't intuitive, we're super open to that, I think, I think it's a big service that people provide, great.\n\nWell, Michael, Rich, it's been fantastic to talk to you, thanks for coming on the show, yeah, thanks for having us, yo, thanks for having us. And don't forget this episode was brought to you by Mailtrap, an email delivery platform that developers love. Try it out for free at mailtrap.io. I want to thank Richard I only and Michael Chow for coming on the show this week and I want to thank you for listening to the Real Python Podcast. Make sure that you click that follow button in your podcast player and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. And while you're there, you can leave us a question or a topic idea. I've been your host Christopher Bailey and look forward to talking to you soon.",
    "tQ4wGZucom4": "Welcome to the Real Python podcast. This is episode 216. What hurdles must be cleared when starting in an international organization? How do you empower others and a community by sharing responsibilities? This week on the show, we speak with Jay Miller about Black Python Devs. Jay shares how the idea of forming a community began through attending conferences. They wanted to welcome more black developers into the Python community.\n\nWe discussed the introduction of Black Python Devs as part of their PyCon 2024 keynote presentation. Jay explains working with a few key people to build the group's foundations. They talk about the difficulty of letting other people share in the responsibilities and ownership as the membership grew. We also discuss the advantages of partnering with a nonprofit organization.\n\nThis episode is brought to you by Influx Data. InfluxDB is a purpose-built time series platform for ingesting, storing, and analyzing metrics, events, and logs with sub-second query responses and high interoperability. Start now at influxdata.com.\n\nAlright, let's get started.\n\nThe Real Python podcast is a weekly conversation about using Python in the real world. My name is Christopher Bailey, your host. Each week, we feature interviews with experts in the community and discussions about the topics, articles, and courses found at Real Python. After the podcast, join us and learn real-world Python skills with the community of experts at Real Python.\n\nHey Jay, how's it going?\n\nGood, it's been quite a while. We've been trying to get you on the show, so I'm very excited to have you here.\n\nYeah, this is like the dream. I've been following the work that you've been doing and I want to be on the show.\n\nNice. It was fun hanging out briefly at PyCon the last couple of times in Salt Lake City. I'm sorry I didn't make it this year. I heard I was missed, so absolutely. I was running around the expo hall being like, where's the Real Python booth? I need to talk to somebody.\n\nWell, I really want to try to get out there next year. It sounds like an amazing venue in an amazing city. I definitely want to check it out. I think there's going to be a cookout or something if Black Python Devs can get the paperwork inked. We're bringing a whole new vibe to PyCon.\n\nThat sounds like another level. Congratulations on your keynote. It turned out really great. Now that it's up on YouTube, everybody can check it out.\n\nThank you. This is the second keynote that I've done, and this one felt different. Anytime that you give between a Meetup talk and a conference talk, or a lightning talk to a regular talk, and then to go into a keynote, someone asked me how much did you prepare and how much of that preparation went out the window as soon as you got on stage? More than usual is the answer.\n\nI feel like it came together well. I definitely love the audiovisual elements. Anytime you can incorporate storytelling, it adds to the presentation. Shout out to Sam whose keynote was fantastic.\n\nI've not enjoyed sitting down and watching a presentation as much. It was easy to stick to the theme of building the Wakanda of the Python community. It writes itself. All the keynotes were great. Simon's was fantastic.\n\nI was super interested in the AI stuff at work sometimes. I was taking notes and thinking, \"Hey, we need to bring Simon to talk to us about stuff.\"\n\nI think this year's selection was top-notch. I've had to have her on the show. I'd like to have her come back and talk again. Simon is somebody I've been trying to figure out a direction for because it's such a wide topic that he's surveying in all the AI stuff.\n\nI think it would be interesting to talk to him about what the end goal is. I've had that conversation with him, so I know some of the secrets. It would be interesting to discuss.\n\nWe live in a world where people can do the inner world thing. In a world, exactly.Like, we're in a time and place now where everyone is looking at AI for a lot of reasons. Whether it's to make more money in their current job, to avoid being replaced by AI in their job, or to start up and get rich quick schemes. Some of the conversations I've had with Simon tie into the authenticity of a human being and his pursuit of knowledge for the greater and common good. The way he shares it is amazing.\n\nI think Simon coming on to talk about why he's doing what he's doing would be a fantastic conversation. Maybe that would be good. You mentioned briefly that you're in a new position since I've talked to you in person. Do you want to talk a little bit about what you're up to lately?\n\nI'm a Staff Developer Advocate at a European company called Ivan. Most folks on the US side will ask, \"Who is Ivan?\" Well, Ivan isn't a person, it's a company. Our goal is to be your trusted data and AI platform, focusing heavily on the data side. Ivan supports various databases and architectures, with employees actively contributing back to those projects.\n\nIvan is known in the European context and is growing in the US. We have some Healthy Growth happening, and our plan is to move into a more global position. My role falls under developer relations, acquisition, and growth, working alongside other professionals who are specific about what they do. It's cool to play an advocacy role alongside them.And really, you can lean on their expertise to make your content better, your presentations better, to make it fit the Academia Model a little bit better, make it better for presenting in a workshop format. Whereas, I'm just used to going on like \"What's up, it's your boy, like and subscribe,\" doing that whole thing.\n\nIn this case, you can get people to check out some of the stuff that you're doing and get suggestions and stuff like that. Absolutely, and the remixes of it are just fantastic. Like, I've made an open search with Python course and when I did it, they were like, \"Oh, I want to present it, but I want to present it from this angle.\" And I was like, \"Oh, I didn't even think about that.\" And then someone else was like, \"Oh, I want to write this for it, but I want to do it in Java.\" And I was like, \"Okay, well, what are the differences?\" So, we start diving in and honestly, there's a saying, like iron sharpens iron, so we're all kind of able to build up our skills by working together but coming at it from different angles. That's really neat.\n\nYou have this running joke of like nobody knows what devrel is, and I think that epitomized it there. What you're saying is that it can be so many different things, it can be documentation, it can be critiquing presentations, and so forth. It sounds like this is, I mean, when we first met in person at PyCon in 2022, you had just gotten that gig at Microsoft, which is a whole story in and of itself. Was that your first devrel job or was there something else before that?\n\nThat was my second. My first devrel role was at Elastic, the makers of Elasticsearch. Honestly, for me being a marketer, I played with a lot of data. I was using Python as the glue to make this cool thing using Python. I think that was my first conference talk, how to build a small business around podcasting and marketing using Python. Having come from Elastic, which is very Java-based, yet so many really awesome Python developers came out of that cohort of Elastic, like Seth Larson who's over the PII Developer in Residence. We worked together at Elastic. Some organizers for PyOhio were all at Elastic. There was this cool movement happening for Python developers at Elastic, and I think most of us have moved on to different things now.\n\nMicrosoft reached out to me and said, \"How would you like to write more Python in your day-to-day?\" I said, \"That sounds great.\" We set that up, and to be honest, I missed doing the data thing. Data is such a cool thing, and I always tell people, you have so much free data around you happening all the time, and you don't even notice it. You might not even be collecting any of it. Take the town you live in, go to Google, put in the name of your town and open data. Depending on the population, you'll have data requirements that the city has to collect, and all of it's usually free, open-source. You can do with it what you want.\n\nMost of my demos try to show off a company product or feature using localized data to inspire someone to go out and play with their own data sets for their city. I joined a local Meetup here, PySprings, and they did a demonstration of some of that open data stuff, which I thought was really cool. The first reaction most people have is, \"I can get my hands on that.\" It may not be in your favorite form, but a lot of CSVs, you might be cleaning it a little bit. It may not be the fastest connection, but it's very cool.I know from hanging out with you for a little bit at Pon especially in 2023 that you have lots of other creative pursuits like video, photography, and music. Does that help in your role, do you think? I think so in being a development person. I definitely think so. I have been told I do too much. I've been told by a lot of people I do too much, so maybe that's an indicator that I indeed do a lot.\n\nDo you mean like you do too many things or that you are able to do too many things that people ask you to do them for them? I think I volunteer too much information about my skill set from time to time, so they're like, \"Oh, well Jay could do this.\" Been there, yep, been there. You make a video and you make it really quick, and then all of a sudden they're like, \"Hey, how did you edit this?\" and you're like, \"Oh yeah, I have like Final Cut and like three other video editing softwares.\" And they're like, \"Right, hey, you're going to edit all of the video for our team now.\" And it's like, \"Oh no, what have I done?\" Yeah, I have been there.\n\nThe school I worked for, I was showing some videos I'd made for friends, and actually I had just really done the music, but the assumption was that I was involved in the project and obviously I then have the skills to make the entire video. I do think that there's some knowledge that goes with that too, like I knew about Epidemic Sound and people like Epidemic Sound. \"What's that?\" Like, \"Oh, it's a way that you can license music for your videos, and if you don't want that, there's like three other services that you can pick from.\" So you're an expert. I mean, that's so funny about it.\n\nBut it's really cool that you're able to kind of go, \"Oh, this thing that I would kind of do in my spare time or this thing that I would do just as a, it felt cool at the moment, like recording the interviews that we did last year at Pon especially in 2023.\" Like, no one asked me to do that, I just had all my video stuff with me because we were doing stuff at the Microsoft Booth. And I was just like, \"What if I just started interviewing people from different perspectives at Pyon us?\" And then, yeah, we did it and then we recorded some of the folks for Microsoft, so then I was like, \"Well, now I've justified it for work, now let me go run off and do the other fun stuff.\" And then we did the same thing at Jen Con, and then this year Jen Con was like, \"Hey, are you doing that thing?\" And I was like, \"Let's talk about finding a producer and like three other people that can do this that are not named Jay Miller.\"\n\nYeah, you are definitely being three or four people at a time. But when you do that, even if it's, I tell people in Black Python Devs all the time, it doesn't have to be perfect. It barely has to be good. If you do it and you just show that there's an interest and there's something there, you'll develop that muscle over time. It's almost like podcasting. I mean, right? I mean, I can see you, you can see me, we're both talking with the professional headphones on plugged into an audio interface and all that stuff. But at the end of the day, most people start with the headphones they got from their phone, right? Or they start with the $50 Blue Snowball or the $9 Blue Yeti. And there's only so much processing that you can do to change that. But honestly, my first podcast ran for seven years, and at one point, it was doing numbers or whatever, and we were looking at getting sponsors, it was bringing in a little bit of money. But once I got to a podcast network, a lot of it was a springboard off of all that experimentation, off of all the like, \"Hey, I'm going to start a podcast where me and three other developers talk about anime that we only get through one anime and it does seven episodes and flops.\" But at the same time, I learned how to record a podcast with three people on it, and I learned the process of editing, I learned about the pacing of doing that, I learned how much planning is required.\n\nSo sometimes it's not a matter of, \"Did I build the million-dollar startup with my Hello World app?\" No, but what did I pull from that that I can apply maybe at a job and go, \"Oh yeah, I learned how to do this when I was messing around with some little project.\" If you want to mention that, that first podcast was that a tech type of thing or what was that?Oh wow, the first podcast that I did was called \"Productivity in Tech.\" I think it's still around. You've always kind of had that bent a little bit, huh? Oh yeah, I'm a Marine Corps veteran. I got out of the Marine Corps and started working. Most military personnel join the military when they're like 18 years old. I joined when I was 19. So, I spent a year on my own and then joined the Marine Corps. You don't really have a good sense of how to work in a corporate job or with a dress code. You've been told exactly what to do for all of your adulthood.\n\nFor me, learning about tips like the Eisenhower Priority Matrix was crucial. I had to figure this out or I was going to lose my job. I approached it not as an expert but as someone eager to learn. My second interview was with someone who now runs a productivity YouTube channel with almost a million subscribers. Over time, I learned that none of us know what we're doing. We're figuring it out as we go along, adapting to challenges.\n\nProductivity is like having a plan, getting punched in the face by a deadline, and then having to dance around it like Muhammad Ali. My podcast, Conduit, took all the lessons I learned and made it more fun. It's more of a hangout where we invite the community to join. Through our podcast, we've seen a book written, weddings happening, and career changes.\n\nWe focus on connections, taking it two weeks at a time. We hold ourselves accountable and give ourselves permission to not always succeed. Writing things down is crucial for accountability. Many times, I've done something last minute because the episode was due the next day. Productivity for me has been a lifelong journey since high school. Getting everything done is essential.Developers love InfluxDB because it excels in real-time performance for time series data offering subsecond query responses and a scalable architecture. It separates storage and compute using cost-effective Apache Parquet files to slash storage costs significantly. Its open architecture allows direct access to data for analytics, business intelligence, and machine learning, eliminating complex ETL needs. Learn more at influxdata.com.\n\nI'm super excited to talk to you about what you were discussing at PyCon about Black Python developers. Maybe we can start with the origin story of how you started to develop this group. My first PyCon was in 2022. I had wanted to go to some before, but then 2020 happened, so that threw a wrench in the plans. As a Black male going to a Python conference, there might be only one other Black person that you see. The goal is to find that person who looks like me. My keynote breaks down the identity of Blackness and how people see it as part of their overall identity. It's cool to see folks like Cojo Adresa and Don Wages at these events. But I started noticing that was all I saw, just Cojo, Don, and myself. I would see images of conferences with a super diverse group of folks, inviting people to join, so there was a bit of a disconnect. At PyCon 2022, I counted how many Black folks I saw, and there were 12 out of 2000 attendees. I started asking everyone I bumped into why they were there, and many were either looking for a job or had received an Opportunity Grant. They were there for a transaction, not because the Python community is friendly. I wanted to change that. I wanted to increase the participation of Black folks at these events. I worked hard the next year to get more people there, to be open about it, and to help others with their talks. We tripled the number of Black attendees to over 30 out of 200, which was better.But we thought we could do even more. More importantly, when the community got behind it and said, \"Let's all work together to make this a reality,\" we started to see an impact and a change. We did an open space, had great conversations, and had a good time. Immediately after, I created a Discord called Black Python Devs. At first, there were only 10 people, but we slowly grew to 50 or 60 at DjangoCon US.\n\nIt was an interesting turning point, located near historic colleges. The interesting part was that communities from Africa heard about what we were doing for the first time at DjangoCon. Communities from five or six countries were represented, sitting at a table and talking about our individual communities and what we could learn from each other.\n\nWe promised to try our best, and over the weekend, we gained 40 new members, sparking interest in different communities. We now have 600+ members, showing what can happen when everyone in the community wants the same thing: safety, accessibility, and equity.\n\nWe approach things with those three principles in mind, finding creative ways to sponsor events and support the community. We bought 75 student tickets for DjangoCon Nigeria and are working on other innovative sponsorships for future events. One idea is to bring books overseas for communities in need, a challenging but rewarding endeavor.\n\nApproaching publishers for support could be beneficial for such projects. It's always a challenge, but it's worth it for the impact it can have. Abigail dugby.Okay, there is a nonprofit that I forgot the name of, I think it's like Books for Africa. Our plan was to support what she was already doing. Most of the people in leadership positions here have been in the community and they've been trying. It's like a collective effort when a community focuses on projects or brings attention. For example, this week there's a workshop in Zimbabwe for people new to Python. Not everyone wants to make a blog, and there will be different concerns and stories in Harare. We need to consider different perspectives.\n\nThere was an episode about assumptions in tech entrepreneurship. The perceptions don't always match reality, and infrastructure needs to be considered. Our sponsorship in Nigeria just went through last week. We had Nigerians telling their stories and designed their own shirts, emphasizing community involvement.\n\nThe recent challenge is funding the sponsorship. Running a nonprofit is different from a Meetup and involves a lot of legalities. Finding a fiscal host is a shortcut, and the Linux Community Foundation offered to support us without much involvement. They appreciated what we were doing and didn't require us to meet specific criteria or use their logo.Exactly, it was purely just like we want to support what you're doing in any way that we can. So, yeah, we go through those negotiations. Of course, it costs them money to support you, so then you have to set up, like, they got to take a percentage of that, which makes sense. And that's funny enough, people are so disturbed by that. I was like every Python Community I know that is under some fiscal host has that exact same deal. And honestly, it makes things so much easier. You don't want to hire a lawyer, you don't want to, yeah, exactly, get those people. And I mean, at Pon us, we were able to raise $21,000 in four days, and a lot of that was because we had the infrastructure in place to make it relatively easy. I mean, granted, we crashed that infrastructure because people were so eager. People were like it's not working, and I was like try it again. Like, oh, it worked this time. So the people were trying to hit that QR code. Exactly, so I mean those are good problems to have, right? Yeah, we're too popular. But yeah, like just having this backer, you know, in The Gnome Foundation behind us, allowing us to at least know that we can operate, we can collect money, we can reach out and find grants, and that ecosystem is full of opportunities of ways to make sure that we're doing as much as we can outside of our own financial limitations, which is super fantastic. That's cool.\n\nOne of the things I was thinking about before we started to talk was like, what would be some of the big hurdles that you would have, and we've mentioned a few of them. But I'm wondering if there are some that we haven't hit yet that were some of the biggest hurdles there of starting this. The biggest one is just understanding, I think we talked about kind of like understanding the geopolitical landscape of doing things. Sure, our bank doesn't send money to Nigeria, Africa is an interesting set of contrast or whatever you want to call it. So many countries and so many different relationships with governmental agencies and whatever. Oh my gosh, and it can change with one election. You know, we're looking at the situation happening in Kenya with the reject finance bill campaign that was going through. We were looking at some of the things now in Nier, there's a couple of countries around that area that are kind of forming this Alliance thing. And anytime we do that, like we're immediately like let me go to the sanctions list and just verify whether or not we can actually give money to this organization or this program. And really just figuring out sometimes the logistic nature of it, of hey luckily Pon Nigeria, some of the organizers are actually based out of Canada, and a lot of their funds were collected in Canada. So we were able to, okay, we can't send to Nigeria, but we can send to Canada, that works. And figuring out like okay, what are we within the boundaries of doing, what are we capable of doing, like make sure we're not breaking any laws, make sure we're not doing anything that's going to cause any trouble. But I mean the other one is just you've got to be very volunteer heavy. I think one of the things that I probably should have done better at the beginning is say no to more things. Okay, so many people were so excited and so eager just as an individual or as a decision maker. I think a lot of it is we want to move at the pace of all the other things. And it becomes incredibly hard to do that when you're sponsoring three or four events at the same time, you want to start an open-source initiative. I'm giving out teasers for things that are coming up. You're launching a book club, you're debating throwing your own conference, you're doing all these different things. And these are possibilities, yes, and you have like five people that are like really eager to do all of those things. And then everybody gets burned out, and it doesn't work. So we've kind of talked about it, and now the way that we approach things is the first step is like who's responsible for this. And there is a very real like if you're responsible for too many things, you, we just have to go, raise your hand. No, you can't, you can't, you got to put your hand down, you're not allowed to volunteer for this. Or you have to give up some of those other things that you're doing and put someone else in charge. And that's cool they have people looking out for each other in that way. And as we've done that, it's been good.I mean it really has been beneficial because one it opens doors. I think a lot of folks in our community see the same faces volunteering, running for boards, and taking initiatives. For a while, we've just become so used to always having to be the person that volunteers because if we don't, who else will speak for the people in our communities? \n\nNow that we are all in the same Community, there is like this, those same people still raising their hands, and we're like why don't we give someone else an opportunity to step up and Lead this thing. Maybe wouldn't you like that? Yeah, there wasn't so much for you to do. I guess it depends on the person's personality, but you'd be surprised how hard it was to be like, \"I'm not going to get involved in this.\" \n\nYou're just so used to doing it, and right, you know if something goes wrong, you're like, \"Ah, see I should have just done the whole thing.\" It's like, no, let them find their footing. We've given so many people the opportunity to step into a leadership position and just be like, \"You don't believe that you're capable of handling all of our sponsorship coordination for the entire continent of Africa. But I think you can do it.\" \n\nAnd then those people just be like, \"Wow, can I put that on my resume?\" And it's like, you sure can, like, go right ahead, like conference coordinator for the entire continent, that sounds amazing. And it's all because I was like, \"I can't do this, it's not going to be me, like I don't have the connections and knowledge.\" Yeah, or the time.\n\nThis week, I want to shine a spotlight on another real python video course. Many websites make their data accessible to third-party Applications through an application programming interface or API. One of the most popular ways to build APIs is the REST architecture style. Python provides some really great tools not only to get data from REST APIs but to build your own Python REST APIs. \n\nThis course is titled \"Interacting with REST APIs and Python.\" It's based on a real Python tutorial by Jason Van Scelt, and your video course instructor is Darren Jones. He'll take you through what REST architecture is, how REST APIs provide access to web data, how to consume data from REST APIs using the requests Library, what are the first steps of building a REST API, and he takes you through working with specific Python tools and the fundamentals of building REST APIs in Flask, Django REST framework, and FastAPI. \n\nReal Python video courses are broken into easily consumable sections and, where needed, include code examples for the technique shown. All lessons have a transcript, including closed captions. Check out the video course, you can find a link in the show notes or you can find it using the enhanced search tool on Real Python.\n\nMaybe this is related to that, but what's something that you wish you knew before you started on this whole journey? How to write grants, that's still a thing that I wish I have. Have you found good resources on any of that? No, and if anyone had, this is me reaching out to the Python Community, call out if you are a grant writer or if you want to point us to some amazing grant writers or even show us how to find and source these grand opportunities. This is a big barrier for us, like, hey, we know that the opportunity and the funding is out there, but is there a website I can go to? Is there like a course I can take? Also, if you have a time machine and you can pause time and give me the ability to do all that stuff, that would be great because your feet are still moving.\n\nI think the other thing I kind of wish I knew was I wish I was a better documentarian. We have a documentation team now, that was one of those things that we were really bad at, like writing down the stuff that we're doing. So let's just get people who want to be technical writers. Is that for your own history, for teaching other members of the team, for sharing your progress, or is it all those things, all of those things, including just like we have this Streamlit application that we want so that people can have a nice little presentation up at a booth so that we're not recreating the will. \n\nBut how do you document that? How do you write the how-to on how to set that up? How do you configure your environment? There is some technical documentation writing, but there is also policy writing, and a lot of it is like, \"Hey Jay, what do you think about this?\" I like, \"Well, I think that this and this and this.\" Oh, Jay's the boss, okay, let's document that so that when it backfires, we can all look at Jay and be like, \"This is what you said.\" \n\nIt's been great, and as we do that, I feel like we're still kind of chasing ourselves on that.Hey, we said that we were going to do this and is it written down anywhere?\nNo? Okay, let's get it written down so someone can hold our feet to the fire when we try to do something other than that. Do you have an idea of how you would gather all that, like where would you post it all or whatever?\nWe're being extremely low tech, just using GitHub. Lots of text files can go inside GitHub. We wanted our entire mission to be open source by default, so as long as we're not sharing personal information, everything is usually available. You just have to ask for it or go onto the GitHub repo and find it.\nI wonder if you could see other organizations that have done something similar. You can look at what they've done. We cribbed that idea from what P Ladies, Django Girls, and Women Who Code were doing. We wanted to see if it would work for us.\nIn the keynote, I mentioned the Southeast Asian Community, a community that we don't have a lot of membership from, but we learned that some of the issues they had were similar to ours. We worked with them to see what they were doing and how they were doing it, and if it was documented somewhere for us to learn from.\nWe also want to reciprocate that and say, \"Here's what we're doing, and we have it written down. You can look at it and take the things that work for you.\"\nWhat would you say is your latest win, the thing you're proud of at the moment?\nJust seeing the confidence of the community growing and expanding outside of the echo chamber we were afraid of becoming. One small win was meeting a group of Nigerian folks in New York and seeing their excitement about our community's support, not just in the US but also back home.\nIt's important because their visas can be revoked, limiting their capabilities and forcing them to leave the country within 24 hours. Being able to provide resources and support no matter where they are is a huge win for us.\nIt's like handing them a golden ticket to join the community, but warning them not to volunteer for everything because then they'll be responsible for the entire continent.\nOne interesting aspect we're exploring is not just expanding diversity in Python, but also helping people prepare for jobs and roles.And maybe this is another shout out or call out to the audience for support. Like the job market right now is weird. I don't have a better word for it because it's not that there aren't jobs, it's just recruiters, even recruiters in the Python space, were talking about a job opening and then the next day you have 2,000 AI-generated applications submitted. But then they're also using AI to filter out all of those applications, so who knows what's happening there. \n\nYou have these moments and I always get excited when I see someone that says, \"Hey, there's a new job and it's remote anywhere,\" and I look and it goes remote anywhere in the US, or remote anywhere in US in Europe. A lot of folks are just like, I don't know if people understand how expensive it is to go through the H1B Visa process or if you're traveling on a student visa, you're not allowed to work or look for work. \n\nExactly, there's a lot on the ground there, and folks are asking me, so now my goal is now that we're on the ground in some of those places, like how do we talk to local businesses, how do we talk to local industries that need developers and say, \"Here's someone that lives down the street from you.\" \n\nI tell people to stop looking at tech companies. My first use of Python was to automate a marketing process that was supposed to take me six months to a year to do, and I got it done in a day thanks to the power of Python. Hospitals are looking for developers, colleges are looking for developers, and there are government jobs that are looking for developers with great benefits. How do we work as an organization to show those companies how to effectively hire for those roles? \n\nI always tell people if you feel like Black Python Devs is a place where you can see people like yourselves, consider joining. You can go to blackpythond devs.com if you are interested in helping support Black Python Devs. You can set up a one-time or recurring donation of any amount that you want. If you have any questions on how to do any of that stuff, you can email me at leadership at blackpythond dev.com. If you're not in a financial position to help, we're always looking for people to say, \"Hey, I have a couple of hours, I'll review someone's code or host a meetup.\"I'm happy to talk to someone. One of the fun things that we're really doing just came out as we're recording this. We're going to be sponsoring Pi Ohio for the next few years, which is nice. Part of that sponsorship includes a monetary aspect, but also how do we connect the Pi Ohio team with local black leaders in Tech in the Ohio area? How do we get them involved to learn what this community needs and what they are looking for? We've done similar things with the PSF and the DSF by providing them with lists of historically black colleges and universities in the area. If you have an organization and want to make what you're doing more approachable, equitable, accessible, and safer for black Python developers, you can reach out to us at leadership@blackpythondevs.com. Let us know what you're doing and what you'd like to see us do. One thing we'll do is identify leaders in your area and connect you with them to work one-on-one.\n\nI have weekly questions I like to ask everybody. What's something you're excited about in the world of Python right now? The PII stuff is really interesting. I have around 20 Python packages wrapped around the static site generator I built for myself to learn Python. I also have other packages I've used as a developer advocate in the Python space. I received emails about two-factor authentication and proper ways to publish to PII through GitHub using their credential system. I'm excited about packaging in the Python space and how it's becoming easier to teach and implement. GitHub repos are free, so why not make stuff and put it out there responsibly?\n\nI'm excited about the work my former colleague Seth Larsson has been doing on the security side. The ES Bomb stuff coming out of that is fascinating. Anything that shakes up what we're doing as a community and a language is super interesting. Every time I see someone hired in the Python community, it's a mini celebration. I was worried about a downturn or pivot in the industry affecting contributions to Python, but it seems the tap is still on, which is great. Companies like Nvidia and Microsoft are making commitments to Python development, recognizing its importance.\n\nI think Python is in a good spot, especially with companies like Nvidia and Microsoft investing in it. People like the faster CPython team are doing great work. How do you stay motivated to keep learning Python? For me, it's not just about learning more Python, but also about doing more things with Python.Okay, more projects, creations, and things, yeah. This move to Ivan as a company, like, I'm working with databases that I've never used before. Some of them don't have SDKs, you know, some of them don't have a Python module. Luckily, most of them do, or they are like a third-party thing. Anytime I see that, it's like an opportunity to contribute. Just being able to jump in and go like, \"Hey, let's figure out how we can better document this Python thing, or let's write some tests for it.\" I've noticed I've been calling myself now more of a developer experience type thing. Sure, how do we get things like Dev containers or code spaces? How do we update contributing docs to make it easier for anybody to come in and just submit a drive-by PR? Done responsibly, they are always welcome. But like, right, you notice a little typo, you shouldn't have to download the entire SDK to fix the typo and then submit it. Do five layers of packaging onto it. How do we just make those things? A lot of it for me is like, as soon as someone tells me to do something and it doesn't involve Python, I'm like, \"Well, how do I do this in Python?\" And then it evolves into learning about things like abstract-based classes and these things that I've never had a use for. But now I'm like, \"Oh, this is cool. Like, I can do this, or I can play around with typing, or I can use this module, and it's going to make it more approachable to people who aren't Python developers, or it's going to make it a little bit easier for developer advocates. I'm a big fan of something like Streamlit, where I'm not a front-end developer at all, but I know that with Streamlit, I can just write Python code and get a really pretty demo. Just teaching developer advocates about that kind of stuff, that's the thing that makes me want to learn more. How do you write Rock, Paper, Scissors in six lines of code, right? You know, should you write Rock, Paper, Scissors in six lines of code? Exactly, yeah. So what's something that you want to learn next? This doesn't have to be about programming. Could be. Oh man, I kind of mentioned the understanding how grants work thing. That's probably the business. I hope somebody hears this and has some information for you. So I would love for someone to email me and be like, \"I'm a grant writer that uses Python.\" Yes, yeah, yeah. I've gotten into plants lately. It's kind of weird. Pandemic here. I'm showing off some of my plants that I got. I actually got them earlier this year. This is my little one that's growing off. I'm trying to grow. This is my wife's suggested ones. And they do the reach out kind of thing. Yeah, they're trying to land and they're like, \"Okay, put it in a thing of water, wait for it to get some roots.\" But yeah, I mean, you mentioned it before. I'm so interested in so many little things. Like, I love doing short form video, but I kind of love the editing process because we're in a space where, like, dating myself prior to YouTube, you know, so yeah, we learned how to do the YouTube thing, and then we learned how to do the social media thing, then we learned how, like, there's going to be a generation of people that are just like the TikTok or the short Instagram reels. The short form video is, yeah, those tools are kind of wild. But how do you teach people Python with that? How do you reach a community of folks with short form video? It's a mystery, it's a challenge. And, you know, that's something that I keep threatening. I threatened Marotta. I was like, if you put me on stage and I get to do the gritty or some TikTok dance on stage, I'm going to own it. But yeah, just learning about new, not even new technology, but new ways of reaching the next generation of Python developers, because I think that if I tell people you got to do it this way, then I'm just perpetuating the same problem that I'm trying to fight against. Yeah, there's a lot of that, you know. That's one of my issues. We didn't get into it, but I had a problem with academia. You too, huh? Yeah, it just didn't work out. That's what I tell people. I was like, yeah, you know, college was great for the whole six weeks that I was there. Yeah, I made it a year and a half, and then yeah, I was just like, this isn't working out for me. I was infatuated with doing music at the time. So.Yeah, so it's all worked out. How can people follow the work that you do online? I would guess there would be a few ways. Yeah, there's so much. I'll throw out my personal site first. Okay, that's KJMiller.com. It's very archaic, but I do my best to share what I'm doing on there. I have a microblog there that also feeds out to Mastodon and that whole thing. If you want to follow me on LinkedIn, I'm Jay Miller. I try to keep everything consistent, so if you see one photo, just look for that photo everywhere, including my website. Take the photo that's on my website and go find that photo on the internet. Jay Miller is pretty common, but yeah, I'm on all things that I'm on at KJ Miller. I'm always creating a new GitHub repo, so if you follow me on GitHub, you'll see what I'm interested in based on the repo that has nothing in it, just like how to do this with Python. So, yeah, you can see me working in live code there.\n\nWould you say render engines are your big project? When I have time for it, which I will say there's a lot of, render engine is one of those things that I should probably talk more about. At the same time, it really is just a project for me to learn Python and package maintenance. It runs my website and almost all the other websites that I'm a part of. I've actually had a few people who are maintainers and contributors, so that's cool. I've got a few contributors, and that's like the coolest thing ever. Let me first and foremost apologize for this horrible code that I wrote, but also learning and letting people share ideas and growing as a developer through there. That's cool.\n\nWell, Jay, I really want to thank you for coming on the show. It's been fantastic to talk to you. I'm so happy we could finally make this happen. Maybe we'll go three more PyCons before I can make it back. I don't think we should do that. I like it. We should make it a little sooner than that. And don't forget for your time series needs, use InfluxDB. It's trusted by leading companies for its scalability, real-time performance, and easy integration with modern data stacks. Start for free at influxdata.com.\n\nI want to thank Jay Miller for coming on the show this week, and I want to thank you for listening to the Real Python Podcast. Make sure you click that follow button in your podcast player, and if you see a subscribe button somewhere, remember that the Real Python Podcast is free. If you like the show, please leave us a review. You can find show notes with links to all the topics we spoke about inside your podcast player or at realpython.com/podcast. While you're there, you can leave us a question or a topic idea. I've been your host, Christopher Bailey, and I look forward to talking to you soon."
}